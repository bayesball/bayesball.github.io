[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Modeling",
    "section": "",
    "text": "This is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "proportion.html",
    "href": "proportion.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "mean.html",
    "href": "mean.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "proportion.html#introduction-thinking-about-a-proportion-subjectively",
    "href": "proportion.html#introduction-thinking-about-a-proportion-subjectively",
    "title": "1  Learning About a Binomial Probability",
    "section": "1.1 Introduction: Thinking About a Proportion Subjectively",
    "text": "1.1 Introduction: Thinking About a Proportion Subjectively\nIn previous chapters, we have seen many examples involving drawing color balls from a box. In those examples, we are given the numbers of balls of various colors in the box, and we consider questions related to calculating probabilities. For example, there are 40 white and 20 red balls in a box. If you draw two balls at random, what is the probability that both balls are white?\nHere we consider a new scenario where we do not know the proportions of color balls in the box. That is, in the previous example, we only know that there are two kinds of color balls in the box, but we don’t know 40 out of 60 of the balls are white (proportion of white = \\(2/3\\)) and 20 out of the 60 of the balls are red (proportion of red = \\(1/3\\)). How can we learn about the proportions of white and red balls? Since counting 60 balls can be tedious, how can we infer those proportions by drawing a sample of balls out of the box and observe the colors of balls in the sample? This becomes an inference question, because we are trying to infer the proportion \\(p\\) of the population, based on a sample from the population.\nLet’s continue discussing the scenario where we are told that there are 60 balls in total in a box, and the balls are either white or red. We do not know the count of balls of each of the two colors. We are given the opportunity to take a random sample of 10 balls out of these 60 balls. We are interested in the quantity \\(p\\), the proportion of red balls in the 60 balls. How can we infer \\(p\\), the proportion of red balls in the population (i.e. the 60 balls), based on the numbers of red and white balls we observe in the sample (i.e. the 10 balls)?\nProportions are like probabilities. Recall in Chapter 1 three views of a probability were discussed. We briefly review them here, and state the specific requirements to obtain each view.\n\nThe classical view: one needs to write down the sample space where each outcome is equally likely.\nThe frequency view: one needs to repeat the random experiments many times under identical conditions.\nThe subjective view: one needs to express one’s opinion about the likelihood of a one-time event.\n\nThe classical view does not seem to work here, because we only know there are two kinds of color balls and the total number of balls is 60. Even if we take a sample of 10 balls, we are only going to observe the proportion of red balls in the sample. There does not seem to be a way for us to write down the sample space where each outcome is equally likely.\nThe frequency view would work here. One could treat the process of obtaining a sample (i.e. taking a random sample of 10 balls from the box) as an experiment, and obtain a sample proportion \\(\\hat{p}\\) from the experiment. One then could repeat the experiment many times under the same condition, get many sample proportions \\(\\hat{p}\\), and summarize all the \\(\\hat{p}\\). When one repeats the experiment enough times (a large number), one gets a good sense about the proportion \\(p\\) of red balls in the population of 60 balls in the box. This process is doable, but tedious, time-consuming, and prone to errors.\nThe subjective view perceives the unknown proportion \\(p\\) subjectively. It does require one to express his or her opinion about the value of \\(p\\), and he or she could be skeptical and unconfident about the opinion. In Chapter 1, a calibration experiment was introduced to help one sharpen an opinion about the likelihood of an event by comparisons with opinion about the likelihood of other events. In this chapter and the chapters to follow, we introduce the key ideas and practice about thinking subjectively about unknowns and quantify one’s opinions about the values of these unknowns using probability distributions.\nAs an example, let’s think about plausible values for the proportion \\(p\\) of red balls. As \\(p\\) is a proportion, it can take any possible value between 0 and 1. In the calibration experiment introduced in Chapter 1, we focus on the scenario where only one value of \\(p\\) is of interest. For example, when one thinks that \\(p\\) is 0.5, it is saying that one’s opinion about the probability of the value \\(p=0.5\\) is one. When we phrase it this way (``one’s opinion about the probability of \\(p=0.5\\) is one”), it sounds like a very strong opinion, because one only allows \\(p\\) to take one possible value, and gives probability one of that happening. Since one typically has no thought about the exact value of the proportion \\(p\\), setting one possible value for the proportion with probability one seems too strong.\nInstead suppose that the proportion \\(p\\) can take multiple values between 0 and 1. In particular, let’s consider two scenarios, in both \\(p\\) can take 10 different values, denoted by set \\(A\\).\n\\[\\begin{eqnarray}\nA = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\}\n\\end{eqnarray}\\]\nThough \\(p\\) can take the same 10 multiple values in both scenarios, we assign different probabilities to each possible value.\n\nScenario 1: \\[\\begin{eqnarray}\nf_1(A) = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)\n\\end{eqnarray}\\]\nScenario 2: \\[\\begin{eqnarray}\nf_2(A) = (0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05) \\nonumber \\\\\n\\end{eqnarray}\\]\n\nTo visually compare the values of two probability distributions \\(f_1(A)\\) and \\(f_2(A)\\), we plot \\(f_1(A)\\) and \\(f_2(A)\\) on the same graph.\n\n\n\n\n\n\n\n\nThe same ten possible values of \\(p\\), but two sets of probabilities.\n\n\n\n\nFigure 7.1 labels the \\(x\\)-axis as the values of \\(p\\) (range from 0 to 1), \\(y\\)-axis as the probabilities (range from 0 to 1). For both panels, there are ten bars, each representing the possible values of \\(p\\) in the set \\(A = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\}\\).\nThe probability assignment in \\(f_1(A)\\) is called a discrete Uniform distribution, where each possible value of the proportion \\(p\\) is equally likely. Since there are ten possible values of \\(p\\), each value gets assigned a probability of \\(1/10 = 0.1\\). This assignment expresses the opinion that \\(p\\) can be any value from the set \\(A = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\}\\), and each value has a probability of \\(0.1\\).\nThe probability assignment in \\(f_2(A)\\) is also discrete, however, we do not see a Uniform distribution pattern of the probabilities across the board. What we see is that the probabilities of the first three values (0.1, 0.2, and 0.3) and last three (0.8, 0.9, and 1.0) values of \\(p\\) are each \\(1/3.5\\) of that of the middle four (0.4, 0.5, 0.6, and 0.7) values. The shape of the bins reflects the opinion that the middle values of \\(p\\) are 3.5 times as likely as the extreme values of \\(p\\).\nBoth sets of probabilities follow the three probability axioms in Chapter 1. One sees that within each set,\n\nEach probability is nonnegative;\nThe sum of the probabilities is 1;\nThe probability of mutually exclusive values is the sum of probability of each value, e.g. probability of \\(p = 0.1\\) or \\(p = 0.2\\) is \\(0.1 + 0.1\\) in \\(f_1(A)\\), and \\(0.05 + 0.05\\) in \\(f_2(A)\\).\n\nIn this introduction, we have presented a way to think about proportions subjectively. We have introduced a way to allow multiple values of \\(p\\), and perform probability assignments that follow the three probability axioms. One probability distribution expresses a unique opinion about the proportion \\(p\\).\nTo answer our inference question “what is the proportion of red balls in the box”, we will take a random sample of 10 balls, and use the observed proportion of red balls in that sample to sharpen and update our belief about \\(p\\). Bayesian inference is a formal method for implementing this way of thinking and problem solving, including three general steps.\n\nStep 1: Prior: express an opinion about the location of the proportion \\(p\\) before sampling.\nStep 2: Data/Likelihood: take the sample and record the observed proportion of red balls.\nStep 3: Posterior:use Bayes’ rule to sharpen and update the previous opinion about \\(p\\) given the information from the sample.\n\nAs indicated in the parentheses, the first step “Prior” constructs prior opinion about the quantity of interest, and a probability distribution is used (like \\(f_1(A)\\) and \\(f_2(A)\\) earlier) to quantify the prior opinion. The name “prior” indicates that the opinion should be formed before collecting any data.\nThe second step “Data” is the process of data collection, where the quantity of interest is observed in the collected data. For example, if our 10-ball sample contains 4 red balls and 6 white balls, the observed proportion of red balls is \\(4/10 = 0.4\\). Informally, how does this information help us sharpen one’s opinion about \\(p\\)? Intuitively one would give more probability to \\(p = 0.4\\), but it is unclear how the probabilities would be redistributed among the 10 values in \\(A\\). Since the sum of all probabilities is 1, is it possible that some of the larger proportion values, such as \\(p = 0.9\\) and \\(p = 1.0\\), will receive probabilities of zero? To address these questions, the third step is needed.\nThe third step “Posterior” combines one’s prior opinion and the collected data to update one’s opinion about the quantity of interest. Just like the example of observing 4 red balls in the 10-ball sample, one needs a structured way of updating the opinion from prior to posterior.\nThroughout this chapter, the entire inference process will be described for learning about a proportion \\(p\\). This chapter will discuss how to express prior opinion that matches with one’s belief, how to extract information from the data/likelihood, and how to update our opinion to its posterior."
  },
  {
    "objectID": "proportion.html#bayesian-inference-with-discrete-priors",
    "href": "proportion.html#bayesian-inference-with-discrete-priors",
    "title": "1  Learning About a Binomial Probability",
    "section": "1.2 Bayesian Inference with Discrete Priors",
    "text": "1.2 Bayesian Inference with Discrete Priors\n\n1.2.1 Example: students’ dining preference\nLet’s start our Bayesian inference for proportion \\(p\\) with discrete prior distributions with a students’ dining preference example. A popular restaurant in a college town has been in business for about 5 years. Though the business is doing well, the restaurant owner wishes to learn more about his customers. Specifically, he is interested in learning about the dining preferences of the students. The owner plans to conduct a survey by asking students “what is your favorite day for eating out?” In particular, he wants to find out what percentage of students prefer to dine on Friday, so he can plan ahead for ordering supplies and giving promotions.\nLet \\(p\\) denote the proportion of all students whose answer is Friday.\n\n\n1.2.2 Discrete prior distributions for proportion \\(p\\)\nBefore giving out the survey, let’s pause and think about the possible values for the proportion \\(p\\). Not only does one want to know about possible values, but also the probabilities associated with the values. A probability distribution provides a measure of belief for the proportion and it ultimately will help the restaurant owner improve his business.\nOne might not know much about students’ dining preference, but it is possible to come up with a list of plausible values for the proportion. There are seven days a week. If each day was equally popular, then one would expect 1/7 or approximately 15% of all students to choose Friday. The owner recognizes that Friday is the start of the weekend, therefore there should be a higher chance of being students’ preferred day of dining out. So perhaps \\(p\\) starts with 0.3. Then what about the largest plausible value? Letting this largest value be 1 seems unrealistic, as there are six other days in the week. Suppose that one chooses 0.8 to be the largest plausible value, and then comes up with the list of values of \\(p\\) to be the six values going from 0.3 to 0.8 with an increment of 0.1.\n\\[\\begin{eqnarray}\np = \\{0.3, 0.4, 0.5, 0.6, 0.7, 0.8\\}\n\\label{eq:dining:p}\n\\end{eqnarray}\\]\nNext one needs to assign probabilities to the list of plausible values of \\(p\\). Since one may not know much about the location of the probabilities \\(p\\), a good place to start is a discrete Uniform prior (recall the discrete Uniform prior distribution for \\(p\\), the proportion of red balls, in Section 7.1). A discrete Uniform prior distribution expresses the opinion that all plausible values of \\(p\\) are equally likely. In the current students’ dining preference example, if one decides on six plausible values of \\(p\\) as in Equation (7.1), each of the six values gets a prior probability of 1/6. One labels this prior as \\(\\pi_l\\), where \\(l\\) stands for laymen (for all of us who are not in the college town restaurant business). Note that in the notation \\(f_l(p)\\), the first \\(p\\) stands for probability, and the \\(p\\) in the parenthesis is our quantity of interest, the proportion \\(p\\) of students preferring to dine out on Friday.\n\\[\\begin{eqnarray}\n\\pi_l(p)= (1/6, 1/6, 1/6, 1/6, 1/6, 1/6)\n\\label{eq:dining:laymenprior}\n\\end{eqnarray}\\]\nWith five years of experience of running his restaurant in this college town, the restaurant owner might have different opinions about likely values of \\(p\\). Suppose he agrees with us that \\(p\\) could take the 6 plausible values from 0.3 to 0.8, but he assigns a different prior distribution for \\(p\\). In particular, the restaurant owner thinks that values of 0.5 and 0.6 are most likely – each of these values is twice as likely as the other values. His prior is labelled as \\(\\pi_e\\), where \\(e\\) stands for expert.\n\\[\\begin{eqnarray}\n\\pi_e(p)= (0.125, 0.125, 0.250, 0.250, 0.125, 0.125)\n\\label{eq:dining:expertprior}\n\\end{eqnarray}\\]\nTo obtain \\(\\pi_e(p)\\) efficiently, one can use the ProbBayes R package. First a data frame is created by providing the list of plausible values of \\(p\\) and corresponding weights assigned to each value using the function data.frame(). As one can see here, one does not have to calculate the probability – one only needs to give the weights (e.g. giving \\(p = 0.3, 0.4, 0.7, 0.8\\) weight 1 and giving \\(p = 0.5, 0.6\\) weight 2, to reflect the owner’s opinion ``0.5 and 0.6 are twice as likely as the other values”).\n\nbayes_table <- data.frame(p = seq(.3, .8, by=.1),\n                          Prior = c(1, 1, 2, 2, 1, 1))\nbayes_table\n\n    p Prior\n1 0.3     1\n2 0.4     1\n3 0.5     2\n4 0.6     2\n5 0.7     1\n6 0.8     1\n\n\nOne uses the function mutate() to normalize these weights to obtain the prior probabilities in the Prior column.\n\nbayes_table %>% mutate(Prior = Prior / sum(Prior)) -> bayes_table\nbayes_table\n\n    p Prior\n1 0.3 0.125\n2 0.4 0.125\n3 0.5 0.250\n4 0.6 0.250\n5 0.7 0.125\n6 0.8 0.125\n\n\nOne conveniently plots the restaurant owner’s prior distribution by use of ggplot2 functions. This distribution is displayed in Figure 7.2.\n\n\n\n\n\nThe restaurant owner’s prior distribution for the proportion \\(p\\).\n\n\n\n\nIt is left as an exercise for the reader to compute and plot the laymen’s prior \\(\\pi_l(p)\\) in Equation (7.2). For the rest of this section, we will work with the expert’s prior \\(\\pi_e(p)\\).\n\n\n1.2.3 Likelihood\nThe next step in the inference process is the data collection. The restaurant owner gives a survey to 20 student diners at the restaurant. Out of the 20 student respondents, 12 say that their favorite day for eating out is Friday. Recall the quantity of interest is proportion \\(p\\) of the population of students choosing Friday.\nThe likelihood is a function of the quantity of interest, which is the proportion \\(p\\). The owner has conducted an experiment 20 times, where each experiment involves a “yes” or “no” answer from the respondent to the rephrased question “whether Friday is your preferred day to dine out”. Then the proportion \\(p\\) is the probability a student answers ``yes”.\nDoes this ring a bell of what we have seen before? Indeed, in Chapter 4, one has seen this type of experiment, a Binomial experiment, similar to the dining survey. Recall that a Binomial experiment needs to satisfy four conditions:\n\nOne is repeating the same basic task or trial many times – let the number of trials be denoted by \\(n\\).\nOn each trial, there are two possible outcomes called success\" orfailure”.\nThe probability of a success, denoted by \\(p\\), is the same for each trial.\nThe results of outcomes from different trials are independent.\n\nIf one recognizes an experiment as being Binomial, then all one needs to know is \\(n\\) and \\(p\\) to determine probabilities for the number of successes \\(Y\\). The probability of \\(y\\) successes in a Binomial experiment is given by\n\\[\\begin{eqnarray}\nProb(Y=y) = {n \\choose y} p^y (1 - p)^{n - y}, y = 0, \\cdots, n.\n\\end{eqnarray}\\]\nAssuming the dining survey is a random sample (thus independent outcomes), this is the result of a Binomial experiment. The likelihood is the chance of 12 successes in 20 trials viewed as a function of the probability of success \\(p\\): \\[\\begin{eqnarray}\nLikelihood = L(p) = {20 \\choose 12} p ^ {12} (1 - p) ^ 8.\n\\label{eq:dining:likelihood}\n\\end{eqnarray}\\]\nGenerally one uses \\(L\\) to denote a likelihood function — one sees in Equation (7.5), \\(L\\) is a function of \\(p\\). Note that the value of \\(n\\), the total number of trials, is known and the number of successes \\(Y\\) is observed to be 12. The proportion \\(p\\), is the parameter of the Binomial experiment and the likelihood is a function of the proportion \\(p\\).\nThe likelihood function \\(L(p)\\) is efficiently computed using the dbinom() function in R. In order to use this function, we need to know the sample size \\(n\\) (20 in the dining survey), the number of successes \\(y\\) (12 in the dining survey), and \\(p\\) (the list of 6 plausible values created in Section 7.2.2; \\(p = \\{0.3, 0.4, 0.5, 0.6, 0.7, 0.8\\}\\)). Note that we only need the plausible values of \\(p\\), not yet the assigned probabilities in the prior distribution. The prior will be used in the third step to update the opinion of \\(p\\) to its posterior.\nBelow is the example R code of finding the probability of 12 successes in a sample of 20 for each value of the proportion \\(p\\). The values are placed in the Likelihood column of the bayes_table data frame.\n\nbayes_table$Likelihood <- dbinom(12, size=20, prob=bayes_table$p)\nbayes_table\n\n    p Prior  Likelihood\n1 0.3 0.125 0.003859282\n2 0.4 0.125 0.035497440\n3 0.5 0.250 0.120134354\n4 0.6 0.250 0.179705788\n5 0.7 0.125 0.114396740\n6 0.8 0.125 0.022160877\n\n\n\n\n1.2.4 Posterior distribution for proportion \\(p\\)\nThe posterior probabilities are found as an application of Bayes’ rule. This recipe will be illustrated first through a step-by-step calculation process. Next the process is demonstrated with the bayesian_crank() function in the ProbBayes R package, which implements the Bayes’ rule calculation and outputs the posterior probabilities.\nLet \\(\\pi(p)\\) to be the prior distribution of \\(p\\), let \\(L(p)\\) denote the likelihood function, and \\(\\pi(p \\mid y)\\) to be the posterior distribution of \\(p\\) after observing the number of successes \\(y\\). For discrete parameters, such as the proportion \\(p\\) in our case, one is able to enumerate the list of plausible values and assign prior probabilities to the values. If \\(p_i\\) represents a particular value of \\(p\\), Bayes’ rule for a discrete parameter has the form \\[\\begin{eqnarray}\n\\pi(p_i \\mid y)  = \\frac{\\pi(p_i) \\times L(p_i)} {\\sum_j \\pi(p_j) \\times L(p_j)},\n\\label{eq:Discrete:bayesrule}\n\\end{eqnarray}\\] where \\(\\pi(p_i)\\) is the prior probability of \\(p = p_i\\), \\(L(p_i)\\) is the likelihood function evaluated at \\(p = p_i\\), and \\(\\pi(p_i \\mid y)\\) is the posterior probability of \\(p = p_i\\) given the number of successes \\(y\\). By the Law of Total Probability, the denominator gives the marginal distribution of the observation \\(y\\).\nBayes’ rule can also be expressed as ``prior times likelihood”: \\[\\begin{eqnarray}\n\\pi(p_i \\mid y)  \\propto \\pi(p_i) \\times L(p_i)\n\\label{eq:Discrete:bayesruleProp}\n\\end{eqnarray}\\] Equation (7.7) ignores the denominator and states that the posterior is proportional to the product of the prior and the likelihood. As one will see soon, the value of the denominator is a constant, meaning that its purpose is to normalize the numerator. It is convenient to work with Bayes’ rule as in Equation (7.7) in later chapters. However, it is instructive to show the exact calculation of Equation (7.6), because one has a finite sum in the denominator and it is possible to obtain the analytical solution. In the case where the prior is continuous, it will be more difficult to analytically compute the normalizing constant.\nReturning to the students’ dining preference example, the list of plausible values of the proportion is \\(p = \\{0.3, 0.4, 0.5, 0.6, 0.7, 0.8\\}\\) and according to the restaurant owner’s expert prior, the assigned probabilities are \\(\\pi_e(p)= (0.125, 0.125, 0.250, 0.250, 0.125, 0.125)\\) (recall Figure 7.2). After observing the number of successes, the likelihood values are calculated for the models using dbinom() function, as presented in Section 7.2.3.\nThe denominator is the sum of the products of the prior and the likelihood at each possible \\(p_i\\), which, given the Law of Total Probability, is equal to the marginal probability of the data \\(f(y)\\). One can think of the above formula as reweighing or normalizing the probability of \\(\\pi(p_i \\mid y)\\) by all possible values of \\(p\\). In the case of discrete models like this, the marginal probability of the likelihood is computed through \\(\\sum_j f(p_j) \\times L(p_j)\\).\nIn this setup, the computation of the posterior probabilities of different \\(p_i\\) values is straightforward. First, one calculates the denominator and denote the value as \\(D\\). \\[\\begin{eqnarray*}\nD &=& \\pi(0.3) \\times L(0.3) + \\pi(0.4) \\times L(0.4) + \\cdots + \\pi(0.8) \\times L(0.8) \\\\\n&=& 0.125 \\times {20 \\choose 12}(0.3)^{12}(1-0.3)^{8} + \\cdots + 0.125 \\times {20 \\choose 12}(0.8)^{12}(1-0.8)^{8} \\nonumber \\\\ &\\approx& 0.0969.\n\\end{eqnarray*}\\] Then the posterior probability of \\(p = 0.3\\) is given by \\[\\begin{eqnarray*}\n\\pi(p = 0.3 \\mid 12) &=& \\frac{\\pi(0.3) \\times L(0.3)}{D} \\\\\n&=& \\frac{0.125 \\times {20 \\choose 12}(0.3)^{12}(1-0.3)^{8}}{D}  \\\\\n&\\approx& 0.005.\n\\end{eqnarray*}\\] In a similar fashion, the posterior probability of \\(p=0.5\\) is calculated as \\[\\begin{eqnarray*}\n\\pi(p = 0.5 \\mid 12) &=& \\frac{\\pi(0.5) \\times L(0.5)}{D} \\\\\n&=& \\frac{0.125 \\times {20 \\choose 12}(0.5)^{12}(1-0.5)^{8}}{D} \\\\\n&\\approx& 0.310.\n\\end{eqnarray*}\\] One sees that the denominator is the same for the posterior probability calculation of every value of \\(p\\). This calculation gets tedious for a large number of possible values of \\(p\\). Relying on statistical software such as R helps us simplify the tasks.\nTo use the bayesian_crank() function, recall that we have already created a data frame with variables p, Prior, and Likelihood. Then the bayesian_crank() function is used to compute the posterior probabilities.\n\nbayesian_crank(bayes_table) -> bayes_table\nbayes_table\n\n    p Prior  Likelihood      Product   Posterior\n1 0.3 0.125 0.003859282 0.0004824102 0.004975901\n2 0.4 0.125 0.035497440 0.0044371799 0.045768032\n3 0.5 0.250 0.120134354 0.0300335884 0.309786454\n4 0.6 0.250 0.179705788 0.0449264469 0.463401326\n5 0.7 0.125 0.114396740 0.0142995925 0.147495530\n6 0.8 0.125 0.022160877 0.0027701096 0.028572757\n\n\nAs one sees in the bayes_table output, the bayesian_crank() function computes the product of Prior and Likelihood and stores the values in the column Product, then normalizes each product with the sum of all products to produce the posterior probabilities, stored in the column Posterior.\nFigure 7.3 compares the prior probabilities in the bottom panel with the posterior probabilities in the top panel. Notice the difference in the two distributions. After observing the survey results (i.e. the data/likelihood), the owner is more confident that \\(p\\) is equal to 0.5 or 0.6, and it is unlikely for \\(p\\) to be 0.3, 0.4, 0.7, and 0.8. Recall that the data gives an observed proportion 12/20 = 0.6. Since the posterior is a combination of prior and data/likelihood, it is not surprising that the data/likelihood helps the owner to sharpen his belief about proportion \\(p\\) and place a larger posterior probability around 0.6.\n\n\n\n\n\nPrior and posterior distributions on the proportion \\(p\\).\n\n\n\n\n\n\n1.2.5 Inference: students’ dining preference\nLet’s revisit the posterior distribution table to perform some inference. What is the posterior probability that over half of the students prefer eating out on Friday? One is interested in the probability that \\(p >\\) 0.5, in the posterior. Looking at the table, this posterior probability is equal to \\[\\begin{eqnarray*}\nProb(p > 0.5) \\approx 0.463 + 0.147 + 0.029 = 0.639.\n\\end{eqnarray*}\\] This means the owner is reasonably confident (with probability 0.639) that over half of the college students prefer to eat out on Friday.\nOne easily obtains the probability from the R output, for example.\n\nsum(bayes_table$Posterior[bayes_table$p > 0.5])\n\n[1] 0.6394696\n\n\n\n\n1.2.6 Discussion: using a discrete prior\nSpecifying a discrete prior has two steps: (1) specifying a list of plausible values of the parameter of interest, and (2) assigning probabilities to the plausible values. It is important to remember the three probability axioms when specifying a discrete prior.\nAfter the prior specification, the next component is the data/likelihood, which can also be broken up into two steps. First, one constructs a suitable experiment that works for the particular scenario. Here one has a Binomial experiment for a survey to a fixed number of respondents, the answers are classified into yes\" andno” or success\" andfailure”, the outcome of interest is the number of successes and trials are independent. From the Binomial distribution, one obtains the likelihood function which is evaluated at each possible value of the parameter of interest. In our example, the dbinom() R function was used to calculate the likelihood function.\nLast, the posterior probabilities are calculated using Bayes’ rule. In particular for the discrete case, follow Equation (7.6). The calculation of the denominator is tedious, however practice with the Bayes’ rule calculation enhances one’s understanding of Bayesian inference. R functions such as bayesian_crank() are helpful for implementing the Bayes’ rule calculations. Bayesian inference follows from a suitable summarization of the posterior probabilities. In our example, inference was illustrated by calculating the probability that over half of the students prefer eating out on Friday.\nLet’s revisit the list of plausible values of proportion \\(p\\) of students preferring Friday in dining out in the example. Although \\(p = 1.0\\), that is, everyone prefers Friday, is very unlikely, one might not want to eliminate this proportion value from consideration. As one observes in the Bayes’ rule calculation process shown in Sections 7.2.3 and 7.2.4, if one does not include \\(p = 1.0\\) as one of the plausible values in the prior distribution in Section 7.2.2, this value will also be given a probability of zero in the posterior.\nAlternatively, one could choose the alternative set of values \\[\\begin{eqnarray*}\np = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\},\n\\end{eqnarray*}\\] and assign a very small prior probability (e.g. 0.05 or even smaller) for \\(p = 1.0\\) to express the opinion that \\(p = 1.0\\) is very unlikely. One may assign small prior probabilities for other large values of \\(p\\) such as \\(p = 0.9\\).\nThis comment illustrates a limitation of specifying a discrete prior for a proportion \\(p\\). If a plausible value is not specified in the prior distribution (e.g. \\(p = 1.0\\) is not in the restaurant owner’s prior distribution), it will be assigned a probability of zero in the posterior (e.g. \\(p = 1.0\\) is not in the restaurant owner’s posterior distribution).\nIt generally is more desirable to have \\(p\\) to be any value in [0, 1] including less plausible values such as \\(p = 1.0\\). To make this happen, the proportion \\(p\\) should be allowed to take any value between 0 and 1, which means \\(p\\) will be a continuous variable. In this situation, it is necessary to construct a continuous prior distribution for \\(p\\). A popular class of continuous prior distributions for proportion is the Beta distribution which is the subject of the next section."
  },
  {
    "objectID": "proportion.html#continuous-priors",
    "href": "proportion.html#continuous-priors",
    "title": "1  Learning About a Binomial Probability",
    "section": "1.3 Continuous Priors",
    "text": "1.3 Continuous Priors\nLet’s continue our students’ dining preference example. A restaurant owner is interested in learning about the proportion \\(p\\) of students whose favorite day for eating out is Friday.\nThe proportion \\(p\\) should be a value between 0 and 1. Previously, we used a discrete prior for \\(p\\), representing the belief that \\(p\\) only takes the six different values 0.3, 0.4, 0.5, 0.6, 0.7, and 0.8. An obvious limitation of this assumption is, what if the true \\(p\\) is 0.55? If the value 0.55 is not specified in the prior distribution of \\(p\\) (that is, a zero probability is assigned to the value \\(p\\) = 0.55), then by the Bayes’ rule calculation (either by hand or by the useful bayesian_crank() function) there will be zero posterior probability assigned to 0.55. It is therefore preferable to specify a prior that allows \\(p\\) to be any value in the interval [0, 1].\nTo represent such a prior belief, it is assumed that \\(p\\) is continuous on [0, 1]. Suppose again that one is a layman unfamiliar with the pattern of dining during a week. Then one possible choice of a continuous prior for \\(p\\) is the continuous Uniform distribution, which expresses the opinion that \\(p\\) is equally likely to take any value between 0 and 1.\nFormally, the probability density function of the continuous Uniform on the interval \\((a, b)\\) is \\[\\begin{eqnarray}\n\\pi(p) =\n\\begin{cases}\n  \\frac{1}{b - a} & \\text{for }a \\le p \\le b,\\\\    \n  0             & \\text{for }p < a \\,\\, \\text{or } p > b.\n\\end{cases}\n\\label{eq:Binomial:Continuous:Uniform}\n\\end{eqnarray}\\] In our situation \\(p\\) is a continuous Uniform random variable on [0, 1], we have \\(\\pi(p) = 1\\) for \\(p \\in [0, 1]\\), and \\(\\pi(p) = 0\\) everywhere else.\nWhat about other possible continuous prior distributions for \\(p\\) on [0, 1]? Consider a prior distribution for the restaurant owner who has some information about the location (i.e. value) of \\(p\\). This owner would be interested in a continuous version of the discrete prior distribution where values of \\(p\\) between 0.3 and 0.8 are more likely than the values at the two ends.\nThe Beta family of continuous distributions is useful for representing prior knowledge in this situation. A Beta distribution, denoted by Beta(\\(a, b)\\), represents probabilities for a random variable falling between 0 and 1. This distribution has two shape parameters, \\(a\\) and \\(b\\), with probability density function given by \\[\\begin{eqnarray}\n\\pi(p) = \\frac{1}{B(a, b)} p^{a - 1} (1 - p)^{b - 1}, \\, \\, 0 \\le p \\le 1,\n\\end{eqnarray}\\] where \\(B(a, b)\\) is the Beta function defined by \\(B(a, b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\), where \\(\\Gamma\\) is the Gamma function. For future reference, it is useful to know that if \\(p \\sim {\\rm Beta}(a, b)\\), its mean \\(E[p] = \\frac{a}{a+b}\\) and its variance \\(V(p) = \\frac{ab}{(a+b)^2(a+b+1)}\\). The continuous Uniform in Equation (7.8) is a special case of the Beta distribution: \\(\\textrm{Uniform}(0, 1) = \\textrm{Beta}(1, 1)\\).\nFor the remainder of this section, Section 7.3.1 introduces the Beta distribution and Beta probabilities, and Section 7.3.2 focuses on several ways of choosing a Beta prior that reflects one’s opinion about the location of a proportion.\n\n1.3.1 The Beta distribution and probabilities\nThe two shape parameters \\(a\\) and \\(b\\) control the shape of the Beta density curve. Figure 7.4 shows density curves of Beta distributions for several choices of the shape parameters. One observes from this figure that the Beta density curve displays vastly different shapes for varying choices of \\(a\\) and \\(b\\). For example, \\(\\textrm{Beta}(0.5, 0.5)\\) represents the prior belief that extreme values of \\(p\\) are likely and \\(p=0.5\\) is the least probable value. In the students’ dining preference example, specifying a \\(\\textrm{Beta}(0.5, 0.5)\\) would reflect the owner’s belief that the proportion of students dining out on Friday is either very high (near one) or very low (near one) and not likely to be moderate values.\n\n\n\n\n\nIllustration of nine Beta density curves.\n\n\n\n\nAs the Beta is a common continuous distribution, R functions are available for Beta distribution calculations. We provide a small example of “Beta” functions for Beta(1, 1), where the two shape parameters 1 and 1 are the second and third arguments of the functions.\nRecall the following useful results from previous material: (1) a \\(\\textrm{Beta}(1, 1)\\) distribution is a Uniform density on (0, 1), (2) the density of \\(\\textrm{Uniform}(0, 1)\\) is \\(\\pi(p) = 1\\) on [0, 1], and (3) if \\(p \\sim \\textrm{Uniform}(0, 1)\\), then the cdf \\(F(x) = Prob(p \\leq x) = x\\) for \\(x \\in [0, 1]\\).\n\ndbeta(): the probability density function for a \\(\\textrm{Beta}(a, b)\\) which takes a value of the random variable as its input and outputs the probability density function at that value.\n\nFor example, we evaluate the density function of \\(\\textrm{Beta}(1, 1)\\) at the values \\(p = 0.5\\) and \\(p = 0.8\\), which should be both 1, and 0 at \\(p = 1.2\\) which should be 0 since this value is outside of [0, 1].\n\ndbeta(c(0.5, 0.8, 1.2), 1, 1)\n\n[1] 1 1 0\n\n\n\npbeta(): the distribution function of a Beta(a; b) random variable, which takes a value x and gives the value of the random variable at that value, F(x).\n\nFor example, suppose one wishes to evaluate the distribution function of \\(\\textrm{Beta}(1, 1)\\) at \\(p = 0.5\\) and \\(p = 0.8\\).\n\npbeta(c(0.5, 0.8), 1, 1)\n\n[1] 0.5 0.8\n\n\nOne calculates the probability of \\(p\\) between 0.5 and 0.8, i.e. \\(Prob(0.5 \\le p \\le 0.8)\\) by taking the difference of the cdf at the two values.\n\npbeta(0.8, 1, 1) - pbeta(0.5, 1, 1)\n\n[1] 0.3\n\n\n\nqbeta(): the quantile function of a \\(\\textrm{Beta}(a, b)\\), which inputs a probability value \\(p\\) and outputs the value of \\(x\\) such that \\(F(x) = p\\).\n\nFor example, suppose one wishes to calculate the quantile of \\(\\textrm{Beta}(1, 1)\\) at \\(p = 0.5\\) and \\(p = 0.8\\).\n\nqbeta(c(0.5, 0.8), 1, 1)\n\n[1] 0.5 0.8\n\n\n\nrbeta(): the random number generator for \\(\\textrm{Beta}(a, b)\\), which inputs the size of a random sample and gives a vector of the simulated random variates.\n\nFor example, suppose one is interested in simulating a sample of size five from \\(\\textrm{Beta}(1, 1)\\).\n\nrbeta(5, 1, 1)\n\n[1] 0.014428665 0.706480894 0.007722286 0.014802991 0.620159572\n\n\nThere are additional functions in the ProbBayes R package that aid in visualizing Beta distribution calculations. For example, suppose one has a \\(\\textrm{Beta}(7, 10)\\) curve and we want to find the chance that \\(p\\) is between 0.4 and 0.8. Looking at Figure 7.5, this probability corresponds to the area of the shaded region. The special function beta_area() will compute and illustrate this probability. Note the use of the vector c(7, 10) to input the two shape parameters.\nbeta_area(0.4, 0.8, c(7, 10))\n\n\n\n\n\nArea represents the probability that a Beta(7, 10) variable lies between 0.4 and 0.8\n\n\n\n\nOne could also find the chance that \\(p\\) is between 0.4 and 0.8 by subtracting two pbeta() functions.\n\npbeta(0.8, 7, 10) - pbeta(0.4, 7, 10)\n\n[1] 0.5269265\n\n\nThe function beta_quantile() works in the same way as qbeta(), the quantile function. However, beta_quantile() automatically produces a plot with the shaded probability area. Figure 7.6 plots and computes the quantile to be 0.408. The chance that \\(p\\) is smaller than 0.408 is 0.5.\nbeta_quantile(0.5, c(7, 10))\n\n\n\n\n\nIllustration of a 0.5 quantile for a Beta(7, 10) variable.\n\n\n\n\nAlternatively, use the qbeta() function without returning a plot.\n\nqbeta(0.5, 7, 10)\n\n[1] 0.4082265\n\n\n\n\n1.3.2 Choosing a Beta density to represent prior opinion\nOne wants to use a \\(\\textrm{Beta}(a, b)\\) density curve to represent one’s prior opinion about the values of the proportion \\(p\\) and their associated probabilities. It is difficult to guess at values of the shape parameters \\(a\\) and \\(b\\) directly. However, there are indirect ways of guessing their values. We present two general methods here.\nThe first method is to consider the shape parameter \\(a\\) as the prior count of “successes” and the other shape parameter \\(b\\) as the prior count of “failures”. Subsequently, the value \\(a + b\\) represents the prior sample size comparable to \\(n\\), the data sample size. Following this setup, one could specify a Beta prior with shape parameter \\(a\\) expressing the number of successes in one’s prior opinion, and the other shape parameter \\(b\\) expressing the number of failures in one’s prior opinion. For example, if one believes that a priori there should be about 4 successes and 4 failures, then one could use \\(\\textrm{Beta}(4, 4)\\) as the prior distribution for the proportion \\(p\\).\nHow can we check if \\(\\textrm{Beta}(4, 4)\\) looks like what we believe a priori? Recall that rbeta() generates a random sample from a Beta distribution. The R script below generates a random sample of size 1000 from \\(\\textrm{Beta}(4, 4)\\) and we plot a histogram and an overlapping density curve. (See top panel of Figure 7.7.) By an inspection of this graph, one decides if this prior is a reasonable approximation to one’s beliefs about the proportion.\n\n\n\n\n\nHistograms of 1000 samples of two Beta density curves Beta(4, 4) and Beta(2, 9).\n\n\n\n\nAs a second example, consider a belief that a priori there are 2 successes and 9 failures, corresponding to the \\(\\textrm{Beta}(2, 9)\\) prior? One can use the rbeta() function take a random sample of 1000 from this prior.\n\nBeta29samples <- rbeta(1000, 2, 9)\n\nComparing the two distributions, note from Figure 7.7 that \\(\\textrm{Beta}(2, 9)\\) favors smaller proportion values than \\(\\textrm{Beta}(4, 4)\\).\nTo further check the quantiles of the prior, one can use the quantile() function on the simulated draws from the prior. For example, if one wishes to check the middle 50% range of values of \\(p\\) from the random sample of values from \\(\\textrm{Beta}(4, 4)\\), one types\n\nBeta44samples <- rbeta(1000, 4, 4)\nquantile(Beta44samples, c(0.25, 0.75))\n\n      25%       75% \n0.3866210 0.6249832 \n\n\nThis tells us that the probability that \\(p \\leq 0.366\\) is 0.25 and the probability that \\(p \\geq 0.616\\) is also 0.25. These probability statements should be checked against one’s prior belief about \\(p\\). If these quantiles do not seem reasonable, one should make adjustments to the values of the shape parameters \\(a\\) and \\(b\\) .\nOn the surface the two priors \\(\\textrm{Beta}(4, 4)\\) and \\(\\textrm{Beta}(40, 40)\\) seem similar in that they both have a mean of \\(0.5\\) and represent similar breakdowns of the success and failure counts. However, the aforementioned concept of prior sample size tells us that \\(\\textrm{Beta}(4, 4)\\) has a prior sample size of 8 while that of \\(\\textrm{Beta}(40, 40)\\) is 80. As we will see in Section 7.4, the prior sample size determines the strength of the prior (i.e. the confidence level in the prior) and so the \\(\\textrm{Beta}(40, 40)\\) prior represents a much stronger belief that \\(p\\) is close to the value 0.5.\nA second indirect method of determining a Beta prior is by specification of quantiles of the distribution. Specifically, one determines the shape parameters \\(a\\) and \\(b\\) by first specifying two quantiles of the Beta density curve, and then finding the Beta density curve that matches these quantiles. Suppose the restaurant owner uses his knowledge to specify the 0.5 and 0.9 quantiles of the proportion \\(p\\) as follows.\n\nFirst, the restaurant owner thinks of a value \\(p_{50}\\) such that the proportion \\(p\\) is equally likely to be smaller or larger than \\(p_{50}\\). After some thought, he thinks that \\(p_{50}\\) = 0.55.\nNext, the owner thinks of a value \\(p_{90}\\) that he is pretty sure (with probability 0.90) that the proportion \\(p\\) is smaller than \\(p_{90}\\). After more thought, he decides \\(p_{90}\\) = 0.80.\n\n One then uses the beta.select() function in the ProbBayes package to find shape parameters \\(a\\) and \\(b\\) of the Beta density curve that match this information. Each quantile is specified by a list with values \\(x\\) and \\(p\\). From the output, we see \\(\\textrm{Beta}(3.06, 2.56)\\) curve represents the owner’s prior beliefs.\n\nbeta.select(list(x = 0.55, p = 0.5),\n            list(x = 0.80, p = 0.9))\n\n[1] 3.06 2.56\n\n\nThe owner’s Beta density curve is shown here. To make sure this prior is reasonable, the owner should compute several probabilities and quantiles for his prior distribution and see if these values correspond to his opinion.\nTo illustrate this checking process, Figure 7.8 shows the middle 50% area of the prior distribution. This graph shows that the probability that \\(p \\leq 0.402\\) is 0.25 and the probability that \\(p \\geq 0.692\\) is also 0.25. If these calculations do not correspond to the owner’s opinion, then maybe some change in the prior distribution would be appropriate.\n\n\n\n\n\nIllustration of the middle 50% of a Beta(3.06, 2.56) curve."
  },
  {
    "objectID": "proportion.html#updating-the-beta-prior",
    "href": "proportion.html#updating-the-beta-prior",
    "title": "1  Learning About a Binomial Probability",
    "section": "1.4 Updating the Beta Prior",
    "text": "1.4 Updating the Beta Prior\nIn the previous section, we have seen that the restaurant owner thinks that a Beta curve with shape parameters 3.06 and 2.56 is a reasonable reflection of his prior opinion about the proportion of students \\(p\\) whose favorite day for eating out is Friday. Therefore, we work with \\(\\textrm{Beta}(3.06, 2.56)\\) as the prior distribution for \\(p\\).\nNow we have the survey results – the survey was administered to 20 students and 12 say that their favorite day for eating out is Friday. As before in Section 7.2, the likelihood, that is the chance of getting this data if the probability of success is \\(p\\) is given by the Binomial formula, \\[\\begin{eqnarray*}\nLikelihood = L(p) = {20 \\choose 12} p ^ {12 }(1 - p) ^ 8.\n\\end{eqnarray*}\\]\nIn this section, the Bayes’ rule calculation of the posterior is presented for the continuous prior case and one discovers an interesting result: if one starts with a Beta prior for a proportion \\(p\\), and the data is Binomial, then the posterior will also be a Beta distribution. The Beta posterior is a natural combination of the information contained in the Beta prior and the Binomial sampling, as one would expect in typical Bayesian inference. This is an illustration of the use of a conjugate prior where the prior and posterior densities are in the same family of distributions.\n\n1.4.1 Bayes’ rule calculation\nFirst we demonstrate the Bayes’ rule calculation of the posterior of \\(p\\) through the proportional statement: \\[\\begin{eqnarray}\n\\pi(p \\mid y) \\propto  \\pi(p) \\times L(p).\n\\end{eqnarray}\\]\nThe prior distribution of \\(p\\), with density \\(\\pi(p)\\), is Beta with shape parameters \\(3.06\\) and \\(2.56\\) \\[\\begin{eqnarray*}\np \\sim \\textrm{Beta}(3.06, 2.56).\n\\end{eqnarray*}\\] The symbol “\\(\\sim\\)” is read “follows”, meaning that the random variable before the symbol follows the distribution after the symbol.\nFor the data/likelihood, we introduce proper notation. Let \\(Y\\) be the random variable of the number of students say that their favorite day for eating out is Friday. We know that the sampling distribution for \\(Y\\) is a Binomial distribution with number of trials \\(20\\) and success probability \\(p\\). Using the notation of ``\\(\\sim\\)“, we have \\[\\begin{eqnarray*}\nY \\sim \\textrm{Binomial}(20, p).\n\\end{eqnarray*}\\] After the value \\(Y = y\\) is observed, \\(L(p) = f(y \\mid p)\\) denotes the likelihood, which is the probability of observing this sample value \\(y\\) viewed as a function of the proportion \\(p\\). (Note that a small letter \\(y\\) is used to denote the actual data observed, as opposed to the random variable \\(Y\\).) From the dining survey, we know that \\(y = 12\\).\nNow we have the following prior density and the likelihood function.\n\nThe prior distribution: \\[\\begin{eqnarray*}\n\\pi(p) = \\frac{1}{B(3.06, 2.56)}p^{3.06-1}(1-p)^{2.56-1}.\n\\end{eqnarray*}\\]\nThe likelihood: \\[\\begin{eqnarray*}\nf(Y =12 \\mid p) = L(p) = {20 \\choose 12}p^{12}(1-p)^{8}.\n\\end{eqnarray*}\\]\n\nBy Bayes’ rule, the posterior density \\(\\pi(p \\mid y)\\) is proportional to the product of the prior and the likelihood.\n\\[\\begin{eqnarray*}\n\\pi(p \\mid y) \\propto \\pi(p) \\times L(p).\n\\end{eqnarray*}\\]\nSubstituting the current prior and likelihood, one can perform the algebra for the posterior density. \\[\\begin{eqnarray}\n\\pi(p \\mid Y = 12) &\\propto& \\pi(p) \\times f(Y = 12 \\mid p) \\nonumber \\\\\n&=&  \\frac{1}{B(3.06, 2.56)}p^{3.06-1}(1-p)^{2.56-1} \\times \\nonumber \\\\\n&& {20 \\choose 12}p^{12}(1-p)^{8} \\nonumber \\\\\n\\texttt{[drop the constants]} &\\propto& p^{12}(1-p)^{8}p^{3.06-1}(1-p)^{2.56-1} \\nonumber \\\\\n\\texttt{[combine the powers]} &=& p^{15.06-1}(1-p)^{10.56-1}. \\nonumber \\\\\n\\end{eqnarray}\\] One observes that the posterior density of \\(p\\) given \\(Y = 12\\) is, up to a proportionality constant, \\[\\begin{eqnarray*}\n\\pi(p \\mid Y = 12) \\propto p^{15.06-1}(1-p)^{10.56-1}.\n\\end{eqnarray*}\\]\n Note that in the posterior derivation, the constants \\({20 \\choose 12}\\) and \\(\\frac{1}{B(3.06, 2.56)}\\) are dropped due to the proportional sign “\\(\\propto\\)”. That is, the expression of \\(\\pi(p \\mid Y = 12)\\) is computed up to some constant. In this case, Appendix A demonstrates the calculation of the constant.\nNext, one recognizes if the posterior distribution of \\(p\\) is recognizable as a member of a familiar family of distributions. In the computation of the posterior, we have intentionally kept the expression of ``\\(-1\\)” in the powers of \\(p\\) and \\(1-p\\) terms, instead of using \\(14.06\\) and \\(9.56\\) directly. By doing this, one recognizes that the posterior density has the familiar form \\[\\begin{eqnarray*}\np^{a-1}(1-p)^{b-1}.\n\\end{eqnarray*}\\] As the reader might have guessed, the posterior distribution turns out to be a Beta distribution with updated shape parameters. That is, the posterior distribution of \\(p\\) given \\(Y = 12\\) is Beta with parameters 15.06 and 10.56.\n\n\n1.4.2 From Beta prior to Beta posterior\nThe results about a proportion \\(p\\) from the Bayes’ rule calculation performed in Section 7.4.1 can be generalized. Suppose one works with the following prior distribution and sampling density:\n\nThe prior distribution: \\[\\begin{eqnarray*}\np \\sim \\textrm{Beta}(a, b)\n\\end{eqnarray*}\\]\nThe sampling density: \\[\\begin{eqnarray*}\nY \\sim \\textrm{Binomial}(n, p)\n\\end{eqnarray*}\\]\n\nOne observes the count \\(Y = y\\), the number of successes in the collected data. Then the posterior distribution of \\(p\\) is another Beta distribution with shape parameters \\(a + y\\) and \\(b + n - y\\).\n\nThe posterior distribution: \\[\\begin{eqnarray}\np \\mid Y = y \\sim \\textrm{Beta}(a + y, b + n - y)\n(\\#eq:betaposterior2)\n\\end{eqnarray}\\]\n\nThe two shape parameters of the Beta posterior distribution, \\(a + y\\) and \\(b + n - y\\), are the sums of the prior and data/likelihood counts of successes and failures, respectively. We algebraically combine the shape parameters of the Beta prior and the Binomial likelihood to obtain the shape parameters of the posterior Beta distribution.\nTable 7.1 demonstrates this process with three rows labelled Prior, Data/Likelihood and Posterior. The Prior row contains the shape parameters of the Beta prior \\(a\\) and \\(b\\) in the Successes and Failures columns, respectively. The Data/Likelihood row contains the number of successes \\(y\\) and the number of failures \\(n - y\\). The shape parameters of the Beta posterior are found by adding the prior parameter values and the data values.\nTable 7.1. Updating the Beta prior.\n\n\n\nSource\nSuccesses\nFailures\n\n\n\n\nPrior\n(a)\n(b)\n\n\nData/Likelihood\n(y)\n(n-y)\n\n\nPosterior\n(a + y)\n(b + n - y)\n\n\n\nIn the following R script we update the Beta shape parameters. We see that the owner’s posterior distribution for \\(p\\) is Beta with shape parameters 15.06 and 10.56.\n\nab <- c(3.06, 2.56)\nyny <- c(12, 8)\n(ab_new <- ab + yny)\n\n[1] 15.06 10.56\n\n\nThe function beta_prior_post() in the ProbBayes R package plots the prior and posterior Beta curves together on one graph, see Figure 7.9.\nbeta_prior_post(ab, ab_new)\n\n\n\n\n\nPrior and posterior curves for the proportion of students who prefer to dine out on Friday.\n\n\n\n\nComparing the two Beta curves, several observations can be made.\n\nOne can compare the prior and posterior Beta curves using the respective means. The mean of a \\(\\textrm{Beta}(a, b)\\) distribution is \\(\\frac{a}{a+b}\\). Using this formula, the posterior mean of \\(p\\) is 15.06 / (15.06 + 10.56) = 0.588 which is slightly larger than the prior mean 3.06 / (30.6 + 2.56) = 0.544. Recall that the sample proportion from the survey results is \\(12/20 = 0.6\\). The posterior mean lies between the prior mean and sample mean and it is closer to the sample mean.\nNext one compares the spreads of the two curves. One sees a much wider spread of the prior Beta curve (dashed line) than that of the posterior Beta curve (solid line). Initially the owner was unsure about the proportion of students favoring Friday to dine out. After observing the results of the survey, the solid posterior curve indicates that he is more certain that \\(p\\) is between 0.5 and 0.7. This sheds light on a general feature of Bayesian inference: the data helps sharpen the belief about the parameter of interest, producing a posterior distribution with a smaller spread than the prior distribution.\n\nThe attractive combination of a Beta prior and a Binomial sampling density to obtain a posterior motivates a definition of conjugate priors. If the prior distribution and the posterior distribution come from the same family of distributions, the prior is then called a conjugate prior. Here a Beta is a conjugate prior for a success probability \\(p\\), since the posterior distribution for \\(p\\) is also in the Beta family. Conjugate priors are specific to the choice of sampling density. For example, a Beta prior is conjugate with Binomial sampling, but not to Normal sampling which is popular for continuous outcome. In Chapter 8 we will discover the conjugate prior distribution for a Normal sampling distribution.\nConjugate priors are desirable because they simplify the Bayesian inference procedure. In the dining preference example, when a \\({\\rm Beta}(3.06, 2.56)\\) prior is assigned to \\(p\\), the posterior is \\({\\rm Beta}(15.06, 10.56)\\) and inference about \\(p\\) is made in a straightforward way. One can easily plot the he prior and posterior Beta distributions as in Figure 7.9. One can also make precise comparative statements about the locations of the prior and posterior distribution using quantiles of a Beta curve.\nAlthough conjugate priors are convenient and straightforward to use, they may not be appropriate for use in a Bayesian analysis. One should choose a prior that fits one’s belief, not one that is convenient to use. In some situations it may be appropriate to choose a prior distribution that does not provide conjugacy. In Chapter 9, we will describe computational methods to facilitate posterior inferences when non-conjugate priors are used. Modern Bayesian posterior computations accommodate a wide variety of choices of prior and sampling distributions. Therefore it is more important to choose a prior that matches one’s prior belief than choosing a prior that is computationally convenient."
  },
  {
    "objectID": "proportion.html#bayesian-inferences-with-continuous-priors",
    "href": "proportion.html#bayesian-inferences-with-continuous-priors",
    "title": "1  Learning About a Binomial Probability",
    "section": "1.5 Bayesian Inferences with Continuous Priors",
    "text": "1.5 Bayesian Inferences with Continuous Priors\nWe will continue with the dining preference example to illustrate different types of Bayesian inference. The restaurant owner has taken his dining survey and the posterior distribution \\(\\textrm{Beta}(15.06, 10.56)\\) reflects his opinion about the proportion \\(p\\) of students whose favorite day for eating out is Friday.\nAll Bayesian inferences about the proportion \\(p\\) are based on various summaries of this posterior Beta distribution. The summary we compute from the posterior will depend on the type of inference. We will focus on three types of inference: (1) testing problems where one is interested in assessing the likelihood of some values of \\(p\\), (2) interval estimations where one wants to find an interval that is likely to contain \\(p\\), and (3) Bayesian prediction where one wants to learn about new observation(s) in the future.\nSimulation will be incorporated for all three types of Bayesian inference problems. Since one has a conjugate prior distribution, one can derive the exact posterior distribution (a Beta) and inferences are performed with the exact posterior Beta distribution. In other situations when conjugacy is not available, meaning that no exact representation of the posterior is available, inferences through simulation are much more widely used. It is instructive to present the exact solutions and the approximated simulation-based solutions together, so one learns through practice and prepare for future use of simulation in other settings.\nThere is nothing magic about simulation. In fact, simulation has been used earlier, when the rbeta() function was used to generate simulated samples from \\(\\textrm{Beta}(4, 4)\\) and \\(\\textrm{Beta}(2, 9)\\) and check the appropriateness of the chosen Beta prior (review Section 7.3.2} as needed). Information on simulation and the relevant R code will be introduced in the description of each inferential problem.\n\n1.5.1 Bayesian hypothesis testing\nSuppose one of the restaurant workers claims that at least 75% of the students prefer to eat out on Friday. Is this a reasonable claim?\nIn traditional classical statistics, one might be interested in testing the hypothesis \\(H: p \\ge 0.75\\).\nFrom a Bayesian viewpoint, it is straightforward to implement this test. Since the hypothesis is an interval of values, one finds the posterior probability that \\(p \\ge 0.75\\) and makes a decision based on the value of this probability. If the probability is small, one rejects this claim.\n First the exact solution will be presented. Since the posterior distribution is \\(\\textrm{Beta}(15.06, 10.56)\\), the owner’s posterior density is graphed and the area under the curve for values of \\(p\\) between 0.75 and 1 is found. The beta_area() function is used to display and show the area; see Figure 7.10. Since the probability is only about 4%, one rejects the worker’s claim that \\(p\\) is at least 0.75.\nbeta_area(lo = 0.75, hi = 1.0,\n          shape_par = c(15.06, 10.56))\n\n\n\n\n\nProbability of the hypothesis from the Beta posterior density.\n\n\n\n\nThis computation can be implemented using simulation. Since the posterior distribution is \\(\\textrm{Beta}(15.06, 10.56)\\), one generates a large number of random values from this Beta distribution, then summarizes the sample of simulated draws to obtain the probability of \\(p \\geq 0.75\\). First a sample of \\(S = 1000\\) from the Beta posterior is taken, storing the results in the vector BetaSamples.\n\nS <- 1000\nBetaSamples <- rbeta(S, 15.06, 10.56)\n\nThe proportion of the 1000 simulated values of \\(p\\) that are at least 0.75 gives an approximation of the probability that \\(p \\geq 0.75\\).\n\nsum(BetaSamples >= 0.75) / S\n\n[1] 0.036\n\n\nThe simulation-based probability estimate is 0.037 which is an accurate approximation to the exact probability 0.04 obtained before.\nIt would be reasonable to question the choice of the number of simulations \\(S = 1000\\). One can change the simulation sample size to larger or smaller values as one sees fit. In general, the larger the value of \\(S\\), the more accurate the approximation. Figure 7.11 shows that the shape of a histogram of the simulated values of \\(p\\) approaches the exact posterior density as the value of \\(S\\) changes from 100 to 10,000. The corresponding simulation-based probabilities of \\(p \\geq 0.75\\) are \\(\\{0.02, 0.05, 0.033, 0.0422\\}\\) indicating that the accuracy of the approximation improves for larger simulation sample sizes.\n\n\n\n\n\nHistograms of simulated draws from Beta(15.06, 10.56) with the exact Beta density overlaid for four different number of samples drawn where \\(S\\) = {10, 500, 1000, 10000}.\n\n\n\n\nOne will observe variation from one simulation from another (see the two different but similar approximated probabilities 0.037 and 0.033 when \\(S = 1000\\)). To replicate one’s results one specifies the seed of the random number simulator set.seed(). Choose any number that you like to put in – if this set.seed() line of code is executed first, then the same sequence of random values will be generated and one replicates the simulation-based computation.\n\n\n1.5.2 Bayesian credible intervals\nAnother type of inference is a Bayesian credible interval, an interval that one is confident contains \\(p\\). Such an interval provides an uncertainty estimate for the parameter \\(p\\). A 90% Bayesian credible interval is an interval that contains 90% of the posterior probability.\nOne convenient 90% credible interval is the “equal tails” interval that contains the middle 90% of the probability content. The function beta_interval() in ProbBayes R package illustrates and computes the equal-tails interval. The shaded area in Figure 7.12 corresponds to \\(90\\%\\) of the posterior probability. The probability \\(p\\) falls between 0.427 and 0.741 is exactly 90 percent.\nbeta_interval(0.9, c(15.06, 10.56))\n\n\n\n\n\nDisplay of 90% probability interval for the proportion \\(p\\).\n\n\n\n\nOne obtains this middle 90% credible interval using the qbeta() function.\n\nqbeta(c(0.05, 0.95), 15.06, 10.56)\n\n[1] 0.4266788 0.7410141\n\n\nThis Bayesian credible interval differs from the interpretation of a traditional confidence interval. With a traditional confidence interval, one does not have confidence that one particular interval will contain \\(p\\). Instead 90% confidence refers to the average coverage of the interval in repeated sampling.\nOther types of Bayesian credible intervals can be computed. For example, instead of a credible interval covering the middle 90% of the posterior probability, one could create a credible interval covers the lower 90%, or the upper 90%, or the middle 95%. The qbeta() function is helpful in achieving all of these different type of intervals, as long as we know the exact posterior distribution, that is, the two shape parameters of the posterior Beta distribution. For example, the following code computes a credible interval that covers the lower 90% of the posterior distribution.\n\nqbeta(c(0.00, 0.90), 15.06, 10.56)\n\n[1] 0.0000000 0.7099912\n\n\nAn alternative way of creating credible intervals is by simulation. One first takes a random sample from the \\(\\textrm{Beta}(15.06, 10.56)\\) distribution, then summarizes the simulated values by finding the two cutoff points of the middle 90% of the sample. The quantile() function is useful for this purpose. As a demonstration, below we simulate \\(S = 1000\\) proportion values and compute the credible interval.\n\nS <- 1000\nBetaSamples <- rbeta(S, 15.06, 10.56)\nquantile(BetaSamples, c(0.05, 0.95))\n\n       5%       95% \n0.4225222 0.7419642 \n\n\nThe approximate middle 90% credible interval is [0.427, 0.733], which is close in value to the exact 90% credible interval [0.427, 0.741] computed using the qbeta() and beta_interval() functions. In an end-of-chapter exercise the reader is encouraged to practice and experiment with different values of the size of the simulated sample \\(S\\).\n\n\n1.5.3 Bayesian prediction\nPrediction is a typical task of Bayesian inference and statistical inference in general. Once we are able to make inference about the parameter in our statistical model, one may be interested in predicting future observations.\nDenote a new observation by the random variable \\(\\tilde{Y}\\). In particular, if the new survey is given to \\(m\\) students, the random variable \\(\\tilde{Y}\\) is the number of students preferring Friday to dine out out of the \\(m\\) respondents. If again the survey is given to a random sample, the random variable \\(\\tilde{Y}\\), conditional on \\(p\\), follows a Binomial distribution with the fixed total number of trails \\(m\\) and success probability \\(p\\). One’s knowledge about the location of \\(p\\) is expressed by the posterior distribution of \\(p\\).\nMathematically, to make a prediction of a new observation, one is asking for the distribution of \\(\\tilde{Y}\\) given the observed data \\(Y = y\\). That is, one is interested in the probability function \\(f(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\) where \\(\\tilde y\\) is a value of \\(\\tilde{Y}\\). But the conditional distribution of \\(\\tilde{Y}\\) given a value of the proportion \\(p\\) is Binomial(\\(m, p\\)) and the current beliefs about \\(p\\) are described by the posterior density. So one writes the joint density of \\(\\tilde{Y}\\) and \\(p\\) as the product \\[\\begin{eqnarray}\nf(\\tilde{Y}= \\tilde{y},  p \\mid Y = y) = f(\\tilde{Y} = \\tilde{y} \\mid p) \\pi(p \\mid Y = y).\n\\end{eqnarray}\\] By integrating out \\(p\\), one obtains the predictive distribution \\[\\begin{eqnarray}\nf(\\tilde{Y} = \\tilde{y} \\mid Y = y) = \\int  f(\\tilde{Y} =\\tilde{y} \\mid p) \\pi(p \\mid Y = y) dp.\n\\label{eq:Binomial:pred}\n\\end{eqnarray}\\]\nThe density of \\(\\tilde{Y}\\) given \\(p\\) is Binomial with \\(m\\) trials and success probability \\(p\\), and the posterior density of \\(p\\) is \\({\\rm Beta}(a + y, b + n - y)\\). After the substitution of densities and an integration step (see Appendix B for the detail), one finds that the predictive density is given by \\[\\begin{eqnarray}\nf(\\tilde{Y} =\\tilde{y}  \\mid Y = y) &=& {m \\choose \\tilde{y}}\n\\frac{B(a + y + \\tilde{y}, b  + n - y + m - \\tilde{y})}{B(a + y, b + n - y)}. \\nonumber \\\\\n\\end{eqnarray}\\] This is the Beta-Binomial distribution with parameters \\(m\\), \\(a + y\\) and \\(b + n - y\\). \\[\\begin{eqnarray}\n\\tilde{Y} \\mid Y = y \\sim \\textrm{Beta-Binomial}(m, a + y, b + n - y).\n\\end{eqnarray}\\] To summarize, Bayesian prediction of a new observation is a Beta-Binomial distribution where \\(m\\) is the number of trials in the new sample, \\(a\\) and \\(b\\) are shape parameters from the Beta prior, and \\(y\\) and \\(n\\) are quantities from the data/likelihood.\nUsing this Beta-Binomial distribution in our example, one computes the predictive probability that \\(\\tilde y\\) students prefer Friday in a new survey of 20 students. We illustrate the use of the pbetap() function from the ProbBayes package. The inputs to pbetap() are the vector of Beta shape parameters \\((a, b)\\), the sample size 20, and the values of \\(\\tilde{y}\\) of interest.\n\na <- 15.06\nb <- 10.56\nprob <- pbetap(c(a, b), 20, 0:20)\npred_distribution <- data.frame(Y = 0:20, \n                                Probability = prob)\n\nprob_plot(pred_distribution,\n          Color = crcblue, Size = 4) +\n  theme(text=element_text(size=18))\n\n\n\n\n\nDisplay of the exact predictive distribution of the number of students \\(\\tilde y\\) favoring Friday in a future sample of 20.\n\n\n\n\nThese predictive probabilities are displayed in Table 7.2 \\(\\ref{tab:predictive_dining}\\) and graphed in Figure 7.13.\nTable 7.2. Predictive distribution of the number of students preferring Friday in a future sample of 20.\n\n\n\nY\nProbability\nY\nProbability\n\n\n\n\n0\n0\n11\n0.127\n\n\n1\n0\n12\n0.134\n\n\n2\n0\n13\n0.127\n\n\n3\n0.001\n14\n0.108\n\n\n4\n0.004\n15\n0.080\n\n\n5\n0.010\n16\n0.052\n\n\n6\n0.021\n17\n0.028\n\n\n7\n0.037\n18\n0.012\n\n\n8\n0.059\n19\n0.004\n\n\n9\n0.085\n20\n0.001\n\n\n10\n0.109\n\n\n\n\n\nLooking at the table, the most likely number of students preferring Friday is 12. Just as in the inference situation, it is desirable to construct an interval that will contain \\(\\tilde Y\\) with a high probability. Suppose the desired probability content is 0.90. One constructs this prediction interval by putting in the most likely values of \\(\\tilde Y\\) until the probability content of the set exceeds 0.90.\nThis method is implemented using the following command:\n\ndiscint(pred_distribution, .9)\n\n$prob\n[1] 0.9185699\n\n$set\n [1]  7  8  9 10 11 12 13 14 15 16\n\n\nOne therefore finds that \\[\nProb(7 \\le \\tilde Y \\le 16) = 0.919.\n\\]\nThis exact predictive distribution is based on the posterior distribution of \\(p\\), as one uses \\(\\pi(p \\mid Y=y)\\) in the integration process in Equation (7.14). For that reason this predictive distribution is called the posterior predictive distribution. There also exists a prior predictive distribution, a topic we will briefly introduce in Section 7.6.\nIn situations where it is difficult to derive the exact predictive distribution, one simulates values from this distribution. One implements this predictive simulation by first simulating draws of the parameter (in this case the proportion \\(p\\)) from its posterior distribution, and then simulating values of the future observation (e.g. the new observation \\(\\tilde{Y}\\)) from the sampling density (here the Binomial distribution).\nWe illustrate this simulation procedure with the generic Beta posterior \\(\\textrm{Beta}(a + y, b + n - y)\\). To simulate a single draw from the predictive distribution, one first simulates a single proportion value \\(p\\) from the Beta posterior and then simulates a new data point \\(\\tilde{y}\\) (the number of successes out of \\(m\\) trials) from a Binomial distribution with sample size \\(m\\) and probability of success given by the simulated draw of \\(p\\). \\[\\begin{eqnarray*}\n\\text{sample}\\,\\, p \\sim {\\rm{Beta}}(a + y, b + n - y) &\\rightarrow& \\text{sample}\\,\\, \\tilde{Y} \\sim {\\rm{Binomial}}(m, p)\n\\end{eqnarray*}\\]\n This process of simulating a single draw is implemented by the rbeta() and rbinom() functions. Let \\(m = n\\) (the size of the future sample is the same as the size of the observed sample).\n\na <- 3.06; b <- 2.56\nn <- 20; y <- 12\npred_p_sim <- rbeta(1, a + y, b + n - y)\n(pred_y_sim <- rbinom(1, n, pred_p_sim))\n\n[1] 14\n\n\nDue to the ability of R to work easily with vectors, ]the same code is essentially used for simulating \\(S = 1000\\) draws from the predictive distribution.\nIn the following R script, pred_p_sim contains 1000 simulated draws from the posterior, and for each element of this posterior sample, the rbinom() function is used to simulate a corresponding value of \\(\\tilde Y\\) from the Binomial sampling density.\n\na <- 3.06; b <- 2.56\nn <- 20; y <- 12\nS <- 1000\npred_p_sim <- rbeta(S, a + y, b + n - y)\npred_y_sim <- rbinom(S, n, pred_p_sim)\n\nFigure 7.14 displays predictive probabilities for the number of students who prefer Fridays using the exact Beta-Binomial and simulation methods. One observes good agreement using these two computation methods.\n\n\n\n\n\nDisplay of the exact and simulated predictive probabilities for dining example.\n\n\n\n\nFor example, using the simulated values of \\(\\tilde Y\\) one finds that \\[\nProb(6 \\le \\tilde Y \\le 15) = 0.927\n\\] which is close in value to the range \\(Prob(7 \\le \\tilde Y \\le 16) = 0.919\\) found using the exact predictive distribution.\n\na <- 15.06\nb <- 10.56\nprob <- pbetap(c(a, b), 20, 0:20)\npred_distribution <- data.frame(Y = 0:20, \n                                Probability = prob)\ndiscint(pred_distribution, .9)\n\n$prob\n[1] 0.9185699\n\n$set\n [1]  7  8  9 10 11 12 13 14 15 16"
  },
  {
    "objectID": "proportion.html#predictive-checking",
    "href": "proportion.html#predictive-checking",
    "title": "1  Learning About a Binomial Probability",
    "section": "1.6 Predictive Checking",
    "text": "1.6 Predictive Checking\nIn the previous section, the use of the predictive distribution has been illustrated in learning about future data. This is more precisely described as the posterior predictive density as one is obtaining this density by integrating the sampling density \\(f(\\tilde Y = \\tilde y \\mid p)\\) over the posterior density \\(\\pi(p \\mid y)\\).\nThe prior predictive density is also useful in model checking. In a Bayesian model where \\(p\\) has a prior \\(\\pi(p)\\) and \\(Y\\) has a sampling density \\(f(Y = y \\mid p)\\), one writes the joint density of \\((p, Y)\\) as the product of the sampling density and the prior: \\[\\begin{eqnarray}\nf(p, Y = y) = f(Y = y \\mid p) \\pi(p).\n\\end{eqnarray}\\] Suppose one conditions on \\(y\\) instead of \\(p\\) and then one obtains an alternative representation of the joint density: \\[\\begin{eqnarray}\nf(p, Y = y) = \\pi(p \\mid Y = y) f(Y = y).\n\\end{eqnarray}\\] The first term in this product, the density \\(\\pi(p \\mid Y = y)\\), is the posterior density of \\(p\\) given the observation \\(y\\); this density is useful for performing inference about the proportion. The second term in this product is the density \\(f(Y = y)\\) is the prior predictive density – this represents the density of future data before the observation \\(y\\) is taken. If the actual observation denoted by \\(y_{obs}\\) is not consistent with the prior predictive density \\(f(Y = y)\\), this indicates some problem with the Bayesian model. Basically, this says that the observed data is unlikely to happen if one simulates predictions of data from our model.\nTo illustrate the use of prior predictive checking, recall that the restaurant owner assigned a Beta(3.06, 2.56) prior to the proportion \\(p\\) of students dining on Friday. A sample of 20 students will be taken. Based on this information, one computes the predictive probability \\(f(Y = y)\\) of \\(y\\) students preferring Friday dining of the sample of 20. This predictive distribution for all possible values of \\(y\\) is displayed in Figure 7.15. Recall that we actually observed \\(y_{obs} = 12\\) Friday diners — this value is shown in Figure 7.15 as a large black dot. This value is in the middle of the distribution – the takeaway is that the observed data is consistent with predictions from the owner’s Bayesian model.\n\n\n\n\n\nPrior predictive distribution of \\(y\\) using the owner’s Beta prior. The observed number of \\(y\\) id indicated with a large black dot. In this case the observed data is consistent with the Bayesian model.\n\n\n\n\nIn contrast, suppose another restaurant worker is more pessimistic about the likelihood of students dining on Friday. This worker’s prior median of the proportion \\(p\\) is 0.2 and her 90th percentile is 0.4 — this information is matched with a Beta prior with shape parameters 2.07 and 7.32. Figure 7.16 displays the predictive density of the number of Friday diners of a sample of 20 using this worker’s prior. Here one reaches a different conclusion. The observed number 12 of Friday diners is in the tail of this predictive distribution — this observation is not consistent with predictions from the Bayesian model. In closer examination, one sees conflict between the information in the worker’s prior and the data — her prior said that the proportion \\(p\\) was close to 0.20 and the data result (12 out of 20 successes) indicates that the proportion is close to 0.60. Predictive checking is helpful in this case in detecting this prior/data conflict.\n\n\n\n\n\nPrior predictive distribution of \\(y\\) using a worker’s Beta prior. The observed number of \\(y\\) is indicated by a large black dot. In this case the observed data is not consistent with the Bayesian model.\n\n\n\n\n\n1.6.1 Comparing Bayesian models\nThe prior predictive distribution is also useful in comparing two Bayesian models. To illustrate model comparison, suppose a second worker at the restaurant is also asked about the fraction of students who dine on Friday. He knows that the owner’s belief about the proportion \\(p\\) is described by a Beta(3.06, 2.56) density, and the fellow worker’s belief about \\(p\\) is represented by a Beta(2.07, 7.32) density. Who should the second worker believe?\nSuppose this second worker believes that both the owner’s and fellow worker’s beliefs about the proportion \\(p\\) are equally plausible. So he places a probability of 0.5 on the Beta(3.06, 2.56) prior and a probability of 0.5 on the Beta(2.07, 7.32) prior. This second worker’s prior \\(\\pi(p)\\) is written as the mixture \\[\\begin{eqnarray}\n\\pi(p) = q \\pi_1(p) + (1 - q) \\pi_2(p),\n\\end{eqnarray}\\] where \\(q = 0.5\\) and \\(\\pi_1\\) and \\(\\pi_2\\) denote the owner’s and worker’s Beta priors.\nNow one observes the survey data – \\(y\\) Fridays in a sample of size \\(n\\). Using the usual prior times likelihood procedure, the posterior density of \\(p\\) is proportional to the product \\[\\begin{eqnarray}\n\\pi(p \\mid Y = y) \\propto \\Big[q \\pi_1(p) + (1 - q) \\pi_2(p)\\Big] \\times\n{n \\choose y} p ^ {y }(1 - p) ^ {n - y}.\n\\end{eqnarray}\\] After some manipulation, one can show that the posterior density for the proportion \\(p\\) has the mixture form \\[\\begin{eqnarray}\n\\pi(p \\mid Y = y) = q(y) \\pi_1(p \\mid Y = y) + (1 - q(y)) \\pi_2(p \\mid Y = y).\n\\end{eqnarray}\\]\nThe posterior densities \\(\\pi_1(p \\mid y)\\) and \\(\\pi_2(p \\mid y)\\) are the familiar Beta forms. For example, \\(\\pi_1(p \\mid Y = y)\\) will be the Beta(3.06 + \\(y\\), 2.56 + \\(n - y\\)) posterior density combining the Beta(3.06, 2.56) prior and the sample data of \\(y\\) successes in a sample of size \\(n\\). Likewise, \\(\\pi_2(p \\mid Y = y)\\) will be the Beta density combining the worker’s Beta(2.07, 7.32) prior and the data.\nThe quantity \\(q(y)\\) represents the posterior probability of the owner’s prior. One expresses this probability as \\[\\begin{eqnarray}\nq(y) = \\frac{q f_1(Y = y)}{q f_1(Y = y) + (1 - q) f_2(Y =y)}\n\\end{eqnarray}\\] where \\(f_1(Y = y)\\) and \\(f_2(Y = y)\\) denote the predictive densities corresponding to the owner’s and worker’s priors. With a little algebra, one represents the posterior odds of the model probabilities as follows.\n\\[\\begin{eqnarray}\n\\frac{P(Prior \\, 1 \\mid Y = y)}{P(Prior \\, 2 \\mid Y = y)} = \\frac{q(y)}{1 - q(y)} = \\left[\\frac{q}{1 - q}\\right] \\left[\\frac{f_1(Y = y)}{f_2(Y = y)}\\right]\n\\end{eqnarray}\\]\nThe posterior odds of the owner’s prior \\(P(Prior \\, 1 \\mid Y = y) / P(Prior \\, 2 \\mid y = y)\\) is written as the product of two terms.\n\nThe ratio \\(q / (1 - q)\\) represents the prior odds of the owner’s prior.\nThe term \\(f_1(Y = y) / f_2(Y = y)\\), the ratio of the predictive densities, is called the Bayes factor. It reflects the relative abilities of the two priors to predict the observation \\(y\\).\n\nThe function binomial.beta.mix() is used to find the Bayes factor for our example. One inputs the prior probabilities of the two models (priors), and the vectors of Beta shape parameters that define the owner’s prior and the worker’s prior. The displayed output is the posterior odds value of 6.77.\n\nprobs <- c(0.5, 0.5)\nbeta_par1 <- c(3.06, 2.56)\nbeta_par2 <- c(2.07, 7.32)\nbeta_par <- rbind(beta_par1, beta_par2)\noutput <- binomial.beta.mix(probs, beta_par, c(12, 8))\n(posterior_odds <- output$probs[1] / output$probs[2])\n\nbeta_par1 \n 6.777823 \n\n\nSince the two priors are given equal probabilities, the prior odds \\(q / (1 - q)\\) is equal to one. In this case the posterior odds is equal to the Bayes factor. The interpretation is that for the given observation (12 successes in 20 trials), there is 6.77 times more support for the owner’s prior than for the worker’s prior. This conclusion is consistent with the earlier work that showed that the observed value of \\(y\\) was inconsistent with the Bayesian model for the worker’s prior.\n\n\n1.6.2 Posterior predictive checking\nAlthough the prior predictive distribution is useful in model checking, it has some disadvantages. One problem is that the distribution \\(f(Y = y)\\) may not exist in the situation where the prior \\(\\pi()\\) is not a proper probability distribution. We will see particular situations in future chapters where a vague or imprecise probability distribution is assigned as our prior and then the prior predictive distribution will not be well-defined. A related issue is that a prior may be assigned that may not accurately reflect one’s prior beliefs about a parameter. Small errors in the specification of the prior will result in errors in the prior predictive distribution. So there needs to be some caution in the use of the prior predictive distribution in assessing the goodness of the Bayesian model.\nAn alternative method of checking the suitability of a Bayesian model is based on the posterior predictive distribution. In this setting, one computes the posterior predictive distribution of a replicated dataset, that is a dataset of the same sample size as our observed sample. One sees if the observed value of \\(y\\) is in the middle of this predictive distribution. If this is true, then this means that the observed sample is consistent with predictions of replicated data. On the other hand, if the observed \\(y\\) is in the tails of the posterior distribution, this indicates some model misspecification which means that there is possibility some issue with the specified prior or sampling density.\nOne attractive aspect of the posterior prediction distribution is that replicated datasets is conveniently simulated. To simulate one replicated dataset, we first simulate a parameter from its posterior distribution, then simulate new data from the data model given the simulated parameter value. In the Beta-Binomial situation, the posterior of the proportion \\(p\\) is \\({{\\rm{Beta}}}(a + y, b + n - y)\\).\nTo simulate a new data point \\(\\tilde{Y} = \\tilde{y}\\), one first simulates a proportion value \\(p^{(1)}\\) from the Beta posterior and then simulate a new data point \\(\\tilde{y}^{(1)}\\) from a Binomial distribution with sample size \\(n\\) and probability of success \\(p^{(1)}\\). If we wish to obtain a sample of size \\(S\\) from the posterior predictive distribution, this process is repeated \\(S\\) times as showed in the following diagram. \\[\\begin{eqnarray*}\n\\text{sample}\\,\\, p^{(1)} \\sim {\\rm{Beta}}(a + y, b + n - y) &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(1)} \\sim {\\rm{Binomial}}(n, p^{(1)})\\\\\n\\text{sample}\\,\\, p^{(2)} \\sim {\\rm{Beta}}(a + y, b + n - y) &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(2)} \\sim {\\rm{Binomial}}(n, p^{(2)})\\\\\n&\\vdots& \\\\\n\\text{sample}\\,\\, p^{(S)} \\sim {\\rm{Beta}}(a + y, b + n - y) &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(S)} \\sim {\\rm{Binomial}}(n, p^{(S)})\n\\end{eqnarray*}\\] The sample \\(\\tilde{y}^{(1)}, ..., \\tilde{y}^{(S)}\\) is an approximation to the posterior predictive distribution that is used for model checking. In practice, one constructs a histogram of this sample and decides if the observed value of \\(y\\) is in the central portion of this predictive distribution. The reader will be given an opportunity to use this algorithm to see if the observed data is consistent with simulations of replicated data from this predictive distribution."
  },
  {
    "objectID": "mean.html#introduction",
    "href": "mean.html#introduction",
    "title": "2  Modeling Measurement and Count Data",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nWe first consider the general situation where there is a hypothetical population of individuals of interest and there is a continuous-valued measurement \\(Y\\) associated with each individual. One represents the collection of measurements from all individuals by means of a continuous probability density \\(f(y)\\). As discussed in Chapter 5, one summarizes this probability density with the mean \\(\\mu\\): \\[\\begin{equation}\n\\mu = \\int y f(y) dy.\n\\end{equation}\\] The value \\(\\mu\\) gives us a sense of the location of a typical value of the continuous measurement \\(Y\\).\nTo learn about the population of measurements, a random sample of individuals \\(Y_1, ..., Y_n\\) will be taken. The general inferential problem is to use these measurements together with any prior beliefs to learn about the population mean \\(\\mu\\). In other words, the goal is to use the collected measurements to learn about a typical value of the population of measurements."
  },
  {
    "objectID": "mean.html#modeling-measurements",
    "href": "mean.html#modeling-measurements",
    "title": "2  Modeling Measurement and Count Data",
    "section": "2.2 Modeling Measurements",
    "text": "2.2 Modeling Measurements\n\n2.2.1 Examples\n\nCollege applications\nHow many college applications does a high school senior in the United States complete? Here one imagines a population of all American high school seniors and the measurement is the number of completed college applications. The unknown quantity of interest is the mean number of applications \\(\\mu\\) completed by these high school seniors. The inferential question may be stated by asking, on average, how many college applications does an American high school senior complete. The answer to this question gives one a sense of the number of completed applications for a typical high school senior. To learn about the average \\(\\mu\\), it would be infeasible to collect this measurement from every high school senior in the U.S. Instead, a survey is typically conducted to a sample of high school seniors (ideally a sample representative of all American high school seniors) and based on the measurements from this sample, some inference is performed about the mean number of college applications.\n\n\nHousehold spending\nHow much does a household in San Francisco spend on housing every month? One visualizes the population of households in San Francisco and the continuous measurement is the amount of money spent on housing (either rent for renters and mortgage for homeowners) for a resident. One can ask “on average, how much does a household spend on housing every month in San Francisco?”, and the answer to this question gives one a sense of the housing costs for a typical household in San Francisco. To learn about the mean value of housing \\(\\mu\\) of all San Francisco residents, a sample survey is conducted. The mean value of the housing costs \\(\\bar y\\) from this sample of surveyed households is informative about the mean housing cost \\(\\mu\\) for all residents.\n\n\nWeights of cats\nSuppose you have a domestic shorthair cat weighing 14 pounds and you want to find out if she is overweight. One imagines a population of all domestic shorthair cats and the continuous measurement is the weight in pounds. Suppose you were able to compute the mean weight \\(\\mu\\) of all shorthair cats. Then by comparing 14 pounds (the weight of our cat) to this mean, you would know whether your cat is overweight, or underweight, or close to the mean. If we were able to find the distribution of the weights of all domestic shorthair cats, then one observes the proportion of weights smaller than 14 pounds in the distribution and learns if the cat is severely overweight. To learn if our cat is overweight, you can ask the vet. How does the vet know? Extensive research has been conducted periodically to record weights of a large sample of domestic shorthair cats, and by using these sample of weights, the vet performs an inference about the mean \\(\\mu\\) of the weights of all domestic shorthair cats.\n\n\nComment elements of an inference problem\nAll three examples have common elements:\n\nOne has an underlying population of measurements, where the measurement is an integer, such as the number of college applications, or continuous, such as a housing cost or a cat weight.\nOne is interested in learning about the value of the mean \\(\\mu\\) of the population of measurements.\nIt is impossible or impractical to collect all measurements from the population, so one will collect a sample of measurements \\(Y_1, ..., Y_n\\) and use the observed measurements to learn about the unknown population mean \\(\\mu\\).\n\n\n\n\n2.2.2 The general approach\nRecall the three general steps of Bayesian inference discussed in Chapter 7 in the context of an unknown proportion \\(p\\).\n\nStep 1: Prior We express an opinion about the location of the proportion \\(p\\) before sampling.\nStep 2: Data/Likelihood We take the sample and record the observed proportion.\nStep 3: Posterior We use Bayes’ rule to sharpen and update the previous opinion about \\(p\\) given the information from the sample.\n\nIn this setting, we have a continuous population of measurements that we represent by the random variable \\(Y\\) with density function \\(f(y)\\). It is convenient to assume that this population has a Normal shape with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). That is, a single measurement \\(Y\\) is assume to come from the density function \\[\\begin{equation}\nf(y) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{(y - \\mu)^2}{2 \\sigma^2}\\right\\}, -\\infty < y< \\infty.\n\\end{equation}\\] displayed in Figure 8.1. To simplify the discussion, it is convenient to assume that the standard deviation \\(\\sigma\\) of the measurement distribution is known. Then the objective is to learn about the single mean measurement \\(\\mu\\).\n\n\n\n\n\nNormal sampling density with mean \\(\\mu\\).\n\n\n\n\nStep 1 in Bayesian inference is to express an opinion about the parameter. In this continuous measurement setting, one constructs a prior for the mean parameter \\(\\mu\\) that expresses one’s opinion about the location of this mean. In this chapter, we discuss different ways to specify a prior distribution for \\(\\mu\\). One attractive discrete approach for expressing this prior opinion, similar to the approach in Chapter 7 for a proportion \\(p\\), has two steps. First one constructs a list of possible values of \\(\\mu\\), and then one assigns probabilities to the possible values to reflect one’s belief. Alternatively, we will describe the use of a continuous prior to represent one’s belief for \\(\\mu\\). This is a more realistic approach for constructing a prior since one typically views the mean as a real-valued parameter.\nStep 2 of our process is to collect measurements from a random sample to gain more information about the parameter \\(\\mu\\). In our first situation, one collects the number of applications from a sample of 100 high school seniors. In the second example, one collects a sample of 2000 housing costs, each from a sampled San Francisco household. The third example collects a sample of 200 different weights of domestic shorthair cats, each from a sampled cat. If these measurements are viewed as independent observations from a Normal sampling density with mean \\(\\mu\\), then one constructs a likelihood function which is the joint density of the sampled measurements viewed as a function of the unknown parameter.\nOnce the prior is specified and measurements have been collected, one proceeds to Step 3 to use Bayes’ rule to update one’s prior opinion to obtain a posterior distribution for the mean \\(\\mu\\). The algebraic implementation of Bayes’ rule is a bit more tedious when dealing with continuous data with a Normal sampling density. But we will see there is a simple procedure for computing the posterior mean and standard deviation.\n\n\n2.2.3 Outline of chapter\nThroughout this chapter, the entire inferential process is described for learning about a mean \\(\\mu\\) assuming a Normal sampling density for the measurements. This chapter discusses how to construct a prior distribution that matches one’s prior belief, how to extract information from the data by the likelihood function, and how to update one’s opinion in the posterior, combining the prior and data information in a natural way.\nSection 8.3 introduces inference with a discrete prior distribution for the mean \\(\\mu\\) and Section 8.4 introduces the continuous family of Normal prior distributions for the mean. The inferential process with a Normal prior distribution is described in detail in Section 8.5. Section 8.6 describes some general Bayesian inference methods in this Normal data/Normal prior setting, such as Bayesian hypothesis testing, Bayesian credible intervals and Bayesian prediction. These sections describe the use of both exact analytical solutions and approximation simulation-based calculations. Section 8.7 introduces the use of the posterior predictive distribution as a general tool for checking if the observed data is consistent with predictions from the Bayesian model.\nThe chapter concludes in Section 8.8 by introducing a popular one-parameter model for counts, the Poisson distribution, and its conjugate Gamma distribution for representing prior opinion. Although this section does not deal with the Normal mean situation, the exposure to the important Gamma-Poisson conjugacy will enhance our understanding and knowledge of the analytical process of combining the prior and likelihood to obtain the posterior distribution."
  },
  {
    "objectID": "mean.html#Normal:Discrete",
    "href": "mean.html#Normal:Discrete",
    "title": "2  Modeling Measurement and Count Data",
    "section": "2.3 Bayesian Inference with Discrete Priors",
    "text": "2.3 Bayesian Inference with Discrete Priors\n\n2.3.1 Example: Roger Federer’s time-to-serve\nRoger Federer is recognized as one of the greatest players in tennis history. One aspect of his play that people enjoy is his businesslike way of serving to start a point in tennis. Federer appears to be efficient in his preparation to serve and some of his service games are completed very quickly. One measures one’s service efficiency by the time-to-serve which is the measured time in seconds between the end of the previous point and the beginning of the current point.\nSince Federer is viewed as an efficient server, this raises the question: how long, on average, is Federer’s time-to-serve? We know two things about his time-to-serve measurements. First, since they are time measurements, they are continuous variables. Second, due to a number of other variables, the measurements will vary from serve to serve. Suppose one collects a single time-to-serve measurement in seconds. denoted as \\(Y\\). It seems reasonable to assume \\(Y\\) is Normally distributed with unknown mean \\(\\mu\\) and standard deviation \\(\\sigma\\). From previous data, we assume that the standard deviation is known and given by \\(\\sigma = 4\\) seconds.\nRecall the Normal probability curve has the general form\n\\[\\begin{equation}\nf(y) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{(y - \\mu)^2}{2 \\sigma^2}\\right\\}, -\\infty < y< \\infty.\n\\end{equation}\\] Since \\(\\sigma = 4\\) is known, the only parameter in Equation (8.3) is \\(\\mu\\). We are interested in learning about the mean time-to-serve \\(\\mu\\).\nA convenient first method of implementing Bayesian inference is by the use of a discrete prior. One specifies a subjective discrete prior for Federer’s mean time-to-serve by specifying a list of plausible values for \\(\\mu\\) and assigning a probability to each of these values.\nIn particular suppose one thinks that values of the equally spaced values \\(\\mu\\) = 15, 16, \\(\\cdots\\), 22 are plausible. In addition, one does not have any good reason to think that any of these values for the mean are more or less likely, so a Uniform prior will be assigned where each value of \\(\\mu\\) is assigned the same probability \\(\\frac{1}{8}\\). \\[\\begin{equation}\n\\pi(\\mu) = \\frac{1}{8}, \\, \\, \\, \\, \\mu = 15, 16, ..., 22.\n\\end{equation}\\] Each value of \\(\\mu\\) corresponds to a particular Normal sampling curve for the time-to-serve measurement. Figure 8.2 displays the eight possible Normal sampling curves. Our prior says that each of these eight sampling curves has the same prior probability.\n\n\n\n\n\n\n\n\nEight possible Normal sampling curves corresponding to a discrete Uniform prior on \\(\\mu\\).\n\n\n\n\nTo learn more about the mean \\(\\mu\\), one collects a single time-to-serve measurement for Federer, and suppose it is 15.1 seconds, that is, one observes \\(Y = 15.1\\). The likelihood function is the Normal density of the actual observation \\(y\\) viewed as a function of the mean \\(\\mu\\) (remember that it was assumed that \\(\\sigma = 4\\) was given). By substituting in the observation \\(y = 15.1\\) and the known value of \\(\\sigma = 4\\), one writes the likelihood function as\n\\[\\begin{eqnarray*}\nL(\\mu) = \\frac{1}{\\sqrt{2 \\pi} 4} \\exp\\left\\{- \\frac{1}{2 (4)^2}(15.1 - \\mu)^2\\right\\}.\n\\end{eqnarray*}\\]\nFor each possible value of \\(\\mu\\), we substitute the value into the likelihood expression. For example, the likelihood of \\(\\mu = 15\\) is equal to \\[\\begin{eqnarray*}\nL(15) &=& \\frac{1}{\\sqrt{2 \\pi} (4)} \\exp\\left(- \\frac{1}{2 (4)^2}(15.1 - 15)^2\\right) \\nonumber \\\\\n&\\approx & 0.0997.\n\\end{eqnarray*}\\] This calculation is repeated for each of the eight values \\(\\mu = 15, 16, \\cdots, 22\\), obtaining eight likelihood values.\nA discrete prior has been assigned to the list of possible values of \\(\\mu\\) and one is now able to apply Bayes’ rule to obtain the posterior distribution for \\(\\mu\\). The posterior probability of the value \\(\\mu = \\mu_i\\) given the data \\(y\\) for a discrete prior has the form \\[\\begin{equation}\n\\pi(\\mu_i \\mid y) = \\frac{\\pi(\\mu_i) \\times L(\\mu_i)}{\\sum_j \\pi(\\mu_j) \\times L(\\mu_j)},\n\\end{equation}\\] where \\(\\pi(\\mu_i)\\) is the prior probability of \\(\\mu = \\mu_i\\) and \\(L(\\mu_i)\\) is the likelihood function evaluated at \\(\\mu = \\mu_i\\).\nIf a discrete Uniform prior distribution for \\(\\mu\\) is assigned, one has \\(\\pi(\\mu_i) = \\frac{1}{8}\\) for all \\(i = 1, \\cdots, 8\\), and \\(\\pi(\\mu_i)\\) is canceled out from the numerator and denominator in Equation (8.5). In this case one calculates the likelihood values \\(L(\\mu_i)\\) for all \\(i = 1, \\cdots, 8\\) and normalizes these values to obtain the posterior probabilities \\(\\pi(\\mu_i \\mid y)\\). Table 8.1 displays the values of \\(\\mu\\) and the corresponding values of Prior, Data/Likelihood, and Posterior. Readers are encouraged to verify the results shown in the table.\nTable 8.1. Value, prior, data/likelihood and posterior for () with a single observation.\n\n\n\n()\nPrior\nData/Likelihood\nPosterior\n\n\n\n\n15\n0.125\n0.0997\n0.1888\n\n\n16\n0.125\n0.0972\n0.1842\n\n\n17\n0.125\n0.0891\n0.1688\n\n\n18\n0.125\n0.0767\n0.1452\n\n\n19\n0.125\n0.0620\n0.1174\n\n\n20\n0.125\n0.0471\n0.0892\n\n\n21\n0.125\n0.0336\n0.0637\n\n\n22\n0.125\n0.0225\n0.0427\n\n\n\nWith the single measurement of time-to-serve of \\(y = 15.1\\), one sees from Table 8.1 that the posterior distribution for \\(\\mu\\) favors values \\(\\mu\\) = 15, and 16. In fact, the posterior probabilities decrease as a function of \\(\\mu\\). The Prior column reminds us that the prior distribution is Uniform. Bayesian inference uses the collected data to sharpen one’s belief about the unknown parameter from the prior distribution to the posterior distribution. For this single observation, the sample mean is \\(y = 15.1\\) and the \\(\\mu\\) value closest to the sample mean (\\(\\mu = 15\\)) is assigned the highest posterior probability.\nTypically one collects multiple time-to-serve measurements. Suppose one collects \\(n\\) time-to-serve measurements, denoted as \\(Y_1, ..., Y_n\\), that are Normally distributed with mean \\(\\mu\\) and fixed standard deviation \\(\\sigma = 4\\). Each observation follows the same Normal density \\[\\begin{equation}\nf(y_i) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{\\frac{-(y_i - \\mu)^2}{2 \\sigma^2}\\right\\}, -\\infty < y_i < \\infty.\n\\end{equation}\\] Again since \\(\\sigma = 4\\) is known, the only parameter in Equation (8.6) is \\(\\mu\\) and we are interested in learning about this mean parameter \\(\\mu\\). Suppose the same discrete Uniform prior is used as in Equation (8.4) and graphed in Figure 8.2. The mean \\(\\mu\\) takes on the values \\(\\{15, 16, \\cdots, 22\\}\\) with each value assigned the same probability of \\(\\frac{1}{8}\\).\nSuppose one collects a sample of 20 times-to-serve for Federer:\n\n15.1 11.8 21.0 22.7 18.6 16.2 11.1 13.2 20.4 19.2 \n21.2 14.3 18.6 16.8 20.3 19.9 15.0 13.4 19.9 15.3\n\nWhen multiple time-to-serve measurements are taken, the likelihood function is the joint density of the actual observed values \\(y_1, ..., y_n\\) viewed as a function of the mean \\(\\mu\\). After some algebra (detailed derivation in Section 8.3.2), one writes the likelihood function as \\[\\begin{eqnarray}\nL(\\mu) & = &\\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{1}{2 \\sigma^2}(y_i - \\mu)^2\\right\\} \\nonumber \\\\\n& \\propto &\\exp\\left\\{-\\frac{n}{2 \\sigma^2}(\\bar y - \\mu)^2\\right\\} \\nonumber \\\\\n& = & \\exp\\left\\{-\\frac{20}{2 (4)^2}(\\bar y - \\mu)^2\\right\\} ,\n\\end{eqnarray}\\] where we have substituted the known values \\(n = 20\\) and the standard deviation \\(\\sigma = 4\\). From our sample, we compute the sample mean \\(\\bar y = (15.1 + 11.8 + ... + 15.3) / 20 = 17.2\\). The value of \\(\\bar y\\) is substituted into Equation (8.7), and for each possible value of \\(\\mu\\), we substitute the value to find the corresponding likelihood. For example, the likelihood of \\(\\mu = 15\\) is equal to \\[\\begin{align*}\nL(15) & = \\exp\\left\\{-\\frac{20}{2 (4)^2}(17.2 - 15)^2\\right\\} \\nonumber \\\\\n& \\approx 0.022.\n\\end{align*}\\] This calculation is repeated for each of the eight values \\(\\mu = 15, 16, ..., 22\\), obtaining eight likelihood values.\nOne now applies Bayes’ rule to obtain the posterior distribution for \\(\\mu\\). The posterior probability of \\(\\mu = \\mu_i\\) given the sequence of recorded times-to-serve \\(y_1, \\cdots, y_n\\) has the form \\[\\begin{equation}\n\\pi(\\mu_i \\mid y_1, \\cdots, y_n) = \\frac{\\pi(\\mu_i) \\times L(\\mu_i)}{\\sum_j \\pi(\\mu_j) \\times L(\\mu_j)},\n\\end{equation}\\] where \\(\\pi(\\mu_i)\\) is the prior probability of \\(\\mu = \\mu_i\\) and \\(L(\\mu_i)\\) is the likelihood function evaluated at \\(\\mu = \\mu_i\\). We saw in equation @ref(eq:normaldiscretejointlikelihood) that only the sample mean, \\(\\bar{y}\\), is needed in the calculation of the likelihood, so \\(\\bar{y}\\) is used in place of \\(y_1, \\cdots, y_n\\) in the formula.\nWith a discrete Uniform prior distribution for \\(\\mu\\), again one has \\(\\pi(\\mu_i) = \\frac{1}{8}\\) for all \\(i = 1, \\cdots, 8\\) and \\(\\pi(\\mu_i)\\) is canceled out from the numerator and denominator in Equation (8.8). One calculates the posterior probabilities by computing \\(L(\\mu_i)\\) for all \\(i = 1, \\cdots, 8\\) and normalizing these values. Table 8.2 displays the values of \\(\\mu\\) and the corresponding values of Prior, Data/Likelihood, and Posterior. Readers are encouraged to verify the results shown in the table.\nTable 8.2. Value, prior, data/likelihood, and posterior for () with (n) observations.\n\n\n\n()\nPrior\nData/Likelihood\nPosterior\n\n\n\n\n15\n0.125\n0.0217\n0.0217\n\n\n16\n0.125\n0.1813\n0.1815\n\n\n17\n0.125\n0.4350\n0.4353\n\n\n18\n0.125\n0.2990\n0.2992\n\n\n19\n0.125\n0.0589\n0.0589\n\n\n20\n0.125\n0.0033\n0.0033\n\n\n21\n0.125\n0.0001\n0.0001\n\n\n22\n0.125\n0.0000\n0.0000\n\n\n\nIt is helpful to construct a graph (see Figure 8.3) where one contrasts the prior and probability probabilities for the mean time-to-serve \\(\\mu\\). While the prior distribution is flat, the posterior distribution for \\(\\mu\\) favors the values \\(\\mu\\) = 16, 17, and 18 seconds. Bayesian inference uses the observed data to revise one’s belief about the unknown parameter from the prior distribution to the posterior distribution. Recall that the sample mean \\(\\bar{y}\\) = 17.2 seconds. From Table 8.2 and Figure 8.3 one sees the clear effect of the observed sample mean – \\(\\mu\\) is likely to be close to the value 17.2.\n\n\n\n\n\nPrior and posterior probabilities of the Normal mean \\(\\mu\\) with a sample of observations.\n\n\n\n\n\n\n2.3.2 Simplification of the likelihood\nThe likelihood function is the joint density of the observations \\(y_1, ..., y_n\\), viewed as a function of the mean \\(\\mu\\) (since \\(\\sigma=4\\) is given). With \\(n\\) observations being identically and independently distributed (i.i.d.) as \\({\\rm{Normal}}({\\mu, 4})\\), the likelihood function is the product of Normal density terms. In the algebra work that will be done shortly, the likelihood, as a function of \\(\\mu\\), is found to be Normal with mean \\(\\bar y\\) and standard deviation \\(\\sigma / \\sqrt{n}\\).\nThe calculation of the posterior probabilities is an application of Bayes’ rule illustrated in earlier chapters. One creates a data frame of values mu and corresponding probabilities Prior. One computes the likelihood values in the variable Likelihood and the posterior probabilities are found using the bayesian_crank() function.\n\ndf <- data.frame(mu = seq(15, 22, 1),\n                 Prior = rep(1/8, 8)) %>% \n  mutate(Likelihood = dnorm(mu, 17.2, 4 / sqrt(20))) \n\ndf <- bayesian_crank(df) \nround(df, 4)\n\n  mu Prior Likelihood Product Posterior\n1 15 0.125     0.0217  0.0027    0.0217\n2 16 0.125     0.1813  0.0227    0.1815\n3 17 0.125     0.4350  0.0544    0.4353\n4 18 0.125     0.2990  0.0374    0.2992\n5 19 0.125     0.0589  0.0074    0.0589\n6 20 0.125     0.0033  0.0004    0.0033\n7 21 0.125     0.0001  0.0000    0.0001\n8 22 0.125     0.0000  0.0000    0.0000\n\n\n\nDerivation of \\(L(\\mu) \\propto \\exp \\left(-\\frac{n}{2 \\sigma^2}(\\bar{y} - \\mu)^2\\right)\\)\nIn the following, we combine the terms in the exponent, expand all of the summation terms, and complete the square to get the result.\n\\[\\begin{eqnarray}\nL(\\mu) &=&  \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{1}{2 \\sigma^2}(y_i - \\mu)^2\\right\\}  \\nonumber \\\\\n       &=& \\left(\\frac{1}{\\sqrt{2 \\pi}\\sigma}\\right)^n \\exp\\left\\{-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2\\right\\}\\nonumber \\\\\n&\\propto& \\exp \\left\\{ -\\frac{1}{2 \\sigma^2} \\sum_{i=1}^{n} (y_i^2 - 2\\mu y_i + \\mu^2)\\right\\} \\nonumber \\\\\n\\texttt{[expand the $\\sum$ terms]} &=& \\exp \\left\\{ -\\frac{1}{2 \\sigma^2} \\left( \\sum_{i=1}^{n} y_i^2 - 2\\mu \\sum_{i=1}^{n} y_i + n\\mu^2 \\right) \\right\\} \\nonumber \\\\\n&\\propto& \\exp \\left\\{- \\frac{1}{2 \\sigma^2} \\left(-2 \\mu \\sum_{i=1}^{n} y_i + n \\mu^2 \\right) \\right\\}\\nonumber \\\\\n\\texttt{[replace $\\sum$ with $n\\bar{y}$]} &=& \\exp \\left\\{ - \\frac{1}{2 \\sigma^2} \\left(-2 n \\mu \\bar{y} + n \\mu^2 \\right) \\right\\}\\nonumber \\\\\n\\texttt{[complete the square]} &=& \\exp \\left\\{ -\\frac{n}{2 \\sigma^2} (\\mu^2 - 2\\mu \\bar{y} + \\bar{y}^2) + \\frac{n}{2 \\sigma^2} \\bar{y}^2\\right\\} \\nonumber \\\\\n&\\propto& \\exp \\left\\{-\\frac{n}{2 \\sigma^2}(\\bar{y} - \\mu)^2\\right\\}\n\\end{eqnarray}\\]\n\n\nSufficient statistic\nThere are different ways of writing and simplifying the likelihood function. One can choose to keep the product sign and each \\(y_i\\) term, and leave the likelihood function as \\[\\begin{equation}\nL(\\mu) =  \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{1}{2 \\sigma^2}(y_i - \\mu)^2\\right\\}.\n\\end{equation}\\] Doing so requires one to calculate the individual likelihood from each time-to-serve measurement \\(y_i\\) and multiply these values to obtain the function \\(L(\\mu)\\) used to obtain the posterior probability.\nIf one instead simplifies the likelihood to be \\[\\begin{equation}\nL(\\mu) \\propto \\exp \\left\\{-\\frac{n}{2 \\sigma^2}(\\bar{y} - \\mu)^2\\right\\},\n\\end{equation}\\] all the proportionality constants drop out in the calculation of the posterior probabilities for different values of \\(\\mu\\). In the application of Bayes’ rule, one only needs to know the number of observations \\(n\\) and the mean time to serve \\(\\bar{y}\\) to calculate the posterior. Since the likelihood function depends on the data only through the value \\(\\bar{y}\\), the statistic \\(\\bar{y}\\) is called a sufficient statistic for the mean \\(\\mu\\).\n\n\n\n2.3.3 Inference: Federer’s time-to-serve\nWhat has one learned about Federer’s mean time-to-serve from this Bayesian analysis? Our prior said that any of the eight possible values of \\(\\mu\\) were equally likely with probability \\(0.125\\). After observing the sample of 20 measurements, one believes \\(\\mu\\) is most likely \\(16\\), 17, and \\(18\\) seconds, with respective probabilities \\(0.181, 0.425\\), and \\(0.299\\). In fact, if one adds up the posterior probabilities, one says that \\(\\mu\\) is in the set {16, 17, 18} seconds with probability \\(0.915\\). \\[\\begin{eqnarray*}\nProb(16 \\leq \\mu \\leq 18) = 0.181 + 0.435 + 0.299 = 0.915\n\\end{eqnarray*}\\] This region of values of \\(\\mu\\) is called a \\(91.5\\%\\) posterior probability region for the mean time-to-serve \\(\\mu\\)."
  },
  {
    "objectID": "mean.html#Normal:Continuous",
    "href": "mean.html#Normal:Continuous",
    "title": "2  Modeling Measurement and Count Data",
    "section": "2.4 Continuous Priors",
    "text": "2.4 Continuous Priors\n\n2.4.1 The Normal prior for mean \\(\\mu\\)\nReturning to our example, one is interested in learning about the time-to-serve for the tennis player Roger Federer. His serving times are believed to be Normally distributed with unknown mean \\(\\mu\\) and known standard deviation \\(\\sigma = 4\\). The focus is on learning about the mean value \\(\\mu\\).\nIn the prior construction in Section 8.3, we assumed \\(\\mu\\) was discrete, taking only integer values from \\(15\\) to \\(22\\). However, the mean time-to-serve \\(\\mu\\) does not have to be an integer. In fact, it is more realistic to assume \\(\\mu\\) is continuous-valued. One widely-used approach for representing one’s belief about a Normal mean is based on a Normal prior density with mean \\(\\mu_0\\) and standard deviation \\(\\sigma_0\\), that is \\[\\begin{eqnarray*}\n\\mu \\sim {\\rm{Normal}}(\\mu_0, \\sigma_0).\n\\end{eqnarray*}\\]\nThere are two parameters for this Normal prior: the value \\(\\mu_0\\) represents one’s “best guess” at the mean time-to-serve \\(\\mu\\) and \\(\\sigma_0\\) indicates how sure one thinks about the guess.\nTo illustrate the use of different priors for \\(\\mu\\), let’s consider the opinion of one tennis fan Joe who has strong prior information about the mean. His best guess at Federer’s mean time-to-serve is 18 seconds so he lets \\(\\mu_0 = 18\\). He is very sure of this guess and so he chooses \\(\\sigma_0\\) to be the relatively small value of \\(0.4\\). In contrast, a second tennis fan Kate also thinks that Federer’s mean time-to-serve is 18 seconds, but does not have a strong belief in this guess and chooses the large value \\(2\\) of the standard deviation \\(\\sigma_0\\). Figure 8.4 shows these two Normal priors for the mean time-to-serve \\(\\mu\\).\n\n\n\n\n\nTwo priors for the Normal mean \\(\\mu\\).\n\n\n\n\nBoth curves are symmetric and bell-shaped, centered at \\(\\mu_0\\) = 18. The main difference is the spread of the two curves: a Normal(8, 0.4) curve is much more concentrated around the mean \\(\\mu_0\\) = 18 compared to the Normal(8, 2) curve. Since the value of the probability density function at a point reflects the probability at that value, the Normal(8, 0.4) prior reflects the belief that the mean time to serve will most likely be around \\(\\mu_0\\) = 18 seconds, whereas the Normal(8, 2) prior indicates that the mean \\(\\mu\\) could be as small as 15 seconds and as large as 20 seconds.\n\n\n2.4.2 Choosing a Normal prior\n\nInformative prior\nHow does one in practice choose a Normal prior for \\(\\mu\\) that reflects prior beliefs about the location of this parameter? One indirect strategy for choosing for selecting values of the prior parameters \\(\\mu_0\\) and \\(\\sigma_0\\) is based on the specification of quantiles. On the basis of one’s prior beliefs, one specifies two quantiles of the Normal density. Then the Normal parameters are found by matching these two quantiles to a particular Normal curve.\nRecall the definition of a quantile — in this setting it is a value of the mean \\(\\mu\\) such that the probability of being smaller than that value is a given probability. To construct one’s prior for Federer’s mean time-to-serve, one thinks first about two quantiles. Suppose one specifies the 0.5 quantile to be 18 seconds — this means that \\(\\mu\\) is equally likely to be smaller or larger than 18 seconds. Next, one decides that the 0.9 quantile is 20 seconds. This means that one’s probability that \\(\\mu\\) is smaller than 20 seconds is 90%. Given values of these two quantiles, the unique Normal curve is found that matches this information.\nThe matching is performed by the R function normal.select(). One inputs two quantiles by ```list} statements, and the output is the mean and standard deviation of the Normal prior.\n\nnormal.select(list(p = 0.5, x = 18), list(p = 0.9, x = 20))\n\n$mu\n[1] 18\n\n$sigma\n[1] 1.560608\n\n\nThe Normal curve with mean \\(\\mu_0 = 18\\) and \\(\\sigma_0 = 1.56\\), displayed in Figure 8.5, matches the prior information stated by the two quantiles.\n\n\n\n\n\nA person’s Normal prior for Federer’s mean time-to-serve \\(\\mu\\).\n\n\n\n\nSince our measurement skills are limited, this prior is just an approximation to one’s beliefs about \\(\\mu\\). We recommend in practice that one perform several checks to see if this Normal prior makes sense. Several functions are available to help in this prior checking.\nFor example, one finds the 0.25 quantile of our prior using the qnorm() function.\n\nqnorm(0.25, 18, 1.56)\n\n[1] 16.9478\n\n\nThis prior says that the prior probability that \\(\\mu\\) is smaller than 16.95 is 25%. If this does not seem reasonable, one would make adjustments in the values of the Normal mean and standard deviation until a reasonable Normal prior is found.\n\n\nWeekly informative prior\nWe have been assuming that one has some information about the mean parameter \\(\\mu\\) that is represented by a Normal prior. What would a user do in the situation where little is known about the location on \\(\\mu\\)? For a Normal prior, the standard deviation \\(\\sigma_0\\) represents the sureness of one’s belief in one’s guess \\(\\mu_0\\) at the value of the mean. If one is really unsure about any guess at \\(\\mu\\), then one assigns the standard deviation \\(\\sigma_0\\) a large value. Then the choice of the prior mean will not matter, so we suggest using a Normal(0, \\(\\sigma_0\\)) with a large value for \\(\\sigma_0\\). This prior indicates that \\(\\mu\\) may plausibly range over a large interval and represents weakly informative prior belief about the parameter.\nAs will be seen later in this chapter, when a vague prior is chosen, the posterior inference for \\(\\mu\\) will largely be driven by the data. This behavior is desirable since this person knows little about the location of \\(\\mu\\) a priori in this situation and wants the data to inform about the location of \\(\\mu\\) with little influence by the prior."
  },
  {
    "objectID": "mean.html#Normal:ContinuousUpdate",
    "href": "mean.html#Normal:ContinuousUpdate",
    "title": "2  Modeling Measurement and Count Data",
    "section": "2.5 Updating the Normal Prior",
    "text": "2.5 Updating the Normal Prior\n\n2.5.1 Introduction\nContinuing our discussion on learning about the mean time-to-serve for Roger Federer, the current prior beliefs about Federer’s mean time-to-serve \\(\\mu\\) are represented by a Normal curve with mean \\(18\\) seconds and standard deviation 1.56 seconds.\nNext some data is collected — Federer’s time-to-serves are recorded for 20 serves and the sample mean is \\(17.2\\) seconds. Recall that we are assuming the population standard deviation \\(\\sigma = 4\\) seconds. The likelihood is given by \\[\\begin{equation}\nL(\\mu) \\propto \\exp \\left\\{-\\frac{n}{2 \\sigma^2}(\\bar{y} - \\mu)^2\\right\\},\n\\end{equation}\\] and with substitution of the values \\(\\bar y = 17.2\\), \\(n = 20\\), and \\(\\sigma = 4\\), we obtain \\[\\begin{eqnarray}\nL(\\mu) &\\propto& \\exp \\left\\{-\\frac{20}{2 (4)^2}(17.2 - \\mu)^2\\right\\} \\nonumber \\\\\n&=& \\exp \\left\\{-\\frac{1}{2(4/\\sqrt{20})^2}(\\mu - 17.2)^2\\right\\}.\n\\end{eqnarray}\\] Viewing the likelihood as a function of the parameter \\(\\mu\\) as in Equation (8.13), the likelihood is recognized as a Normal density with mean \\(\\bar y = 17.2\\) and standard deviation \\(\\sigma / \\sqrt{n} = 4 / \\sqrt{20} = 0.89\\).\nThe Bayes’ rule calculation is very familiar to the reader — one obtains the posterior density curve by multiplying the Normal prior by the likelihood. If one writes down the product of the Normal likelihood and the Normal prior density and works through some messy algebra, one will discover that the posterior density also has the Normal density form.\nThe Normal prior is said to be conjugate since the prior and posterior densities come from the same distribution family: Normal. To be more specific, suppose the observation has a Normal sampling density with unknown mean \\(\\mu\\) and known standard deviation \\(\\sigma\\). If one specifies a Normal prior for the unknown mean \\(\\mu\\) with mean \\(\\mu_0\\) and standard deviation \\(\\sigma_0\\), one obtains a Normal posterior for \\(\\mu\\) with updated parameters \\(\\mu_n\\) and \\(\\sigma_n\\).\nIn Section 8.5.2, we provide a quick peak at this posterior updating without worrying about the mathematical derivation and Section 8.5.3 describes the details of the Bayes’ rule calculation. Section 8.5.4 looks at the conjugacy more closely and provides some insight on the effects of prior and likelihood on the posterior distribution.\n\n\n2.5.2 A quick peak at the update procedure\nIt is convenient to describe the updating procedure by use of a table. In Table 8.3, there are rows corresponding to Prior, Data/Likelihood, and Posterior and columns corresponding to Mean, Precision, and Standard Deviation. The mean and standard deviation of the Normal prior are placed in the “Prior” row, and the sample mean and standard error are placed in the “Data/Likelihood” row.\nTable 8.3. Updating the Normal prior: step 1.\n\n\n\nType\nMean\nPrecision\nStand\n\n\n\n\nPrior\n18.00\n\n1.56\n\n\nData/Likelihood\n17.20\n\n0.89\n\n\nPosterior\n\n\n\n\n\n\nWe define the precision, \\(\\phi\\), to be the reciprocal of the square of the standard deviation. We compute the precisions of the prior and data from the given standard deviations: \\[\\begin{equation*}\n\\phi_{prior} = \\frac{1}{\\sigma_0^2} = \\frac{1}{1.56^2} = 0.41, \\, \\, \\,\n\\phi_{data} = \\frac{1}{\\sigma^2 / n} = \\frac{1}{0.89^2} = 1.26.\n\\end{equation*}\\] We enter the precisions in the corresponding rows of Table 8.4 \\(\\ref{table:normalupdate2}\\).\nTable 8.4. Updating the Normal prior: step 2.\n\n\n\nType\nMean\nPrecision\nStand\n\n\n\n\nPrior\n18.00\n0.41\n1.56\n\n\nData/Likelihood\n17.20\n1.26\n0.89\n\n\nPosterior\n\n\n\n\n\n\nWe will shortly see that the Posterior precision is the sum of the Prior precision and the Data/Likelihood precisions:\n\\[\\begin{equation*}\n\\phi_{post} = \\phi_{prior} + \\phi_{data} = 0.41 + 1.26 = 1.67.\n\\end{equation*}\\] Once the posterior precision is computed, the posterior standard deviation is computed as the reciprocal of the square root of the precision. \\[\\begin{equation*}\n\\sigma_n = \\frac{1}{\\sqrt{\\phi_{post}}} = \\frac{1}{\\sqrt{1.67}} = 0.77.\n\\end{equation*}\\] These precisions and standard deviations are entered into Table 8.5.\nTable 8.5. Updating the Normal prior: step 3.\n\n\n\nType\nMean\nPrecision\nStand\n\n\n\n\nPrior\n18.00\n0.41\n1.56\n\n\nData/Likelihood\n17.20\n1.26\n0.89\n\n\nPosterior\n\n1.67\n0.77\n\n\n\nThe posterior mean is a weighted average of the Prior and Data/Likelihood means where the weights are given by the corresponding precisions. That is, the formula is given by \\[\\begin{eqnarray}\n\\mu_n = \\frac{\\phi_{prior} \\times \\mu_0 + \\phi_{data} \\times \\bar y}{\\phi_{prior} + \\phi_{data}}.\n\\end{eqnarray}\\] By making appropriate substitutions, we obtain the posterior mean: \\[\\begin{eqnarray*}\n\\mu_n = \\frac{0.41 \\times 18.00 + 1.26 \\times 17.20}{0.41 + 1.26} = 17.40.\n\\end{eqnarray*}\\] The posterior density is Normal with mean \\(17.40\\) seconds and standard deviation \\(0.77\\) seconds. See Table 8.6 for the final update step.\nTable 8.6. Updating the Normal prior: step 4.\n\n\n\nType\nMean\nPrecision\nStand\n\n\n\n\nPrior\n18.00\n0.41\n1.56\n\n\nData/Likelihood\n17.20\n1.26\n0.89\n\n\nPosterior\n17.40\n1.67\n0.77\n\n\n\nThe Normal updating is performed by the R function normal_update(). One inputs two vectors – prior is a vector of the prior mean and standard deviation and data is a vector of the sample mean and standard error. The output is a vector of the posterior mean and posterior standard deviation.\n\nprior <- c(18, 1.56)\ndata <- c(17.20, 0.89)\nnormal_update(prior, data)\n\n[1] 17.3964473  0.7730412\n\n\nThe prior and posterior densities are displayed in Figure 8.6. As usually the case, the posterior density has a smaller spread since the posterior has more information than the prior about Federer’s mean time-to-serve. More information about a parameter indicates less uncertainty and a smaller spread of the posterior density. In the process from prior to posterior, one sees how the data modifies one’s initial belief about the parameter \\(\\mu\\).\n\n\n\n\n\nPrior and posterior curves for Federer’s mean time-to-serve \\(\\mu\\).\n\n\n\n\n\n\n2.5.3 Bayes’ rule calculation\nSection 8.5.2 gave an overview of the updating procedure for a Normal prior and Normal sampling. In this section we explain (1) why it is preferable to work with the precisions instead of the standard deviations; (2) why the precisions act as the weights in the calculation of the posterior mean and (3) why the posterior is a Normal distribution.\nRecall a precision is the reciprocal of the square of the standard deviation. We use \\(\\phi = \\frac{1}{\\sigma^2}\\) to represent the precision of a single observation in the Normal data/likelihood, and \\(\\phi_0 = \\frac{1}{\\sigma_0^2}\\) to represent the precision in the Normal prior.\n\nWe write down the likelihood of \\(\\mu\\), combining terms, and writing the expression in terms of the precision \\(\\phi\\). \\[\\begin{eqnarray}\ny_1, \\cdots, y_n \\mid \\mu, \\sigma &\\overset{i.i.d.}{\\sim}& {\\rm{Normal}}(\\mu, \\sigma)\\\\% \\equiv {\\rm{Normal}}(\\mu, \\frac{1}{\\phi}) \\\\\n\\end{eqnarray}\\] \\[\\begin{eqnarray}\nL(\\mu) = f(y_1, \\cdots, y_n \\mid \\mu, \\sigma) &=& \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_i-\\mu)^2\\right\\} \\nonumber \\\\\n&=& \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}}\\phi^{\\frac{1}{2}} \\exp\\left\\{-\\frac{\\phi}{2}(y_i - \\mu)^2)\\right\\}\\nonumber \\\\\n&=& \\left(\\frac{1}{\\sqrt{2\\pi}}\\right)^n \\phi^{\\frac{n}{2}} \\exp\\left\\{-\\frac{\\phi}{2}\\sum_{i=1}^{n}(y_i - \\mu)^2)\\right\\}\\nonumber \\\\\n\\end{eqnarray}\\]\n\nNote that \\(\\sigma\\) is assumed known, therefore the likelihood function is only in terms of \\(\\mu\\), i.e. \\(L(\\mu)\\).\n\nIn similar fashion, we write down the prior density for \\(\\mu\\) including the prior precision \\(\\phi_0\\). \\[\\begin{eqnarray}\n\\mu  &\\sim& {\\rm{Normal}}(\\mu_0, \\sigma_0) \\\\%\\equiv {\\rm{Normal}}(\\mu_0, \\frac{1}{\\phi_0}) \\\\\n\\end{eqnarray}\\] \\[\\begin{eqnarray}\n\\pi(\\mu) &=& \\frac{1}{\\sqrt{2\\pi}\\sigma_0} \\exp\\left\\{-\\frac{1}{2\\sigma_0^2}(\\mu - \\mu_0)^2)\\right\\}\\nonumber \\\\\n&=& \\frac{1}{\\sqrt{2\\pi}}\\phi_0^{\\frac{1}{2}} \\exp\\left\\{-\\frac{\\phi_0}{2}(\\mu - \\mu_0)^2\\right\\}\n\\end{eqnarray}\\]\nBayes’ rule is applied by multiplying the prior by the likelihood to obtain the posterior. In deriving the posterior of \\(\\mu\\), the manipulations require careful consideration regarding what is known. The only unknown variable is \\(\\mu\\), so any “constants” or known quantities not depending on \\(\\mu\\) can be dropped/added with the proportionality sign “\\(\\propto\\)”.\n\n\\[\\begin{eqnarray}\n\\pi(\\mu \\mid y_1, \\cdots, y_n, \\sigma) &\\propto&  \\pi(\\mu) L(\\mu) \\nonumber \\\\\n&\\propto& \\exp\\left\\{-\\frac{\\phi_0}{2}(\\mu - \\mu_0)^2\\right\\} \\times \\exp\\left\\{-\\frac{n\\phi}{2}(\\mu - \\bar{y})^2\\right\\} \\nonumber \\\\\n&\\propto& \\exp\\left\\{-\\frac{1}{2}(\\phi_0 +n\\phi)\\mu^2 + \\frac{1}{2}(2\\mu_0\\phi_0 + 2n\\phi\\bar{y})\\mu\\right\\} \\nonumber \\\\\n\\texttt{[complete the square]} &\\propto& \\exp\\left\\{-\\frac{1}{2}(\\phi_0 + n\\phi)(\\mu - \\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi})^2\\right\\} \\\\\n\\end{eqnarray}\\]\nLooking closely at the final expression, one recognizes that the posterior for \\(\\mu\\) is a Normal density with mean and precision parameters. Specifically we recognize \\((\\phi_0 + n \\phi)\\) as the posterior precision and \\((\\frac{\\phi_0 \\mu_0 + n \\phi\\bar{y}}{\\phi_0 + n \\phi})\\) as the posterior mean. Summarizing, we have derived the following posterior distribution of \\(\\mu\\),\n\\[\\begin{eqnarray}\n\\mu \\mid y_1, \\cdots, y_n, \\sigma \\sim {\\rm{Normal}}\\left(\\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi}, \\sqrt{\\frac{1}{\\phi_0 + n \\phi}}\\right).\n\\end{eqnarray}\\]\nIn passing, it should be noted that the same result would be attained using the standard deviations, \\(\\sigma\\) and \\(\\sigma_0\\), instead of the precisions, \\(\\phi\\) and \\(\\phi_0\\). It is preferable to work with the precisions due to the relative simplicity of the notation. In particular, one sees in Table Table 8.5 that the posterior precision is the sum of the prior and data/likelihood precisions, that is, the posterior precision \\(\\phi_n = \\phi_0 + n \\phi\\).\n\n\n2.5.4 Conjugate Normal prior\nLet’s summarize our calculations in Section 8.5.3. We collect a sequence of continuous observations that are assumed identically and independently distributed as \\(\\textrm{Normal}(\\mu, \\sigma)\\), and a Normal prior is assigned to the mean parameter \\(\\mu\\).\n\nThe sampling model: \\[\\begin{eqnarray}\nY_1, \\cdots, Y_n \\mid \\mu, \\sigma &\\overset{i.i.d.}{\\sim}& {\\rm{Normal}}(\\mu, \\sigma)\n\\end{eqnarray}\\] When \\(\\sigma\\) (or \\(\\phi\\)) is known, and mean \\(\\mu\\) is the only parameter in the likelihood.\nThe prior distribution: \\[\\begin{eqnarray}\n\\mu  &\\sim& {\\rm{Normal}}(\\mu_0, \\sigma_0)\n\\end{eqnarray}\\]\nAfter \\(Y_1 = y_1, ..., Y_n = y_n\\) are observed, the posterior distribution for the mean \\(\\mu\\) is another Normal distribution with mean \\(\\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi}\\) and precision \\(\\phi_0 + n \\phi\\) (thus standard deviation \\(\\sqrt{\\frac{1}{\\phi_0 + n \\phi}}\\)):\n\n\\[\\begin{eqnarray}\n\\mu \\mid y_1, \\cdots, y_n, \\sigma \\sim {\\rm{Normal}}\\left(\\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi}, \\sqrt{\\frac{1}{\\phi_0 + n \\phi}}\\right).\n\\end{eqnarray}\\]\nIn this situation where the sampling standard deviation \\(\\sigma\\) is known, the Normal density is a conjugate prior for the mean of a Normal distribution, as the posterior distribution for \\(\\mu\\) is another Normal density with updated parameters. Conjugacy is a convenient property as the posterior distribution for \\(\\mu\\) has a convenient functional form. Conjugacy allows one to conduct Bayesian inference through exact analytical solutions and simulation. Also conjugacy provides insight on how the data and prior are combined in the posterior distribution.\n\nThe posterior compromises between the prior and the sample\nRecall that Bayesian inference is a general approach where one initializes a prior belief for an unknown quantity, collects data expressed through a likelihood function, and combines prior and likelihood to give an updated belief for the unknown quantity. In Chapter 7, we have seen how the posterior mean of a proportion is a compromise between the prior mean and sample proportion (refer to Section 7.4.2 as needed). In the current Normal mean case, the posterior mean is similarly viewed as an estimate that compromises between the prior mean and sample mean. One rewrites the posterior mean in Equation (8.23) as follows: \\[\\begin{eqnarray}\n\\mu_n = \\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi} &=& \\frac{\\phi_0}{\\phi_0 + n\\phi} \\mu_0 +  \n\\frac{n\\phi}{\\phi_0 + n\\phi}  \\bar{y}.\n\\end{eqnarray}\\] The prior precision is equal to \\(\\phi_0\\) and the precision in the likelihood for any \\(y_i\\) is \\(\\phi\\). Since there are \\(n\\) observations, the precision in the joint likelihood is \\(n\\phi\\). The posterior mean is a weighted average of the prior mean \\(\\mu_0\\) and sample mean \\(\\bar y\\) where the weights are proportional to the associated precisions.\n\n\nThe posterior accumulates information in the prior and the sample\nIn addition, the precision of the posterior Normal mean is the sum of the precisions of the prior and likelihood. That is, \\[\\begin{equation}\n\\phi_n = \\phi_0 + n \\phi.\n\\end{equation}\\] The implication is that the posterior standard deviation will always be smaller than either the prior standard deviation or the sampling standard error: \\[\\begin{equation*}\n\\sigma_n < \\sigma_0, \\, \\, \\, \\sigma_n < \\frac{\\sigma}{\\sqrt{n}}.\n\\end{equation*}\\]"
  },
  {
    "objectID": "mean.html#Normal:ContinuousInference",
    "href": "mean.html#Normal:ContinuousInference",
    "title": "2  Modeling Measurement and Count Data",
    "section": "2.6 Bayesian Inferences for Continuous Normal Mean",
    "text": "2.6 Bayesian Inferences for Continuous Normal Mean\nContinuing with the example about Federer’s time-to-serve, our Normal prior had mean 18 seconds and standard deviation 1.56 seconds. After collecting 20 time-to-serve measurements with a sample mean of 17.2, the posterior distribution \\(\\textrm{Normal}(17.4, 0.77)\\) reflects our opinion about the mean time-to-serve.\nBayesian inferences about the mean \\(\\mu\\) are based on various summaries of this posterior Normal distribution. Because the exact posterior distribution of mean \\(\\mu\\) is Normal, it is convenient to use R functions such as pnorm() and qnorm() to conduct Bayesian hypothesis testing and construct Bayesian credible intervals. Simulation-based methods utilizing functions such as rnorm() are also useful to provide approximations to those inferences. A sequence of examples are given in Section 8.6.1.\nPredictions of future data are also of interest. For example, one might want to predict the next time-to-serve measurement based on the posterior distribution of \\(\\mu\\) being \\(\\textrm{Normal}(17.4, 0.77)\\). In Section 8.6.2, details of the prediction procedure and examples are provided.\n\n2.6.1 Bayesian hypothesis testing and credible interval\n\nA testing problem\nIn a testing problem, one is interested in checking the validity of a statement about a population quantity. In our tennis example, suppose someone says that Federer takes on average at least 19 seconds to serve. Is this a reasonable statement?\nThe current beliefs about Federer’s mean time-to-serve are summarized by a Normal distribution with mean 17.4 seconds and standard deviation 0.77 seconds. To assess if the statement ``\\(\\mu\\) is 19 seconds or more” is reasonable, one simply computes its posterior probability, \\(Prob(\\mu \\geq 19 \\mid \\mu_n = 17.4, \\sigma_n = 0.77)\\).\n\n1 - pnorm(19, 17.4, 0.77)\n\n[1] 0.01885827\n\n\nThis probability is about 0.019, a small value, so one would conclude that this person’s statement is unlikely to be true.\nThis is the exact solution using the pnorm() function with mean 17.4 and standard deviation 0.77. As seen in Chapter 7, simulation provides an alternative approach to obtaining the probability \\(Prob(\\mu \\geq 19 \\mid \\mu_n = 17.4, \\sigma_n = 0.77)\\). To implement the simulation approach, recall that one generates a large number of values from the posterior distribution and summarizes this simulated sample. In particular, using the following R script, one generates 1000 values from the \\(\\textrm{Normal}(17.4, 0.77)\\) distribution and approximates the probability of “\\(\\mu\\) is 19 seconds or more” by computing the percentage of values that falls above 19.\n\n\n\n\nS <- 1000\nNormalSamples <- rnorm(S, 17.4, 0.77)\nsum(NormalSamples >= 19) / S\n\n[1] 0.024\n\n\nThe reader might notice that the approximated value of 0.024 differs from the exact answer of 0.019 using the pnorm() function. One way to improve the accuracy of the approximation is by increasing the number of simulated values. For example, increasing S from 1000 to 10,000 provides a better approximation to the exact probability 0.019.\n\n\n\n\nS <- 10000\nNormalSamples <- rnorm(S, 17.4, 0.77)\nsum(NormalSamples >= 19) / S\n\n[1] 0.0175\n\n\n\n\nA Bayesian interval estimate\nBayesian credible intervals for the mean parameter \\(\\mu\\) can be achieved both by exact calculation and simulation. Recall that a Bayesian credible interval is an interval that contains the unknown parameter with a certain probability content. For example, a 90% Bayesian credible interval for the parameter \\(\\mu\\) is an interval containing \\(\\mu\\) with a probability of 0.90.\nThe exact interval is obtained by using the R function qnorm(). For example, with the posterior distribution for \\(\\mu\\) being \\(\\textrm{Normal}(17.4, 0.77)\\), the following R script shows that a 90% central Bayesian credible interval is (16.133, 18.667). That is, the posterior probability of \\(\\mu\\) falls between 16.133 and 18.667 is exactly 90%.\n\nqnorm(c(0.05, 0.95), 17.4, 0.77)\n\n[1] 16.13346 18.66654\n\n\nFor simulation-based inference, one generates a large number of values from its posterior distribution, then finds the 5th and 95th sample quantiles to obtain the middle 90% of the generated values. Below one sees that a 90% credible interval for posterior of \\(\\mu\\) is approximately (16.151, 18.691).\n\n\n\n\nS <- 1000\nNormalSamples <- rnorm(S, 17.4, 0.77)\nquantile(NormalSamples, c(0.05, 0.95))\n\n      5%      95% \n16.15061 18.69062 \n\n\nThe Bayesian credible intervals can also be used for testing hypothesis. Suppose one again wants to evaluate the statement “Federer takes on average at least 19 seconds to serve.” One answers this question by computing the 90% credible interval. One notes that the values of \\(\\mu\\) ``at least 19” are not included in the exact 90% credible interval (16.15, 18.69). The interpretation is that the probability is at least 0.90 that Federer’s average time-to-service is smaller than 19 seconds. One could obtain a wider credible interval, say by computing a central 95% credible interval (see the R output below), and observe that 19 is out of the interval. This indicates we are 95% confident that 19 seconds is not the value of Federer’s average time-to-serve.\n\nqnorm(c(0.025, 0.975), 17.4, 0.77)\n\n[1] 15.89083 18.90917\n\n\nOn the basis of this credible interval calculation, one concludes that the statement about Federer’s time-to-serve is unlikely to be true. This conclusion is consistent with the typical Bayesian hypothesis testing procedure given at the beginning of this section.\n\n\n\n2.6.2 Bayesian prediction\nSuppose one is interested in predicting Federer’s future time-to-serve. Since one has already updated the belief about the parameter, the mean \\(\\mu\\), the prediction is made based on its posterior predictive distribution.\nHow to make one future prediction of Federer’s time-to-serve? In Chapter 7, we have seen two different approaches for predicting of a new survey outcome of students’ dining preferences. One approach in Chapter 7 is based on the derivation of the exact posterior predictive distribution \\(f(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\) which was shown to be a Beta-Binomial distribution. The second approach is a simulation-based approach, which involves two steps: first, sample a value of the parameter from its posterior distribution (a Beta distribution), and second, sample a prediction from the data model based on the sampled parameter draw (a Binomial distribution). When the sample size in the simulation-based approach is sufficiently large, a prediction interval from the simulation-based approach is an accurate approximation to the exact prediction interval.\n\nExact predictive distribution\nWe first describe the exact posterior predictive distribution. Consider making a prediction of a single Federer’s time-to-serve \\(\\tilde{Y}\\). In general, suppose the sampling density of \\(\\tilde{Y}\\) given \\(\\mu\\) and \\(\\sigma\\) is \\(f(\\tilde{Y} = \\tilde{y} \\mid \\mu)\\) and suppose the current beliefs about \\(\\mu\\) are represented by the density \\(\\pi(\\mu)\\). The joint density of \\((\\tilde{y}, \\mu)\\) is given by the product \\[\\begin{equation}\nf(\\tilde{Y} = \\tilde{y}, \\mu) = f(\\tilde{Y} = \\tilde{y} \\mid \\mu) \\pi(\\mu),\n\\end{equation}\\] and by integrating out \\(\\mu\\), the predictive density of \\(\\tilde{Y}\\) is given by \\[\\begin{equation}\nf(\\tilde{Y} = \\tilde{y}) = \\int f(\\tilde{Y} = \\tilde{y} \\mid \\mu) \\pi(\\mu) d\\mu.\n\\end{equation}\\]\nThe computation of the predictive density is possible for this Normal sampling model with a Normal prior. It is assumed that \\(f(\\tilde{Y} = \\tilde{y} \\mid \\mu)\\) is Normal with mean \\(\\mu\\) and standard deviation \\(\\sigma\\) and that the current beliefs about \\(\\mu\\) are described by a Normal density with mean \\(\\mu_0\\) and standard deviation \\(\\sigma_0\\). Then it is possible to integrate out \\(\\mu\\) from the joint density of \\((\\tilde{y}, \\mu)\\) and one finds that the predictive density for \\(\\tilde{Y}\\) is Normal with mean and standard deviation given by \\[\\begin{equation}\nE(\\tilde{Y}) = \\mu_0, \\, \\, SD(\\tilde{Y}) = \\sqrt{\\sigma^2 + \\sigma_0^2}.\n\\end{equation}\\]\nThis result can be used to derive the posterior predictive distribution of \\(f(\\tilde{Y} = \\tilde{y} \\mid Y_1, \\cdots, Y_n)\\), where \\(\\tilde{Y}\\) is a future observation and \\(Y_1, \\cdots, Y_n\\) are \\(n\\) \\(i.i.d.\\) observations from a Normal sampling density with unknown mean \\(\\mu\\) and known standard deviation \\(\\sigma\\). After observing the sample values \\(y_1, \\cdots, y_n\\), the current beliefs about the mean \\(\\mu\\) are represented by a Normal\\((\\mu_n, \\sigma_n)\\) density, where the mean and standard deviation are given by \\[\\begin{equation}\n\\mu_n = \\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi},  \\sigma_n = \\sqrt{\\frac{1}{\\phi_0 + n \\phi}}.\n\\end{equation}\\] Then by applying our general result in Equation (8.28), the posterior predictive density of the single future observation \\(\\tilde{Y}\\) is Normal with mean \\(\\mu_n\\) and standard deviation \\(\\sqrt{\\sigma^2 + \\sigma_n^2}.\\) That is, \\[\\begin{eqnarray}\n\\tilde{Y} = \\tilde{y} \\mid y_1, \\cdots, y_n, \\sigma \\sim \\textrm{Normal}(\\mu_n, \\sqrt{\\sigma^2 + \\sigma_n^2}).\n\\end{eqnarray}\\]\nAn important aspect of the predictive distribution for \\(\\tilde{Y}\\) is on the variance term \\(\\sigma^2 + \\sigma_n^2\\). The variability of a future prediction comes from two sources: (1) the data model variance \\(\\sigma^2\\), and (2) the posterior variance \\(\\sigma_n^2\\). Recall that the posterior variance \\(\\sigma_n^2 = \\frac{1}{\\phi_0 + n\\phi}\\). If one fixes values of \\(\\phi_0\\) and \\(\\phi\\) and allow the sample size \\(n\\) to grow, the posterior variance will approach zero. In this ``large \\(n\\)” case, the uncertainty in inference about the population mean \\(\\mu\\) will decrease – essentially we are certain about the location of \\(\\mu\\). However the uncertainty in prediction will not decrease towards zero. In contrast, in this large sample case, the variance of \\(\\tilde{Y}\\) will decrease and approach the sampling variance \\(\\sigma^2\\).\n\n\nPredictions by simulation\nThe alternative method of computing the predictive distribution is by simulation. In this setting, there are two unknowns – the mean parameter \\(\\mu\\) and the future observation \\(\\tilde Y\\). One simulates a value from the predictive distribution in two steps: first, one simulates a value of the parameter \\(\\mu\\) from its posterior distribution; second, use this simulated parameter draw to simulate a future observation \\(\\tilde Y\\) from the data model. In particular, the following algorithm is used to simulate a single value from the posterior predictive distribution.\n\nSample a value of \\(\\mu\\) from its posterior distribution \\[\\begin{eqnarray}\n\\mu \\sim \\textrm{Normal}\\left(\\frac{\\phi_0\\mu_0 + n\\phi\\bar{y}}{\\phi_0 + n\\phi}, \\sqrt{\\frac{1}{\\phi_0 + n\\phi}}\\right),\n\\end{eqnarray}\\]\nSample a new observation \\(\\tilde{Y}\\) from the data model (i.e. a prediction) \\[\\begin{eqnarray}\n\\tilde{Y} \\sim \\textrm{Normal}(\\mu, \\sigma).\n\\end{eqnarray}\\]\n\nThis two-step procedure is implemented for our time-to-serve example using the following R script.\n\n\n\n\nsigma <- 4\nmu_n <- 17.4\nsigma_n <- 0.77\npred_mu_sim <- rnorm(1, mu_n, sigma_n)\n(pred_y_sim <- rnorm(1, pred_mu_sim, sigma))\n\n[1] 16.04772\n\n\nThe script can easily be updated to create \\(S\\) = 1000 predictions, which is helpful to make summary about predictions.\n\n\n\n\nS <- 1000\npred_mu_sim <- rnorm(S, mu_n, sigma_n)\npred_y_sim <- rnorm(S, pred_mu_sim, sigma)\n\nThe vector pred_y_sim contains 1000 predictions of Federer’s time-to-serve.\n\n\n\n\n\nDisplay of the exact and simulated time-to-serve for Federer’s example.\n\n\n\n\nTo evaluate the accuracy of the simulation-based predictions, Figure 8.7 displays the exact and a density estimate of the simulation-based predictive densities for a single time-to-serve measurement. One observes pretty good agreement using these two computation methods in this example."
  },
  {
    "objectID": "mean.html#Normal:PPC",
    "href": "mean.html#Normal:PPC",
    "title": "2  Modeling Measurement and Count Data",
    "section": "2.7 Posterior Predictive Checking",
    "text": "2.7 Posterior Predictive Checking\nIn Section 8.6, the use of the posterior predictive distribution for predicting a future time-to-serve measurement was described. As discussed in Chapter 7, this distribution is also helpful for assessing the suitability of the Bayesian model.\nIn our example, we observed 20 times-to-serve for Federer. The question is whether these observed times are consistent with replicated data from the posterior predictive distribution. In this setting, replicated refers to the same sample size as our original sample. In other words, if one takes samples of 20 from the posterior predictive distribution, do these replicated datasets resemble the observed sample?\nSince the population standard deviation is known as \\(\\sigma = 4\\) seconds, the sampling distribution of \\(Y\\) is Normal with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). One simulates replicated data \\(\\tilde Y_1, ..., \\tilde Y_{20}\\) from the posterior predictive distribution in two steps:\n\nSample a value of \\(\\mu\\) from its posterior distribution \\[\\begin{eqnarray}\n\\mu \\sim \\textrm{Normal}\\left(\\frac{\\phi_0\\mu_0 + n\\phi\\bar{y}}{\\phi_0 + n\\phi}, \\sqrt{\\frac{1}{\\phi_0 + n\\phi}}\\right).\n\\end{eqnarray}\\]\nSample \\(\\tilde Y_1, ..., \\tilde Y_{20}\\) from the data model \\[\\begin{eqnarray}\n\\tilde{Y} \\sim \\textrm{Normal}(\\mu, \\sigma).\n\\end{eqnarray}\\]\n\nThis method is implemented in the following R script to simulate 1000 replicated samples from the posterior predictive distribution. The vector pred_mu_sim contains draws from the posterior distribution and the matrix ytilde contains the simulated predictions where each row of the matrix is a simulated sample of 20 future times.\n\n\n\n\nsigma <- 4\nmu_n <- 17.4\nsigma_n <- 0.77\nS <- 1000\npred_mu_sim <- rnorm(S, mu_n, sigma_n)\nsim_ytilde <- function(j){\n  rnorm(20, pred_mu_sim[j], sigma)\n}\nytilde <- t(sapply(1:S, sim_ytilde))\n\nTo judge goodness of fit, we wish to compare these simulated replicated datasets from the posterior predictive distribution with the observed data. One convenient way to implement this comparison is to compute some “testing function”, \\(T(\\tilde y)\\), on each replicated dataset. If we have 1000 replicated datasets, one has 1000 values of the testing function. One constructs a graph of these values and overlays the value of the testing function on the observed data \\(T(y)\\). If the observed value is in the tail of the posterior predictive distribution of \\(T(\\tilde y)\\), this indicates some misfit of the observed data with the Bayesian model.\nTo implement this procedure, one needs to choose a testing function \\(T(\\tilde y)\\). Suppose, for example, one decides to use the sample mean \\(T(\\tilde y) = \\sum \\tilde y_j / 20\\). In the R script, we compute the sample mean on each row of the simulated prediction matrix.\n\npred_ybar_sim <- apply(ytilde, 1, mean)\n\nFigure 8.8 displays a density estimate of the simulated values from the posterior predictive distribution of \\(\\bar Y\\) and the observed value of the sample mean \\(\\bar Y = 17.20\\) is displayed as a vertical line. Since this observed mean is in the middle of this distribution, one concludes that this observation is consistent with samples predicted from the Bayesian model. It should be noted that this conclusion about model fit is sensitive to the choice of checking function \\(T()\\). In the end-of-chapter exercises, the reader will explore the suitability of this model using alternative choices for the checking function.\n\n\n\n\n\nDisplay of the posterior predictive mean time-to-serve for twenty observations. The observed mean time-to-serve value is displayed by a vertical line."
  },
  {
    "objectID": "mean.html#modeling-count-data",
    "href": "mean.html#modeling-count-data",
    "title": "2  Modeling Measurement and Count Data",
    "section": "2.8 Modeling Count Data",
    "text": "2.8 Modeling Count Data\nTo further illustrate the Bayesian approach to inference for measurements, consider Poisson sampling, a popular model for count data. One assumes that one observes a random sample from a Poisson distribution with an unknown rate parameter \\(\\lambda\\). The conjugate prior for the Poisson mean is the Gamma distribution. This scenario provides further practice in various Bayesian computations, such as computing the likelihood function and posterior distribution, and obtaining the predictive distribution to learn about future data. In this section, we focus on the main results and the detailed derivations are left as end-of-chapter exercises.\n\n2.8.1 Examples\nCounts of patients in an emergency room\nA hospital wants to determine how many doctors and nurses to assign on their emergency room (ER) team between 10pm and 11pm during the week. An important piece of information is the count of patients arriving in the ER in this one-hour period.\nFor a count measurement variable such as the count of patients, a popular sampling model is the Poisson distribution. This distribution is used to model the number of times an event occurs in an interval of time or space. In the current example, the event is a patient’s arrival to the ER, and the time interval is the period between 10pm and 11pm. The hospital wishes to learn about the average count of patients arriving to the ER each hour. Perhaps more importantly, the hospital wants to predict the patient count since that will directly address the scheduling of doctors and nurses question.\nCounts of visitors to a website\nAs a second example, suppose one is interested in monitoring the popularity of a particular blog focusing on baseball analytics. Table 8.7 displays the number of visitors viewing this blog for 28 days during June of 2019. In this setting, the event of interest is a visit to the blog website and the time interval is a single day. The blog author is particularly interested in learning about the average number of visitors during the days Monday through Friday and predicting the number of visits for a future day in the summer of 2019.\nTable 8.7. Number of visitors to a baseball blog site during different days during June, 2019.\n\n\n\n\nFri\nSat\nSun\nMon\nTue\nWed\nThu\n\n\n\n\nWeek 1\n95\n81\n85\n100\n111\n130\n113\n\n\nWeek 2\n92\n65\n78\n96\n118\n120\n104\n\n\nWeek 3\n91\n91\n79\n106\n91\n114\n110\n\n\nWeek 4\n98\n61\n84\n96\n126\n119\n90\n\n\n\nCount of visitors to blog during 28 days during June 2019.\n\n\n2.8.2 The Poisson distribution\n Let the random variable \\(Y\\) denote the number of occurrences of an event in an interval with sample space \\(\\{0, 1, 2, \\cdots \\}\\). In contrast to the Normally distributed continuous measurement, note that \\(Y\\) only takes integer values from 0 to infinity. The variable \\(Y\\) follows a Poisson distribution with rate parameter \\(\\lambda\\) when the probability mass function (pmf) of observing \\(y\\) events in an interval is given by\n\\[\\begin{eqnarray}\nf(Y = y \\mid \\lambda) = e^{-\\lambda}\\frac{\\lambda^y}{y!}, \\, \\, y = 0, 1, 2, ...\n\\end{eqnarray}\\] where \\(\\lambda\\) is the average number of events per interval, \\(e = 2.71828...\\) is Euler’s number, and \\(y!\\) is the factorial of \\(y\\).\nThe Poisson sampling model is based on several assumptions about the sampling process. One assumes that the time interval is fixed, counts of arrivals occurring during different time intervals are independent, and the rate \\(\\lambda\\) at which the arrivals occur is constant over time. To check the suitability of the Poisson distribution for the examples, one needs to check the conditions one by one.\n\nThe time interval is fixed in the ER example as we observe patient arrivals during a one hour period between 10pm and 11pm. For the blog visits example, the fixed time period is one day.\nIn both examples, one assumes that events occur independently during different time intervals. In the ER example it is reasonable to assume that the time of one patient’s arrival does not influence the time of another patient’s arrival. For the website visits example, if different people are visiting the website on different days, then one could assume the number of visits on one day would be independent of the number of visits on another day.\nIs it reasonable to assume the rate \\(\\lambda\\) at which events occur is constant through the time interval? In the ER example, one might not think that the rate of patient arrivals would change much through one hour during the evening, so it seems reasonable to assume that the average number of events is constant in the fixed interval. Similarly, if one focuses on weekdays, then for the website visits example, it is reasonable to assume that the average number of visits remains constant across days.\n\nIn some situations, the second and third conditions will be violated. In our ER example, the occurrence of serious accidents may bring multiple groups of patients to the ER at certain time intervals. In this case, arrival times of patients may not be independent and the arrival rate \\(\\lambda\\) in one subinterval will be higher than the arrival rate of another subinterval. When such situations occur, one needs to decide about the severity of the violation of the conditions and possibly use an alternative sampling model instead of the Poisson.\nAs evident in Equation (8.35), the Poisson distribution has only one parameter, the rate parameter \\(\\lambda\\), so the Poisson sampling model belongs to the family of one-parameter sampling models. The Binomial data model with success probability \\(p\\) and the Normal data model with mean parameter \\(\\mu\\) (with known standard deviation) are two other examples of one-parameter models. One distinguishes these models by the type of possible sample values, discrete or continuous. The Binomial random variable is the number of successes and the Poisson random variable is a count of arrivals, so they both are discrete one-parameter models. In contrast, the Normal sampling data model is a continuous one-parameter model.\n\n\n2.8.3 Bayesian inferences\n The reader should be familiar with the typical procedure of Bayesian inference and prediction for one-parameter models. We rewrite this procedure in the context of the Poisson sampling model.\n\n[Step 1] One constructs a prior expressing an opinion about the location of the rate \\(\\lambda\\) before any data is collected.\n[Step 2] One takes the sample of intervals and records the number of arrivals in each interval. From this data, one forms the likelihood, the probability of these observations expressed as a function of \\(\\lambda\\).\n[Step 3] One uses Bayes’ rule to compute the posterior – this distribution updates the prior opinion about \\(\\lambda\\) given the information from the data.\nIn addition, one computes the predictive distribution to learn about the number of arrivals in future intervals. The posterior predictive distribution is also useful in checking the appropriateness of our model.\n\nGamma prior distribution\nOne begins by constructing a prior density to express one’s opinion about the rate parameter \\(\\lambda\\). Since the rate is a positive continuous parameter, one needs to construct a prior density that places its support only on positive values. The convenient choice of prior distributions for Poisson sampling is the Gamma distribution which has a density function given by \\[\\begin{eqnarray}\n\\pi(\\lambda \\mid \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma{(\\alpha)}} \\lambda^{\\alpha-1}e^{-\\beta \\lambda}, \\,\\,\\, \\text{for}\\,\\, \\lambda > 0, \\,\\, \\text{and}\\,\\,  \\alpha, \\beta > 0,\n\\end{eqnarray}\\] where \\(\\Gamma(\\alpha)\\) is the Gamma function evaluated at \\(\\alpha\\). The Gamma density is a continuous density where the support is on positive values. It depends on two parameters, a positive shape parameter \\(\\alpha\\) and a positive rate parameter \\(\\beta\\).\nThe Gamma density is a flexible family of distributions that can reflect many different types of prior beliefs about the location of the parameter \\(\\lambda\\). One chooses values of the shape \\(\\alpha\\) and the rate \\(\\beta\\) so that the Gamma density matches one’s prior information about the location of \\(\\lambda\\). In R, the function dgamma() gives the density, pgamma() gives the distribution function and qgamma() gives the quantile function for the Gamma distribution. These functions are helpful in graphing the prior and choosing values of the shape and rate parameters that match prior statements about Gamma percentiles and probabilities. We provide an illustration of choosing a subjective Gamma prior in the example.\nSampling and the likelihood\nSuppose that \\(Y_1, ..., Y_n\\) represent the observed counts in \\(n\\) time intervals where the counts are independent and each \\(Y_i\\) follows a Poisson distribution with rate \\(\\lambda\\). The joint mass function of \\(Y_1, ..., Y_n\\) is obtained by multiplying the Poisson densities. \\[\\begin{eqnarray}\nf(Y_1 = y_1, ... ,  Y_n = y_n \\mid \\lambda ) &=& \\prod_{i=1}^{n}f(y_i \\mid \\lambda) \\nonumber \\\\\n                                       &\\propto& \\lambda^{\\sum_{i=1}^{n}y_i} e^{-n\\lambda}.   \n\\end{eqnarray}\\] Once the counts \\(y_1, ..., y_n\\) are observed, the likelihood of \\(\\lambda\\) is the joint probability of observing this data, viewed as a function of the rate parameter \\(\\lambda\\). \\[\\begin{equation}\nL(\\lambda) = \\lambda^{\\sum_{i=1}^{n}y_i} e^{-n\\lambda}.\n\\end{equation}\\]\nIf the rate parameter \\(\\lambda\\) in the Poisson sampling model follows a Gamma prior distribution, then it turns out that the posterior distribution for \\(\\lambda\\) will also have a Gamma density with updated parameters. This demonstrates that the Gamma density is the conjugate distribution for Poisson sampling as the prior and posterior densities both come from the same family of distribution: Gamma.\nWe begin by assuming that the Poisson parameter \\(\\lambda\\) has a Gamma distribution with shape and rate parameters \\(\\alpha\\) and \\(\\beta\\), that is, \\(\\lambda \\sim\\) Gamma\\((\\alpha, \\beta)\\). If one multiplies the Gamma prior by the likelihood function \\(L(\\lambda)\\), then in an end-of-chapter exercise you will show that the posterior density of \\(\\lambda\\) is Gamma\\((\\alpha_n, \\beta_n)\\), where the updated parameters \\(\\alpha_n\\) and \\(\\beta_n\\) are given by \\[\\begin{equation}\n\\alpha_n = \\alpha + \\sum_{i=1}^n y_i, \\, \\, \\, \\beta_n = \\beta + n.\n\\end{equation}\\]\nInference about \\(\\lambda\\)\nOnce the posterior distribution has been derived, then all inferences about the Poisson parameter \\(\\lambda\\) are performed by computing particular summaries of the Gamma posterior distribution. In particular, one may be interested in testing if \\(\\lambda\\) falls in a particular region by computing a posterior probability. All of these computations are facilitated using the pgamma(), qgamma(), and rgamma() functions. Or one may be interested in constructing an interval estimate for \\(\\lambda\\). In the end-of-chapter exercises, there are opportunities to perform these inferences using a dataset containing a sample of ER arrival counts.\nPrediction of future data\nOne advantage of using a conjugate prior is that the predictive density for a future observation \\(\\tilde Y\\) is available in closed form. Suppose \\(\\lambda\\) is assigned a \\(\\textrm{Gamma}(\\alpha, \\beta\\)) prior. Then the prior predictive density of \\(\\tilde Y\\) is given by \\[\\begin{eqnarray}\nf(\\tilde{Y} = \\tilde y)  &=& \\int f(\\tilde{Y} = \\tilde{y} \\mid \\lambda) \\pi(\\lambda) \\lambda  \\nonumber \\\\\n& =& \\int \\frac{e^{-\\lambda} \\lambda^{\\tilde y}} {\\tilde y!}  \n\\frac{\\beta^{\\alpha}}{\\Gamma{(\\alpha)}} \\lambda^{\\alpha-1}e^{-\\beta \\lambda} d \\lambda  \\nonumber \\\\\n&=& \\frac{\\Gamma(\\alpha + \\tilde y)}{\\Gamma(\\alpha)}\n\\frac{\\beta^\\alpha}{(\\beta + 1)^{\\tilde y + \\alpha}}.\n\\end{eqnarray}\\]\nIn addition, the posterior distribution of \\(\\lambda\\) also has the Gamma form with updated parameters \\(\\alpha_n\\) and \\(\\beta_n\\). So Equation (8.40) also provides the posterior predictive distribution for a future count \\(\\tilde Y\\) using the updated parameter values.\nFor prediction purposes, there are several ways of summarizing the predictive distribution. One can use the formula in Equation (8.40) to directly compute \\(f(\\tilde Y)\\) for a list of values of \\(\\tilde Y\\) and then one uses the computed probabilities to form a prediction interval for \\(\\tilde Y\\). Alternately, one simulates values of \\(\\tilde Y\\) in a two-step process. For example, if one wants to simulate a draw from the posterior predictive distribution, one would first simulate a value \\(\\lambda\\) from its posterior distribution, and given that simulated draw \\(\\lambda^*\\), simulate \\(\\tilde Y\\) from a Poisson distribution with mean \\(\\lambda^*\\). Repeating this process for a large number of iterations provides a sample from the posterior prediction distribution that one uses to construct a prediction interval.\n\n\n2.8.4 Case study: Learning about website counts\nLet’s return to the website example where one is interested in learning about the average weekday visits to a baseball analytics blog site. One observes the counts \\(y_1, ..., y_{20}\\) displayed in the “Mon”, “Tue”, “Wed”, “Thu”, “Fri” columns of Table 8.7. We assume the {\\(y_i\\)} represent a random sample from a Poisson distribution with mean parameter \\(\\lambda\\).\nSuppose one’s prior guess at the value of \\(\\lambda\\) is 80 and one wishes to match this information with a Gamma(\\(\\alpha, \\beta\\)) prior. Two helpful facts about the Gamma distribution are that the mean and variance are equal to \\(\\mu = \\alpha / \\beta\\) and \\(\\sigma^2 =\\alpha / \\beta^2 = \\mu / \\beta,\\) respectively. Figure 8.9 displays three Gamma curves for values \\((\\alpha, \\beta\\)) = (80, 1), (40, 0.5), and (20, 0.25). Each of these Gamma curves have a mean of 80 and the curves become more diffuse as the parameter \\(\\beta\\) moves from 1 to 0.25. After some thought, the user believes that the Gamma(80, 1) matches her prior beliefs. To check, she computes a prior probability interval. Using the qgamma() function, she finds that her 90% prior probability interval is \\(Prob(65.9 < \\lambda < 95.3) = 0.90\\) and this appears to be a reasonable approximation to her prior beliefs.\n\n\n\n\n\nThree Gamma(\\(\\alpha, \\beta\\)) plausible prior distributions for the average number of weekday visits to the website.\n\n\n\n\nFrom the data, we compute \\(\\sum_{i=1}^{20} y_i = 2120\\) and the sample size is \\(n = 20\\). The posterior distribution is Gamma(\\(\\alpha_n, \\beta_n)\\) where the updated parameters are \\[\\begin{equation*}\n\\alpha_n = 80 + 2120 = 2200, \\, \\, \\beta_n = 1 + 20 = 21.\n\\end{equation*}\\] Figure 8.10 displays the Gamma posterior curve for \\(\\lambda\\). This figure displays a 90% probability interval which is found using the qgamma() function to be (101.1, 108.5). The interpretation is that the average number of visits lies between 101.1 and 108.5 with probability 0.90.\n\n\n\n\n\nPosterior curve for the mean number of visits \\(\\lambda\\) to the website. The shaded region shows the limits of a 90% interval estimate.\n\n\n\n\nSuppose the user is interested in predicting the number of blog visits \\(\\tilde Y\\) at a future summer weekday. One simulates the posterior predictive distribution by first simulating 1000 values from the Gamma posterior, and then simulating values of \\(\\tilde Y\\) from Poisson distributions where the Poisson means come from the posterior. Figure 8.11 displays a histogram of the simulated values from the predictive distribution. The 5th and 95th quantiles of this distribution are computed to be 88 and 123 – there is a 90% probability that that the number of visitors in a future weekday will fall in the interval (88, 123).\n\n\n    5%    95% \n 88.95 123.00 \n\n\n\n\n\nHistogram of a simulated sample from the posterior predictive distribution of the number of visitors to the website on a future day."
  }
]