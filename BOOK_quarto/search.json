[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Modeling",
    "section": "",
    "text": "A traditional introduction to statistical thinking and methods is the two-semester probability and statistics course offered in mathematics and statistics departments. This traditional course provides an introduction to calculus-based probability and statistical inference. The first half of the course is an introduction to probability including discrete, continuous and multivariate distributions. The chapters on functions of random variables and sampling distributions naturally lead into statistical inference including point estimates and hypothesis testing, regression models, design of experiments and ANOVA models.\nAlthough this traditional course remains popular, there seems to be little discussion in this course on the application of the inferential material in modern statistical practice. Although there are benefits in discussing methods of estimation such as maximum likelihood, and optimal inference such as a best hypothesis test, the students learn little about statistical computation and simulation-based inferential methods. As stated in Cobb (2015), there appears to be a disconnect between the statistical content we teach and statistical practice.\n\n\n\nThe development of any new statistics course should be consistent with current thinking of faculty dedicated to teaching statistics at the undergraduate level. Cobb (2015) argues that we need to deeply rethink our undergraduate statistics curriculum from the ground up. Towards this general goal, Cobb (2015) proposes “five imperatives” that can help the process of creating this new curriculum. These imperatives are to (1) flatten prerequisites, (2) seek depth in understanding fundamental concepts, (3) embrace computation in statistics, (4) exploit the use of context to motivate statistical concepts, and (5) implement research-based learning.\n\n\n\nThere are good reasons for introducing the Bayesian perspective at the calculus-based undergraduate level. First, many people believe that the Bayesian approach provides a more intuitive and straightforward introduction than the frequentist approach to statistical inference. Given that the students are learning probability, Bayes provides a useful way of using probability to update beliefs from data. Second, given the large growth of Bayesian applied work in recent years, it is desirable to introduce the undergraduate students to some modern Bayesian applications of statistical methodology. The timing of a Bayesian course is right given the readily availability of Bayesian instructional material and an increasing amount of Bayesian computational resources.\nWe propose that Cobb’s five imperatives can be implemented through a Bayesian statistics course. Simulation provides an attractive “flattened prerequisites” strategy in performing inference. In a Bayesian inferential calculation, one avoids the integration issue by simulating a large number of values from the posterior distribution and summarizing this simulated sample. %Moreover, this Bayesian course can introduce the family of Markov chain Monte Carlo (MCMC) simulation algorithms used by Bayesian scientists that are applicable a wide variety of inferential problems, further “embrace computation”. Moreover, by teaching fundamentals of Bayesian inference of conjugate models together with simulation-based inference, students gain a deeper understanding of Bayesian thinking. Familiarity with simulation methods in the conjugate case prepares students for the use of simulation algorithms later for more advanced Bayesian models.\nOne advantage of a Bayes perspective is the opportunity to input expert opinion by the prior distribution which allows students to “exploit context” beyond a traditional statistical analysis.\nIt is desirable to introduce some strategies for constructing one’s prior when one has substantive prior information. In the case where one has little prior knowledge, some discussion about suitable weakly informative priors is needed. This text introduces strategies for constructing one’s prior in the situations when one has substantial prior information and when one has little prior knowledge.\nTo further “exploit context”, we introduce one particular Bayesian success story: the use of hierarchical modeling when one wishes to simultaneously estimates parameters from several groups. In many applied statistical analyses, a common problem is to combine estimates from several groups, often with certain groups having a limited amount of available data. Through interesting applications, we introduce hierarchical modeling as an effective way to achieve partial pooling of the separate estimates.\nThe value of these hierarchical models can be demonstrated by use of simple examples such as the simultaneous estimation of several proportions.\nThanks to a number of general-purpose software programs available for Bayesian MCMC computation (e.g. openBUGS, JAGS, Nimble, and Stan), students are able to learn and apply more advanced Bayesian models for complex problems. We believe it is important to introduce the students to at least one of these programs which “flattens the prerequisite” of computational experience and “embraces computation”. The main task in the use of these programs is the specification of a script defining the Bayesian model, and the Bayesian fitting is implemented by a single function that inputs the model description, the data and prior parameters, and any tuning parameters of the algorithm.\nThere are several benefits to using general-purpose software. First, by writing the script defining the full Bayesian model, the students get a deeper understanding of the sampling and prior components of the model. Second, by use of this software for sophisticated models such as hierarchical models, this software lowers the bar for students to implement these methods. The focus of the students’ work is not the computation but rather the summarization and interpretation of the MCMC output.\nBy writing the script defining the full Bayesian model, we believe the students get a deeper understanding of the sampling and prior components of the model. Moreover, by use of this software for sophisticated models such as hierarchical models, it lowers the bar for students implementing these methods. The focus of the students’ work is not the computation but rather the summarization and interpretation of the MCMC output. Students interested in the nuts and bolts of the MCMC algorithms can further their learning through directed research or independent study.\nLast, we believe all aspects of a Bayesian analysis are communicated best through interesting case studies. In a good case study, one describes the background of the study and the inferential or predictive problems of interest. In a Bayesian applied analysis in particular, one learns about the construction of the prior to represent expert opinion, the development of the likelihood, and the use of the posterior distribution to address the questions of interest. We therefore propose the inclusion of fully-developed case studies in a Bayesian course for students’ learning and practice. Based on our teaching experience, having students work on a course project is the best way for them to learn, resonating with Cobb’s “teach through research”."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "proportion.html",
    "href": "proportion.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "mean.html",
    "href": "mean.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "proportion.html#introduction-thinking-about-a-proportion-subjectively",
    "href": "proportion.html#introduction-thinking-about-a-proportion-subjectively",
    "title": "2  Learning About a Binomial Probability",
    "section": "2.1 Introduction: Thinking About a Proportion Subjectively",
    "text": "2.1 Introduction: Thinking About a Proportion Subjectively\nIn previous chapters, we have seen many examples involving drawing color balls from a box. In those examples, we are given the numbers of balls of various colors in the box, and we consider questions related to calculating probabilities. For example, there are 40 white and 20 red balls in a box. If you draw two balls at random, what is the probability that both balls are white?\nHere we consider a new scenario where we do not know the proportions of color balls in the box. That is, in the previous example, we only know that there are two kinds of color balls in the box, but we don’t know 40 out of 60 of the balls are white (proportion of white = \\(2/3\\)) and 20 out of the 60 of the balls are red (proportion of red = \\(1/3\\)). How can we learn about the proportions of white and red balls? Since counting 60 balls can be tedious, how can we infer those proportions by drawing a sample of balls out of the box and observe the colors of balls in the sample? This becomes an inference question, because we are trying to infer the proportion \\(p\\) of the population, based on a sample from the population.\nLet’s continue discussing the scenario where we are told that there are 60 balls in total in a box, and the balls are either white or red. We do not know the count of balls of each of the two colors. We are given the opportunity to take a random sample of 10 balls out of these 60 balls. We are interested in the quantity \\(p\\), the proportion of red balls in the 60 balls. How can we infer \\(p\\), the proportion of red balls in the population (i.e. the 60 balls), based on the numbers of red and white balls we observe in the sample (i.e. the 10 balls)?\nProportions are like probabilities. Recall in Chapter 1 three views of a probability were discussed. We briefly review them here, and state the specific requirements to obtain each view.\n\nThe classical view: one needs to write down the sample space where each outcome is equally likely.\nThe frequency view: one needs to repeat the random experiments many times under identical conditions.\nThe subjective view: one needs to express one’s opinion about the likelihood of a one-time event.\n\nThe classical view does not seem to work here, because we only know there are two kinds of color balls and the total number of balls is 60. Even if we take a sample of 10 balls, we are only going to observe the proportion of red balls in the sample. There does not seem to be a way for us to write down the sample space where each outcome is equally likely.\nThe frequency view would work here. One could treat the process of obtaining a sample (i.e. taking a random sample of 10 balls from the box) as an experiment, and obtain a sample proportion \\(\\hat{p}\\) from the experiment. One then could repeat the experiment many times under the same condition, get many sample proportions \\(\\hat{p}\\), and summarize all the \\(\\hat{p}\\). When one repeats the experiment enough times (a large number), one gets a good sense about the proportion \\(p\\) of red balls in the population of 60 balls in the box. This process is doable, but tedious, time-consuming, and prone to errors.\nThe subjective view perceives the unknown proportion \\(p\\) subjectively. It does require one to express his or her opinion about the value of \\(p\\), and he or she could be skeptical and unconfident about the opinion. In Chapter 1, a calibration experiment was introduced to help one sharpen an opinion about the likelihood of an event by comparisons with opinion about the likelihood of other events. In this chapter and the chapters to follow, we introduce the key ideas and practice about thinking subjectively about unknowns and quantify one’s opinions about the values of these unknowns using probability distributions.\nAs an example, let’s think about plausible values for the proportion \\(p\\) of red balls. As \\(p\\) is a proportion, it can take any possible value between 0 and 1. In the calibration experiment introduced in Chapter 1, we focus on the scenario where only one value of \\(p\\) is of interest. For example, when one thinks that \\(p\\) is 0.5, it is saying that one’s opinion about the probability of the value \\(p=0.5\\) is one. When we phrase it this way (“one’s opinion about the probability of \\(p=0.5\\) is one”), it sounds like a very strong opinion, because one only allows \\(p\\) to take one possible value, and gives probability one of that happening. Since one typically has no thought about the exact value of the proportion \\(p\\), setting one possible value for the proportion with probability one seems too strong.\nInstead suppose that the proportion \\(p\\) can take multiple values between 0 and 1. In particular, let’s consider two scenarios, in both \\(p\\) can take 10 different values, denoted by set \\(A\\).\n\\[\\begin{eqnarray}\nA = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\}\n\\end{eqnarray}\\]\nThough \\(p\\) can take the same 10 multiple values in both scenarios, we assign different probabilities to each possible value.\n\nScenario 1: \\[\\begin{eqnarray}\nf_1(A) = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)\n\\end{eqnarray}\\]\nScenario 2: \\[\\begin{eqnarray}\nf_2(A) = (0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05) \\nonumber \\\\\n\\end{eqnarray}\\]\n\nTo visually compare the values of two probability distributions \\(f_1(A)\\) and \\(f_2(A)\\), we plot \\(f_1(A)\\) and \\(f_2(A)\\) on the same graph.\n\n\n\n\n\n\n\n\nThe same ten possible values of \\(p\\), but two sets of probabilities.\n\n\n\n\nFigure 7.1 labels the \\(x\\)-axis as the values of \\(p\\) (range from 0 to 1), \\(y\\)-axis as the probabilities (range from 0 to 1). For both panels, there are ten bars, each representing the possible values of \\(p\\) in the set \\(A = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\}\\).\nThe probability assignment in \\(f_1(A)\\) is called a discrete Uniform distribution, where each possible value of the proportion \\(p\\) is equally likely. Since there are ten possible values of \\(p\\), each value gets assigned a probability of \\(1/10 = 0.1\\). This assignment expresses the opinion that \\(p\\) can be any value from the set \\(A = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\}\\), and each value has a probability of \\(0.1\\).\nThe probability assignment in \\(f_2(A)\\) is also discrete, however, we do not see a Uniform distribution pattern of the probabilities across the board. What we see is that the probabilities of the first three values (0.1, 0.2, and 0.3) and last three (0.8, 0.9, and 1.0) values of \\(p\\) are each \\(1/3.5\\) of that of the middle four (0.4, 0.5, 0.6, and 0.7) values. The shape of the bins reflects the opinion that the middle values of \\(p\\) are 3.5 times as likely as the extreme values of \\(p\\).\nBoth sets of probabilities follow the three probability axioms in Chapter 1. One sees that within each set,\n\nEach probability is nonnegative;\nThe sum of the probabilities is 1;\nThe probability of mutually exclusive values is the sum of probability of each value, e.g. probability of \\(p = 0.1\\) or \\(p = 0.2\\) is \\(0.1 + 0.1\\) in \\(f_1(A)\\), and \\(0.05 + 0.05\\) in \\(f_2(A)\\).\n\nIn this introduction, we have presented a way to think about proportions subjectively. We have introduced a way to allow multiple values of \\(p\\), and perform probability assignments that follow the three probability axioms. One probability distribution expresses a unique opinion about the proportion \\(p\\).\nTo answer our inference question “what is the proportion of red balls in the box”, we will take a random sample of 10 balls, and use the observed proportion of red balls in that sample to sharpen and update our belief about \\(p\\). Bayesian inference is a formal method for implementing this way of thinking and problem solving, including three general steps.\n\nStep 1: Prior: express an opinion about the location of the proportion \\(p\\) before sampling.\nStep 2: Data/Likelihood: take the sample and record the observed proportion of red balls.\nStep 3: Posterior:use Bayes’ rule to sharpen and update the previous opinion about \\(p\\) given the information from the sample.\n\nAs indicated in the parentheses, the first step “Prior” constructs prior opinion about the quantity of interest, and a probability distribution is used (like \\(f_1(A)\\) and \\(f_2(A)\\) earlier) to quantify the prior opinion. The name “prior” indicates that the opinion should be formed before collecting any data.\nThe second step “Data” is the process of data collection, where the quantity of interest is observed in the collected data. For example, if our 10-ball sample contains 4 red balls and 6 white balls, the observed proportion of red balls is \\(4/10 = 0.4\\). Informally, how does this information help us sharpen one’s opinion about \\(p\\)? Intuitively one would give more probability to \\(p = 0.4\\), but it is unclear how the probabilities would be redistributed among the 10 values in \\(A\\). Since the sum of all probabilities is 1, is it possible that some of the larger proportion values, such as \\(p = 0.9\\) and \\(p = 1.0\\), will receive probabilities of zero? To address these questions, the third step is needed.\nThe third step “Posterior” combines one’s prior opinion and the collected data to update one’s opinion about the quantity of interest. Just like the example of observing 4 red balls in the 10-ball sample, one needs a structured way of updating the opinion from prior to posterior.\nThroughout this chapter, the entire inference process will be described for learning about a proportion \\(p\\). This chapter will discuss how to express prior opinion that matches with one’s belief, how to extract information from the data/likelihood, and how to update our opinion to its posterior."
  },
  {
    "objectID": "proportion.html#bayesian-inference-with-discrete-priors",
    "href": "proportion.html#bayesian-inference-with-discrete-priors",
    "title": "2  Learning About a Binomial Probability",
    "section": "2.2 Bayesian Inference with Discrete Priors",
    "text": "2.2 Bayesian Inference with Discrete Priors\n\n2.2.1 Example: students’ dining preference\nLet’s start our Bayesian inference for proportion \\(p\\) with discrete prior distributions with a students’ dining preference example. A popular restaurant in a college town has been in business for about 5 years. Though the business is doing well, the restaurant owner wishes to learn more about his customers. Specifically, he is interested in learning about the dining preferences of the students. The owner plans to conduct a survey by asking students “what is your favorite day for eating out?” In particular, he wants to find out what percentage of students prefer to dine on Friday, so he can plan ahead for ordering supplies and giving promotions.\nLet \\(p\\) denote the proportion of all students whose answer is Friday.\n\n\n2.2.2 Discrete prior distributions for proportion \\(p\\)\nBefore giving out the survey, let’s pause and think about the possible values for the proportion \\(p\\). Not only does one want to know about possible values, but also the probabilities associated with the values. A probability distribution provides a measure of belief for the proportion and it ultimately will help the restaurant owner improve his business.\nOne might not know much about students’ dining preference, but it is possible to come up with a list of plausible values for the proportion. There are seven days a week. If each day was equally popular, then one would expect 1/7 or approximately 15% of all students to choose Friday. The owner recognizes that Friday is the start of the weekend, therefore there should be a higher chance of being students’ preferred day of dining out. So perhaps \\(p\\) starts with 0.3. Then what about the largest plausible value? Letting this largest value be 1 seems unrealistic, as there are six other days in the week. Suppose that one chooses 0.8 to be the largest plausible value, and then comes up with the list of values of \\(p\\) to be the six values going from 0.3 to 0.8 with an increment of 0.1.\n\\[\\begin{eqnarray}\np = \\{0.3, 0.4, 0.5, 0.6, 0.7, 0.8\\}\n\\label{eq:dining:p}\n\\end{eqnarray}\\]\nNext one needs to assign probabilities to the list of plausible values of \\(p\\). Since one may not know much about the location of the probabilities \\(p\\), a good place to start is a discrete Uniform prior (recall the discrete Uniform prior distribution for \\(p\\), the proportion of red balls, in Section 7.1). A discrete Uniform prior distribution expresses the opinion that all plausible values of \\(p\\) are equally likely. In the current students’ dining preference example, if one decides on six plausible values of \\(p\\) as in Equation (7.1), each of the six values gets a prior probability of 1/6. One labels this prior as \\(\\pi_l\\), where \\(l\\) stands for laymen (for all of us who are not in the college town restaurant business). Note that in the notation \\(f_l(p)\\), the first \\(p\\) stands for probability, and the \\(p\\) in the parenthesis is our quantity of interest, the proportion \\(p\\) of students preferring to dine out on Friday.\n\\[\\begin{eqnarray}\n\\pi_l(p)= (1/6, 1/6, 1/6, 1/6, 1/6, 1/6)\n\\label{eq:dining:laymenprior}\n\\end{eqnarray}\\]\nWith five years of experience of running his restaurant in this college town, the restaurant owner might have different opinions about likely values of \\(p\\). Suppose he agrees with us that \\(p\\) could take the 6 plausible values from 0.3 to 0.8, but he assigns a different prior distribution for \\(p\\). In particular, the restaurant owner thinks that values of 0.5 and 0.6 are most likely – each of these values is twice as likely as the other values. His prior is labelled as \\(\\pi_e\\), where \\(e\\) stands for expert.\n\\[\\begin{eqnarray}\n\\pi_e(p)= (0.125, 0.125, 0.250, 0.250, 0.125, 0.125)\n\\label{eq:dining:expertprior}\n\\end{eqnarray}\\]\nTo obtain \\(\\pi_e(p)\\) efficiently, one can use the ProbBayes R package. First a data frame is created by providing the list of plausible values of \\(p\\) and corresponding weights assigned to each value using the function data.frame(). As one can see here, one does not have to calculate the probability – one only needs to give the weights (e.g. giving \\(p = 0.3, 0.4, 0.7, 0.8\\) weight 1 and giving \\(p = 0.5, 0.6\\) weight 2, to reflect the owner’s opinion “0.5 and 0.6 are twice as likely as the other values”).\n\nbayes_table <- data.frame(p = seq(.3, .8, by=.1),\n                          Prior = c(1, 1, 2, 2, 1, 1))\nbayes_table\n\n    p Prior\n1 0.3     1\n2 0.4     1\n3 0.5     2\n4 0.6     2\n5 0.7     1\n6 0.8     1\n\n\nOne uses the function mutate() to normalize these weights to obtain the prior probabilities in the Prior column.\n\nbayes_table %>% mutate(Prior = Prior / sum(Prior)) -> bayes_table\nbayes_table\n\n    p Prior\n1 0.3 0.125\n2 0.4 0.125\n3 0.5 0.250\n4 0.6 0.250\n5 0.7 0.125\n6 0.8 0.125\n\n\nOne conveniently plots the restaurant owner’s prior distribution by use of ggplot2 functions. This distribution is displayed in Figure 7.2.\n\n\n\n\n\nThe restaurant owner’s prior distribution for the proportion \\(p\\).\n\n\n\n\nIt is left as an exercise for the reader to compute and plot the laymen’s prior \\(\\pi_l(p)\\) in Equation (7.2). For the rest of this section, we will work with the expert’s prior \\(\\pi_e(p)\\).\n\n\n2.2.3 Likelihood\nThe next step in the inference process is the data collection. The restaurant owner gives a survey to 20 student diners at the restaurant. Out of the 20 student respondents, 12 say that their favorite day for eating out is Friday. Recall the quantity of interest is proportion \\(p\\) of the population of students choosing Friday.\nThe likelihood is a function of the quantity of interest, which is the proportion \\(p\\). The owner has conducted an experiment 20 times, where each experiment involves a “yes” or “no” answer from the respondent to the rephrased question “whether Friday is your preferred day to dine out”. Then the proportion \\(p\\) is the probability a student answers “yes”.\nDoes this ring a bell of what we have seen before? Indeed, in Chapter 4, one has seen this type of experiment, a Binomial experiment, similar to the dining survey. Recall that a Binomial experiment needs to satisfy four conditions:\n\nOne is repeating the same basic task or trial many times – let the number of trials be denoted by \\(n\\).\nOn each trial, there are two possible outcomes called “success” or “failure”.\nThe probability of a success, denoted by \\(p\\), is the same for each trial.\nThe results of outcomes from different trials are independent.\n\nIf one recognizes an experiment as being Binomial, then all one needs to know is \\(n\\) and \\(p\\) to determine probabilities for the number of successes \\(Y\\). The probability of \\(y\\) successes in a Binomial experiment is given by\n\\[\\begin{eqnarray}\nProb(Y=y) = {n \\choose y} p^y (1 - p)^{n - y}, y = 0, \\cdots, n.\n\\end{eqnarray}\\]\nAssuming the dining survey is a random sample (thus independent outcomes), this is the result of a Binomial experiment. The likelihood is the chance of 12 successes in 20 trials viewed as a function of the probability of success \\(p\\): \\[\\begin{eqnarray}\nLikelihood = L(p) = {20 \\choose 12} p ^ {12} (1 - p) ^ 8.\n\\label{eq:dining:likelihood}\n\\end{eqnarray}\\]\nGenerally one uses \\(L\\) to denote a likelihood function — one sees in Equation (7.5), \\(L\\) is a function of \\(p\\). Note that the value of \\(n\\), the total number of trials, is known and the number of successes \\(Y\\) is observed to be 12. The proportion \\(p\\), is the parameter of the Binomial experiment and the likelihood is a function of the proportion \\(p\\).\nThe likelihood function \\(L(p)\\) is efficiently computed using the dbinom() function in R. In order to use this function, we need to know the sample size \\(n\\) (20 in the dining survey), the number of successes \\(y\\) (12 in the dining survey), and \\(p\\) (the list of 6 plausible values created in Section 7.2.2; \\(p = \\{0.3, 0.4, 0.5, 0.6, 0.7, 0.8\\}\\)). Note that we only need the plausible values of \\(p\\), not yet the assigned probabilities in the prior distribution. The prior will be used in the third step to update the opinion of \\(p\\) to its posterior.\nBelow is the example R code of finding the probability of 12 successes in a sample of 20 for each value of the proportion \\(p\\). The values are placed in the Likelihood column of the bayes_table data frame.\n\nbayes_table$Likelihood <- dbinom(12, size=20, prob=bayes_table$p)\nbayes_table\n\n    p Prior  Likelihood\n1 0.3 0.125 0.003859282\n2 0.4 0.125 0.035497440\n3 0.5 0.250 0.120134354\n4 0.6 0.250 0.179705788\n5 0.7 0.125 0.114396740\n6 0.8 0.125 0.022160877\n\n\n\n\n2.2.4 Posterior distribution for proportion \\(p\\)\nThe posterior probabilities are found as an application of Bayes’ rule. This recipe will be illustrated first through a step-by-step calculation process. Next the process is demonstrated with the bayesian_crank() function in the ProbBayes R package, which implements the Bayes’ rule calculation and outputs the posterior probabilities.\nLet \\(\\pi(p)\\) to be the prior distribution of \\(p\\), let \\(L(p)\\) denote the likelihood function, and \\(\\pi(p \\mid y)\\) to be the posterior distribution of \\(p\\) after observing the number of successes \\(y\\). For discrete parameters, such as the proportion \\(p\\) in our case, one is able to enumerate the list of plausible values and assign prior probabilities to the values. If \\(p_i\\) represents a particular value of \\(p\\), Bayes’ rule for a discrete parameter has the form \\[\\begin{eqnarray}\n\\pi(p_i \\mid y)  = \\frac{\\pi(p_i) \\times L(p_i)} {\\sum_j \\pi(p_j) \\times L(p_j)},\n\\label{eq:Discrete:bayesrule}\n\\end{eqnarray}\\] where \\(\\pi(p_i)\\) is the prior probability of \\(p = p_i\\), \\(L(p_i)\\) is the likelihood function evaluated at \\(p = p_i\\), and \\(\\pi(p_i \\mid y)\\) is the posterior probability of \\(p = p_i\\) given the number of successes \\(y\\). By the Law of Total Probability, the denominator gives the marginal distribution of the observation \\(y\\).\nBayes’ rule can also be expressed as “prior times likelihood”: \\[\\begin{eqnarray}\n\\pi(p_i \\mid y)  \\propto \\pi(p_i) \\times L(p_i)\n\\label{eq:Discrete:bayesruleProp}\n\\end{eqnarray}\\] Equation (7.7) ignores the denominator and states that the posterior is proportional to the product of the prior and the likelihood. As one will see soon, the value of the denominator is a constant, meaning that its purpose is to normalize the numerator. It is convenient to work with Bayes’ rule as in Equation (7.7) in later chapters. However, it is instructive to show the exact calculation of Equation (7.6), because one has a finite sum in the denominator and it is possible to obtain the analytical solution. In the case where the prior is continuous, it will be more difficult to analytically compute the normalizing constant.\nReturning to the students’ dining preference example, the list of plausible values of the proportion is \\(p = \\{0.3, 0.4, 0.5, 0.6, 0.7, 0.8\\}\\) and according to the restaurant owner’s expert prior, the assigned probabilities are \\(\\pi_e(p)= (0.125, 0.125, 0.250, 0.250, 0.125, 0.125)\\) (recall Figure 7.2). After observing the number of successes, the likelihood values are calculated for the models using dbinom() function, as presented in Section 7.2.3.\nThe denominator is the sum of the products of the prior and the likelihood at each possible \\(p_i\\), which, given the Law of Total Probability, is equal to the marginal probability of the data \\(f(y)\\). One can think of the above formula as reweighing or normalizing the probability of \\(\\pi(p_i \\mid y)\\) by all possible values of \\(p\\). In the case of discrete models like this, the marginal probability of the likelihood is computed through \\(\\sum_j f(p_j) \\times L(p_j)\\).\nIn this setup, the computation of the posterior probabilities of different \\(p_i\\) values is straightforward. First, one calculates the denominator and denote the value as \\(D\\). \\[\\begin{eqnarray*}\nD &=& \\pi(0.3) \\times L(0.3) + \\pi(0.4) \\times L(0.4) + \\cdots + \\pi(0.8) \\times L(0.8) \\\\\n&=& 0.125 \\times {20 \\choose 12}(0.3)^{12}(1-0.3)^{8} + \\cdots + 0.125 \\times {20 \\choose 12}(0.8)^{12}(1-0.8)^{8} \\nonumber \\\\ &\\approx& 0.0969.\n\\end{eqnarray*}\\] Then the posterior probability of \\(p = 0.3\\) is given by \\[\\begin{eqnarray*}\n\\pi(p = 0.3 \\mid 12) &=& \\frac{\\pi(0.3) \\times L(0.3)}{D} \\\\\n&=& \\frac{0.125 \\times {20 \\choose 12}(0.3)^{12}(1-0.3)^{8}}{D}  \\\\\n&\\approx& 0.005.\n\\end{eqnarray*}\\] In a similar fashion, the posterior probability of \\(p=0.5\\) is calculated as \\[\\begin{eqnarray*}\n\\pi(p = 0.5 \\mid 12) &=& \\frac{\\pi(0.5) \\times L(0.5)}{D} \\\\\n&=& \\frac{0.125 \\times {20 \\choose 12}(0.5)^{12}(1-0.5)^{8}}{D} \\\\\n&\\approx& 0.310.\n\\end{eqnarray*}\\] One sees that the denominator is the same for the posterior probability calculation of every value of \\(p\\). This calculation gets tedious for a large number of possible values of \\(p\\). Relying on statistical software such as R helps us simplify the tasks.\nTo use the bayesian_crank() function, recall that we have already created a data frame with variables p, Prior, and Likelihood. Then the bayesian_crank() function is used to compute the posterior probabilities.\n\nbayesian_crank(bayes_table) -> bayes_table\nbayes_table\n\n    p Prior  Likelihood      Product   Posterior\n1 0.3 0.125 0.003859282 0.0004824102 0.004975901\n2 0.4 0.125 0.035497440 0.0044371799 0.045768032\n3 0.5 0.250 0.120134354 0.0300335884 0.309786454\n4 0.6 0.250 0.179705788 0.0449264469 0.463401326\n5 0.7 0.125 0.114396740 0.0142995925 0.147495530\n6 0.8 0.125 0.022160877 0.0027701096 0.028572757\n\n\nAs one sees in the bayes_table output, the bayesian_crank() function computes the product of Prior and Likelihood and stores the values in the column Product, then normalizes each product with the sum of all products to produce the posterior probabilities, stored in the column Posterior.\nFigure 7.3 compares the prior probabilities in the bottom panel with the posterior probabilities in the top panel. Notice the difference in the two distributions. After observing the survey results (i.e. the data/likelihood), the owner is more confident that \\(p\\) is equal to 0.5 or 0.6, and it is unlikely for \\(p\\) to be 0.3, 0.4, 0.7, and 0.8. Recall that the data gives an observed proportion 12/20 = 0.6. Since the posterior is a combination of prior and data/likelihood, it is not surprising that the data/likelihood helps the owner to sharpen his belief about proportion \\(p\\) and place a larger posterior probability around 0.6.\n\n\n\n\n\nPrior and posterior distributions on the proportion \\(p\\).\n\n\n\n\n\n\n2.2.5 Inference: students’ dining preference\nLet’s revisit the posterior distribution table to perform some inference. What is the posterior probability that over half of the students prefer eating out on Friday? One is interested in the probability that \\(p >\\) 0.5, in the posterior. Looking at the table, this posterior probability is equal to \\[\\begin{eqnarray*}\nProb(p > 0.5) \\approx 0.463 + 0.147 + 0.029 = 0.639.\n\\end{eqnarray*}\\] This means the owner is reasonably confident (with probability 0.639) that over half of the college students prefer to eat out on Friday.\nOne easily obtains the probability from the R output, for example.\n\nsum(bayes_table$Posterior[bayes_table$p > 0.5])\n\n[1] 0.6394696\n\n\n\n\n2.2.6 Discussion: using a discrete prior\nSpecifying a discrete prior has two steps: (1) specifying a list of plausible values of the parameter of interest, and (2) assigning probabilities to the plausible values. It is important to remember the three probability axioms when specifying a discrete prior.\nAfter the prior specification, the next component is the data/likelihood, which can also be broken up into two steps. First, one constructs a suitable experiment that works for the particular scenario. Here one has a Binomial experiment for a survey to a fixed number of respondents, the answers are classified into “yes” and “no” or “success” and “failure”, the outcome of interest is the number of successes and trials are independent. From the Binomial distribution, one obtains the likelihood function which is evaluated at each possible value of the parameter of interest. In our example, the dbinom() R function was used to calculate the likelihood function.\nLast, the posterior probabilities are calculated using Bayes’ rule. In particular for the discrete case, follow Equation (7.6). The calculation of the denominator is tedious, however practice with the Bayes’ rule calculation enhances one’s understanding of Bayesian inference. R functions such as bayesian_crank() are helpful for implementing the Bayes’ rule calculations. Bayesian inference follows from a suitable summarization of the posterior probabilities. In our example, inference was illustrated by calculating the probability that over half of the students prefer eating out on Friday.\nLet’s revisit the list of plausible values of proportion \\(p\\) of students preferring Friday in dining out in the example. Although \\(p = 1.0\\), that is, everyone prefers Friday, is very unlikely, one might not want to eliminate this proportion value from consideration. As one observes in the Bayes’ rule calculation process shown in Sections 7.2.3 and 7.2.4, if one does not include \\(p = 1.0\\) as one of the plausible values in the prior distribution in Section 7.2.2, this value will also be given a probability of zero in the posterior.\nAlternatively, one could choose the alternative set of values \\[\\begin{eqnarray*}\np = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\},\n\\end{eqnarray*}\\] and assign a very small prior probability (e.g. 0.05 or even smaller) for \\(p = 1.0\\) to express the opinion that \\(p = 1.0\\) is very unlikely. One may assign small prior probabilities for other large values of \\(p\\) such as \\(p = 0.9\\).\nThis comment illustrates a limitation of specifying a discrete prior for a proportion \\(p\\). If a plausible value is not specified in the prior distribution (e.g. \\(p = 1.0\\) is not in the restaurant owner’s prior distribution), it will be assigned a probability of zero in the posterior (e.g. \\(p = 1.0\\) is not in the restaurant owner’s posterior distribution).\nIt generally is more desirable to have \\(p\\) to be any value in [0, 1] including less plausible values such as \\(p = 1.0\\). To make this happen, the proportion \\(p\\) should be allowed to take any value between 0 and 1, which means \\(p\\) will be a continuous variable. In this situation, it is necessary to construct a continuous prior distribution for \\(p\\). A popular class of continuous prior distributions for proportion is the Beta distribution which is the subject of the next section."
  },
  {
    "objectID": "proportion.html#continuous-priors",
    "href": "proportion.html#continuous-priors",
    "title": "2  Learning About a Binomial Probability",
    "section": "2.3 Continuous Priors",
    "text": "2.3 Continuous Priors\nLet’s continue our students’ dining preference example. A restaurant owner is interested in learning about the proportion \\(p\\) of students whose favorite day for eating out is Friday.\nThe proportion \\(p\\) should be a value between 0 and 1. Previously, we used a discrete prior for \\(p\\), representing the belief that \\(p\\) only takes the six different values 0.3, 0.4, 0.5, 0.6, 0.7, and 0.8. An obvious limitation of this assumption is, what if the true \\(p\\) is 0.55? If the value 0.55 is not specified in the prior distribution of \\(p\\) (that is, a zero probability is assigned to the value \\(p\\) = 0.55), then by the Bayes’ rule calculation (either by hand or by the useful bayesian_crank() function) there will be zero posterior probability assigned to 0.55. It is therefore preferable to specify a prior that allows \\(p\\) to be any value in the interval [0, 1].\nTo represent such a prior belief, it is assumed that \\(p\\) is continuous on [0, 1]. Suppose again that one is a layman unfamiliar with the pattern of dining during a week. Then one possible choice of a continuous prior for \\(p\\) is the continuous Uniform distribution, which expresses the opinion that \\(p\\) is equally likely to take any value between 0 and 1.\nFormally, the probability density function of the continuous Uniform on the interval \\((a, b)\\) is \\[\\begin{eqnarray}\n\\pi(p) =\n\\begin{cases}\n  \\frac{1}{b - a} & \\text{for }a \\le p \\le b,\\\\    \n  0             & \\text{for }p < a \\,\\, \\text{or } p > b.\n\\end{cases}\n\\label{eq:Binomial:Continuous:Uniform}\n\\end{eqnarray}\\] In our situation \\(p\\) is a continuous Uniform random variable on [0, 1], we have \\(\\pi(p) = 1\\) for \\(p \\in [0, 1]\\), and \\(\\pi(p) = 0\\) everywhere else.\nWhat about other possible continuous prior distributions for \\(p\\) on [0, 1]? Consider a prior distribution for the restaurant owner who has some information about the location (i.e. value) of \\(p\\). This owner would be interested in a continuous version of the discrete prior distribution where values of \\(p\\) between 0.3 and 0.8 are more likely than the values at the two ends.\nThe Beta family of continuous distributions is useful for representing prior knowledge in this situation. A Beta distribution, denoted by Beta(\\(a, b)\\), represents probabilities for a random variable falling between 0 and 1. This distribution has two shape parameters, \\(a\\) and \\(b\\), with probability density function given by \\[\\begin{eqnarray}\n\\pi(p) = \\frac{1}{B(a, b)} p^{a - 1} (1 - p)^{b - 1}, \\, \\, 0 \\le p \\le 1,\n\\end{eqnarray}\\] where \\(B(a, b)\\) is the Beta function defined by \\(B(a, b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\), where \\(\\Gamma\\) is the Gamma function. For future reference, it is useful to know that if \\(p \\sim {\\rm Beta}(a, b)\\), its mean \\(E[p] = \\frac{a}{a+b}\\) and its variance \\(V(p) = \\frac{ab}{(a+b)^2(a+b+1)}\\). The continuous Uniform in Equation (7.8) is a special case of the Beta distribution: \\(\\textrm{Uniform}(0, 1) = \\textrm{Beta}(1, 1)\\).\nFor the remainder of this section, Section 7.3.1 introduces the Beta distribution and Beta probabilities, and Section 7.3.2 focuses on several ways of choosing a Beta prior that reflects one’s opinion about the location of a proportion.\n\n2.3.1 The Beta distribution and probabilities\nThe two shape parameters \\(a\\) and \\(b\\) control the shape of the Beta density curve. Figure 7.4 shows density curves of Beta distributions for several choices of the shape parameters. One observes from this figure that the Beta density curve displays vastly different shapes for varying choices of \\(a\\) and \\(b\\). For example, \\(\\textrm{Beta}(0.5, 0.5)\\) represents the prior belief that extreme values of \\(p\\) are likely and \\(p=0.5\\) is the least probable value. In the students’ dining preference example, specifying a \\(\\textrm{Beta}(0.5, 0.5)\\) would reflect the owner’s belief that the proportion of students dining out on Friday is either very high (near one) or very low (near one) and not likely to be moderate values.\n\n\n\n\n\nIllustration of nine Beta density curves.\n\n\n\n\nAs the Beta is a common continuous distribution, R functions are available for Beta distribution calculations. We provide a small example of “Beta” functions for Beta(1, 1), where the two shape parameters 1 and 1 are the second and third arguments of the functions.\nRecall the following useful results from previous material: (1) a \\(\\textrm{Beta}(1, 1)\\) distribution is a Uniform density on (0, 1), (2) the density of \\(\\textrm{Uniform}(0, 1)\\) is \\(\\pi(p) = 1\\) on [0, 1], and (3) if \\(p \\sim \\textrm{Uniform}(0, 1)\\), then the cdf \\(F(x) = Prob(p \\leq x) = x\\) for \\(x \\in [0, 1]\\).\n\ndbeta(): the probability density function for a \\(\\textrm{Beta}(a, b)\\) which takes a value of the random variable as its input and outputs the probability density function at that value.\n\nFor example, we evaluate the density function of \\(\\textrm{Beta}(1, 1)\\) at the values \\(p = 0.5\\) and \\(p = 0.8\\), which should be both 1, and 0 at \\(p = 1.2\\) which should be 0 since this value is outside of [0, 1].\n\ndbeta(c(0.5, 0.8, 1.2), 1, 1)\n\n[1] 1 1 0\n\n\n\npbeta(): the distribution function of a Beta(a; b) random variable, which takes a value x and gives the value of the random variable at that value, F(x).\n\nFor example, suppose one wishes to evaluate the distribution function of \\(\\textrm{Beta}(1, 1)\\) at \\(p = 0.5\\) and \\(p = 0.8\\).\n\npbeta(c(0.5, 0.8), 1, 1)\n\n[1] 0.5 0.8\n\n\nOne calculates the probability of \\(p\\) between 0.5 and 0.8, i.e. \\(Prob(0.5 \\le p \\le 0.8)\\) by taking the difference of the cdf at the two values.\n\npbeta(0.8, 1, 1) - pbeta(0.5, 1, 1)\n\n[1] 0.3\n\n\n\nqbeta(): the quantile function of a \\(\\textrm{Beta}(a, b)\\), which inputs a probability value \\(p\\) and outputs the value of \\(x\\) such that \\(F(x) = p\\).\n\nFor example, suppose one wishes to calculate the quantile of \\(\\textrm{Beta}(1, 1)\\) at \\(p = 0.5\\) and \\(p = 0.8\\).\n\nqbeta(c(0.5, 0.8), 1, 1)\n\n[1] 0.5 0.8\n\n\n\nrbeta(): the random number generator for \\(\\textrm{Beta}(a, b)\\), which inputs the size of a random sample and gives a vector of the simulated random variates.\n\nFor example, suppose one is interested in simulating a sample of size five from \\(\\textrm{Beta}(1, 1)\\).\n\nrbeta(5, 1, 1)\n\n[1] 0.734675335 0.480856595 0.145059246 0.797390149 0.006913549\n\n\nThere are additional functions in the ProbBayes R package that aid in visualizing Beta distribution calculations. For example, suppose one has a \\(\\textrm{Beta}(7, 10)\\) curve and we want to find the chance that \\(p\\) is between 0.4 and 0.8. Looking at Figure 7.5, this probability corresponds to the area of the shaded region. The special function beta_area() will compute and illustrate this probability. Note the use of the vector c(7, 10) to input the two shape parameters.\nbeta_area(0.4, 0.8, c(7, 10))\n\n\n\n\n\nArea represents the probability that a Beta(7, 10) variable lies between 0.4 and 0.8\n\n\n\n\nOne could also find the chance that \\(p\\) is between 0.4 and 0.8 by subtracting two pbeta() functions.\n\npbeta(0.8, 7, 10) - pbeta(0.4, 7, 10)\n\n[1] 0.5269265\n\n\nThe function beta_quantile() works in the same way as qbeta(), the quantile function. However, beta_quantile() automatically produces a plot with the shaded probability area. Figure 7.6 plots and computes the quantile to be 0.408. The chance that \\(p\\) is smaller than 0.408 is 0.5.\nbeta_quantile(0.5, c(7, 10))\n\n\n\n\n\nIllustration of a 0.5 quantile for a Beta(7, 10) variable.\n\n\n\n\nAlternatively, use the qbeta() function without returning a plot.\n\nqbeta(0.5, 7, 10)\n\n[1] 0.4082265\n\n\n\n\n2.3.2 Choosing a Beta density to represent prior opinion\nOne wants to use a \\(\\textrm{Beta}(a, b)\\) density curve to represent one’s prior opinion about the values of the proportion \\(p\\) and their associated probabilities. It is difficult to guess at values of the shape parameters \\(a\\) and \\(b\\) directly. However, there are indirect ways of guessing their values. We present two general methods here.\nThe first method is to consider the shape parameter \\(a\\) as the prior count of “successes” and the other shape parameter \\(b\\) as the prior count of “failures”. Subsequently, the value \\(a + b\\) represents the prior sample size comparable to \\(n\\), the data sample size. Following this setup, one could specify a Beta prior with shape parameter \\(a\\) expressing the number of successes in one’s prior opinion, and the other shape parameter \\(b\\) expressing the number of failures in one’s prior opinion. For example, if one believes that a priori there should be about 4 successes and 4 failures, then one could use \\(\\textrm{Beta}(4, 4)\\) as the prior distribution for the proportion \\(p\\).\nHow can we check if \\(\\textrm{Beta}(4, 4)\\) looks like what we believe a priori? Recall that rbeta() generates a random sample from a Beta distribution. The R script below generates a random sample of size 1000 from \\(\\textrm{Beta}(4, 4)\\) and we plot a histogram and an overlapping density curve. (See top panel of Figure 7.7.) By an inspection of this graph, one decides if this prior is a reasonable approximation to one’s beliefs about the proportion.\n\n\n\n\n\nHistograms of 1000 samples of two Beta density curves Beta(4, 4) and Beta(2, 9).\n\n\n\n\nAs a second example, consider a belief that a priori there are 2 successes and 9 failures, corresponding to the \\(\\textrm{Beta}(2, 9)\\) prior? One can use the rbeta() function take a random sample of 1000 from this prior.\n\nBeta29samples <- rbeta(1000, 2, 9)\n\nComparing the two distributions, note from Figure 7.7 that \\(\\textrm{Beta}(2, 9)\\) favors smaller proportion values than \\(\\textrm{Beta}(4, 4)\\).\nTo further check the quantiles of the prior, one can use the quantile() function on the simulated draws from the prior. For example, if one wishes to check the middle 50% range of values of \\(p\\) from the random sample of values from \\(\\textrm{Beta}(4, 4)\\), one types\n\nBeta44samples <- rbeta(1000, 4, 4)\nquantile(Beta44samples, c(0.25, 0.75))\n\n      25%       75% \n0.3751779 0.6287124 \n\n\nThis tells us that the probability that \\(p \\leq 0.366\\) is 0.25 and the probability that \\(p \\geq 0.616\\) is also 0.25. These probability statements should be checked against one’s prior belief about \\(p\\). If these quantiles do not seem reasonable, one should make adjustments to the values of the shape parameters \\(a\\) and \\(b\\) .\nOn the surface the two priors \\(\\textrm{Beta}(4, 4)\\) and \\(\\textrm{Beta}(40, 40)\\) seem similar in that they both have a mean of \\(0.5\\) and represent similar breakdowns of the success and failure counts. However, the aforementioned concept of prior sample size tells us that \\(\\textrm{Beta}(4, 4)\\) has a prior sample size of 8 while that of \\(\\textrm{Beta}(40, 40)\\) is 80. As we will see in Section 7.4, the prior sample size determines the strength of the prior (i.e. the confidence level in the prior) and so the \\(\\textrm{Beta}(40, 40)\\) prior represents a much stronger belief that \\(p\\) is close to the value 0.5.\nA second indirect method of determining a Beta prior is by specification of quantiles of the distribution. Specifically, one determines the shape parameters \\(a\\) and \\(b\\) by first specifying two quantiles of the Beta density curve, and then finding the Beta density curve that matches these quantiles. Suppose the restaurant owner uses his knowledge to specify the 0.5 and 0.9 quantiles of the proportion \\(p\\) as follows.\n\nFirst, the restaurant owner thinks of a value \\(p_{50}\\) such that the proportion \\(p\\) is equally likely to be smaller or larger than \\(p_{50}\\). After some thought, he thinks that \\(p_{50}\\) = 0.55.\nNext, the owner thinks of a value \\(p_{90}\\) that he is pretty sure (with probability 0.90) that the proportion \\(p\\) is smaller than \\(p_{90}\\). After more thought, he decides \\(p_{90}\\) = 0.80.\n\n One then uses the beta.select() function in the ProbBayes package to find shape parameters \\(a\\) and \\(b\\) of the Beta density curve that match this information. Each quantile is specified by a list with values \\(x\\) and \\(p\\). From the output, we see \\(\\textrm{Beta}(3.06, 2.56)\\) curve represents the owner’s prior beliefs.\n\nbeta.select(list(x = 0.55, p = 0.5),\n            list(x = 0.80, p = 0.9))\n\n[1] 3.06 2.56\n\n\nThe owner’s Beta density curve is shown here. To make sure this prior is reasonable, the owner should compute several probabilities and quantiles for his prior distribution and see if these values correspond to his opinion.\nTo illustrate this checking process, Figure 7.8 shows the middle 50% area of the prior distribution. This graph shows that the probability that \\(p \\leq 0.402\\) is 0.25 and the probability that \\(p \\geq 0.692\\) is also 0.25. If these calculations do not correspond to the owner’s opinion, then maybe some change in the prior distribution would be appropriate.\n\n\n\n\n\nIllustration of the middle 50% of a Beta(3.06, 2.56) curve."
  },
  {
    "objectID": "proportion.html#updating-the-beta-prior",
    "href": "proportion.html#updating-the-beta-prior",
    "title": "2  Learning About a Binomial Probability",
    "section": "2.4 Updating the Beta Prior",
    "text": "2.4 Updating the Beta Prior\nIn the previous section, we have seen that the restaurant owner thinks that a Beta curve with shape parameters 3.06 and 2.56 is a reasonable reflection of his prior opinion about the proportion of students \\(p\\) whose favorite day for eating out is Friday. Therefore, we work with \\(\\textrm{Beta}(3.06, 2.56)\\) as the prior distribution for \\(p\\).\nNow we have the survey results – the survey was administered to 20 students and 12 say that their favorite day for eating out is Friday. As before in Section 7.2, the likelihood, that is the chance of getting this data if the probability of success is \\(p\\) is given by the Binomial formula, \\[\\begin{eqnarray*}\nLikelihood = L(p) = {20 \\choose 12} p ^ {12 }(1 - p) ^ 8.\n\\end{eqnarray*}\\]\nIn this section, the Bayes’ rule calculation of the posterior is presented for the continuous prior case and one discovers an interesting result: if one starts with a Beta prior for a proportion \\(p\\), and the data is Binomial, then the posterior will also be a Beta distribution. The Beta posterior is a natural combination of the information contained in the Beta prior and the Binomial sampling, as one would expect in typical Bayesian inference. This is an illustration of the use of a conjugate prior where the prior and posterior densities are in the same family of distributions.\n\n2.4.1 Bayes’ rule calculation\nFirst we demonstrate the Bayes’ rule calculation of the posterior of \\(p\\) through the proportional statement: \\[\\begin{eqnarray}\n\\pi(p \\mid y) \\propto  \\pi(p) \\times L(p).\n\\end{eqnarray}\\]\nThe prior distribution of \\(p\\), with density \\(\\pi(p)\\), is Beta with shape parameters \\(3.06\\) and \\(2.56\\) \\[\\begin{eqnarray*}\np \\sim \\textrm{Beta}(3.06, 2.56).\n\\end{eqnarray*}\\] The symbol “\\(\\sim\\)” is read “follows”, meaning that the random variable before the symbol follows the distribution after the symbol.\nFor the data/likelihood, we introduce proper notation. Let \\(Y\\) be the random variable of the number of students say that their favorite day for eating out is Friday. We know that the sampling distribution for \\(Y\\) is a Binomial distribution with number of trials \\(20\\) and success probability \\(p\\). Using the notation of “\\(\\sim\\)”, we have \\[\\begin{eqnarray*}\nY \\sim \\textrm{Binomial}(20, p).\n\\end{eqnarray*}\\] After the value \\(Y = y\\) is observed, \\(L(p) = f(y \\mid p)\\) denotes the likelihood, which is the probability of observing this sample value \\(y\\) viewed as a function of the proportion \\(p\\). (Note that a small letter \\(y\\) is used to denote the actual data observed, as opposed to the random variable \\(Y\\).) From the dining survey, we know that \\(y = 12\\).\nNow we have the following prior density and the likelihood function.\n\nThe prior distribution: \\[\\begin{eqnarray*}\n\\pi(p) = \\frac{1}{B(3.06, 2.56)}p^{3.06-1}(1-p)^{2.56-1}.\n\\end{eqnarray*}\\]\nThe likelihood: \\[\\begin{eqnarray*}\nf(Y =12 \\mid p) = L(p) = {20 \\choose 12}p^{12}(1-p)^{8}.\n\\end{eqnarray*}\\]\n\nBy Bayes’ rule, the posterior density \\(\\pi(p \\mid y)\\) is proportional to the product of the prior and the likelihood.\n\\[\\begin{eqnarray*}\n\\pi(p \\mid y) \\propto \\pi(p) \\times L(p).\n\\end{eqnarray*}\\]\nSubstituting the current prior and likelihood, one can perform the algebra for the posterior density. \\[\\begin{eqnarray}\n\\pi(p \\mid Y = 12) &\\propto& \\pi(p) \\times f(Y = 12 \\mid p) \\nonumber \\\\\n&=&  \\frac{1}{B(3.06, 2.56)}p^{3.06-1}(1-p)^{2.56-1} \\times \\nonumber \\\\\n&& {20 \\choose 12}p^{12}(1-p)^{8} \\nonumber \\\\\n\\texttt{[drop the constants]} &\\propto& p^{12}(1-p)^{8}p^{3.06-1}(1-p)^{2.56-1} \\nonumber \\\\\n\\texttt{[combine the powers]} &=& p^{15.06-1}(1-p)^{10.56-1}. \\nonumber \\\\\n\\end{eqnarray}\\] One observes that the posterior density of \\(p\\) given \\(Y = 12\\) is, up to a proportionality constant, \\[\\begin{eqnarray*}\n\\pi(p \\mid Y = 12) \\propto p^{15.06-1}(1-p)^{10.56-1}.\n\\end{eqnarray*}\\]\n Note that in the posterior derivation, the constants \\({20 \\choose 12}\\) and \\(\\frac{1}{B(3.06, 2.56)}\\) are dropped due to the proportional sign “\\(\\propto\\)”. That is, the expression of \\(\\pi(p \\mid Y = 12)\\) is computed up to some constant. In this case, Appendix A demonstrates the calculation of the constant.\nNext, one recognizes if the posterior distribution of \\(p\\) is recognizable as a member of a familiar family of distributions. In the computation of the posterior, we have intentionally kept the expression of “\\(-1\\)” in the powers of \\(p\\) and \\(1-p\\) terms, instead of using \\(14.06\\) and \\(9.56\\) directly. By doing this, one recognizes that the posterior density has the familiar form \\[\\begin{eqnarray*}\np^{a-1}(1-p)^{b-1}.\n\\end{eqnarray*}\\] As the reader might have guessed, the posterior distribution turns out to be a Beta distribution with updated shape parameters. That is, the posterior distribution of \\(p\\) given \\(Y = 12\\) is Beta with parameters 15.06 and 10.56.\n\n\n2.4.2 From Beta prior to Beta posterior\nThe results about a proportion \\(p\\) from the Bayes’ rule calculation performed in Section 7.4.1 can be generalized. Suppose one works with the following prior distribution and sampling density:\n\nThe prior distribution: \\[\\begin{eqnarray*}\np \\sim \\textrm{Beta}(a, b)\n\\end{eqnarray*}\\]\nThe sampling density: \\[\\begin{eqnarray*}\nY \\sim \\textrm{Binomial}(n, p)\n\\end{eqnarray*}\\]\n\nOne observes the count \\(Y = y\\), the number of successes in the collected data. Then the posterior distribution of \\(p\\) is another Beta distribution with shape parameters \\(a + y\\) and \\(b + n - y\\).\n\nThe posterior distribution: \\[\\begin{eqnarray}\np \\mid Y = y \\sim \\textrm{Beta}(a + y, b + n - y)\n(\\#eq:betaposterior2)\n\\end{eqnarray}\\]\n\nThe two shape parameters of the Beta posterior distribution, \\(a + y\\) and \\(b + n - y\\), are the sums of the prior and data/likelihood counts of successes and failures, respectively. We algebraically combine the shape parameters of the Beta prior and the Binomial likelihood to obtain the shape parameters of the posterior Beta distribution.\nTable 7.1 demonstrates this process with three rows labelled Prior, Data/Likelihood and Posterior. The Prior row contains the shape parameters of the Beta prior \\(a\\) and \\(b\\) in the Successes and Failures columns, respectively. The Data/Likelihood row contains the number of successes \\(y\\) and the number of failures \\(n - y\\). The shape parameters of the Beta posterior are found by adding the prior parameter values and the data values.\nTable 7.1. Updating the Beta prior.\n\n\n\nSource\nSuccesses\nFailures\n\n\n\n\nPrior\n(a)\n(b)\n\n\nData/Likelihood\n(y)\n(n-y)\n\n\nPosterior\n(a + y)\n(b + n - y)\n\n\n\nIn the following R script we update the Beta shape parameters. We see that the owner’s posterior distribution for \\(p\\) is Beta with shape parameters 15.06 and 10.56.\n\nab <- c(3.06, 2.56)\nyny <- c(12, 8)\n(ab_new <- ab + yny)\n\n[1] 15.06 10.56\n\n\nThe function beta_prior_post() in the ProbBayes R package plots the prior and posterior Beta curves together on one graph, see Figure 7.9.\nbeta_prior_post(ab, ab_new)\n\n\n\n\n\nPrior and posterior curves for the proportion of students who prefer to dine out on Friday.\n\n\n\n\nComparing the two Beta curves, several observations can be made.\n\nOne can compare the prior and posterior Beta curves using the respective means. The mean of a \\(\\textrm{Beta}(a, b)\\) distribution is \\(\\frac{a}{a+b}\\). Using this formula, the posterior mean of \\(p\\) is 15.06 / (15.06 + 10.56) = 0.588 which is slightly larger than the prior mean 3.06 / (30.6 + 2.56) = 0.544. Recall that the sample proportion from the survey results is \\(12/20 = 0.6\\). The posterior mean lies between the prior mean and sample mean and it is closer to the sample mean.\nNext one compares the spreads of the two curves. One sees a much wider spread of the prior Beta curve (dashed line) than that of the posterior Beta curve (solid line). Initially the owner was unsure about the proportion of students favoring Friday to dine out. After observing the results of the survey, the solid posterior curve indicates that he is more certain that \\(p\\) is between 0.5 and 0.7. This sheds light on a general feature of Bayesian inference: the data helps sharpen the belief about the parameter of interest, producing a posterior distribution with a smaller spread than the prior distribution.\n\nThe attractive combination of a Beta prior and a Binomial sampling density to obtain a posterior motivates a definition of conjugate priors. If the prior distribution and the posterior distribution come from the same family of distributions, the prior is then called a conjugate prior. Here a Beta is a conjugate prior for a success probability \\(p\\), since the posterior distribution for \\(p\\) is also in the Beta family. Conjugate priors are specific to the choice of sampling density. For example, a Beta prior is conjugate with Binomial sampling, but not to Normal sampling which is popular for continuous outcome. In Chapter 8 we will discover the conjugate prior distribution for a Normal sampling distribution.\nConjugate priors are desirable because they simplify the Bayesian inference procedure. In the dining preference example, when a \\({\\rm Beta}(3.06, 2.56)\\) prior is assigned to \\(p\\), the posterior is \\({\\rm Beta}(15.06, 10.56)\\) and inference about \\(p\\) is made in a straightforward way. One can easily plot the he prior and posterior Beta distributions as in Figure 7.9. One can also make precise comparative statements about the locations of the prior and posterior distribution using quantiles of a Beta curve.\nAlthough conjugate priors are convenient and straightforward to use, they may not be appropriate for use in a Bayesian analysis. One should choose a prior that fits one’s belief, not one that is convenient to use. In some situations it may be appropriate to choose a prior distribution that does not provide conjugacy. In Chapter 9, we will describe computational methods to facilitate posterior inferences when non-conjugate priors are used. Modern Bayesian posterior computations accommodate a wide variety of choices of prior and sampling distributions. Therefore it is more important to choose a prior that matches one’s prior belief than choosing a prior that is computationally convenient."
  },
  {
    "objectID": "proportion.html#bayesian-inferences-with-continuous-priors",
    "href": "proportion.html#bayesian-inferences-with-continuous-priors",
    "title": "2  Learning About a Binomial Probability",
    "section": "2.5 Bayesian Inferences with Continuous Priors",
    "text": "2.5 Bayesian Inferences with Continuous Priors\nWe will continue with the dining preference example to illustrate different types of Bayesian inference. The restaurant owner has taken his dining survey and the posterior distribution \\(\\textrm{Beta}(15.06, 10.56)\\) reflects his opinion about the proportion \\(p\\) of students whose favorite day for eating out is Friday.\nAll Bayesian inferences about the proportion \\(p\\) are based on various summaries of this posterior Beta distribution. The summary we compute from the posterior will depend on the type of inference. We will focus on three types of inference: (1) testing problems where one is interested in assessing the likelihood of some values of \\(p\\), (2) interval estimations where one wants to find an interval that is likely to contain \\(p\\), and (3) Bayesian prediction where one wants to learn about new observation(s) in the future.\nSimulation will be incorporated for all three types of Bayesian inference problems. Since one has a conjugate prior distribution, one can derive the exact posterior distribution (a Beta) and inferences are performed with the exact posterior Beta distribution. In other situations when conjugacy is not available, meaning that no exact representation of the posterior is available, inferences through simulation are much more widely used. It is instructive to present the exact solutions and the approximated simulation-based solutions together, so one learns through practice and prepare for future use of simulation in other settings.\nThere is nothing magic about simulation. In fact, simulation has been used earlier, when the rbeta() function was used to generate simulated samples from \\(\\textrm{Beta}(4, 4)\\) and \\(\\textrm{Beta}(2, 9)\\) and check the appropriateness of the chosen Beta prior (review Section 7.3.2} as needed). Information on simulation and the relevant R code will be introduced in the description of each inferential problem.\n\n2.5.1 Bayesian hypothesis testing\nSuppose one of the restaurant workers claims that at least 75% of the students prefer to eat out on Friday. Is this a reasonable claim?\nIn traditional classical statistics, one might be interested in testing the hypothesis \\(H: p \\ge 0.75\\).\nFrom a Bayesian viewpoint, it is straightforward to implement this test. Since the hypothesis is an interval of values, one finds the posterior probability that \\(p \\ge 0.75\\) and makes a decision based on the value of this probability. If the probability is small, one rejects this claim.\n First the exact solution will be presented. Since the posterior distribution is \\(\\textrm{Beta}(15.06, 10.56)\\), the owner’s posterior density is graphed and the area under the curve for values of \\(p\\) between 0.75 and 1 is found. The beta_area() function is used to display and show the area; see Figure 7.10. Since the probability is only about 4%, one rejects the worker’s claim that \\(p\\) is at least 0.75.\nbeta_area(lo = 0.75, hi = 1.0,\n          shape_par = c(15.06, 10.56))\n\n\n\n\n\nProbability of the hypothesis from the Beta posterior density.\n\n\n\n\nThis computation can be implemented using simulation. Since the posterior distribution is \\(\\textrm{Beta}(15.06, 10.56)\\), one generates a large number of random values from this Beta distribution, then summarizes the sample of simulated draws to obtain the probability of \\(p \\geq 0.75\\). First a sample of \\(S = 1000\\) from the Beta posterior is taken, storing the results in the vector BetaSamples.\n\nS <- 1000\nBetaSamples <- rbeta(S, 15.06, 10.56)\n\nThe proportion of the 1000 simulated values of \\(p\\) that are at least 0.75 gives an approximation of the probability that \\(p \\geq 0.75\\).\n\nsum(BetaSamples >= 0.75) / S\n\n[1] 0.032\n\n\nThe simulation-based probability estimate is 0.037 which is an accurate approximation to the exact probability 0.04 obtained before.\nIt would be reasonable to question the choice of the number of simulations \\(S = 1000\\). One can change the simulation sample size to larger or smaller values as one sees fit. In general, the larger the value of \\(S\\), the more accurate the approximation. Figure 7.11 shows that the shape of a histogram of the simulated values of \\(p\\) approaches the exact posterior density as the value of \\(S\\) changes from 100 to 10,000. The corresponding simulation-based probabilities of \\(p \\geq 0.75\\) are \\(\\{0.02, 0.05, 0.033, 0.0422\\}\\) indicating that the accuracy of the approximation improves for larger simulation sample sizes.\n\n\n\n\n\nHistograms of simulated draws from Beta(15.06, 10.56) with the exact Beta density overlaid for four different number of samples drawn where \\(S\\) = {10, 500, 1000, 10000}.\n\n\n\n\nOne will observe variation from one simulation from another (see the two different but similar approximated probabilities 0.037 and 0.033 when \\(S = 1000\\)). To replicate one’s results one specifies the seed of the random number simulator set.seed(). Choose any number that you like to put in – if this set.seed() line of code is executed first, then the same sequence of random values will be generated and one replicates the simulation-based computation.\n\n\n2.5.2 Bayesian credible intervals\nAnother type of inference is a Bayesian credible interval, an interval that one is confident contains \\(p\\). Such an interval provides an uncertainty estimate for the parameter \\(p\\). A 90% Bayesian credible interval is an interval that contains 90% of the posterior probability.\nOne convenient 90% credible interval is the “equal tails” interval that contains the middle 90% of the probability content. The function beta_interval() in ProbBayes R package illustrates and computes the equal-tails interval. The shaded area in Figure 7.12 corresponds to \\(90\\%\\) of the posterior probability. The probability \\(p\\) falls between 0.427 and 0.741 is exactly 90 percent.\nbeta_interval(0.9, c(15.06, 10.56))\n\n\n\n\n\nDisplay of 90% probability interval for the proportion \\(p\\).\n\n\n\n\nOne obtains this middle 90% credible interval using the qbeta() function.\n\nqbeta(c(0.05, 0.95), 15.06, 10.56)\n\n[1] 0.4266788 0.7410141\n\n\nThis Bayesian credible interval differs from the interpretation of a traditional confidence interval. With a traditional confidence interval, one does not have confidence that one particular interval will contain \\(p\\). Instead 90% confidence refers to the average coverage of the interval in repeated sampling.\nOther types of Bayesian credible intervals can be computed. For example, instead of a credible interval covering the middle 90% of the posterior probability, one could create a credible interval covers the lower 90%, or the upper 90%, or the middle 95%. The qbeta() function is helpful in achieving all of these different type of intervals, as long as we know the exact posterior distribution, that is, the two shape parameters of the posterior Beta distribution. For example, the following code computes a credible interval that covers the lower 90% of the posterior distribution.\n\nqbeta(c(0.00, 0.90), 15.06, 10.56)\n\n[1] 0.0000000 0.7099912\n\n\nAn alternative way of creating credible intervals is by simulation. One first takes a random sample from the \\(\\textrm{Beta}(15.06, 10.56)\\) distribution, then summarizes the simulated values by finding the two cutoff points of the middle 90% of the sample. The quantile() function is useful for this purpose. As a demonstration, below we simulate \\(S = 1000\\) proportion values and compute the credible interval.\n\nS <- 1000\nBetaSamples <- rbeta(S, 15.06, 10.56)\nquantile(BetaSamples, c(0.05, 0.95))\n\n       5%       95% \n0.4330113 0.7363911 \n\n\nThe approximate middle 90% credible interval is [0.427, 0.733], which is close in value to the exact 90% credible interval [0.427, 0.741] computed using the qbeta() and beta_interval() functions. In an end-of-chapter exercise the reader is encouraged to practice and experiment with different values of the size of the simulated sample \\(S\\).\n\n\n2.5.3 Bayesian prediction\nPrediction is a typical task of Bayesian inference and statistical inference in general. Once we are able to make inference about the parameter in our statistical model, one may be interested in predicting future observations.\nDenote a new observation by the random variable \\(\\tilde{Y}\\). In particular, if the new survey is given to \\(m\\) students, the random variable \\(\\tilde{Y}\\) is the number of students preferring Friday to dine out out of the \\(m\\) respondents. If again the survey is given to a random sample, the random variable \\(\\tilde{Y}\\), conditional on \\(p\\), follows a Binomial distribution with the fixed total number of trails \\(m\\) and success probability \\(p\\). One’s knowledge about the location of \\(p\\) is expressed by the posterior distribution of \\(p\\).\nMathematically, to make a prediction of a new observation, one is asking for the distribution of \\(\\tilde{Y}\\) given the observed data \\(Y = y\\). That is, one is interested in the probability function \\(f(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\) where \\(\\tilde y\\) is a value of \\(\\tilde{Y}\\). But the conditional distribution of \\(\\tilde{Y}\\) given a value of the proportion \\(p\\) is Binomial(\\(m, p\\)) and the current beliefs about \\(p\\) are described by the posterior density. So one writes the joint density of \\(\\tilde{Y}\\) and \\(p\\) as the product \\[\\begin{eqnarray}\nf(\\tilde{Y}= \\tilde{y},  p \\mid Y = y) = f(\\tilde{Y} = \\tilde{y} \\mid p) \\pi(p \\mid Y = y).\n\\end{eqnarray}\\] By integrating out \\(p\\), one obtains the predictive distribution \\[\\begin{eqnarray}\nf(\\tilde{Y} = \\tilde{y} \\mid Y = y) = \\int  f(\\tilde{Y} =\\tilde{y} \\mid p) \\pi(p \\mid Y = y) dp.\n\\label{eq:Binomial:pred}\n\\end{eqnarray}\\]\nThe density of \\(\\tilde{Y}\\) given \\(p\\) is Binomial with \\(m\\) trials and success probability \\(p\\), and the posterior density of \\(p\\) is \\({\\rm Beta}(a + y, b + n - y)\\). After the substitution of densities and an integration step (see Appendix B for the detail), one finds that the predictive density is given by \\[\\begin{eqnarray}\nf(\\tilde{Y} =\\tilde{y}  \\mid Y = y) &=& {m \\choose \\tilde{y}}\n\\frac{B(a + y + \\tilde{y}, b  + n - y + m - \\tilde{y})}{B(a + y, b + n - y)}. \\nonumber \\\\\n\\end{eqnarray}\\] This is the Beta-Binomial distribution with parameters \\(m\\), \\(a + y\\) and \\(b + n - y\\). \\[\\begin{eqnarray}\n\\tilde{Y} \\mid Y = y \\sim \\textrm{Beta-Binomial}(m, a + y, b + n - y).\n\\end{eqnarray}\\] To summarize, Bayesian prediction of a new observation is a Beta-Binomial distribution where \\(m\\) is the number of trials in the new sample, \\(a\\) and \\(b\\) are shape parameters from the Beta prior, and \\(y\\) and \\(n\\) are quantities from the data/likelihood.\nUsing this Beta-Binomial distribution in our example, one computes the predictive probability that \\(\\tilde y\\) students prefer Friday in a new survey of 20 students. We illustrate the use of the pbetap() function from the ProbBayes package. The inputs to pbetap() are the vector of Beta shape parameters \\((a, b)\\), the sample size 20, and the values of \\(\\tilde{y}\\) of interest.\n\na <- 15.06\nb <- 10.56\nprob <- pbetap(c(a, b), 20, 0:20)\npred_distribution <- data.frame(Y = 0:20, \n                                Probability = prob)\n\nprob_plot(pred_distribution,\n          Color = crcblue, Size = 4) +\n  theme(text=element_text(size=18))\n\n\n\n\n\nDisplay of the exact predictive distribution of the number of students \\(\\tilde y\\) favoring Friday in a future sample of 20.\n\n\n\n\nThese predictive probabilities are displayed in Table 7.2 \\(\\ref{tab:predictive_dining}\\) and graphed in Figure 7.13.\nTable 7.2. Predictive distribution of the number of students preferring Friday in a future sample of 20.\n\n\n\nY\nProbability\nY\nProbability\n\n\n\n\n0\n0\n11\n0.127\n\n\n1\n0\n12\n0.134\n\n\n2\n0\n13\n0.127\n\n\n3\n0.001\n14\n0.108\n\n\n4\n0.004\n15\n0.080\n\n\n5\n0.010\n16\n0.052\n\n\n6\n0.021\n17\n0.028\n\n\n7\n0.037\n18\n0.012\n\n\n8\n0.059\n19\n0.004\n\n\n9\n0.085\n20\n0.001\n\n\n10\n0.109\n\n\n\n\n\nLooking at the table, the most likely number of students preferring Friday is 12. Just as in the inference situation, it is desirable to construct an interval that will contain \\(\\tilde Y\\) with a high probability. Suppose the desired probability content is 0.90. One constructs this prediction interval by putting in the most likely values of \\(\\tilde Y\\) until the probability content of the set exceeds 0.90.\nThis method is implemented using the following command:\n\ndiscint(pred_distribution, .9)\n\n$prob\n[1] 0.9185699\n\n$set\n [1]  7  8  9 10 11 12 13 14 15 16\n\n\nOne therefore finds that \\[\nProb(7 \\le \\tilde Y \\le 16) = 0.919.\n\\]\nThis exact predictive distribution is based on the posterior distribution of \\(p\\), as one uses \\(\\pi(p \\mid Y=y)\\) in the integration process in Equation (7.14). For that reason this predictive distribution is called the posterior predictive distribution. There also exists a prior predictive distribution, a topic we will briefly introduce in Section 7.6.\nIn situations where it is difficult to derive the exact predictive distribution, one simulates values from this distribution. One implements this predictive simulation by first simulating draws of the parameter (in this case the proportion \\(p\\)) from its posterior distribution, and then simulating values of the future observation (e.g. the new observation \\(\\tilde{Y}\\)) from the sampling density (here the Binomial distribution).\nWe illustrate this simulation procedure with the generic Beta posterior \\(\\textrm{Beta}(a + y, b + n - y)\\). To simulate a single draw from the predictive distribution, one first simulates a single proportion value \\(p\\) from the Beta posterior and then simulates a new data point \\(\\tilde{y}\\) (the number of successes out of \\(m\\) trials) from a Binomial distribution with sample size \\(m\\) and probability of success given by the simulated draw of \\(p\\). \\[\\begin{eqnarray*}\n\\text{sample}\\,\\, p \\sim {\\rm{Beta}}(a + y, b + n - y) &\\rightarrow& \\text{sample}\\,\\, \\tilde{Y} \\sim {\\rm{Binomial}}(m, p)\n\\end{eqnarray*}\\]\n This process of simulating a single draw is implemented by the rbeta() and rbinom() functions. Let \\(m = n\\) (the size of the future sample is the same as the size of the observed sample).\n\na <- 3.06; b <- 2.56\nn <- 20; y <- 12\npred_p_sim <- rbeta(1, a + y, b + n - y)\n(pred_y_sim <- rbinom(1, n, pred_p_sim))\n\n[1] 13\n\n\nDue to the ability of R to work easily with vectors, ]the same code is essentially used for simulating \\(S = 1000\\) draws from the predictive distribution.\nIn the following R script, pred_p_sim contains 1000 simulated draws from the posterior, and for each element of this posterior sample, the rbinom() function is used to simulate a corresponding value of \\(\\tilde Y\\) from the Binomial sampling density.\n\na <- 3.06; b <- 2.56\nn <- 20; y <- 12\nS <- 1000\npred_p_sim <- rbeta(S, a + y, b + n - y)\npred_y_sim <- rbinom(S, n, pred_p_sim)\n\nFigure 7.14 displays predictive probabilities for the number of students who prefer Fridays using the exact Beta-Binomial and simulation methods. One observes good agreement using these two computation methods.\n\n\n\n\n\nDisplay of the exact and simulated predictive probabilities for dining example.\n\n\n\n\nFor example, using the simulated values of \\(\\tilde Y\\) one finds that \\[\nProb(6 \\le \\tilde Y \\le 15) = 0.927\n\\] which is close in value to the range \\(Prob(7 \\le \\tilde Y \\le 16) = 0.919\\) found using the exact predictive distribution.\n\na <- 15.06\nb <- 10.56\nprob <- pbetap(c(a, b), 20, 0:20)\npred_distribution <- data.frame(Y = 0:20, \n                                Probability = prob)\ndiscint(pred_distribution, .9)\n\n$prob\n[1] 0.9185699\n\n$set\n [1]  7  8  9 10 11 12 13 14 15 16"
  },
  {
    "objectID": "proportion.html#predictive-checking",
    "href": "proportion.html#predictive-checking",
    "title": "2  Learning About a Binomial Probability",
    "section": "2.6 Predictive Checking",
    "text": "2.6 Predictive Checking\nIn the previous section, the use of the predictive distribution has been illustrated in learning about future data. This is more precisely described as the posterior predictive density as one is obtaining this density by integrating the sampling density \\(f(\\tilde Y = \\tilde y \\mid p)\\) over the posterior density \\(\\pi(p \\mid y)\\).\nThe prior predictive density is also useful in model checking. In a Bayesian model where \\(p\\) has a prior \\(\\pi(p)\\) and \\(Y\\) has a sampling density \\(f(Y = y \\mid p)\\), one writes the joint density of \\((p, Y)\\) as the product of the sampling density and the prior: \\[\\begin{eqnarray}\nf(p, Y = y) = f(Y = y \\mid p) \\pi(p).\n\\end{eqnarray}\\] Suppose one conditions on \\(y\\) instead of \\(p\\) and then one obtains an alternative representation of the joint density: \\[\\begin{eqnarray}\nf(p, Y = y) = \\pi(p \\mid Y = y) f(Y = y).\n\\end{eqnarray}\\] The first term in this product, the density \\(\\pi(p \\mid Y = y)\\), is the posterior density of \\(p\\) given the observation \\(y\\); this density is useful for performing inference about the proportion. The second term in this product is the density \\(f(Y = y)\\) is the prior predictive density – this represents the density of future data before the observation \\(y\\) is taken. If the actual observation denoted by \\(y_{obs}\\) is not consistent with the prior predictive density \\(f(Y = y)\\), this indicates some problem with the Bayesian model. Basically, this says that the observed data is unlikely to happen if one simulates predictions of data from our model.\nTo illustrate the use of prior predictive checking, recall that the restaurant owner assigned a Beta(3.06, 2.56) prior to the proportion \\(p\\) of students dining on Friday. A sample of 20 students will be taken. Based on this information, one computes the predictive probability \\(f(Y = y)\\) of \\(y\\) students preferring Friday dining of the sample of 20. This predictive distribution for all possible values of \\(y\\) is displayed in Figure 7.15. Recall that we actually observed \\(y_{obs} = 12\\) Friday diners — this value is shown in Figure 7.15 as a large black dot. This value is in the middle of the distribution – the takeaway is that the observed data is consistent with predictions from the owner’s Bayesian model.\n\n\n\n\n\nPrior predictive distribution of \\(y\\) using the owner’s Beta prior. The observed number of \\(y\\) id indicated with a large black dot. In this case the observed data is consistent with the Bayesian model.\n\n\n\n\nIn contrast, suppose another restaurant worker is more pessimistic about the likelihood of students dining on Friday. This worker’s prior median of the proportion \\(p\\) is 0.2 and her 90th percentile is 0.4 — this information is matched with a Beta prior with shape parameters 2.07 and 7.32. Figure 7.16 displays the predictive density of the number of Friday diners of a sample of 20 using this worker’s prior. Here one reaches a different conclusion. The observed number 12 of Friday diners is in the tail of this predictive distribution — this observation is not consistent with predictions from the Bayesian model. In closer examination, one sees conflict between the information in the worker’s prior and the data — her prior said that the proportion \\(p\\) was close to 0.20 and the data result (12 out of 20 successes) indicates that the proportion is close to 0.60. Predictive checking is helpful in this case in detecting this prior/data conflict.\n\n\n\n\n\nPrior predictive distribution of \\(y\\) using a worker’s Beta prior. The observed number of \\(y\\) is indicated by a large black dot. In this case the observed data is not consistent with the Bayesian model.\n\n\n\n\n\n2.6.1 Comparing Bayesian models\nThe prior predictive distribution is also useful in comparing two Bayesian models. To illustrate model comparison, suppose a second worker at the restaurant is also asked about the fraction of students who dine on Friday. He knows that the owner’s belief about the proportion \\(p\\) is described by a Beta(3.06, 2.56) density, and the fellow worker’s belief about \\(p\\) is represented by a Beta(2.07, 7.32) density. Who should the second worker believe?\nSuppose this second worker believes that both the owner’s and fellow worker’s beliefs about the proportion \\(p\\) are equally plausible. So he places a probability of 0.5 on the Beta(3.06, 2.56) prior and a probability of 0.5 on the Beta(2.07, 7.32) prior. This second worker’s prior \\(\\pi(p)\\) is written as the mixture \\[\\begin{eqnarray}\n\\pi(p) = q \\pi_1(p) + (1 - q) \\pi_2(p),\n\\end{eqnarray}\\] where \\(q = 0.5\\) and \\(\\pi_1\\) and \\(\\pi_2\\) denote the owner’s and worker’s Beta priors.\nNow one observes the survey data – \\(y\\) Fridays in a sample of size \\(n\\). Using the usual prior times likelihood procedure, the posterior density of \\(p\\) is proportional to the product \\[\\begin{eqnarray}\n\\pi(p \\mid Y = y) \\propto \\Big[q \\pi_1(p) + (1 - q) \\pi_2(p)\\Big] \\times\n{n \\choose y} p ^ {y }(1 - p) ^ {n - y}.\n\\end{eqnarray}\\] After some manipulation, one can show that the posterior density for the proportion \\(p\\) has the mixture form \\[\\begin{eqnarray}\n\\pi(p \\mid Y = y) = q(y) \\pi_1(p \\mid Y = y) + (1 - q(y)) \\pi_2(p \\mid Y = y).\n\\end{eqnarray}\\]\nThe posterior densities \\(\\pi_1(p \\mid y)\\) and \\(\\pi_2(p \\mid y)\\) are the familiar Beta forms. For example, \\(\\pi_1(p \\mid Y = y)\\) will be the Beta(3.06 + \\(y\\), 2.56 + \\(n - y\\)) posterior density combining the Beta(3.06, 2.56) prior and the sample data of \\(y\\) successes in a sample of size \\(n\\). Likewise, \\(\\pi_2(p \\mid Y = y)\\) will be the Beta density combining the worker’s Beta(2.07, 7.32) prior and the data.\nThe quantity \\(q(y)\\) represents the posterior probability of the owner’s prior. One expresses this probability as \\[\\begin{eqnarray}\nq(y) = \\frac{q f_1(Y = y)}{q f_1(Y = y) + (1 - q) f_2(Y =y)}\n\\end{eqnarray}\\] where \\(f_1(Y = y)\\) and \\(f_2(Y = y)\\) denote the predictive densities corresponding to the owner’s and worker’s priors. With a little algebra, one represents the posterior odds of the model probabilities as follows.\n\\[\\begin{eqnarray}\n\\frac{P(Prior \\, 1 \\mid Y = y)}{P(Prior \\, 2 \\mid Y = y)} = \\frac{q(y)}{1 - q(y)} = \\left[\\frac{q}{1 - q}\\right] \\left[\\frac{f_1(Y = y)}{f_2(Y = y)}\\right]\n\\end{eqnarray}\\]\nThe posterior odds of the owner’s prior \\(P(Prior \\, 1 \\mid Y = y) / P(Prior \\, 2 \\mid y = y)\\) is written as the product of two terms.\n\nThe ratio \\(q / (1 - q)\\) represents the prior odds of the owner’s prior.\nThe term \\(f_1(Y = y) / f_2(Y = y)\\), the ratio of the predictive densities, is called the Bayes factor. It reflects the relative abilities of the two priors to predict the observation \\(y\\).\n\nThe function binomial.beta.mix() is used to find the Bayes factor for our example. One inputs the prior probabilities of the two models (priors), and the vectors of Beta shape parameters that define the owner’s prior and the worker’s prior. The displayed output is the posterior odds value of 6.77.\n\nprobs <- c(0.5, 0.5)\nbeta_par1 <- c(3.06, 2.56)\nbeta_par2 <- c(2.07, 7.32)\nbeta_par <- rbind(beta_par1, beta_par2)\noutput <- binomial.beta.mix(probs, beta_par, c(12, 8))\n(posterior_odds <- output$probs[1] / output$probs[2])\n\nbeta_par1 \n 6.777823 \n\n\nSince the two priors are given equal probabilities, the prior odds \\(q / (1 - q)\\) is equal to one. In this case the posterior odds is equal to the Bayes factor. The interpretation is that for the given observation (12 successes in 20 trials), there is 6.77 times more support for the owner’s prior than for the worker’s prior. This conclusion is consistent with the earlier work that showed that the observed value of \\(y\\) was inconsistent with the Bayesian model for the worker’s prior.\n\n\n2.6.2 Posterior predictive checking\nAlthough the prior predictive distribution is useful in model checking, it has some disadvantages. One problem is that the distribution \\(f(Y = y)\\) may not exist in the situation where the prior \\(\\pi()\\) is not a proper probability distribution. We will see particular situations in future chapters where a vague or imprecise probability distribution is assigned as our prior and then the prior predictive distribution will not be well-defined. A related issue is that a prior may be assigned that may not accurately reflect one’s prior beliefs about a parameter. Small errors in the specification of the prior will result in errors in the prior predictive distribution. So there needs to be some caution in the use of the prior predictive distribution in assessing the goodness of the Bayesian model.\nAn alternative method of checking the suitability of a Bayesian model is based on the posterior predictive distribution. In this setting, one computes the posterior predictive distribution of a replicated dataset, that is a dataset of the same sample size as our observed sample. One sees if the observed value of \\(y\\) is in the middle of this predictive distribution. If this is true, then this means that the observed sample is consistent with predictions of replicated data. On the other hand, if the observed \\(y\\) is in the tails of the posterior distribution, this indicates some model misspecification which means that there is possibility some issue with the specified prior or sampling density.\nOne attractive aspect of the posterior prediction distribution is that replicated datasets is conveniently simulated. To simulate one replicated dataset, we first simulate a parameter from its posterior distribution, then simulate new data from the data model given the simulated parameter value. In the Beta-Binomial situation, the posterior of the proportion \\(p\\) is \\({{\\rm{Beta}}}(a + y, b + n - y)\\).\nTo simulate a new data point \\(\\tilde{Y} = \\tilde{y}\\), one first simulates a proportion value \\(p^{(1)}\\) from the Beta posterior and then simulate a new data point \\(\\tilde{y}^{(1)}\\) from a Binomial distribution with sample size \\(n\\) and probability of success \\(p^{(1)}\\). If we wish to obtain a sample of size \\(S\\) from the posterior predictive distribution, this process is repeated \\(S\\) times as showed in the following diagram. \\[\\begin{eqnarray*}\n\\text{sample}\\,\\, p^{(1)} \\sim {\\rm{Beta}}(a + y, b + n - y) &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(1)} \\sim {\\rm{Binomial}}(n, p^{(1)})\\\\\n\\text{sample}\\,\\, p^{(2)} \\sim {\\rm{Beta}}(a + y, b + n - y) &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(2)} \\sim {\\rm{Binomial}}(n, p^{(2)})\\\\\n&\\vdots& \\\\\n\\text{sample}\\,\\, p^{(S)} \\sim {\\rm{Beta}}(a + y, b + n - y) &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(S)} \\sim {\\rm{Binomial}}(n, p^{(S)})\n\\end{eqnarray*}\\] The sample \\(\\tilde{y}^{(1)}, ..., \\tilde{y}^{(S)}\\) is an approximation to the posterior predictive distribution that is used for model checking. In practice, one constructs a histogram of this sample and decides if the observed value of \\(y\\) is in the central portion of this predictive distribution. The reader will be given an opportunity to use this algorithm to see if the observed data is consistent with simulations of replicated data from this predictive distribution."
  },
  {
    "objectID": "mean.html#introduction",
    "href": "mean.html#introduction",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nWe first consider the general situation where there is a hypothetical population of individuals of interest and there is a continuous-valued measurement \\(Y\\) associated with each individual. One represents the collection of measurements from all individuals by means of a continuous probability density \\(f(y)\\). As discussed in Chapter 5, one summarizes this probability density with the mean \\(\\mu\\): \\[\\begin{equation}\n\\mu = \\int y f(y) dy.\n\\end{equation}\\] The value \\(\\mu\\) gives us a sense of the location of a typical value of the continuous measurement \\(Y\\).\nTo learn about the population of measurements, a random sample of individuals \\(Y_1, ..., Y_n\\) will be taken. The general inferential problem is to use these measurements together with any prior beliefs to learn about the population mean \\(\\mu\\). In other words, the goal is to use the collected measurements to learn about a typical value of the population of measurements."
  },
  {
    "objectID": "mean.html#modeling-measurements",
    "href": "mean.html#modeling-measurements",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.2 Modeling Measurements",
    "text": "3.2 Modeling Measurements\n\n3.2.1 Examples\n\nCollege applications\nHow many college applications does a high school senior in the United States complete? Here one imagines a population of all American high school seniors and the measurement is the number of completed college applications. The unknown quantity of interest is the mean number of applications \\(\\mu\\) completed by these high school seniors. The inferential question may be stated by asking, on average, how many college applications does an American high school senior complete. The answer to this question gives one a sense of the number of completed applications for a typical high school senior. To learn about the average \\(\\mu\\), it would be infeasible to collect this measurement from every high school senior in the U.S. Instead, a survey is typically conducted to a sample of high school seniors (ideally a sample representative of all American high school seniors) and based on the measurements from this sample, some inference is performed about the mean number of college applications.\n\n\nHousehold spending\nHow much does a household in San Francisco spend on housing every month? One visualizes the population of households in San Francisco and the continuous measurement is the amount of money spent on housing (either rent for renters and mortgage for homeowners) for a resident. One can ask “on average, how much does a household spend on housing every month in San Francisco?”, and the answer to this question gives one a sense of the housing costs for a typical household in San Francisco. To learn about the mean value of housing \\(\\mu\\) of all San Francisco residents, a sample survey is conducted. The mean value of the housing costs \\(\\bar y\\) from this sample of surveyed households is informative about the mean housing cost \\(\\mu\\) for all residents.\n\n\nWeights of cats\nSuppose you have a domestic shorthair cat weighing 14 pounds and you want to find out if she is overweight. One imagines a population of all domestic shorthair cats and the continuous measurement is the weight in pounds. Suppose you were able to compute the mean weight \\(\\mu\\) of all shorthair cats. Then by comparing 14 pounds (the weight of our cat) to this mean, you would know whether your cat is overweight, or underweight, or close to the mean. If we were able to find the distribution of the weights of all domestic shorthair cats, then one observes the proportion of weights smaller than 14 pounds in the distribution and learns if the cat is severely overweight. To learn if our cat is overweight, you can ask the vet. How does the vet know? Extensive research has been conducted periodically to record weights of a large sample of domestic shorthair cats, and by using these sample of weights, the vet performs an inference about the mean \\(\\mu\\) of the weights of all domestic shorthair cats.\n\n\nComment elements of an inference problem\nAll three examples have common elements:\n\nOne has an underlying population of measurements, where the measurement is an integer, such as the number of college applications, or continuous, such as a housing cost or a cat weight.\nOne is interested in learning about the value of the mean \\(\\mu\\) of the population of measurements.\nIt is impossible or impractical to collect all measurements from the population, so one will collect a sample of measurements \\(Y_1, ..., Y_n\\) and use the observed measurements to learn about the unknown population mean \\(\\mu\\).\n\n\n\n\n3.2.2 The general approach\nRecall the three general steps of Bayesian inference discussed in Chapter 7 in the context of an unknown proportion \\(p\\).\n\nStep 1: Prior We express an opinion about the location of the proportion \\(p\\) before sampling.\nStep 2: Data/Likelihood We take the sample and record the observed proportion.\nStep 3: Posterior We use Bayes’ rule to sharpen and update the previous opinion about \\(p\\) given the information from the sample.\n\nIn this setting, we have a continuous population of measurements that we represent by the random variable \\(Y\\) with density function \\(f(y)\\). It is convenient to assume that this population has a Normal shape with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). That is, a single measurement \\(Y\\) is assume to come from the density function \\[\\begin{equation}\nf(y) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{(y - \\mu)^2}{2 \\sigma^2}\\right\\}, -\\infty < y< \\infty.\n\\end{equation}\\] displayed in Figure 8.1. To simplify the discussion, it is convenient to assume that the standard deviation \\(\\sigma\\) of the measurement distribution is known. Then the objective is to learn about the single mean measurement \\(\\mu\\).\n\n\n\n\n\nNormal sampling density with mean \\(\\mu\\).\n\n\n\n\nStep 1 in Bayesian inference is to express an opinion about the parameter. In this continuous measurement setting, one constructs a prior for the mean parameter \\(\\mu\\) that expresses one’s opinion about the location of this mean. In this chapter, we discuss different ways to specify a prior distribution for \\(\\mu\\). One attractive discrete approach for expressing this prior opinion, similar to the approach in Chapter 7 for a proportion \\(p\\), has two steps. First one constructs a list of possible values of \\(\\mu\\), and then one assigns probabilities to the possible values to reflect one’s belief. Alternatively, we will describe the use of a continuous prior to represent one’s belief for \\(\\mu\\). This is a more realistic approach for constructing a prior since one typically views the mean as a real-valued parameter.\nStep 2 of our process is to collect measurements from a random sample to gain more information about the parameter \\(\\mu\\). In our first situation, one collects the number of applications from a sample of 100 high school seniors. In the second example, one collects a sample of 2000 housing costs, each from a sampled San Francisco household. The third example collects a sample of 200 different weights of domestic shorthair cats, each from a sampled cat. If these measurements are viewed as independent observations from a Normal sampling density with mean \\(\\mu\\), then one constructs a likelihood function which is the joint density of the sampled measurements viewed as a function of the unknown parameter.\nOnce the prior is specified and measurements have been collected, one proceeds to Step 3 to use Bayes’ rule to update one’s prior opinion to obtain a posterior distribution for the mean \\(\\mu\\). The algebraic implementation of Bayes’ rule is a bit more tedious when dealing with continuous data with a Normal sampling density. But we will see there is a simple procedure for computing the posterior mean and standard deviation.\n\n\n3.2.3 Outline of chapter\nThroughout this chapter, the entire inferential process is described for learning about a mean \\(\\mu\\) assuming a Normal sampling density for the measurements. This chapter discusses how to construct a prior distribution that matches one’s prior belief, how to extract information from the data by the likelihood function, and how to update one’s opinion in the posterior, combining the prior and data information in a natural way.\nSection 8.3 introduces inference with a discrete prior distribution for the mean \\(\\mu\\) and Section 8.4 introduces the continuous family of Normal prior distributions for the mean. The inferential process with a Normal prior distribution is described in detail in Section 8.5. Section 8.6 describes some general Bayesian inference methods in this Normal data/Normal prior setting, such as Bayesian hypothesis testing, Bayesian credible intervals and Bayesian prediction. These sections describe the use of both exact analytical solutions and approximation simulation-based calculations. Section 8.7 introduces the use of the posterior predictive distribution as a general tool for checking if the observed data is consistent with predictions from the Bayesian model.\nThe chapter concludes in Section 8.8 by introducing a popular one-parameter model for counts, the Poisson distribution, and its conjugate Gamma distribution for representing prior opinion. Although this section does not deal with the Normal mean situation, the exposure to the important Gamma-Poisson conjugacy will enhance our understanding and knowledge of the analytical process of combining the prior and likelihood to obtain the posterior distribution."
  },
  {
    "objectID": "mean.html#Normal:Discrete",
    "href": "mean.html#Normal:Discrete",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.3 Bayesian Inference with Discrete Priors",
    "text": "3.3 Bayesian Inference with Discrete Priors\n\n3.3.1 Example: Roger Federer’s time-to-serve\nRoger Federer is recognized as one of the greatest players in tennis history. One aspect of his play that people enjoy is his businesslike way of serving to start a point in tennis. Federer appears to be efficient in his preparation to serve and some of his service games are completed very quickly. One measures one’s service efficiency by the time-to-serve which is the measured time in seconds between the end of the previous point and the beginning of the current point.\nSince Federer is viewed as an efficient server, this raises the question: how long, on average, is Federer’s time-to-serve? We know two things about his time-to-serve measurements. First, since they are time measurements, they are continuous variables. Second, due to a number of other variables, the measurements will vary from serve to serve. Suppose one collects a single time-to-serve measurement in seconds. denoted as \\(Y\\). It seems reasonable to assume \\(Y\\) is Normally distributed with unknown mean \\(\\mu\\) and standard deviation \\(\\sigma\\). From previous data, we assume that the standard deviation is known and given by \\(\\sigma = 4\\) seconds.\nRecall the Normal probability curve has the general form\n\\[\\begin{equation}\nf(y) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{(y - \\mu)^2}{2 \\sigma^2}\\right\\}, -\\infty < y< \\infty.\n\\end{equation}\\] Since \\(\\sigma = 4\\) is known, the only parameter in Equation (8.3) is \\(\\mu\\). We are interested in learning about the mean time-to-serve \\(\\mu\\).\nA convenient first method of implementing Bayesian inference is by the use of a discrete prior. One specifies a subjective discrete prior for Federer’s mean time-to-serve by specifying a list of plausible values for \\(\\mu\\) and assigning a probability to each of these values.\nIn particular suppose one thinks that values of the equally spaced values \\(\\mu\\) = 15, 16, \\(\\cdots\\), 22 are plausible. In addition, one does not have any good reason to think that any of these values for the mean are more or less likely, so a Uniform prior will be assigned where each value of \\(\\mu\\) is assigned the same probability \\(\\frac{1}{8}\\). \\[\\begin{equation}\n\\pi(\\mu) = \\frac{1}{8}, \\, \\, \\, \\, \\mu = 15, 16, ..., 22.\n\\end{equation}\\] Each value of \\(\\mu\\) corresponds to a particular Normal sampling curve for the time-to-serve measurement. Figure 8.2 displays the eight possible Normal sampling curves. Our prior says that each of these eight sampling curves has the same prior probability.\n\n\n\n\n\n\n\n\nEight possible Normal sampling curves corresponding to a discrete Uniform prior on \\(\\mu\\).\n\n\n\n\nTo learn more about the mean \\(\\mu\\), one collects a single time-to-serve measurement for Federer, and suppose it is 15.1 seconds, that is, one observes \\(Y = 15.1\\). The likelihood function is the Normal density of the actual observation \\(y\\) viewed as a function of the mean \\(\\mu\\) (remember that it was assumed that \\(\\sigma = 4\\) was given). By substituting in the observation \\(y = 15.1\\) and the known value of \\(\\sigma = 4\\), one writes the likelihood function as\n\\[\\begin{eqnarray*}\nL(\\mu) = \\frac{1}{\\sqrt{2 \\pi} 4} \\exp\\left\\{- \\frac{1}{2 (4)^2}(15.1 - \\mu)^2\\right\\}.\n\\end{eqnarray*}\\]\nFor each possible value of \\(\\mu\\), we substitute the value into the likelihood expression. For example, the likelihood of \\(\\mu = 15\\) is equal to \\[\\begin{eqnarray*}\nL(15) &=& \\frac{1}{\\sqrt{2 \\pi} (4)} \\exp\\left(- \\frac{1}{2 (4)^2}(15.1 - 15)^2\\right) \\nonumber \\\\\n&\\approx & 0.0997.\n\\end{eqnarray*}\\] This calculation is repeated for each of the eight values \\(\\mu = 15, 16, \\cdots, 22\\), obtaining eight likelihood values.\nA discrete prior has been assigned to the list of possible values of \\(\\mu\\) and one is now able to apply Bayes’ rule to obtain the posterior distribution for \\(\\mu\\). The posterior probability of the value \\(\\mu = \\mu_i\\) given the data \\(y\\) for a discrete prior has the form \\[\\begin{equation}\n\\pi(\\mu_i \\mid y) = \\frac{\\pi(\\mu_i) \\times L(\\mu_i)}{\\sum_j \\pi(\\mu_j) \\times L(\\mu_j)},\n\\end{equation}\\] where \\(\\pi(\\mu_i)\\) is the prior probability of \\(\\mu = \\mu_i\\) and \\(L(\\mu_i)\\) is the likelihood function evaluated at \\(\\mu = \\mu_i\\).\nIf a discrete Uniform prior distribution for \\(\\mu\\) is assigned, one has \\(\\pi(\\mu_i) = \\frac{1}{8}\\) for all \\(i = 1, \\cdots, 8\\), and \\(\\pi(\\mu_i)\\) is canceled out from the numerator and denominator in Equation (8.5). In this case one calculates the likelihood values \\(L(\\mu_i)\\) for all \\(i = 1, \\cdots, 8\\) and normalizes these values to obtain the posterior probabilities \\(\\pi(\\mu_i \\mid y)\\). Table 8.1 displays the values of \\(\\mu\\) and the corresponding values of Prior, Data/Likelihood, and Posterior. Readers are encouraged to verify the results shown in the table.\nTable 8.1. Value, prior, data/likelihood and posterior for () with a single observation.\n\n\n\n()\nPrior\nData/Likelihood\nPosterior\n\n\n\n\n15\n0.125\n0.0997\n0.1888\n\n\n16\n0.125\n0.0972\n0.1842\n\n\n17\n0.125\n0.0891\n0.1688\n\n\n18\n0.125\n0.0767\n0.1452\n\n\n19\n0.125\n0.0620\n0.1174\n\n\n20\n0.125\n0.0471\n0.0892\n\n\n21\n0.125\n0.0336\n0.0637\n\n\n22\n0.125\n0.0225\n0.0427\n\n\n\nWith the single measurement of time-to-serve of \\(y = 15.1\\), one sees from Table 8.1 that the posterior distribution for \\(\\mu\\) favors values \\(\\mu\\) = 15, and 16. In fact, the posterior probabilities decrease as a function of \\(\\mu\\). The Prior column reminds us that the prior distribution is Uniform. Bayesian inference uses the collected data to sharpen one’s belief about the unknown parameter from the prior distribution to the posterior distribution. For this single observation, the sample mean is \\(y = 15.1\\) and the \\(\\mu\\) value closest to the sample mean (\\(\\mu = 15\\)) is assigned the highest posterior probability.\nTypically one collects multiple time-to-serve measurements. Suppose one collects \\(n\\) time-to-serve measurements, denoted as \\(Y_1, ..., Y_n\\), that are Normally distributed with mean \\(\\mu\\) and fixed standard deviation \\(\\sigma = 4\\). Each observation follows the same Normal density \\[\\begin{equation}\nf(y_i) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{\\frac{-(y_i - \\mu)^2}{2 \\sigma^2}\\right\\}, -\\infty < y_i < \\infty.\n\\end{equation}\\] Again since \\(\\sigma = 4\\) is known, the only parameter in Equation (8.6) is \\(\\mu\\) and we are interested in learning about this mean parameter \\(\\mu\\). Suppose the same discrete Uniform prior is used as in Equation (8.4) and graphed in Figure 8.2. The mean \\(\\mu\\) takes on the values \\(\\{15, 16, \\cdots, 22\\}\\) with each value assigned the same probability of \\(\\frac{1}{8}\\).\nSuppose one collects a sample of 20 times-to-serve for Federer:\n\n15.1 11.8 21.0 22.7 18.6 16.2 11.1 13.2 20.4 19.2 \n21.2 14.3 18.6 16.8 20.3 19.9 15.0 13.4 19.9 15.3\n\nWhen multiple time-to-serve measurements are taken, the likelihood function is the joint density of the actual observed values \\(y_1, ..., y_n\\) viewed as a function of the mean \\(\\mu\\). After some algebra (detailed derivation in Section 8.3.2), one writes the likelihood function as \\[\\begin{eqnarray}\nL(\\mu) & = &\\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{1}{2 \\sigma^2}(y_i - \\mu)^2\\right\\} \\nonumber \\\\\n& \\propto &\\exp\\left\\{-\\frac{n}{2 \\sigma^2}(\\bar y - \\mu)^2\\right\\} \\nonumber \\\\\n& = & \\exp\\left\\{-\\frac{20}{2 (4)^2}(\\bar y - \\mu)^2\\right\\} ,\n\\end{eqnarray}\\] where we have substituted the known values \\(n = 20\\) and the standard deviation \\(\\sigma = 4\\). From our sample, we compute the sample mean \\(\\bar y = (15.1 + 11.8 + ... + 15.3) / 20 = 17.2\\). The value of \\(\\bar y\\) is substituted into Equation (8.7), and for each possible value of \\(\\mu\\), we substitute the value to find the corresponding likelihood. For example, the likelihood of \\(\\mu = 15\\) is equal to \\[\\begin{align*}\nL(15) & = \\exp\\left\\{-\\frac{20}{2 (4)^2}(17.2 - 15)^2\\right\\} \\nonumber \\\\\n& \\approx 0.022.\n\\end{align*}\\] This calculation is repeated for each of the eight values \\(\\mu = 15, 16, ..., 22\\), obtaining eight likelihood values.\nOne now applies Bayes’ rule to obtain the posterior distribution for \\(\\mu\\). The posterior probability of \\(\\mu = \\mu_i\\) given the sequence of recorded times-to-serve \\(y_1, \\cdots, y_n\\) has the form \\[\\begin{equation}\n\\pi(\\mu_i \\mid y_1, \\cdots, y_n) = \\frac{\\pi(\\mu_i) \\times L(\\mu_i)}{\\sum_j \\pi(\\mu_j) \\times L(\\mu_j)},\n\\end{equation}\\] where \\(\\pi(\\mu_i)\\) is the prior probability of \\(\\mu = \\mu_i\\) and \\(L(\\mu_i)\\) is the likelihood function evaluated at \\(\\mu = \\mu_i\\). We saw in equation @ref(eq:normaldiscretejointlikelihood) that only the sample mean, \\(\\bar{y}\\), is needed in the calculation of the likelihood, so \\(\\bar{y}\\) is used in place of \\(y_1, \\cdots, y_n\\) in the formula.\nWith a discrete Uniform prior distribution for \\(\\mu\\), again one has \\(\\pi(\\mu_i) = \\frac{1}{8}\\) for all \\(i = 1, \\cdots, 8\\) and \\(\\pi(\\mu_i)\\) is canceled out from the numerator and denominator in Equation (8.8). One calculates the posterior probabilities by computing \\(L(\\mu_i)\\) for all \\(i = 1, \\cdots, 8\\) and normalizing these values. Table 8.2 displays the values of \\(\\mu\\) and the corresponding values of Prior, Data/Likelihood, and Posterior. Readers are encouraged to verify the results shown in the table.\nTable 8.2. Value, prior, data/likelihood, and posterior for () with (n) observations.\n\n\n\n()\nPrior\nData/Likelihood\nPosterior\n\n\n\n\n15\n0.125\n0.0217\n0.0217\n\n\n16\n0.125\n0.1813\n0.1815\n\n\n17\n0.125\n0.4350\n0.4353\n\n\n18\n0.125\n0.2990\n0.2992\n\n\n19\n0.125\n0.0589\n0.0589\n\n\n20\n0.125\n0.0033\n0.0033\n\n\n21\n0.125\n0.0001\n0.0001\n\n\n22\n0.125\n0.0000\n0.0000\n\n\n\nIt is helpful to construct a graph (see Figure 8.3) where one contrasts the prior and probability probabilities for the mean time-to-serve \\(\\mu\\). While the prior distribution is flat, the posterior distribution for \\(\\mu\\) favors the values \\(\\mu\\) = 16, 17, and 18 seconds. Bayesian inference uses the observed data to revise one’s belief about the unknown parameter from the prior distribution to the posterior distribution. Recall that the sample mean \\(\\bar{y}\\) = 17.2 seconds. From Table 8.2 and Figure 8.3 one sees the clear effect of the observed sample mean – \\(\\mu\\) is likely to be close to the value 17.2.\n\n\n\n\n\nPrior and posterior probabilities of the Normal mean \\(\\mu\\) with a sample of observations.\n\n\n\n\n\n\n3.3.2 Simplification of the likelihood\nThe likelihood function is the joint density of the observations \\(y_1, ..., y_n\\), viewed as a function of the mean \\(\\mu\\) (since \\(\\sigma=4\\) is given). With \\(n\\) observations being identically and independently distributed (i.i.d.) as \\({\\rm{Normal}}({\\mu, 4})\\), the likelihood function is the product of Normal density terms. In the algebra work that will be done shortly, the likelihood, as a function of \\(\\mu\\), is found to be Normal with mean \\(\\bar y\\) and standard deviation \\(\\sigma / \\sqrt{n}\\).\nThe calculation of the posterior probabilities is an application of Bayes’ rule illustrated in earlier chapters. One creates a data frame of values mu and corresponding probabilities Prior. One computes the likelihood values in the variable Likelihood and the posterior probabilities are found using the bayesian_crank() function.\n\ndf <- data.frame(mu = seq(15, 22, 1),\n                 Prior = rep(1/8, 8)) %>% \n  mutate(Likelihood = dnorm(mu, 17.2, 4 / sqrt(20))) \n\ndf <- bayesian_crank(df) \nround(df, 4)\n\n  mu Prior Likelihood Product Posterior\n1 15 0.125     0.0217  0.0027    0.0217\n2 16 0.125     0.1813  0.0227    0.1815\n3 17 0.125     0.4350  0.0544    0.4353\n4 18 0.125     0.2990  0.0374    0.2992\n5 19 0.125     0.0589  0.0074    0.0589\n6 20 0.125     0.0033  0.0004    0.0033\n7 21 0.125     0.0001  0.0000    0.0001\n8 22 0.125     0.0000  0.0000    0.0000\n\n\n\nDerivation of \\(L(\\mu) \\propto \\exp \\left(-\\frac{n}{2 \\sigma^2}(\\bar{y} - \\mu)^2\\right)\\)\nIn the following, we combine the terms in the exponent, expand all of the summation terms, and complete the square to get the result.\n\\[\\begin{eqnarray}\nL(\\mu) &=&  \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{1}{2 \\sigma^2}(y_i - \\mu)^2\\right\\}  \\nonumber \\\\\n       &=& \\left(\\frac{1}{\\sqrt{2 \\pi}\\sigma}\\right)^n \\exp\\left\\{-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2\\right\\}\\nonumber \\\\\n&\\propto& \\exp \\left\\{ -\\frac{1}{2 \\sigma^2} \\sum_{i=1}^{n} (y_i^2 - 2\\mu y_i + \\mu^2)\\right\\} \\nonumber \\\\\n\\texttt{[expand the $\\sum$ terms]} &=& \\exp \\left\\{ -\\frac{1}{2 \\sigma^2} \\left( \\sum_{i=1}^{n} y_i^2 - 2\\mu \\sum_{i=1}^{n} y_i + n\\mu^2 \\right) \\right\\} \\nonumber \\\\\n&\\propto& \\exp \\left\\{- \\frac{1}{2 \\sigma^2} \\left(-2 \\mu \\sum_{i=1}^{n} y_i + n \\mu^2 \\right) \\right\\}\\nonumber \\\\\n\\texttt{[replace $\\sum$ with $n\\bar{y}$]} &=& \\exp \\left\\{ - \\frac{1}{2 \\sigma^2} \\left(-2 n \\mu \\bar{y} + n \\mu^2 \\right) \\right\\}\\nonumber \\\\\n\\texttt{[complete the square]} &=& \\exp \\left\\{ -\\frac{n}{2 \\sigma^2} (\\mu^2 - 2\\mu \\bar{y} + \\bar{y}^2) + \\frac{n}{2 \\sigma^2} \\bar{y}^2\\right\\} \\nonumber \\\\\n&\\propto& \\exp \\left\\{-\\frac{n}{2 \\sigma^2}(\\bar{y} - \\mu)^2\\right\\}\n\\end{eqnarray}\\]\n\n\nSufficient statistic\nThere are different ways of writing and simplifying the likelihood function. One can choose to keep the product sign and each \\(y_i\\) term, and leave the likelihood function as \\[\\begin{equation}\nL(\\mu) =  \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{1}{2 \\sigma^2}(y_i - \\mu)^2\\right\\}.\n\\end{equation}\\] Doing so requires one to calculate the individual likelihood from each time-to-serve measurement \\(y_i\\) and multiply these values to obtain the function \\(L(\\mu)\\) used to obtain the posterior probability.\nIf one instead simplifies the likelihood to be \\[\\begin{equation}\nL(\\mu) \\propto \\exp \\left\\{-\\frac{n}{2 \\sigma^2}(\\bar{y} - \\mu)^2\\right\\},\n\\end{equation}\\] all the proportionality constants drop out in the calculation of the posterior probabilities for different values of \\(\\mu\\). In the application of Bayes’ rule, one only needs to know the number of observations \\(n\\) and the mean time to serve \\(\\bar{y}\\) to calculate the posterior. Since the likelihood function depends on the data only through the value \\(\\bar{y}\\), the statistic \\(\\bar{y}\\) is called a sufficient statistic for the mean \\(\\mu\\).\n\n\n\n3.3.3 Inference: Federer’s time-to-serve\nWhat has one learned about Federer’s mean time-to-serve from this Bayesian analysis? Our prior said that any of the eight possible values of \\(\\mu\\) were equally likely with probability \\(0.125\\). After observing the sample of 20 measurements, one believes \\(\\mu\\) is most likely \\(16\\), 17, and \\(18\\) seconds, with respective probabilities \\(0.181, 0.425\\), and \\(0.299\\). In fact, if one adds up the posterior probabilities, one says that \\(\\mu\\) is in the set {16, 17, 18} seconds with probability \\(0.915\\). \\[\\begin{eqnarray*}\nProb(16 \\leq \\mu \\leq 18) = 0.181 + 0.435 + 0.299 = 0.915\n\\end{eqnarray*}\\] This region of values of \\(\\mu\\) is called a \\(91.5\\%\\) posterior probability region for the mean time-to-serve \\(\\mu\\)."
  },
  {
    "objectID": "mean.html#Normal:Continuous",
    "href": "mean.html#Normal:Continuous",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.4 Continuous Priors",
    "text": "3.4 Continuous Priors\n\n3.4.1 The Normal prior for mean \\(\\mu\\)\nReturning to our example, one is interested in learning about the time-to-serve for the tennis player Roger Federer. His serving times are believed to be Normally distributed with unknown mean \\(\\mu\\) and known standard deviation \\(\\sigma = 4\\). The focus is on learning about the mean value \\(\\mu\\).\nIn the prior construction in Section 8.3, we assumed \\(\\mu\\) was discrete, taking only integer values from \\(15\\) to \\(22\\). However, the mean time-to-serve \\(\\mu\\) does not have to be an integer. In fact, it is more realistic to assume \\(\\mu\\) is continuous-valued. One widely-used approach for representing one’s belief about a Normal mean is based on a Normal prior density with mean \\(\\mu_0\\) and standard deviation \\(\\sigma_0\\), that is \\[\\begin{eqnarray*}\n\\mu \\sim {\\rm{Normal}}(\\mu_0, \\sigma_0).\n\\end{eqnarray*}\\]\nThere are two parameters for this Normal prior: the value \\(\\mu_0\\) represents one’s “best guess” at the mean time-to-serve \\(\\mu\\) and \\(\\sigma_0\\) indicates how sure one thinks about the guess.\nTo illustrate the use of different priors for \\(\\mu\\), let’s consider the opinion of one tennis fan Joe who has strong prior information about the mean. His best guess at Federer’s mean time-to-serve is 18 seconds so he lets \\(\\mu_0 = 18\\). He is very sure of this guess and so he chooses \\(\\sigma_0\\) to be the relatively small value of \\(0.4\\). In contrast, a second tennis fan Kate also thinks that Federer’s mean time-to-serve is 18 seconds, but does not have a strong belief in this guess and chooses the large value \\(2\\) of the standard deviation \\(\\sigma_0\\). Figure 8.4 shows these two Normal priors for the mean time-to-serve \\(\\mu\\).\n\n\n\n\n\nTwo priors for the Normal mean \\(\\mu\\).\n\n\n\n\nBoth curves are symmetric and bell-shaped, centered at \\(\\mu_0\\) = 18. The main difference is the spread of the two curves: a Normal(8, 0.4) curve is much more concentrated around the mean \\(\\mu_0\\) = 18 compared to the Normal(8, 2) curve. Since the value of the probability density function at a point reflects the probability at that value, the Normal(8, 0.4) prior reflects the belief that the mean time to serve will most likely be around \\(\\mu_0\\) = 18 seconds, whereas the Normal(8, 2) prior indicates that the mean \\(\\mu\\) could be as small as 15 seconds and as large as 20 seconds.\n\n\n3.4.2 Choosing a Normal prior\n\nInformative prior\nHow does one in practice choose a Normal prior for \\(\\mu\\) that reflects prior beliefs about the location of this parameter? One indirect strategy for choosing for selecting values of the prior parameters \\(\\mu_0\\) and \\(\\sigma_0\\) is based on the specification of quantiles. On the basis of one’s prior beliefs, one specifies two quantiles of the Normal density. Then the Normal parameters are found by matching these two quantiles to a particular Normal curve.\nRecall the definition of a quantile — in this setting it is a value of the mean \\(\\mu\\) such that the probability of being smaller than that value is a given probability. To construct one’s prior for Federer’s mean time-to-serve, one thinks first about two quantiles. Suppose one specifies the 0.5 quantile to be 18 seconds — this means that \\(\\mu\\) is equally likely to be smaller or larger than 18 seconds. Next, one decides that the 0.9 quantile is 20 seconds. This means that one’s probability that \\(\\mu\\) is smaller than 20 seconds is 90%. Given values of these two quantiles, the unique Normal curve is found that matches this information.\nThe matching is performed by the R function normal.select(). One inputs two quantiles by list} statements, and the output is the mean and standard deviation of the Normal prior.\n\nnormal.select(list(p = 0.5, x = 18), list(p = 0.9, x = 20))\n\n$mu\n[1] 18\n\n$sigma\n[1] 1.560608\n\n\nThe Normal curve with mean \\(\\mu_0 = 18\\) and \\(\\sigma_0 = 1.56\\), displayed in Figure 8.5, matches the prior information stated by the two quantiles.\n\n\n\n\n\nA person’s Normal prior for Federer’s mean time-to-serve \\(\\mu\\).\n\n\n\n\nSince our measurement skills are limited, this prior is just an approximation to one’s beliefs about \\(\\mu\\). We recommend in practice that one perform several checks to see if this Normal prior makes sense. Several functions are available to help in this prior checking.\nFor example, one finds the 0.25 quantile of our prior using the qnorm() function.\n\nqnorm(0.25, 18, 1.56)\n\n[1] 16.9478\n\n\nThis prior says that the prior probability that \\(\\mu\\) is smaller than 16.95 is 25%. If this does not seem reasonable, one would make adjustments in the values of the Normal mean and standard deviation until a reasonable Normal prior is found.\n\n\nWeekly informative prior\nWe have been assuming that one has some information about the mean parameter \\(\\mu\\) that is represented by a Normal prior. What would a user do in the situation where little is known about the location on \\(\\mu\\)? For a Normal prior, the standard deviation \\(\\sigma_0\\) represents the sureness of one’s belief in one’s guess \\(\\mu_0\\) at the value of the mean. If one is really unsure about any guess at \\(\\mu\\), then one assigns the standard deviation \\(\\sigma_0\\) a large value. Then the choice of the prior mean will not matter, so we suggest using a Normal(0, \\(\\sigma_0\\)) with a large value for \\(\\sigma_0\\). This prior indicates that \\(\\mu\\) may plausibly range over a large interval and represents weakly informative prior belief about the parameter.\nAs will be seen later in this chapter, when a vague prior is chosen, the posterior inference for \\(\\mu\\) will largely be driven by the data. This behavior is desirable since this person knows little about the location of \\(\\mu\\) a priori in this situation and wants the data to inform about the location of \\(\\mu\\) with little influence by the prior."
  },
  {
    "objectID": "mean.html#Normal:ContinuousUpdate",
    "href": "mean.html#Normal:ContinuousUpdate",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.5 Updating the Normal Prior",
    "text": "3.5 Updating the Normal Prior\n\n3.5.1 Introduction\nContinuing our discussion on learning about the mean time-to-serve for Roger Federer, the current prior beliefs about Federer’s mean time-to-serve \\(\\mu\\) are represented by a Normal curve with mean \\(18\\) seconds and standard deviation 1.56 seconds.\nNext some data is collected — Federer’s time-to-serves are recorded for 20 serves and the sample mean is \\(17.2\\) seconds. Recall that we are assuming the population standard deviation \\(\\sigma = 4\\) seconds. The likelihood is given by \\[\\begin{equation}\nL(\\mu) \\propto \\exp \\left\\{-\\frac{n}{2 \\sigma^2}(\\bar{y} - \\mu)^2\\right\\},\n\\end{equation}\\] and with substitution of the values \\(\\bar y = 17.2\\), \\(n = 20\\), and \\(\\sigma = 4\\), we obtain \\[\\begin{eqnarray}\nL(\\mu) &\\propto& \\exp \\left\\{-\\frac{20}{2 (4)^2}(17.2 - \\mu)^2\\right\\} \\nonumber \\\\\n&=& \\exp \\left\\{-\\frac{1}{2(4/\\sqrt{20})^2}(\\mu - 17.2)^2\\right\\}.\n\\end{eqnarray}\\] Viewing the likelihood as a function of the parameter \\(\\mu\\) as in Equation (8.13), the likelihood is recognized as a Normal density with mean \\(\\bar y = 17.2\\) and standard deviation \\(\\sigma / \\sqrt{n} = 4 / \\sqrt{20} = 0.89\\).\nThe Bayes’ rule calculation is very familiar to the reader — one obtains the posterior density curve by multiplying the Normal prior by the likelihood. If one writes down the product of the Normal likelihood and the Normal prior density and works through some messy algebra, one will discover that the posterior density also has the Normal density form.\nThe Normal prior is said to be conjugate since the prior and posterior densities come from the same distribution family: Normal. To be more specific, suppose the observation has a Normal sampling density with unknown mean \\(\\mu\\) and known standard deviation \\(\\sigma\\). If one specifies a Normal prior for the unknown mean \\(\\mu\\) with mean \\(\\mu_0\\) and standard deviation \\(\\sigma_0\\), one obtains a Normal posterior for \\(\\mu\\) with updated parameters \\(\\mu_n\\) and \\(\\sigma_n\\).\nIn Section 8.5.2, we provide a quick peak at this posterior updating without worrying about the mathematical derivation and Section 8.5.3 describes the details of the Bayes’ rule calculation. Section 8.5.4 looks at the conjugacy more closely and provides some insight on the effects of prior and likelihood on the posterior distribution.\n\n\n3.5.2 A quick peak at the update procedure\nIt is convenient to describe the updating procedure by use of a table. In Table 8.3, there are rows corresponding to Prior, Data/Likelihood, and Posterior and columns corresponding to Mean, Precision, and Standard Deviation. The mean and standard deviation of the Normal prior are placed in the “Prior” row, and the sample mean and standard error are placed in the “Data/Likelihood” row.\nTable 8.3. Updating the Normal prior: step 1.\n\n\n\nType\nMean\nPrecision\nStand\n\n\n\n\nPrior\n18.00\n\n1.56\n\n\nData/Likelihood\n17.20\n\n0.89\n\n\nPosterior\n\n\n\n\n\n\nWe define the precision, \\(\\phi\\), to be the reciprocal of the square of the standard deviation. We compute the precisions of the prior and data from the given standard deviations: \\[\\begin{equation*}\n\\phi_{prior} = \\frac{1}{\\sigma_0^2} = \\frac{1}{1.56^2} = 0.41, \\, \\, \\,\n\\phi_{data} = \\frac{1}{\\sigma^2 / n} = \\frac{1}{0.89^2} = 1.26.\n\\end{equation*}\\] We enter the precisions in the corresponding rows of Table 8.4 \\(\\ref{table:normalupdate2}\\).\nTable 8.4. Updating the Normal prior: step 2.\n\n\n\nType\nMean\nPrecision\nStand\n\n\n\n\nPrior\n18.00\n0.41\n1.56\n\n\nData/Likelihood\n17.20\n1.26\n0.89\n\n\nPosterior\n\n\n\n\n\n\nWe will shortly see that the Posterior precision is the sum of the Prior precision and the Data/Likelihood precisions:\n\\[\\begin{equation*}\n\\phi_{post} = \\phi_{prior} + \\phi_{data} = 0.41 + 1.26 = 1.67.\n\\end{equation*}\\] Once the posterior precision is computed, the posterior standard deviation is computed as the reciprocal of the square root of the precision. \\[\\begin{equation*}\n\\sigma_n = \\frac{1}{\\sqrt{\\phi_{post}}} = \\frac{1}{\\sqrt{1.67}} = 0.77.\n\\end{equation*}\\] These precisions and standard deviations are entered into Table 8.5.\nTable 8.5. Updating the Normal prior: step 3.\n\n\n\nType\nMean\nPrecision\nStand\n\n\n\n\nPrior\n18.00\n0.41\n1.56\n\n\nData/Likelihood\n17.20\n1.26\n0.89\n\n\nPosterior\n\n1.67\n0.77\n\n\n\nThe posterior mean is a weighted average of the Prior and Data/Likelihood means where the weights are given by the corresponding precisions. That is, the formula is given by \\[\\begin{eqnarray}\n\\mu_n = \\frac{\\phi_{prior} \\times \\mu_0 + \\phi_{data} \\times \\bar y}{\\phi_{prior} + \\phi_{data}}.\n\\end{eqnarray}\\] By making appropriate substitutions, we obtain the posterior mean: \\[\\begin{eqnarray*}\n\\mu_n = \\frac{0.41 \\times 18.00 + 1.26 \\times 17.20}{0.41 + 1.26} = 17.40.\n\\end{eqnarray*}\\] The posterior density is Normal with mean \\(17.40\\) seconds and standard deviation \\(0.77\\) seconds. See Table 8.6 for the final update step.\nTable 8.6. Updating the Normal prior: step 4.\n\n\n\nType\nMean\nPrecision\nStand\n\n\n\n\nPrior\n18.00\n0.41\n1.56\n\n\nData/Likelihood\n17.20\n1.26\n0.89\n\n\nPosterior\n17.40\n1.67\n0.77\n\n\n\nThe Normal updating is performed by the R function normal_update(). One inputs two vectors – prior is a vector of the prior mean and standard deviation and data is a vector of the sample mean and standard error. The output is a vector of the posterior mean and posterior standard deviation.\n\nprior <- c(18, 1.56)\ndata <- c(17.20, 0.89)\nnormal_update(prior, data)\n\n[1] 17.3964473  0.7730412\n\n\nThe prior and posterior densities are displayed in Figure 8.6. As usually the case, the posterior density has a smaller spread since the posterior has more information than the prior about Federer’s mean time-to-serve. More information about a parameter indicates less uncertainty and a smaller spread of the posterior density. In the process from prior to posterior, one sees how the data modifies one’s initial belief about the parameter \\(\\mu\\).\n\n\n\n\n\nPrior and posterior curves for Federer’s mean time-to-serve \\(\\mu\\).\n\n\n\n\n\n\n3.5.3 Bayes’ rule calculation\nSection 8.5.2 gave an overview of the updating procedure for a Normal prior and Normal sampling. In this section we explain (1) why it is preferable to work with the precisions instead of the standard deviations; (2) why the precisions act as the weights in the calculation of the posterior mean and (3) why the posterior is a Normal distribution.\nRecall a precision is the reciprocal of the square of the standard deviation. We use \\(\\phi = \\frac{1}{\\sigma^2}\\) to represent the precision of a single observation in the Normal data/likelihood, and \\(\\phi_0 = \\frac{1}{\\sigma_0^2}\\) to represent the precision in the Normal prior.\n\nWe write down the likelihood of \\(\\mu\\), combining terms, and writing the expression in terms of the precision \\(\\phi\\). \\[\\begin{eqnarray}\ny_1, \\cdots, y_n \\mid \\mu, \\sigma &\\overset{i.i.d.}{\\sim}& {\\rm{Normal}}(\\mu, \\sigma)\\\\% \\equiv {\\rm{Normal}}(\\mu, \\frac{1}{\\phi}) \\\\\n\\end{eqnarray}\\] \\[\\begin{eqnarray}\nL(\\mu) = f(y_1, \\cdots, y_n \\mid \\mu, \\sigma) &=& \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_i-\\mu)^2\\right\\} \\nonumber \\\\\n&=& \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}}\\phi^{\\frac{1}{2}} \\exp\\left\\{-\\frac{\\phi}{2}(y_i - \\mu)^2)\\right\\}\\nonumber \\\\\n&=& \\left(\\frac{1}{\\sqrt{2\\pi}}\\right)^n \\phi^{\\frac{n}{2}} \\exp\\left\\{-\\frac{\\phi}{2}\\sum_{i=1}^{n}(y_i - \\mu)^2)\\right\\}\\nonumber \\\\\n\\end{eqnarray}\\]\n\nNote that \\(\\sigma\\) is assumed known, therefore the likelihood function is only in terms of \\(\\mu\\), i.e. \\(L(\\mu)\\).\n\nIn similar fashion, we write down the prior density for \\(\\mu\\) including the prior precision \\(\\phi_0\\). \\[\\begin{eqnarray}\n\\mu  &\\sim& {\\rm{Normal}}(\\mu_0, \\sigma_0) \\\\%\\equiv {\\rm{Normal}}(\\mu_0, \\frac{1}{\\phi_0}) \\\\\n\\end{eqnarray}\\] \\[\\begin{eqnarray}\n\\pi(\\mu) &=& \\frac{1}{\\sqrt{2\\pi}\\sigma_0} \\exp\\left\\{-\\frac{1}{2\\sigma_0^2}(\\mu - \\mu_0)^2)\\right\\}\\nonumber \\\\\n&=& \\frac{1}{\\sqrt{2\\pi}}\\phi_0^{\\frac{1}{2}} \\exp\\left\\{-\\frac{\\phi_0}{2}(\\mu - \\mu_0)^2\\right\\}\n\\end{eqnarray}\\]\nBayes’ rule is applied by multiplying the prior by the likelihood to obtain the posterior. In deriving the posterior of \\(\\mu\\), the manipulations require careful consideration regarding what is known. The only unknown variable is \\(\\mu\\), so any “constants” or known quantities not depending on \\(\\mu\\) can be dropped/added with the proportionality sign “\\(\\propto\\)”.\n\n\\[\\begin{eqnarray}\n\\pi(\\mu \\mid y_1, \\cdots, y_n, \\sigma) &\\propto&  \\pi(\\mu) L(\\mu) \\nonumber \\\\\n&\\propto& \\exp\\left\\{-\\frac{\\phi_0}{2}(\\mu - \\mu_0)^2\\right\\} \\times \\exp\\left\\{-\\frac{n\\phi}{2}(\\mu - \\bar{y})^2\\right\\} \\nonumber \\\\\n&\\propto& \\exp\\left\\{-\\frac{1}{2}(\\phi_0 +n\\phi)\\mu^2 + \\frac{1}{2}(2\\mu_0\\phi_0 + 2n\\phi\\bar{y})\\mu\\right\\} \\nonumber \\\\\n\\texttt{[complete the square]} &\\propto& \\exp\\left\\{-\\frac{1}{2}(\\phi_0 + n\\phi)(\\mu - \\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi})^2\\right\\} \\\\\n\\end{eqnarray}\\]\nLooking closely at the final expression, one recognizes that the posterior for \\(\\mu\\) is a Normal density with mean and precision parameters. Specifically we recognize \\((\\phi_0 + n \\phi)\\) as the posterior precision and \\((\\frac{\\phi_0 \\mu_0 + n \\phi\\bar{y}}{\\phi_0 + n \\phi})\\) as the posterior mean. Summarizing, we have derived the following posterior distribution of \\(\\mu\\),\n\\[\\begin{eqnarray}\n\\mu \\mid y_1, \\cdots, y_n, \\sigma \\sim {\\rm{Normal}}\\left(\\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi}, \\sqrt{\\frac{1}{\\phi_0 + n \\phi}}\\right).\n\\end{eqnarray}\\]\nIn passing, it should be noted that the same result would be attained using the standard deviations, \\(\\sigma\\) and \\(\\sigma_0\\), instead of the precisions, \\(\\phi\\) and \\(\\phi_0\\). It is preferable to work with the precisions due to the relative simplicity of the notation. In particular, one sees in Table Table 8.5 that the posterior precision is the sum of the prior and data/likelihood precisions, that is, the posterior precision \\(\\phi_n = \\phi_0 + n \\phi\\).\n\n\n3.5.4 Conjugate Normal prior\nLet’s summarize our calculations in Section 8.5.3. We collect a sequence of continuous observations that are assumed identically and independently distributed as \\(\\textrm{Normal}(\\mu, \\sigma)\\), and a Normal prior is assigned to the mean parameter \\(\\mu\\).\n\nThe sampling model: \\[\\begin{eqnarray}\nY_1, \\cdots, Y_n \\mid \\mu, \\sigma &\\overset{i.i.d.}{\\sim}& {\\rm{Normal}}(\\mu, \\sigma)\n\\end{eqnarray}\\] When \\(\\sigma\\) (or \\(\\phi\\)) is known, and mean \\(\\mu\\) is the only parameter in the likelihood.\nThe prior distribution: \\[\\begin{eqnarray}\n\\mu  &\\sim& {\\rm{Normal}}(\\mu_0, \\sigma_0)\n\\end{eqnarray}\\]\nAfter \\(Y_1 = y_1, ..., Y_n = y_n\\) are observed, the posterior distribution for the mean \\(\\mu\\) is another Normal distribution with mean \\(\\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi}\\) and precision \\(\\phi_0 + n \\phi\\) (thus standard deviation \\(\\sqrt{\\frac{1}{\\phi_0 + n \\phi}}\\)):\n\n\\[\\begin{eqnarray}\n\\mu \\mid y_1, \\cdots, y_n, \\sigma \\sim {\\rm{Normal}}\\left(\\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi}, \\sqrt{\\frac{1}{\\phi_0 + n \\phi}}\\right).\n\\end{eqnarray}\\]\nIn this situation where the sampling standard deviation \\(\\sigma\\) is known, the Normal density is a conjugate prior for the mean of a Normal distribution, as the posterior distribution for \\(\\mu\\) is another Normal density with updated parameters. Conjugacy is a convenient property as the posterior distribution for \\(\\mu\\) has a convenient functional form. Conjugacy allows one to conduct Bayesian inference through exact analytical solutions and simulation. Also conjugacy provides insight on how the data and prior are combined in the posterior distribution.\n\nThe posterior compromises between the prior and the sample\nRecall that Bayesian inference is a general approach where one initializes a prior belief for an unknown quantity, collects data expressed through a likelihood function, and combines prior and likelihood to give an updated belief for the unknown quantity. In Chapter 7, we have seen how the posterior mean of a proportion is a compromise between the prior mean and sample proportion (refer to Section 7.4.2 as needed). In the current Normal mean case, the posterior mean is similarly viewed as an estimate that compromises between the prior mean and sample mean. One rewrites the posterior mean in Equation (8.23) as follows: \\[\\begin{eqnarray}\n\\mu_n = \\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi} &=& \\frac{\\phi_0}{\\phi_0 + n\\phi} \\mu_0 +  \n\\frac{n\\phi}{\\phi_0 + n\\phi}  \\bar{y}.\n\\end{eqnarray}\\] The prior precision is equal to \\(\\phi_0\\) and the precision in the likelihood for any \\(y_i\\) is \\(\\phi\\). Since there are \\(n\\) observations, the precision in the joint likelihood is \\(n\\phi\\). The posterior mean is a weighted average of the prior mean \\(\\mu_0\\) and sample mean \\(\\bar y\\) where the weights are proportional to the associated precisions.\n\n\nThe posterior accumulates information in the prior and the sample\nIn addition, the precision of the posterior Normal mean is the sum of the precisions of the prior and likelihood. That is, \\[\\begin{equation}\n\\phi_n = \\phi_0 + n \\phi.\n\\end{equation}\\] The implication is that the posterior standard deviation will always be smaller than either the prior standard deviation or the sampling standard error: \\[\\begin{equation*}\n\\sigma_n < \\sigma_0, \\, \\, \\, \\sigma_n < \\frac{\\sigma}{\\sqrt{n}}.\n\\end{equation*}\\]"
  },
  {
    "objectID": "mean.html#Normal:ContinuousInference",
    "href": "mean.html#Normal:ContinuousInference",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.6 Bayesian Inferences for Continuous Normal Mean",
    "text": "3.6 Bayesian Inferences for Continuous Normal Mean\nContinuing with the example about Federer’s time-to-serve, our Normal prior had mean 18 seconds and standard deviation 1.56 seconds. After collecting 20 time-to-serve measurements with a sample mean of 17.2, the posterior distribution \\(\\textrm{Normal}(17.4, 0.77)\\) reflects our opinion about the mean time-to-serve.\nBayesian inferences about the mean \\(\\mu\\) are based on various summaries of this posterior Normal distribution. Because the exact posterior distribution of mean \\(\\mu\\) is Normal, it is convenient to use R functions such as pnorm() and qnorm() to conduct Bayesian hypothesis testing and construct Bayesian credible intervals. Simulation-based methods utilizing functions such as rnorm() are also useful to provide approximations to those inferences. A sequence of examples are given in Section 8.6.1.\nPredictions of future data are also of interest. For example, one might want to predict the next time-to-serve measurement based on the posterior distribution of \\(\\mu\\) being \\(\\textrm{Normal}(17.4, 0.77)\\). In Section 8.6.2, details of the prediction procedure and examples are provided.\n\n3.6.1 Bayesian hypothesis testing and credible interval\n\nA testing problem\nIn a testing problem, one is interested in checking the validity of a statement about a population quantity. In our tennis example, suppose someone says that Federer takes on average at least 19 seconds to serve. Is this a reasonable statement?\nThe current beliefs about Federer’s mean time-to-serve are summarized by a Normal distribution with mean 17.4 seconds and standard deviation 0.77 seconds. To assess if the statement “\\(\\mu\\) is 19 seconds or more” is reasonable, one simply computes its posterior probability, \\(Prob(\\mu \\geq 19 \\mid \\mu_n = 17.4, \\sigma_n = 0.77)\\).\n\n1 - pnorm(19, 17.4, 0.77)\n\n[1] 0.01885827\n\n\nThis probability is about 0.019, a small value, so one would conclude that this person’s statement is unlikely to be true.\nThis is the exact solution using the pnorm() function with mean 17.4 and standard deviation 0.77. As seen in Chapter 7, simulation provides an alternative approach to obtaining the probability \\(Prob(\\mu \\geq 19 \\mid \\mu_n = 17.4, \\sigma_n = 0.77)\\). To implement the simulation approach, recall that one generates a large number of values from the posterior distribution and summarizes this simulated sample. In particular, using the following R script, one generates 1000 values from the \\(\\textrm{Normal}(17.4, 0.77)\\) distribution and approximates the probability of “\\(\\mu\\) is 19 seconds or more” by computing the percentage of values that falls above 19.\n\n\n\n\nS <- 1000\nNormalSamples <- rnorm(S, 17.4, 0.77)\nsum(NormalSamples >= 19) / S\n\n[1] 0.024\n\n\nThe reader might notice that the approximated value of 0.024 differs from the exact answer of 0.019 using the pnorm() function. One way to improve the accuracy of the approximation is by increasing the number of simulated values. For example, increasing S from 1000 to 10,000 provides a better approximation to the exact probability 0.019.\n\n\n\n\nS <- 10000\nNormalSamples <- rnorm(S, 17.4, 0.77)\nsum(NormalSamples >= 19) / S\n\n[1] 0.0175\n\n\n\n\nA Bayesian interval estimate\nBayesian credible intervals for the mean parameter \\(\\mu\\) can be achieved both by exact calculation and simulation. Recall that a Bayesian credible interval is an interval that contains the unknown parameter with a certain probability content. For example, a 90% Bayesian credible interval for the parameter \\(\\mu\\) is an interval containing \\(\\mu\\) with a probability of 0.90.\nThe exact interval is obtained by using the R function qnorm(). For example, with the posterior distribution for \\(\\mu\\) being \\(\\textrm{Normal}(17.4, 0.77)\\), the following R script shows that a 90% central Bayesian credible interval is (16.133, 18.667). That is, the posterior probability of \\(\\mu\\) falls between 16.133 and 18.667 is exactly 90%.\n\nqnorm(c(0.05, 0.95), 17.4, 0.77)\n\n[1] 16.13346 18.66654\n\n\nFor simulation-based inference, one generates a large number of values from its posterior distribution, then finds the 5th and 95th sample quantiles to obtain the middle 90% of the generated values. Below one sees that a 90% credible interval for posterior of \\(\\mu\\) is approximately (16.151, 18.691).\n\n\n\n\nS <- 1000\nNormalSamples <- rnorm(S, 17.4, 0.77)\nquantile(NormalSamples, c(0.05, 0.95))\n\n      5%      95% \n16.15061 18.69062 \n\n\nThe Bayesian credible intervals can also be used for testing hypothesis. Suppose one again wants to evaluate the statement “Federer takes on average at least 19 seconds to serve.” One answers this question by computing the 90% credible interval. One notes that the values of \\(\\mu\\) “at least 19” are not included in the exact 90% credible interval (16.15, 18.69). The interpretation is that the probability is at least 0.90 that Federer’s average time-to-service is smaller than 19 seconds. One could obtain a wider credible interval, say by computing a central 95% credible interval (see the R output below), and observe that 19 is out of the interval. This indicates we are 95% confident that 19 seconds is not the value of Federer’s average time-to-serve.\n\nqnorm(c(0.025, 0.975), 17.4, 0.77)\n\n[1] 15.89083 18.90917\n\n\nOn the basis of this credible interval calculation, one concludes that the statement about Federer’s time-to-serve is unlikely to be true. This conclusion is consistent with the typical Bayesian hypothesis testing procedure given at the beginning of this section.\n\n\n\n3.6.2 Bayesian prediction\nSuppose one is interested in predicting Federer’s future time-to-serve. Since one has already updated the belief about the parameter, the mean \\(\\mu\\), the prediction is made based on its posterior predictive distribution.\nHow to make one future prediction of Federer’s time-to-serve? In Chapter 7, we have seen two different approaches for predicting of a new survey outcome of students’ dining preferences. One approach in Chapter 7 is based on the derivation of the exact posterior predictive distribution \\(f(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\) which was shown to be a Beta-Binomial distribution. The second approach is a simulation-based approach, which involves two steps: first, sample a value of the parameter from its posterior distribution (a Beta distribution), and second, sample a prediction from the data model based on the sampled parameter draw (a Binomial distribution). When the sample size in the simulation-based approach is sufficiently large, a prediction interval from the simulation-based approach is an accurate approximation to the exact prediction interval.\n\nExact predictive distribution\nWe first describe the exact posterior predictive distribution. Consider making a prediction of a single Federer’s time-to-serve \\(\\tilde{Y}\\). In general, suppose the sampling density of \\(\\tilde{Y}\\) given \\(\\mu\\) and \\(\\sigma\\) is \\(f(\\tilde{Y} = \\tilde{y} \\mid \\mu)\\) and suppose the current beliefs about \\(\\mu\\) are represented by the density \\(\\pi(\\mu)\\). The joint density of \\((\\tilde{y}, \\mu)\\) is given by the product \\[\\begin{equation}\nf(\\tilde{Y} = \\tilde{y}, \\mu) = f(\\tilde{Y} = \\tilde{y} \\mid \\mu) \\pi(\\mu),\n\\end{equation}\\] and by integrating out \\(\\mu\\), the predictive density of \\(\\tilde{Y}\\) is given by \\[\\begin{equation}\nf(\\tilde{Y} = \\tilde{y}) = \\int f(\\tilde{Y} = \\tilde{y} \\mid \\mu) \\pi(\\mu) d\\mu.\n\\end{equation}\\]\nThe computation of the predictive density is possible for this Normal sampling model with a Normal prior. It is assumed that \\(f(\\tilde{Y} = \\tilde{y} \\mid \\mu)\\) is Normal with mean \\(\\mu\\) and standard deviation \\(\\sigma\\) and that the current beliefs about \\(\\mu\\) are described by a Normal density with mean \\(\\mu_0\\) and standard deviation \\(\\sigma_0\\). Then it is possible to integrate out \\(\\mu\\) from the joint density of \\((\\tilde{y}, \\mu)\\) and one finds that the predictive density for \\(\\tilde{Y}\\) is Normal with mean and standard deviation given by \\[\\begin{equation}\nE(\\tilde{Y}) = \\mu_0, \\, \\, SD(\\tilde{Y}) = \\sqrt{\\sigma^2 + \\sigma_0^2}.\n\\end{equation}\\]\nThis result can be used to derive the posterior predictive distribution of \\(f(\\tilde{Y} = \\tilde{y} \\mid Y_1, \\cdots, Y_n)\\), where \\(\\tilde{Y}\\) is a future observation and \\(Y_1, \\cdots, Y_n\\) are \\(n\\) \\(i.i.d.\\) observations from a Normal sampling density with unknown mean \\(\\mu\\) and known standard deviation \\(\\sigma\\). After observing the sample values \\(y_1, \\cdots, y_n\\), the current beliefs about the mean \\(\\mu\\) are represented by a Normal\\((\\mu_n, \\sigma_n)\\) density, where the mean and standard deviation are given by \\[\\begin{equation}\n\\mu_n = \\frac{\\phi_0 \\mu_0 + n\\phi\\bar{y} }{\\phi_0 + n \\phi},  \\sigma_n = \\sqrt{\\frac{1}{\\phi_0 + n \\phi}}.\n\\end{equation}\\] Then by applying our general result in Equation (8.28), the posterior predictive density of the single future observation \\(\\tilde{Y}\\) is Normal with mean \\(\\mu_n\\) and standard deviation \\(\\sqrt{\\sigma^2 + \\sigma_n^2}.\\) That is, \\[\\begin{eqnarray}\n\\tilde{Y} = \\tilde{y} \\mid y_1, \\cdots, y_n, \\sigma \\sim \\textrm{Normal}(\\mu_n, \\sqrt{\\sigma^2 + \\sigma_n^2}).\n\\end{eqnarray}\\]\nAn important aspect of the predictive distribution for \\(\\tilde{Y}\\) is on the variance term \\(\\sigma^2 + \\sigma_n^2\\). The variability of a future prediction comes from two sources: (1) the data model variance \\(\\sigma^2\\), and (2) the posterior variance \\(\\sigma_n^2\\). Recall that the posterior variance \\(\\sigma_n^2 = \\frac{1}{\\phi_0 + n\\phi}\\). If one fixes values of \\(\\phi_0\\) and \\(\\phi\\) and allow the sample size \\(n\\) to grow, the posterior variance will approach zero. In this “large \\(n\\)” case, the uncertainty in inference about the population mean \\(\\mu\\) will decrease – essentially we are certain about the location of \\(\\mu\\). However the uncertainty in prediction will not decrease towards zero. In contrast, in this large sample case, the variance of \\(\\tilde{Y}\\) will decrease and approach the sampling variance \\(\\sigma^2\\).\n\n\nPredictions by simulation\nThe alternative method of computing the predictive distribution is by simulation. In this setting, there are two unknowns – the mean parameter \\(\\mu\\) and the future observation \\(\\tilde Y\\). One simulates a value from the predictive distribution in two steps: first, one simulates a value of the parameter \\(\\mu\\) from its posterior distribution; second, use this simulated parameter draw to simulate a future observation \\(\\tilde Y\\) from the data model. In particular, the following algorithm is used to simulate a single value from the posterior predictive distribution.\n\nSample a value of \\(\\mu\\) from its posterior distribution \\[\\begin{eqnarray}\n\\mu \\sim \\textrm{Normal}\\left(\\frac{\\phi_0\\mu_0 + n\\phi\\bar{y}}{\\phi_0 + n\\phi}, \\sqrt{\\frac{1}{\\phi_0 + n\\phi}}\\right),\n\\end{eqnarray}\\]\nSample a new observation \\(\\tilde{Y}\\) from the data model (i.e. a prediction) \\[\\begin{eqnarray}\n\\tilde{Y} \\sim \\textrm{Normal}(\\mu, \\sigma).\n\\end{eqnarray}\\]\n\nThis two-step procedure is implemented for our time-to-serve example using the following R script.\n\n\n\n\nsigma <- 4\nmu_n <- 17.4\nsigma_n <- 0.77\npred_mu_sim <- rnorm(1, mu_n, sigma_n)\n(pred_y_sim <- rnorm(1, pred_mu_sim, sigma))\n\n[1] 16.04772\n\n\nThe script can easily be updated to create \\(S\\) = 1000 predictions, which is helpful to make summary about predictions.\n\n\n\n\nS <- 1000\npred_mu_sim <- rnorm(S, mu_n, sigma_n)\npred_y_sim <- rnorm(S, pred_mu_sim, sigma)\n\nThe vector pred_y_sim contains 1000 predictions of Federer’s time-to-serve.\n\n\n\n\n\nDisplay of the exact and simulated time-to-serve for Federer’s example.\n\n\n\n\nTo evaluate the accuracy of the simulation-based predictions, Figure 8.7 displays the exact and a density estimate of the simulation-based predictive densities for a single time-to-serve measurement. One observes pretty good agreement using these two computation methods in this example."
  },
  {
    "objectID": "mean.html#Normal:PPC",
    "href": "mean.html#Normal:PPC",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.7 Posterior Predictive Checking",
    "text": "3.7 Posterior Predictive Checking\nIn Section 8.6, the use of the posterior predictive distribution for predicting a future time-to-serve measurement was described. As discussed in Chapter 7, this distribution is also helpful for assessing the suitability of the Bayesian model.\nIn our example, we observed 20 times-to-serve for Federer. The question is whether these observed times are consistent with replicated data from the posterior predictive distribution. In this setting, replicated refers to the same sample size as our original sample. In other words, if one takes samples of 20 from the posterior predictive distribution, do these replicated datasets resemble the observed sample?\nSince the population standard deviation is known as \\(\\sigma = 4\\) seconds, the sampling distribution of \\(Y\\) is Normal with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). One simulates replicated data \\(\\tilde Y_1, ..., \\tilde Y_{20}\\) from the posterior predictive distribution in two steps:\n\nSample a value of \\(\\mu\\) from its posterior distribution \\[\\begin{eqnarray}\n\\mu \\sim \\textrm{Normal}\\left(\\frac{\\phi_0\\mu_0 + n\\phi\\bar{y}}{\\phi_0 + n\\phi}, \\sqrt{\\frac{1}{\\phi_0 + n\\phi}}\\right).\n\\end{eqnarray}\\]\nSample \\(\\tilde Y_1, ..., \\tilde Y_{20}\\) from the data model \\[\\begin{eqnarray}\n\\tilde{Y} \\sim \\textrm{Normal}(\\mu, \\sigma).\n\\end{eqnarray}\\]\n\nThis method is implemented in the following R script to simulate 1000 replicated samples from the posterior predictive distribution. The vector pred_mu_sim contains draws from the posterior distribution and the matrix ytilde contains the simulated predictions where each row of the matrix is a simulated sample of 20 future times.\n\n\n\n\nsigma <- 4\nmu_n <- 17.4\nsigma_n <- 0.77\nS <- 1000\npred_mu_sim <- rnorm(S, mu_n, sigma_n)\nsim_ytilde <- function(j){\n  rnorm(20, pred_mu_sim[j], sigma)\n}\nytilde <- t(sapply(1:S, sim_ytilde))\n\nTo judge goodness of fit, we wish to compare these simulated replicated datasets from the posterior predictive distribution with the observed data. One convenient way to implement this comparison is to compute some “testing function”, \\(T(\\tilde y)\\), on each replicated dataset. If we have 1000 replicated datasets, one has 1000 values of the testing function. One constructs a graph of these values and overlays the value of the testing function on the observed data \\(T(y)\\). If the observed value is in the tail of the posterior predictive distribution of \\(T(\\tilde y)\\), this indicates some misfit of the observed data with the Bayesian model.\nTo implement this procedure, one needs to choose a testing function \\(T(\\tilde y)\\). Suppose, for example, one decides to use the sample mean \\(T(\\tilde y) = \\sum \\tilde y_j / 20\\). In the R script, we compute the sample mean on each row of the simulated prediction matrix.\n\npred_ybar_sim <- apply(ytilde, 1, mean)\n\nFigure 8.8 displays a density estimate of the simulated values from the posterior predictive distribution of \\(\\bar Y\\) and the observed value of the sample mean \\(\\bar Y = 17.20\\) is displayed as a vertical line. Since this observed mean is in the middle of this distribution, one concludes that this observation is consistent with samples predicted from the Bayesian model. It should be noted that this conclusion about model fit is sensitive to the choice of checking function \\(T()\\). In the end-of-chapter exercises, the reader will explore the suitability of this model using alternative choices for the checking function.\n\n\n\n\n\nDisplay of the posterior predictive mean time-to-serve for twenty observations. The observed mean time-to-serve value is displayed by a vertical line."
  },
  {
    "objectID": "mean.html#modeling-count-data",
    "href": "mean.html#modeling-count-data",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.8 Modeling Count Data",
    "text": "3.8 Modeling Count Data\nTo further illustrate the Bayesian approach to inference for measurements, consider Poisson sampling, a popular model for count data. One assumes that one observes a random sample from a Poisson distribution with an unknown rate parameter \\(\\lambda\\). The conjugate prior for the Poisson mean is the Gamma distribution. This scenario provides further practice in various Bayesian computations, such as computing the likelihood function and posterior distribution, and obtaining the predictive distribution to learn about future data. In this section, we focus on the main results and the detailed derivations are left as end-of-chapter exercises.\n\n3.8.1 Examples\nCounts of patients in an emergency room\nA hospital wants to determine how many doctors and nurses to assign on their emergency room (ER) team between 10pm and 11pm during the week. An important piece of information is the count of patients arriving in the ER in this one-hour period.\nFor a count measurement variable such as the count of patients, a popular sampling model is the Poisson distribution. This distribution is used to model the number of times an event occurs in an interval of time or space. In the current example, the event is a patient’s arrival to the ER, and the time interval is the period between 10pm and 11pm. The hospital wishes to learn about the average count of patients arriving to the ER each hour. Perhaps more importantly, the hospital wants to predict the patient count since that will directly address the scheduling of doctors and nurses question.\nCounts of visitors to a website\nAs a second example, suppose one is interested in monitoring the popularity of a particular blog focusing on baseball analytics. Table 8.7 displays the number of visitors viewing this blog for 28 days during June of 2019. In this setting, the event of interest is a visit to the blog website and the time interval is a single day. The blog author is particularly interested in learning about the average number of visitors during the days Monday through Friday and predicting the number of visits for a future day in the summer of 2019.\nTable 8.7. Number of visitors to a baseball blog site during different days during June, 2019.\n\n\n\n\nFri\nSat\nSun\nMon\nTue\nWed\nThu\n\n\n\n\nWeek 1\n95\n81\n85\n100\n111\n130\n113\n\n\nWeek 2\n92\n65\n78\n96\n118\n120\n104\n\n\nWeek 3\n91\n91\n79\n106\n91\n114\n110\n\n\nWeek 4\n98\n61\n84\n96\n126\n119\n90\n\n\n\nCount of visitors to blog during 28 days during June 2019.\n\n\n3.8.2 The Poisson distribution\n Let the random variable \\(Y\\) denote the number of occurrences of an event in an interval with sample space \\(\\{0, 1, 2, \\cdots \\}\\). In contrast to the Normally distributed continuous measurement, note that \\(Y\\) only takes integer values from 0 to infinity. The variable \\(Y\\) follows a Poisson distribution with rate parameter \\(\\lambda\\) when the probability mass function (pmf) of observing \\(y\\) events in an interval is given by\n\\[\\begin{eqnarray}\nf(Y = y \\mid \\lambda) = e^{-\\lambda}\\frac{\\lambda^y}{y!}, \\, \\, y = 0, 1, 2, ...\n\\end{eqnarray}\\] where \\(\\lambda\\) is the average number of events per interval, \\(e = 2.71828...\\) is Euler’s number, and \\(y!\\) is the factorial of \\(y\\).\nThe Poisson sampling model is based on several assumptions about the sampling process. One assumes that the time interval is fixed, counts of arrivals occurring during different time intervals are independent, and the rate \\(\\lambda\\) at which the arrivals occur is constant over time. To check the suitability of the Poisson distribution for the examples, one needs to check the conditions one by one.\n\nThe time interval is fixed in the ER example as we observe patient arrivals during a one hour period between 10pm and 11pm. For the blog visits example, the fixed time period is one day.\nIn both examples, one assumes that events occur independently during different time intervals. In the ER example it is reasonable to assume that the time of one patient’s arrival does not influence the time of another patient’s arrival. For the website visits example, if different people are visiting the website on different days, then one could assume the number of visits on one day would be independent of the number of visits on another day.\nIs it reasonable to assume the rate \\(\\lambda\\) at which events occur is constant through the time interval? In the ER example, one might not think that the rate of patient arrivals would change much through one hour during the evening, so it seems reasonable to assume that the average number of events is constant in the fixed interval. Similarly, if one focuses on weekdays, then for the website visits example, it is reasonable to assume that the average number of visits remains constant across days.\n\nIn some situations, the second and third conditions will be violated. In our ER example, the occurrence of serious accidents may bring multiple groups of patients to the ER at certain time intervals. In this case, arrival times of patients may not be independent and the arrival rate \\(\\lambda\\) in one subinterval will be higher than the arrival rate of another subinterval. When such situations occur, one needs to decide about the severity of the violation of the conditions and possibly use an alternative sampling model instead of the Poisson.\nAs evident in Equation (8.35), the Poisson distribution has only one parameter, the rate parameter \\(\\lambda\\), so the Poisson sampling model belongs to the family of one-parameter sampling models. The Binomial data model with success probability \\(p\\) and the Normal data model with mean parameter \\(\\mu\\) (with known standard deviation) are two other examples of one-parameter models. One distinguishes these models by the type of possible sample values, discrete or continuous. The Binomial random variable is the number of successes and the Poisson random variable is a count of arrivals, so they both are discrete one-parameter models. In contrast, the Normal sampling data model is a continuous one-parameter model.\n\n\n3.8.3 Bayesian inferences\n The reader should be familiar with the typical procedure of Bayesian inference and prediction for one-parameter models. We rewrite this procedure in the context of the Poisson sampling model.\n\n[Step 1] One constructs a prior expressing an opinion about the location of the rate \\(\\lambda\\) before any data is collected.\n[Step 2] One takes the sample of intervals and records the number of arrivals in each interval. From this data, one forms the likelihood, the probability of these observations expressed as a function of \\(\\lambda\\).\n[Step 3] One uses Bayes’ rule to compute the posterior – this distribution updates the prior opinion about \\(\\lambda\\) given the information from the data.\nIn addition, one computes the predictive distribution to learn about the number of arrivals in future intervals. The posterior predictive distribution is also useful in checking the appropriateness of our model.\n\nGamma prior distribution\nOne begins by constructing a prior density to express one’s opinion about the rate parameter \\(\\lambda\\). Since the rate is a positive continuous parameter, one needs to construct a prior density that places its support only on positive values. The convenient choice of prior distributions for Poisson sampling is the Gamma distribution which has a density function given by \\[\\begin{eqnarray}\n\\pi(\\lambda \\mid \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma{(\\alpha)}} \\lambda^{\\alpha-1}e^{-\\beta \\lambda}, \\,\\,\\, \\text{for}\\,\\, \\lambda > 0, \\,\\, \\text{and}\\,\\,  \\alpha, \\beta > 0,\n\\end{eqnarray}\\] where \\(\\Gamma(\\alpha)\\) is the Gamma function evaluated at \\(\\alpha\\). The Gamma density is a continuous density where the support is on positive values. It depends on two parameters, a positive shape parameter \\(\\alpha\\) and a positive rate parameter \\(\\beta\\).\nThe Gamma density is a flexible family of distributions that can reflect many different types of prior beliefs about the location of the parameter \\(\\lambda\\). One chooses values of the shape \\(\\alpha\\) and the rate \\(\\beta\\) so that the Gamma density matches one’s prior information about the location of \\(\\lambda\\). In R, the function dgamma() gives the density, pgamma() gives the distribution function and qgamma() gives the quantile function for the Gamma distribution. These functions are helpful in graphing the prior and choosing values of the shape and rate parameters that match prior statements about Gamma percentiles and probabilities. We provide an illustration of choosing a subjective Gamma prior in the example.\nSampling and the likelihood\nSuppose that \\(Y_1, ..., Y_n\\) represent the observed counts in \\(n\\) time intervals where the counts are independent and each \\(Y_i\\) follows a Poisson distribution with rate \\(\\lambda\\). The joint mass function of \\(Y_1, ..., Y_n\\) is obtained by multiplying the Poisson densities. \\[\\begin{eqnarray}\nf(Y_1 = y_1, ... ,  Y_n = y_n \\mid \\lambda ) &=& \\prod_{i=1}^{n}f(y_i \\mid \\lambda) \\nonumber \\\\\n                                       &\\propto& \\lambda^{\\sum_{i=1}^{n}y_i} e^{-n\\lambda}.   \n\\end{eqnarray}\\] Once the counts \\(y_1, ..., y_n\\) are observed, the likelihood of \\(\\lambda\\) is the joint probability of observing this data, viewed as a function of the rate parameter \\(\\lambda\\). \\[\\begin{equation}\nL(\\lambda) = \\lambda^{\\sum_{i=1}^{n}y_i} e^{-n\\lambda}.\n\\end{equation}\\]\nIf the rate parameter \\(\\lambda\\) in the Poisson sampling model follows a Gamma prior distribution, then it turns out that the posterior distribution for \\(\\lambda\\) will also have a Gamma density with updated parameters. This demonstrates that the Gamma density is the conjugate distribution for Poisson sampling as the prior and posterior densities both come from the same family of distribution: Gamma.\nWe begin by assuming that the Poisson parameter \\(\\lambda\\) has a Gamma distribution with shape and rate parameters \\(\\alpha\\) and \\(\\beta\\), that is, \\(\\lambda \\sim\\) Gamma\\((\\alpha, \\beta)\\). If one multiplies the Gamma prior by the likelihood function \\(L(\\lambda)\\), then in an end-of-chapter exercise you will show that the posterior density of \\(\\lambda\\) is Gamma\\((\\alpha_n, \\beta_n)\\), where the updated parameters \\(\\alpha_n\\) and \\(\\beta_n\\) are given by \\[\\begin{equation}\n\\alpha_n = \\alpha + \\sum_{i=1}^n y_i, \\, \\, \\, \\beta_n = \\beta + n.\n\\end{equation}\\]\nInference about \\(\\lambda\\)\nOnce the posterior distribution has been derived, then all inferences about the Poisson parameter \\(\\lambda\\) are performed by computing particular summaries of the Gamma posterior distribution. In particular, one may be interested in testing if \\(\\lambda\\) falls in a particular region by computing a posterior probability. All of these computations are facilitated using the pgamma(), qgamma(), and rgamma() functions. Or one may be interested in constructing an interval estimate for \\(\\lambda\\). In the end-of-chapter exercises, there are opportunities to perform these inferences using a dataset containing a sample of ER arrival counts.\nPrediction of future data\nOne advantage of using a conjugate prior is that the predictive density for a future observation \\(\\tilde Y\\) is available in closed form. Suppose \\(\\lambda\\) is assigned a \\(\\textrm{Gamma}(\\alpha, \\beta\\)) prior. Then the prior predictive density of \\(\\tilde Y\\) is given by \\[\\begin{eqnarray}\nf(\\tilde{Y} = \\tilde y)  &=& \\int f(\\tilde{Y} = \\tilde{y} \\mid \\lambda) \\pi(\\lambda) \\lambda  \\nonumber \\\\\n& =& \\int \\frac{e^{-\\lambda} \\lambda^{\\tilde y}} {\\tilde y!}  \n\\frac{\\beta^{\\alpha}}{\\Gamma{(\\alpha)}} \\lambda^{\\alpha-1}e^{-\\beta \\lambda} d \\lambda  \\nonumber \\\\\n&=& \\frac{\\Gamma(\\alpha + \\tilde y)}{\\Gamma(\\alpha)}\n\\frac{\\beta^\\alpha}{(\\beta + 1)^{\\tilde y + \\alpha}}.\n\\end{eqnarray}\\]\nIn addition, the posterior distribution of \\(\\lambda\\) also has the Gamma form with updated parameters \\(\\alpha_n\\) and \\(\\beta_n\\). So Equation (8.40) also provides the posterior predictive distribution for a future count \\(\\tilde Y\\) using the updated parameter values.\nFor prediction purposes, there are several ways of summarizing the predictive distribution. One can use the formula in Equation (8.40) to directly compute \\(f(\\tilde Y)\\) for a list of values of \\(\\tilde Y\\) and then one uses the computed probabilities to form a prediction interval for \\(\\tilde Y\\). Alternately, one simulates values of \\(\\tilde Y\\) in a two-step process. For example, if one wants to simulate a draw from the posterior predictive distribution, one would first simulate a value \\(\\lambda\\) from its posterior distribution, and given that simulated draw \\(\\lambda^*\\), simulate \\(\\tilde Y\\) from a Poisson distribution with mean \\(\\lambda^*\\). Repeating this process for a large number of iterations provides a sample from the posterior prediction distribution that one uses to construct a prediction interval.\n\n\n3.8.4 Case study: Learning about website counts\nLet’s return to the website example where one is interested in learning about the average weekday visits to a baseball analytics blog site. One observes the counts \\(y_1, ..., y_{20}\\) displayed in the “Mon”, “Tue”, “Wed”, “Thu”, “Fri” columns of Table 8.7. We assume the {\\(y_i\\)} represent a random sample from a Poisson distribution with mean parameter \\(\\lambda\\).\nSuppose one’s prior guess at the value of \\(\\lambda\\) is 80 and one wishes to match this information with a Gamma(\\(\\alpha, \\beta\\)) prior. Two helpful facts about the Gamma distribution are that the mean and variance are equal to \\(\\mu = \\alpha / \\beta\\) and \\(\\sigma^2 =\\alpha / \\beta^2 = \\mu / \\beta,\\) respectively. Figure 8.9 displays three Gamma curves for values \\((\\alpha, \\beta\\)) = (80, 1), (40, 0.5), and (20, 0.25). Each of these Gamma curves have a mean of 80 and the curves become more diffuse as the parameter \\(\\beta\\) moves from 1 to 0.25. After some thought, the user believes that the Gamma(80, 1) matches her prior beliefs. To check, she computes a prior probability interval. Using the qgamma() function, she finds that her 90% prior probability interval is \\(Prob(65.9 < \\lambda < 95.3) = 0.90\\) and this appears to be a reasonable approximation to her prior beliefs.\n\n\n\n\n\nThree Gamma(\\(\\alpha, \\beta\\)) plausible prior distributions for the average number of weekday visits to the website.\n\n\n\n\nFrom the data, we compute \\(\\sum_{i=1}^{20} y_i = 2120\\) and the sample size is \\(n = 20\\). The posterior distribution is Gamma(\\(\\alpha_n, \\beta_n)\\) where the updated parameters are \\[\\begin{equation*}\n\\alpha_n = 80 + 2120 = 2200, \\, \\, \\beta_n = 1 + 20 = 21.\n\\end{equation*}\\] Figure 8.10 displays the Gamma posterior curve for \\(\\lambda\\). This figure displays a 90% probability interval which is found using the qgamma() function to be (101.1, 108.5). The interpretation is that the average number of visits lies between 101.1 and 108.5 with probability 0.90.\n\n\n\n\n\nPosterior curve for the mean number of visits \\(\\lambda\\) to the website. The shaded region shows the limits of a 90% interval estimate.\n\n\n\n\nSuppose the user is interested in predicting the number of blog visits \\(\\tilde Y\\) at a future summer weekday. One simulates the posterior predictive distribution by first simulating 1000 values from the Gamma posterior, and then simulating values of \\(\\tilde Y\\) from Poisson distributions where the Poisson means come from the posterior. Figure 8.11 displays a histogram of the simulated values from the predictive distribution. The 5th and 95th quantiles of this distribution are computed to be 88 and 123 – there is a 90% probability that that the number of visitors in a future weekday will fall in the interval (88, 123).\n\n\n    5%    95% \n 88.95 123.00 \n\n\n\n\n\nHistogram of a simulated sample from the posterior predictive distribution of the number of visitors to the website on a future day."
  },
  {
    "objectID": "mcmc.html",
    "href": "mcmc.html",
    "title": "4  Simulation by Markov Chain Monte Carlo",
    "section": "",
    "text": "The Bayesian models in Chapters 7 and 8 describe the application of conjugate priors where the prior and posterior belong to the same family of distributions. In these cases, the posterior distribution has a convenient functional form such as a Beta density or Normal density, and the posterior distributions are easy to summarize. For example, if the posterior density has a Normal form, one uses the R functions pnorm() and qnorm() to compute posterior probabilities and quantiles.\nIn a general Bayesian problem, the data \\(Y\\) comes from a sampling density \\(f(y \\mid \\theta)\\) and the parameter \\(\\theta\\) is assigned a prior density \\(\\pi(\\theta)\\). After \\(Y = y\\) has been observed, the likelihood function is equal to \\(L(\\theta) = f(y \\mid \\theta)\\) and the posterior density is written as \\[\\begin{equation}\n\\pi(\\theta \\mid y) = \\frac{\\pi(\\theta) L(\\theta)}\n{\\int \\pi(\\theta) L(\\theta) d\\theta}.\n\\end{equation}\\] If the prior and likelihood function do not combine in a helpful way, the normalizing constant \\(\\int \\pi(\\theta) L(\\theta) d\\theta\\) can not be evaluated analytically. In addition, summaries of the posterior distribution are expressed as ratios of integrals. For example, the posterior mean of \\(\\theta\\) is given by \\[\\begin{equation}\nE(\\theta \\mid y) = \\frac{\\int \\theta \\pi(\\theta) L(\\theta) d\\theta}\n{\\int \\pi(\\theta) L(\\theta) d\\theta}.\n\\end{equation}\\] Computation of the posterior mean requires the evaluation of two integrals, each not expressible in closed-form.\nThe following sections illustrate this general problem where integrals of the product of the likelihood and prior can not be evaluated analytically and so there are challenges in summarizing the posterior distribution.\n\n\n\n\nSuppose you are planning to move to Buffalo, New York. You currently live on the west coast of the United States where the weather is warm and you are wondering about the snowfall you will encounter in Buffalo in the following winter season.\nSuppose you focus on the quantity \\(\\mu\\), the average snowfall during the month of January. After some reflection, you are 50 percent confident that \\(\\mu\\) falls between 8 and 12 inches. That is, the 25th percentile of your prior for \\(\\mu\\) is 8 inches and the 75th percentile is 12 inches.\nA Normal prior\nOnce you have figured out your prior information, you construct a prior density for \\(\\mu\\) that matches this information. In one of the end-of-chapter exercises, you can confirm that one possible density matching this information is a Normal density with mean 10 and standard deviation 3.\nWe collect data for the last 20 seasons in January. Assume that these observations of January snowfall are Normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). For simplicity we assume that the sampling standard deviation \\(\\sigma\\) is equal to the observed standard deviation \\(s\\). The observed sample mean \\(\\bar y\\) and corresponding standard error are given by \\(\\bar y = 26.785\\) and \\(se = s / \\sqrt{n} = 3.236\\).\nWith this Normal prior and Normal sampling, results from Chapter 8 are applied to find the posterior distribution of \\(\\mu\\).\nThe normal_update() function is used to find the mean and standard deviation of the Normal posterior distribution.\n(post1 <- normal_update(c(10, 3), c(ybar, se)))\n[1] 17.75676  2.20020\nIn Figure 9.1 the prior, likelihood, and posterior are displayed on the same graph. Initially you believed that \\(\\mu\\) was close to 10 inches, the data says that the mean is in the neighborhood of 26.75 inches, and the posterior is a compromise, where \\(\\mu\\) is in an interval about 17.75 inches.\n\n\n\n\n\nPrior, likelihood, and posterior of a Normal mean with a Normal prior.\n\n\n\n\nAn alternative prior\nLooking at Figure 9.1, there is some concern about this particular Bayesian analysis. Since the main probability contents of the prior and likelihood functions have little overlap, there is serious conflict between the information in your prior and the information from the data.\nSince we have a prior-data conflict, it would make sense to revisit our choice for a prior density on \\(\\mu\\). Remember you specified the quartiles for \\(\\mu\\) to be 8 and 12 inches. Another symmetric density that matches this information is a Cauchy density with location 10 inches and scale parameter 2 inches. The reader can confirm that the quantiles of a Cauchy(10, 2) do match your prior information. [Hint: use the qcauchy() R command.]\nIn Figure 9.2 we compare the Normal and Cauchy priors graphically. Remember these two densities have the same quartiles at 8 and 12 inches. But the two priors have different shapes – the Cauchy prior is more peaked near the median value 10 and has tails that decrease to zero at a slower rate than the Normal. In other words, the Cauchy curve has flatter tails than the Normal curve.\n\n\n\n\n\nTwo priors for representing prior opinion about a Normal mean.\n\n\n\n\nWith the use of a \\(\\textrm{Cauchy}(10, 2)\\) prior and the same Normal likelihood, the posterior density of \\(\\mu\\) is\n\\[\\begin{equation}\n\\pi(\\mu \\mid y) \\propto  \\pi(\\mu)L(\\mu) \\propto  \n\\frac{1}{1 + \\left(\\frac{\\mu - 10}{2}\\right)^2} \\times \\exp\\left\\{-\\frac{n}{2 \\sigma^2}(\\bar y - \\mu)^2\\right\\}.\n\\end{equation}\\]\nIn contrast with a Normal prior, one can not algebraically simplify this likelihood times prior product to obtain a “nice” functional expression for the posterior density in terms of the mean \\(\\mu\\). That raises the question – how does one implement a Bayesian analysis when one can not easily express the posterior density in a convenient functional form?\n\n\n\n\nIn the problem in learning about a Normal mean \\(\\mu\\) in Chapter 8, it was assumed that the sampling standard deviation \\(\\sigma\\) was known. This is unrealistic – in most settings, if one is uncertain about the mean of the population, then likely the population standard deviation will also be unknown. From a Bayesian perspective, since we have two unknown parameters \\(\\mu\\) and \\(\\sigma\\), this situation presents new challenges. One needs to construct a joint prior \\(\\pi(\\mu, \\sigma)\\) for the two parameters – up to this point, we have only discussed constructing a prior distribution for a single parameter. Also, although one can compute the posterior density by the usual “prior times likelihood” recipe, it may be difficult to get nice analytic answers with this posterior to obtain particular inferences of interest.\n\n\n\n\nIn Chapters 7 and 8, we illustrated the use of simulation to summarize posterior distributions of a specific functional form such as the Beta and Normal. In this chapter, we introduce a general class of algorithms, collectively called Markov chain Monte Carlo (MCMC), that can be used to simulate the posterior from general Bayesian models. These algorithms are based on a general probability model called a Markov chain and Section 9.2 describes this probability model for situations where the possible models are finite. Section 9.3 introduces the Metropolis sampler, a general algorithm for simulating from an arbitrary posterior distribution. Section 9.4 describes the implementation of this simulation algorithm for the Normal sampling problem with a Cauchy prior. Section 9.5 introduces another MCMC simulation algorithm, Gibbs sampling, that is well-suited for simulation from posterior distributions of many parameters. One issue in the implementation of these MCMC algorithms is that the simulation draws represent an approximate sample from the posterior distribution. Section 9.6 describes some common diagnostic methods for seeing if the simulated sample is a suitable exploration of the posterior distribution. Finally in Section 9.7, we describe the use of a general-purpose software program Just Another Gibbs Sampler (JAGS) and R interface for implementing these MCMC algorithms."
  },
  {
    "objectID": "mcmc.html#markov-chains",
    "href": "mcmc.html#markov-chains",
    "title": "4  Simulation by Markov Chain Monte Carlo",
    "section": "4.2 Markov Chains",
    "text": "4.2 Markov Chains\n\n\n4.2.1 Definition\n\nSince our simulation algorithms are based on Markov chains, we begin by defining this class of probability models in the situation where the possible outcomes are finite. Suppose a person takes a random walk on a number line on the values 1, 2, 3, 4, 5, 6. If the person is currently at an interior value (2, 3, 4, or 5), in the next second she is equally likely to remain at that number or move to an adjacent number. If she does move, she is equally likely to move left or right. If the person is currently at one of the end values (1 or 6), in the next second she is equally likely to stay still or move to the adjacent location.\nThis is a simple example of a discrete Markov chain. A Markov chain describes probabilistic movement between a number of states. Here there are six possible states, 1 through 6, corresponding to the possible locations of the walker. Given that the person is at a current location, she moves to other locations with specified probabilities. The probability that she moves to another location depends only on her current location and not on previous locations visited. We describe movement between states in terms of transition probabilities – they describe the likelihoods of moving between all possible states in a single step in a Markov chain. We summarize the transition probabilities by means of a transition matrix \\(P\\): \\[\nP = \\begin{bmatrix}\n.50 &.50& 0& 0& 0& 0 \\\\\n.25 &.50& .25& 0& 0& 0\\\\\n0 &.25& .50& .25& 0& 0\\\\\n0 &0& .25& .50& .25& 0\\\\\n0 &0& 0& .25& .50& .25\\\\\n0 &0& 0& 0& .50& .50\\\\\n\\end{bmatrix}\n\\] The first row in \\(P\\) gives the probabilities of moving to all states 1 through 6 in a single step from location 1, the second row gives the transition probabilities in a single step from location 2, and so on.\nThere are several important properties of this particular Markov chain. It is possible to go from every state to every state in one or more steps – a Markov chain with this property is said to be irreducible. Given that the person is in a particular state, if the person can only return to this state at regular intervals, then the Markov chain is said to be periodic. This example is aperiodic since the walker cannot return to the current state at regular intervals.\n\n\n4.2.2 Some properties\n\nWe represent one’s current location as a probability row vector of the form \\[\\begin{equation*}\np = (p_1, p_2, p_3, p_4, p_5, p_6),\n\\end{equation*}\\] where \\(p_i\\) represents the probability that the person is currently in state \\(i\\). If \\(p^{(j)}\\) represents the location of the traveler at step \\(j\\), then the location of the traveler at the \\(j + 1\\) step is given by the matrix product \\[\\begin{equation*}\np^{(j+1)} = p^{(j)} P.\n\\end{equation*}\\] Moreover, if \\(p^{(j)}\\) represents the location at step \\(j\\), then the location of the traveler after \\(m\\) additional steps, \\(p^{(j+m)}\\), is given by the matrix product \\[\\begin{equation*}\np^{(j+m)} = p^{(j)} P^m,\n\\end{equation*}\\] where \\(P^m\\) indicates the matrix multiplication \\(P \\times P \\times ... \\times P\\) (the matrix \\(P\\) multiplied by itself \\(m\\) times).\nTo illustrate for our example using R, suppose that the person begins at state 3 that is represented in R by the vector p with a 1 in the third entry:\n\np <- c(0, 0, 1, 0, 0, 0)\n\nWe also define the transition matrix by use of the matrix() function.\n\nP <- matrix(c(.5, .5, 0, 0, 0, 0,\n              .25, .5, .25, 0, 0, 0,\n              0, .25, .5, .25, 0, 0,\n              0, 0, .25, .5, .25, 0,\n              0, 0, 0, .25, .5, .25,\n              0, 0, 0, 0, .5, .5),\n              nrow=6, ncol=6, byrow=TRUE)\n\nIf one multiplies this vector by the matrix P, one obtains the probabilities of being in all six states after one move.\n\nprint(p %*% P, digits = 5)\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    0 0.25  0.5 0.25    0    0\n\n\nAfter one move (starting at state 3), our walker will be at states 2, 3, and 4 with respective probabilities 0.25, 0.5, and 0.25. If one multiplies p by the matrix P four times, one obtains the probabilities of being in the different states after four moves.\n\nprint(p %*% P %*% P %*% P %*% P, digits = 5)\n\n        [,1] [,2]    [,3]    [,4]    [,5]    [,6]\n[1,] 0.10938 0.25 0.27734 0.21875 0.11328 0.03125\n\n\nStarting from state 3, this particular person is most likely will be in states 2, 3, and 4 after four moves.\nFor an irreducible, aperiodic Markov chain, there is a limiting behavior of the matrix power \\(P^m\\) as \\(m\\) approaches infinity. Specifically, this limit is equal to \\[\\begin{equation}\nW = \\lim_{m \\rightarrow \\infty} P^m,\n\\end{equation}\\] where \\(W\\) has common rows equal to \\(w\\). The implication of this result is that, as one takes an infinite number of moves, the probability of landing at a particular state does not depend on the initial starting state.\nOne can demonstrate this result empirically for our example. Using a loop, we take the transition matrix \\(P\\) to the 100th power by repeatedly multiplying the transition matrix by itself. From this calculation below, note that the rows of the matrix Pm appear to be approaching a constant vector. Specifically, it appears the constant vector \\(w\\) is equal to (0.1, 0.2, 0.2, 0.2, 0.2, 0.1).\n\nPm <- diag(rep(1, 6))\nfor(j in 1:100){\n  Pm <- Pm %*% P\n}\nprint(Pm, digits = 5)\n\n         [,1]    [,2]    [,3]    [,4]    [,5]     [,6]\n[1,] 0.100009 0.20001 0.20001 0.19999 0.19999 0.099991\n[2,] 0.100007 0.20001 0.20000 0.20000 0.19999 0.099993\n[3,] 0.100003 0.20000 0.20000 0.20000 0.20000 0.099997\n[4,] 0.099997 0.20000 0.20000 0.20000 0.20000 0.100003\n[5,] 0.099993 0.19999 0.20000 0.20000 0.20001 0.100007\n[6,] 0.099991 0.19999 0.19999 0.20001 0.20001 0.100009\n\n\nFrom this result about the limiting behavior of the matrix power \\(P^m\\), one can derive a rule for determining this constant vector. Suppose we can find a probability vector \\(w\\) such that \\(wP = w\\). This vector \\(w\\) is said to be the stationary distribution. If a Markov chain is irreducible and aperiodic, then it has a unique stationary distribution. Moreover, as illustrated above, the limiting distribution of this Markov chain, as the number of steps approaches infinity, will be equal to this stationary distribution.\n\n\n4.2.3 Simulating a Markov chain\n\nAnother method for demonstrating the existence of the stationary distribution of our Markov chain by running a simulation experiment. We start our random walk at a particular state, say location 3, and then simulate many steps of the Markov chain using the transition matrix \\(P\\). The relative frequencies of our traveler in the six locations after many steps will eventually approach the stationary distribution \\(w\\).\nIn R we have already defined the transition matrix P. To begin the simulation exercise, we set up a storage vector s for the locations of our traveler in the random walk. We indicate that the starting location for our traveler is state 3 and perform a loop to simulate 10,000 draws from the Markov chain. We use the sample() function to simulate one step – the arguments to this function indicate that we are sampling a single value from the set {1, 2, 3, 4, 5, 6} with probabilities given by the \\(s_j^1\\) row of the transition matrix \\(P\\), where \\(s_j^1\\) is the current location of our traveler.\n\ns <- vector(\"numeric\", 10000)\ns[1] <- 3\nfor (j in 2:10000)\ns[j] <- sample(1:6, size=1, prob=P[s[j - 1], ])\n\nSuppose that we record the relative frequencies of each of the outcomes 1, 2, …, 6 after each iteration of the simulation. Figure 9.3 graphs the relative frequencies of each of the outcomes as a function of the iteration number.\n\n\n\n\n\nRelative frequencies of the states 1 through 6 as a function of the number of iterations for Markov chain simulation. As the number of iterations increases, the relative frequencies appear to approach the probabilities in the stationary distribution \\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1)\\).\n\n\n\n\nIt appears from Figure 9.3 that the relative frequencies of the states are converging to the stationary distribution \\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1).\\) One confirms that this specific vector \\(w\\) is indeed the stationary distribution of this chain by multiplying \\(w\\) by the transition matrix \\(P\\) and noticing that the product is equal to \\(w\\).\n\nw <- matrix(c(.1,.2,.2,.2,.2,.1), nrow=1, ncol=6)\n w %*% P\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]  0.1  0.2  0.2  0.2  0.2  0.1"
  },
  {
    "objectID": "mcmc.html#the-metropolis-algorithm",
    "href": "mcmc.html#the-metropolis-algorithm",
    "title": "4  Simulation by Markov Chain Monte Carlo",
    "section": "4.3 The Metropolis Algorithm",
    "text": "4.3 The Metropolis Algorithm\n\n\n4.3.1 Example: Walking on a number line\n\nMarkov chains can be used to sample from an arbitrary probability distribution. To introduce a general Markov chain sampling algorithm, we illustrate sampling from a discrete distribution. Suppose one defines a discrete probability distribution on the integers 1, …, \\(K\\).\nAs an example, we write a short function pd() in R taking on the values 1, …, 8 with probabilities proportional to the values 5, 10, 4, 4, 20, 20, 12, and 5. Note that these probabilities don’t sum to one, but we will shortly see that only the relative sizes of these values are relevant in this algorithm. A line graph of this probability distribution is displayed in Figure 9.4.\npd <- function(x){\n  values <- c(5, 10, 4, 4, 20, 20, 12, 5)\n  ifelse(x %in% 1:length(values), values[x], 0)\n}\nprob_dist <- data.frame(x = 1:8, \n                        prob = pd(1:8))\n\n\n\n\n\nA discrete probability distribution on the values 1, …, 8.\n\n\n\n\nTo simulate from this probability distribution, we will take a simple random walk described as follows.\n\nWe start at any possible location of our random variable from 1 to \\(K = 8\\).\nTo decide where to visit next, a fair coin is flipped. If the coin lands heads, we think about visiting the location one value to the left, and if coin lands tails, we consider visiting the location one value to right. We call this location the “candidate” location.\nWe compute \\[\\begin{equation}\nR = \\frac{pd(candidate)}{pd(current)},\n\\end{equation}\\] the ratio of the probabilities at the candidate and current locations.\nWe spin a continuous spinner that lands anywhere from 0 to 1 – call the random spin \\(X\\). If \\(X\\) is smaller than \\(R\\), we move to the candidate location, and otherwise we remain at the current location.\n\nSteps 1 through 4 define an irreducible, aperiodic Markov chain on the state values {1, 2, …, 8} where Step 1 gives the starting location and the transition matrix \\(P\\) is defined by Steps 2 through 4. One way of “discovering” the discrete probability distribution \\(pd\\) is by starting at any location and walking through the distribution many times repeating Steps 2, 3, and 4 (propose a candidate location, compute the ratio, and decide whether to visit the candidate location). If this process is repeated for a large number of steps, the distribution of our actual visits should approximate the probability distribution \\(pd\\).\nA R function random_walk() is written implementing this random walk algorithm. There are three inputs to this function, the probability distribution pd, the starting location start and the number of steps of the algorithm s.\nrandom_walk <- function(pd, start, num_steps){\n  y <- rep(0, num_steps)\n  current <- start\n  for (j in 1:num_steps){\n    candidate <- current + sample(c(-1, 1), 1)\n    prob <- pd(candidate) / pd(current)\n    if (runif(1) < prob) current <- candidate\n    y[j] <- current\n  }\n  return(y)\n}\nWe have already defined the probability distribution by use of the function pd(). Below, we implement the random walk algorithm by inputting this probability function, starting at the value \\(X = 4\\) and running the algorithm for \\(s\\) = 10,000 iterations.\nout <- random_walk(pd, 4, 10000)\ndata.frame(out) %>% group_by(out) %>% \n  summarize(N = n(), Prob = N / 10000) -> S\nIn Figure 9.5 a histogram of the simulated values from the random walk is compared with the actual probability distribution. Note that the collection of simulated draws appears to be a close match to the true probabilities.\n\n\n\n\n\nHistogram of simulated draws from the random walk compared with the actual probabilities of the distribution.\n\n\n\n\n\n\n4.3.2 The general algorithm\n\nA popular way of simulating from a general continuous posterior distribution is by using a generalization of the discrete Markov chain setup described in the random walk example in the previous section. The Markov chain Monte Carlo sampling strategy sets up an irreducible, aperiodic Markov chain for which the stationary distribution equals the posterior distribution of interest. This method, called the Metropolis algorithm, is applicable to a wide range of Bayesian inference problems.\nHere the Metropolis algorithm is presented and illustrated. This algorithm is a special case of the Metropolis-Hastings algorithm, where the proposal distribution is symmetric (e.g. Uniform or Normal).\nSuppose the posterior density is written as \\[\\begin{equation*}\n\\pi_n(\\theta) \\propto  \\pi(\\theta) L(\\theta),\n\\end{equation*}\\] where \\(\\pi(\\theta)\\) is the prior and \\(L(\\theta)\\) is the likelihood function. In this algorithm, it is not necessary to compute the normalizing constant – only the product of likelihood and prior is needed.\n\n(START) As in the random walk algorithm, we begin by selecting any \\(\\theta\\) value where the posterior density is positive – the value we select \\(\\theta^{(0)}\\) is the starting value.\n(PROPOSE) Given the current simulated value \\(\\theta^{(j)}\\) we propose a new value \\(\\theta^P\\) which is selected at random in the interval (\\(\\theta^{(j)} - C, \\theta^{(j)} + C)\\) where \\(C\\) is a preselected constant.\n(ACCEPTANCE PROBABILITY) One computes the ratio \\(R\\) of the posterior density at the proposed value and the current value: \\[\\begin{equation}\nR = \\frac{\\pi_n(\\theta^{P})}{\\pi_n(\\theta^{(j)})}.\n\\end{equation}\\] The acceptance probability is the minimum of \\(R\\) and 1: \\[\\begin{equation}\nPROB = \\min\\{R, 1\\}.\n\\end{equation}\\]\n(MOVE OR STAY?) One simulates a Uniform random variable \\(U\\). If \\(U\\) is smaller than the acceptance probability \\(PROB\\), one moves to the proposed value \\(\\theta^P\\); otherwise one stays at the current value \\(\\theta^{(j)}\\). In other words, the next simulated draw \\(\\theta^{(j+1)}\\) \\[\\begin{equation}\n\\theta^{(j+1)} =\n\\begin{cases}\n  \\theta^{p} & \\mbox{if} \\, \\, U < PROB, \\\\\n  \\theta^{(j)} & \\mbox{elsewhere}.\n\\end{cases}\n\\end{equation}\\]\n(CONTINUE) One continues by returning to Step 2 – propose a new simulated value, compute an acceptance probability, decide to move to the proposed value or stay, and so on.\n\nFigure 9.6 illustrates how the Metropolis algorithm works. The bell-shaped curve is the posterior density of interest. In the top-left panel, the solid dot represents the current simulated draw and the black bar represents the proposal region. One simulates the proposed value represented by the “P” symbol. One computes the probability of accepting this proposed value – in this case, this probability is 0.02. By simulating a Uniform draw, one decides not to accept this proposal and the new simulated draw is the current value shown in the top-right panel. A different scenario is shown in the bottom panels. One proposes a value corresponding to a higher posterior density value. The probability of accepting this proposal is 1 and the bottom left graph shows that the new simulated draw is the proposed value.\n\n\n\n\n\nIllustration of the Metropolis algorithm. The left graphs show the proposal region and two possible proposal values and the right graphs show the result of either accepting or rejecting the proposal.\n\n\n\n\n\n\n4.3.3 A general function for the Metropolis algorithm\n\nSince the Metropolis is a relatively simple algorithm, one writes a short function in R to implement this sampling for an arbitrary probability distribution.\nThe function metropolis() has five inputs: logpost is a function defining the logarithm of the density, current is the starting value, C defines the neighborhood where one looks for a proposal value, iter is the number of iterations of the algorithm, and ... denotes any data or parameters needed in the function logpost().\nmetropolis <- function(logpost, current, C, iter, ...){\n  S <- rep(0, iter) \n  n_accept <- 0\n  for(j in 1:iter){\n  candidate <- runif(1, min=current - C, \n                       max=current + C)\n  prob <- exp(logpost(candidate, ...) - \n             logpost(current, ...))\n  accept <- ifelse(runif(1) < prob, \"yes\", \"no\")\n  current <- ifelse(accept == \"yes\", \n                    candidate, current)\n  S[j] <- current\n  n_accept <- n_accept + (accept == \"yes\")\n  }\n  list(S=S, accept_rate=n_accept / iter)\n}"
  },
  {
    "objectID": "mcmc.html#example-cauchy-normal-problem",
    "href": "mcmc.html#example-cauchy-normal-problem",
    "title": "4  Simulation by Markov Chain Monte Carlo",
    "section": "4.4 Example: Cauchy-Normal problem",
    "text": "4.4 Example: Cauchy-Normal problem\n\nTo illustrate using the metropolis() function, suppose we wish to simulate 1000 values from the posterior distribution in our Buffalo snowfall problem where one uses a Cauchy prior to model one’s prior opinion about the mean snowfall amount. Recall that the posterior density of \\(\\mu\\) is proportional to \\[\\begin{equation}\n\\pi(\\mu \\mid y) \\propto \\frac{1}{1 + \\left(\\frac{\\mu - 10}{2}\\right)^2} \\times \\exp\\left\\{-\\frac{n}{2 \\sigma^2}(\\bar y - \\mu)^2\\right\\}.\n\\end{equation}\\] There are four inputs to this posterior – the mean \\(\\bar y\\) and corresponding standard error \\(\\sigma / \\sqrt{n}\\), and the location parameter 10 and the scale parameter 2 for the Cauchy prior. Recall that for the Buffalo snowfall, we observed \\(\\bar y = 26.785\\) and \\(\\sigma / \\sqrt{n} = 3.236\\).\nFirst we need to define a short function defining the logarithm of the posterior density function. Ignoring constants, the logarithm of this density is given by \\[\\begin{equation}\n\\log \\pi(\\mu \\mid y) =  -\n\\log\\left\\{1 + \\left(\\frac{\\mu - 10}{2}\\right)^2\\right\\} -\\frac{n}{2 \\sigma^2}(\\bar y - \\mu)^2.\n\\end{equation}\\]\nThe function lpost() returns the value of the logarithm of the posterior where s is a list containing the four inputs ybar, se, loc, and scale.\nlpost <- function(theta, s){\n    dcauchy(theta, s$loc, s$scale, log = TRUE) +\n    dnorm(s$ybar, theta, s$se, log = TRUE)\n}\nA list named s is defined that contains these inputs for this particular problem.\ns <- list(loc = 10, scale = 2,\n          ybar = mean(data$JAN),\n          se = sd(data$JAN) / sqrt(20))\nNow we are ready to apply the Metropolis algorithm as coded in the function metropolis(). The inputs to this function are the log posterior function lpost, the starting value \\(\\mu = 5\\), the width of the proposal density \\(C = 20\\), the number of iterations 10,000, and the list s that contains the inputs to the log posterior function.\nout <- metropolis(lpost, 5, 20, 10000, s)\nThe output variable out has two components – S is a vector of the simulated draws and accept_rate gives the acceptance rate of the algorithm.\n\n4.4.1 Choice of starting value and proposal region\n\nIn implementing this Metropolis algorithm, the user has to make two choices. One needs to select a starting value for the algorithm and select a value of \\(C\\) which determines the width of the proposal region.\nAssuming that the starting value is a place where the density is positive, then this particular choice in usual practice is not critical. In the event where the probability density at the starting value is small, the algorithm will move towards the region where the density is more probable.\nThe choice of the constant \\(C\\) is more critical. If one chooses a very small value of \\(C\\), then the simulated values from the algorithm tend to be strongly correlated and it takes a relatively long time to explore the entire probability distribution. In contrast, if \\(C\\) is chosen too large, then it is more likely that proposal values will not be accepted and the simulated values tend to get stuck at the current values. One monitors the choice of \\(C\\) by computing the acceptance rate, the proportion of proposal values that are accepted. If the acceptance rate is large, that indicates that the simulated values are highly correlated and the algorithm is not efficiently exploring the distribution. If the acceptance rate is low, then few candidate values are accepted and the algorithm tends to be ``sticky” or stuck at current draws.\nWe illustrate different choices of \\(C\\) for the mean amount of Buffalo snowfall problem. In each case, we start with the value \\(\\mu = 20\\) and try the \\(C\\) values 0.3, 3, 30, and 200. In each case, we simulate 5000 values of the MCMC chain. Figure 9.7 shows in each case a line graph of the simulated draws against the iteration number and the acceptance rate of the algorithm is displayed.\n\n\n\n\n\nTrace plots of simulated draws using different choices of the constant \\(C\\).\n\n\n\n\nWhen one chooses a small value \\(C = 0.3\\) (top-left panel in Figure 9.7), note that the graph of simulated draws has a snake-like appearance. Due to the strong autocorrelation of the simulated draws, the sampler does a relatively poor job of exploring the posterior distribution. One measure that this sampler is not working well is the large acceptance rate of 0.9702. On the other hand, if one uses a large value \\(C = 200\\) (bottom-right panel in Figure 9.7), the flat-portions in the graph indicates there are many occurrences where the chain will not move from the current value. The low acceptance rate of 0.0272 indicates this problem. The more moderate values of \\(C = 3\\) and \\(C = 30\\) (top-right and bottom-left panels in Figure 9.7) produce more acceptable streams of simulated values, although the respectively acceptance rates (0.8158 and 0.179) are very different.\nIn practice, it is recommended that the Metropolis algorithm has an acceptance rate between 20% and 40%. For this example, this would suggest trying an alternative choice of \\(C\\) between 2 and 20.\n\n\n4.4.2 Collecting the simulated draws\nUsing MCMC diagnostic methods that will be described in Section 9.6, one sees that the simulated draws are a reasonable approximation to the posterior density of \\(\\mu\\). One displays the posterior density by computing a density estimate of the simulated sample. In Figure 9.8, we plot the prior, likelihood, and posterior density for the mean amount of Buffalo snowfall \\(\\mu\\) using the Cauchy prior. Recall that we have prior-data conflict, the prior says that the mean snowfall is about 10 inches and the likelihood indicates that the mean snowfall was around 27 inches. When a Normal prior was applied, we found that the posterior mean was 17.75 inches – actually the posterior density has little overlap with the prior or the likelihood in Figure 9.1. In contrast, it is seen from Figure 9.8 that the posterior density using the Cauchy density resembles the likelihood. Essentially this posterior analysis says that our prior information was off the mark and the posterior is most influenced by the data.\n\n\n\n\n\nPrior, likelihood, and posterior of a Normal mean with a Cauchy prior."
  },
  {
    "objectID": "mcmc.html#gibbs-sampling",
    "href": "mcmc.html#gibbs-sampling",
    "title": "4  Simulation by Markov Chain Monte Carlo",
    "section": "4.5 Gibbs Sampling",
    "text": "4.5 Gibbs Sampling\n\nIn our examples, we have focused on the use of the Metropolis sampler in simulating from a probability distribution of a single variable. Here we introduce an MCMC algorithm for simulating from a probability distribution of several variables based on conditional distributions: the Gibbs sampling algorithm. As we will see, it facilitates parameter estimation in Bayesian models with more than one parameter, providing data analysts much flexibility in specifying Bayesian models.\n\n4.5.1 Bivariate discrete distribution}\n\nTo introduce the Gibbs sampling method, suppose that the random variables \\(X\\) and \\(Y\\) each take on the values 1, 2, 3, 4, and the joint probability distribution is given in the following table.\n\n\n\n\n\n\n\n\n\n\n(Y)\n1\n2\n3\n4\n\n\n1\n0.100\n0.075\n0.050\n0.025\n\n\n2\n0.075\n0.100\n0.075\n0.050\n\n\n3\n0.050\n0.075\n0.100\n0.075\n\n\n4\n0.025\n0.050\n0.075\n0.100\n\n\n\nSuppose it is of interest to simulate from this joint distribution of \\((X, Y)\\). We set up a Markov chain by taking simulated draws from the conditional distributions \\(f(x \\mid y)\\) and \\(f(y \\mid x)\\). Let’s describe this Markov chain by example. Suppose the algorithm starts at the value \\(X = 1\\).\n\n[Step 1] One simulates \\(Y\\) from the conditional distribution \\(f(y \\mid X = 1)\\). This conditional distribution is represented by the probabilities in the first column of the probability matrix.\n\n\n\n\n(Y)\nProbability\n\n\n\n\n1\n0.100\n\n\n2\n0.075\n\n\n3\n0.050\n\n\n4\n0.025\n\n\n\n(Actually these values are proportional to the distribution \\(f(y \\mid X = 1)\\).) Suppose we perform this simulation and obtain \\(Y = 2\\).\n\n[Step 2] Next one simulates \\(X\\) from the conditional distribution of \\(f(x \\mid Y = 2).\\) This distribution is found by looking at the probabilities in the second row of the probability matrix.\n\n\n\n\n(X)\n1\n2\n3\n4\n\n\n\n\nProbability\n0.075\n0.100\n0.075\n0.050\n\n\n\nSuppose the simulated draw from this distribution is \\(X = 3\\).\nBy implementing Steps 1 and 2, we have one iteration of Gibbs sampling, obtaining the simulated pair \\((X, Y) = (3, 2)\\). To continue this algorithm, we repeat Steps 1 and 2 many times where we condition in each case on the most recently simulated values of \\(X\\) or \\(Y\\).\nBy simulating successively from the distributions \\(f(y \\mid x)\\) and \\(f(x \\mid y)\\), one defines a Markov chain that moves from one simulated pair \\((X^{(j)}, Y^{(j)})\\) to the next simulated pair \\((X^{(j+1)}, Y^{(j+1)})\\). In theory, after simulating from these two conditional distributions a large number of times, the distribution will converge to the joint probability distribution of \\((X, Y)\\).\nWe write a short R function gibbs_discrete() to implement Gibbs sampling for a two-parameter discrete distribution where the probabilities are represented in a matrix. One inputs the matrix p and the output is a matrix of simulated draws of \\(X\\) and \\(Y\\) where each row corresponds to a simulated pair. By default, the sampler starts at the value \\(X = 1\\) and 1000 iterations of the algorithm will be taken.\ngibbs_discrete <- function(p, i = 1, iter = 1000){\n  x <- matrix(0, iter, 2)\n  nX <- dim(p)[1]\n  nY <- dim(p)[2]\n  for(k in 1:iter){\n    j <- sample(1:nY, 1, prob = p[i, ])\n    i <- sample(1:nX, 1, prob = p[, j])\n    x[k, ] <- c(i, j)\n  }\n  x\n}\nThe function gibbs_discrete() is run using the probability matrix for our example. The output is converted to a data frame and we tally the counts for each possible pair of values of \\((X, Y)\\), and then divide the counts by the simulation sample size of 1000. One can check that the relative frequencies of these pairs are good approximations to the joint probabilities.\nsp <- data.frame(gibbs_discrete(p))\nnames(sp) <- c(\"X\", \"Y\")\ntable(sp) / 1000\n    Y\nX       1     2     3     4\n  1 0.086 0.058 0.050 0.020\n  2 0.061 0.081 0.079 0.048\n  3 0.046 0.070 0.090 0.079\n  4 0.017 0.036 0.068 0.111\n\n\n4.5.2 Beta-binomial sampling\n\nThe previous example demonstrated Gibbs sampling for a two-parameter discrete distribution. In fact, the Gibbs sampling algorithm works for any two-parameter distribution. To illustrate, consider a familiar Bayesian model discussed in Chapter 7. Suppose we flip a coin \\(n\\) times and observe \\(y\\) heads where the probability of heads is \\(p\\), and our prior for the heads probability is described by a Beta curve with shape parameters \\(a\\) and \\(b\\). It is convenient to write \\(X \\mid Y = y\\) as the conditional distribution of \\(X\\) given \\(Y=y\\). Using this notation we have\n\\[\\begin{equation}\nY \\mid p \\sim  \\textrm{Binomial}(n, p),\n\\end{equation}\\] \\[\\begin{equation}\np \\sim \\textrm{Beta}(a, b).\n\\end{equation}\\]\nTo implement Gibbs sampling for this situation, one needs to identify the two conditional distributions \\(Y \\mid p\\) and \\(p \\mid Y\\). First write down the joint density of \\((Y, p)\\) which is found by multiplying the marginal density \\(\\pi(p)\\) with the conditional density \\(f(y \\mid p)\\).\n\\[\\begin{eqnarray}\nf(Y = y, p) &=& \\pi(p)f(Y = y \\mid p) \\nonumber \\\\\n&=&  \\left[\\frac{1}{B(a, b)} p^{a - 1} (1-p)^{b-1}\\right] \\left[{n \\choose y} p^y (1 - p)^{n-y}\\right]. \\nonumber \\\\\n\\end{eqnarray}\\]\n\nThe conditional density \\(f(Y = y \\mid p)\\) is found by fixing a value of the proportion \\(p\\) and then the only random variable is \\(Y\\). This distribution is \\(\\textrm{Binomial}(n, p)\\) which actually was given in the statement of the problem.\nTurning things around, the conditional density \\(\\pi(p \\mid y)\\) takes the number of successes \\(y\\) and views the joint density as a function only of the random variable \\(p\\). Ignoring constants, we see this conditional density is proportional to \\[\\begin{equation}\np^{y + a - 1} (1 - p)^{n - y + b - 1},\n\\end{equation}\\] which we recognize as a Beta distribution with shape parameters \\(y + a\\) and \\(n - y + b\\). Using our notation, we have \\(p \\mid y \\sim \\textrm{Beta}(y + a, n - y + b)\\).\n\nOnce these conditional distributions are identified, it is straightforward to write an algorithm to implement Gibbs sampling. For example, suppose \\(n = 20\\) and the prior density for \\(p\\) is \\(\\textrm{Beta}(5, 5)\\). Suppose that the current simulated value of \\(p\\) is \\(p^{(j)}\\).\n\nSimulate \\(Y^{(j)}\\) from a \\(\\textrm{Binomial}(20, p^{(j)})\\) distribution.\n\ny <- rbinom(1, size = 20, prob = p)\n\nGiven the current simulated value \\(y^{(j)}\\), simulate \\(p^{(j+1)}\\) from a Beta distribution with shape parameters \\(y^{(j)} + 5\\) and \\(20 - y^{(j)} + 5\\).\n\np <- rbeta(1, y + a, n - y + b)\nThe R function gibbs_betabin() will implement Gibbs sampling for this problem. One inputs the sample size \\(n\\) and the shape parameters \\(a\\) and \\(b\\). By default, one starts the algorithm at the proportion value \\(p = 0.5\\) and one takes 1000 iterations of the algorithm.\ngibbs_betabin <- function(n, a, b, p = 0.5, iter = 1000){\n  x <- matrix(0, iter, 2)\n  for(k in 1:iter){\n    y <- rbinom(1, size = n, prob = p)\n    p <- rbeta(1, y + a, n - y + b )\n    x[k, ] <- c(y, p)\n  }\n  x\n}\nBelow we run Gibbs sampling for this Beta-Binomial model with \\(n = 20\\), \\(a = 5\\), and \\(b = 5\\). After performing 1000 iterations, one regards the matrix sp as an approximate simulated sample from the joint distribution of \\(Y\\) and \\(p\\). A histogram is constructed of the simulated draws of \\(Y\\) in Figure 9.9. This graph represents an approximate sample from the marginal distribution \\(f(y)\\) of \\(Y\\).\nsp <- data.frame(gibbs_betabin(20, 5, 5))\n\n\n\n\n\nHistogram of simulated draws of \\(Y\\) from Gibbs sampling for the Beta-Binomial model with \\(n = 20\\), \\(a = 5\\), and \\(b = 5\\).\n\n\n\n\n\n\n4.5.3 Normal sampling – both parameters unknown\n\nIn Chapter 8, we considered the situation of sampling from a Normal distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). To simplify this to a one-parameter model, we assumed that the value of \\(\\sigma\\) was known and focused on the problem of learning about the mean \\(\\mu\\). Since Gibbs sampling provides us to simulate from posterior distributions of more than one parameter, we can generalize to the more realistic situation where both the mean and the standard deviation are unknown.\nSuppose we take a sample of \\(n\\) observations \\(Y_1, .., Y_n\\) from a Normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Recall the sampling density of \\(Y_i\\) has the form \\[\\begin{equation}\nf(y_i \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{- \\frac{1}{2 \\sigma^2}(y_i - \\mu)^2\\right\\}.\n\\end{equation}\\] It will be convenient to reexpress the variance \\(\\sigma\\) by the precision \\(\\phi\\) where \\[\\begin{equation}\n\\phi = \\frac{1}{\\sigma^2}.\n\\end{equation}\\] The precision \\(\\phi\\) reflects the strength in knowledge about the location of the observation \\(Y_i\\). If \\(Y_i\\) is likely to be close to the mean \\(\\mu\\), then the variance \\(\\sigma^2\\) would be small and so the precision \\(\\phi\\) would be large. So we restate the sampling model as follows. The observations \\(Y_1, .., Y_n\\) are a random sample from a Normal density with mean \\(\\mu\\) and precision \\(\\phi\\), where the sampling density of \\(Y_i\\) is given by \\[\\begin{equation}\nf(y_i \\mid \\mu, \\phi) = \\frac{\\sqrt{\\phi}}{\\sqrt{2 \\pi}} \\exp\\left\\{- \\frac{\\phi}{2}(y_i - \\mu)^2\\right\\}.\n\\end{equation}\\]\nThe next step is to construct a prior density on the parameter vector \\((\\mu, \\phi)\\). A convenient choice for this prior is to assume that one’s opinion about the location of the mean \\(\\mu\\) is independent of one’s belief about the location of the precision \\(\\phi\\). So we assume that \\(\\mu\\) and \\(\\phi\\) are independent, so one writes the joint prior density as \\[\\begin{equation}\n\\pi(\\mu, \\phi) = \\pi_{\\mu}(\\mu) \\pi_{\\phi}(\\phi),\n\\end{equation}\\] where \\(\\pi_{\\mu}()\\) and \\(\\pi_{\\phi}()\\) are marginal densities. For convenience, each of these marginal priors are assigned conjugate forms: we assume that \\(\\mu\\) is Normal with mean \\(\\mu_0\\) and precision \\(\\phi_0\\): \\[\\begin{equation}\n\\pi_{\\mu}(\\mu) = \\frac{\\sqrt{\\phi_0}}{\\sqrt{2 \\pi}} \\exp\\left\\{-\\frac{\\phi_0}{2}(\\mu - \\mu_0)^2\\right\\}.\n\\end{equation}\\] The prior for the precision parameter \\(\\phi\\) is assumed Gamma with parameters \\(a\\) and \\(b\\): \\[\\begin{equation}\n\\pi_{\\phi}(\\phi) = \\frac{b^a}{\\Gamma(a)} \\phi^{a-1} \\exp(-b \\phi), \\, \\, \\phi  > 0.\n\\end{equation}\\]\nOnce values of \\(y_1, ..., y_n\\) are observed, the likelihood is the density of these Normal observations viewed as a function of the mean \\(\\mu\\) and the precision parameter \\(\\phi\\). Simplifying the expression and removing constants, one obtains: \\[\\begin{align}\n        L(\\mu, \\phi) &=\\prod_{i=1}^n \\frac{\\sqrt{\\phi}}{\\sqrt{2 \\pi}} \\exp\\left\\{-\\frac{\\phi}{2}(y_i - \\mu)^2\\right\\} \\nonumber \\\\\n        & \\propto \\phi^{n/2} \\exp\\left\\{-\\frac{\\phi}{2}\\sum_{i=1}^n (y_i - \\mu)^2\\right\\}.\n\\end{align}\\]\nTo implement Gibbs sampling, one first writes down the expression for the posterior density as the product of the likelihood and prior where any constants not involving the parameters are removed.\n\\[\\begin{eqnarray}\n\\pi(\\mu, \\phi \\mid y_1, \\cdots, y_n ) &\\propto & \\phi^{n/2} \\exp\\left\\{-\\frac{\\phi}{2}\\sum_{i=1}^n (y_i - \\mu)^2\\right\\} \\nonumber \\\\\n& \\times & \\exp\\left\\{-\\frac{\\phi_0}{2}(\\mu - \\mu_0)^2\\right\\}  \\phi^{a-1} \\exp(-b \\phi).\n\\end{eqnarray}\\]\nNext, the two conditional posterior distributions \\(\\pi(\\mu \\mid \\phi, y_1, \\cdots, y_n)\\) and \\(\\pi(\\phi \\mid \\mu, y_1, \\cdots, y_n)\\) are identified.\n\nThe first conditional density \\(\\pi(\\mu \\mid \\phi, y_1, \\cdots, y_n)\\) follows from the work in Chapter 8 on Bayesian inference about a mean with a conjugate prior when the sampling standard deviation was assumed known. One obtains that this conditional distribution \\(\\pi(\\mu \\mid \\phi, y_1, \\cdots, y_n)\\) is Normal with mean \\[\\begin{equation}\n\\mu_n = \\frac{\\phi_0 \\mu_0  + n \\phi \\bar y }{\\phi_0  + n \\phi}.\n\\end{equation}\\] and standard deviation \\[\\begin{equation}\n\\sigma_n = \\sqrt{\\frac{1}{\\phi_0  + n \\phi}}.\n\\end{equation}\\]\nCollecting terms, the second conditional density \\(\\pi(\\phi \\mid \\mu, y_1, \\cdots, y_n)\\) is proportional to \\[\\begin{equation}\n\\pi(\\phi \\mid \\mu, y_1, \\cdots y_n) \\propto \\phi^{n/2 + a - 1} \\exp\\left\\{-\\phi\\left[\\frac{1}{2}\\sum_{i=1}^n (y_i- \\mu)^2 + b\\right]\\right\\}. \\\\\n\\end{equation}\\] The second conditional distribution \\(\\pi(\\phi \\mid \\mu, y_1, \\cdots, y_n)\\) is seen to be a Gamma density with parameters \\[\\begin{equation}\na_n = \\frac{n}{2} + a,\n\\end{equation}\\] \\[\\begin{equation}\nb_n = \\frac{1}{2}\\sum_{i=1}^n (y_i - \\mu)^2 + b.\n\\end{equation}\\]\n\nAn R function gibbs_normal() is written to implement this Gibbs sampling simulation. The inputs to this function are a list s containing the vector of observations y and the prior parameters mu0, phi0, a, and b, the starting value of the precision parameter \\(\\phi\\), phi, and the number of Gibbs sampling iterations S. This function is similar in structure to the gibbs_betabin() function – the two simulations in the Gibbs sampling are accomplished by use of the rnorm() and ```rgamma()} functions.\ngibbs_normal <- function(s, phi = 0.002, iter = 1000){\n  ybar <- mean(s$y)\n  n <- length(s$y)\n  mu0 <- s$mu0\n  phi0 <- s$phi0\n  a <- s$a\n  b <- s$b\n  x <- matrix(0, iter, 2)\n  for(k in 1:iter){\n   mun <- (phi0 * mu0 + n * phi * ybar) /\n      (phi0 + n * phi)\n    sigman <- sqrt(1 / (phi0 + n * phi))\n    mu <- rnorm(1, mean = mun, sd = sigman)\n    an <- n / 2 + a\n    bn <- sum((s$y - mu) ^ 2) / 2 + b\n    phi <- rgamma(1, shape = an, rate = bn)\n    x[k, ] <- c(mu, phi)\n  }\n  x\n}\nWe run this function for our Buffalo snowfall example where now the sampling model is Normal with both the mean \\(\\mu\\) and standard deviation \\(\\sigma\\) unknown. The prior distribution assumes that \\(\\mu\\) and the precision \\(\\phi\\) are independent, where \\(\\mu\\) is Normal with mean 10 and standard deviation 3 (i.e. precision \\(1/3^2\\)), and \\(\\phi\\) is Gamma with \\(a = b = 1\\). The output of this function is a matrix ```out} where the two columns of the matrix correspond to random draws of \\(\\mu\\) and \\(\\phi\\) from the posterior distribution.\ns <- list(y = data$JAN, mu0 = 10, phi0 = 1/3^2, a = 1, b = 1)\nout <- gibbs_normal(s, iter=10000)\nBy performing the transformation \\(\\sigma = \\sqrt{1 / \\phi}\\), one obtains a sample of the simulated draws of the standard deviation \\(\\sigma\\). Figure 9.10 \\(\\ref{fig:mcmc9}\\) displays a scatterplot of the posterior draws of \\(\\mu\\) and \\(\\sigma\\).\n\n\n\n\n\nScatterplot of simulated draws of the posterior distribution of mean and standard deviation from Gibbs sampling for the Normal sampling model with independent priors on the mean and the precision."
  },
  {
    "objectID": "mcmc.html#mcmc-inputs-and-diagnostics",
    "href": "mcmc.html#mcmc-inputs-and-diagnostics",
    "title": "4  Simulation by Markov Chain Monte Carlo",
    "section": "4.6 MCMC Inputs and Diagnostics",
    "text": "4.6 MCMC Inputs and Diagnostics\n\n\n4.6.1 Burn-in, starting values, and multiple chains\n\nIn theory, the Metropolis and Gibbs sampling algorithms will produce simulated draws that converge to the posterior distribution of interest. But in typical practice, it may take a number of iterations before the simulation values are close to the posterior distribution. So in general it is recommended that one run the algorithm for a number of “burn-in” iterations before one collects iterations for inference. The JAGS software that is introduced in Section 9.7 will allow the user to specify the number of burn-in iterations.\nIn the examples, we have illustrated running a single “chain” where one has a single starting value and one collects simulated draws from many iterations. It is possible that the MCMC sample will depend on the choice of starting value. So a general recommendation is to run the MCMC algorithm several times using different starting values. In this case, one will have multiple MCMC chains. By comparing the inferential summaries from the different chains one explores the sensitivity of the inference to the choice of starting value. Although we will focus on the use of a single chain, we will explore the use of different starting values and multiple chains in an example in this chapter. The JAGS software and other programs to implement MCMC will allow for different starting values and several chains.\n\n\n4.6.2 Diagnostics\nThe output of a single chain from the Metropolis and Gibbs algorithms is a vector or matrix of simulated draws. Before one believes that a collection of simulated draws is a close approximation to the posterior distribution, some special diagnostic methods should be initially performed.\nTrace plot\nIt is helpful to construct a trace plot which is a line plot of the simulated draws of the parameter of interest graphed against the iteration number. Figure 9.11 displays a trace plot of the simulated draws of \\(\\mu\\) from the Metropolis algorithm for our Buffalo snowfall example for Normal sampling (known standard deviation) with a Cauchy prior. Section 9.4.1 shows some sample trace plots for Metropolis sampler. As discussed in that section, it is undesirable to have a snack-like appearance in the trace plot indicating a high acceptance rate. Also, Section 9.4.1 displays a trace plot with many flat portions that indicates a sampler with a low acceptance rate. From the authors’ experience, the trace plot in Figure 9.11 indicates that the sampler is using a good value of the constant \\(C\\) and efficiently sampling from the posterior distribution.\n\n\n\n\n\nTrace plot of simulated draws of normal mean using the Metropolis algorithm with \\(C = 20\\).\n\n\n\n\nAutocorrelation plot\nSince one is simulating a dependent sequence of values of the parameter, one is concerned about the possible strong correlation between successive draws of the sampler. One visualizes this dependence by computing the correlation of the pairs {\\(\\theta^{(j)}, \\theta^{(j + l)}\\)} and plotting this “lag-correlation” as a function of the lag value \\(l\\). This autocorrelation plot of the simulated draws from our example is displayed in Figure 9.12. If there is a strong degree of autocorrelation in the sequence, then there will be a large correlation of these pairs even for large values of the lag value. Figure 9.12 is an example of a suitable autocorrelation graph where the lag correlation values quickly drop to zero as a function of the lag value. This autocorrelation graph is another indication that the Metropolis algorithm is providing an efficient sampler of the posterior.\n\n\n\n\n\nAutocorrelation plot of simulated draws of normal mean using the Metropolis algorithm with \\(C = 20\\).\n\n\n\n\n\n\n4.6.3 Graphs and summaries\nIf the trace plot or autocorrelation plot indicate issues with the Metropolis sampler, then the width of the proposal \\(C\\) should be adjusted and the algorithm run again. Since we believe that the Metropolis simulation stream is reasonable with the use of the value \\(C = 20\\) , then one uses a histogram of simulated draws, as displayed in Figure 9.13 to represent the posterior distribution. Alternatively, a density estimate of the simulated draws can be used to show a smoothed representation of the posterior density. Figure \\(\\ref{fig:mcmc8}\\) places a density estimate on top of the histogram of the simulated values of the parameter \\(\\mu\\).\n\n\n\n\n\nHistogram of simulated draws of the normal mean using the Metropolis algorithm with \\(C = 20\\). The solid curve is a density estimate of the simulated values.\n\n\n\n\nOne estimates different summaries of the posterior distribution by computing different summaries of the simulated sample. In our Cauchy-Normal model, one estimates, for example, the posterior mean of \\(\\mu\\) by computing the mean of the simulated posterior draws: \\[\\begin{equation}\nE(\\mu \\mid y) \\approx \\frac{\\sum_{j = 1}^S \\mu^{(j)}}{S}.\n\\end{equation}\\] One typically wants to estimate the simulation standard error of this MCMC estimate. If the draws from the posterior were independent, then the Monte Carlo standard error of this posterior mean estimate would be given by the standard deviation of the draws divided by the square root of the simulation sample size: \\[\\begin{equation}\nse = \\frac{sd(\\{\\mu^{(j)}\\})}{\\sqrt{S}}.\n\\end{equation}\\] However, this estimate of the standard error is not correct since the MCMC sample is not independent (the simulated value \\(\\mu^{(j)}\\) depends on the value of the previous simulated value \\(\\mu^{(j-1)}\\)). One obtains a more accurate estimate of Monte Carlo standard error by using time-series methods. As we will see in the examples of Section 9.7, this standard error estimate will be larger than the “naive” standard error estimate that assumes the MCMC sample values are independent."
  },
  {
    "objectID": "mcmc.html#using-jags",
    "href": "mcmc.html#using-jags",
    "title": "4  Simulation by Markov Chain Monte Carlo",
    "section": "4.7 Using JAGS",
    "text": "4.7 Using JAGS\n\nSections 9.3 and 9.5 have illustrated general strategies for simulating from a posterior distribution of one or more parameters. Over the years, there has been an effort to develop general-purpose Bayesian computing software that would take a Bayesian model (i.e. the specification of a prior and sampling density as input), and use an MCMC algorithm to output a matrix of simulated draws from the posterior. One of the earliest Bayesian simulation-based computing software was BUGS (for Bayesian inference Using Gibbs Sampling) and we illustrate in this text applications of a similar package JAGS (for Just Another Gibbs Sampler).\nThe use of JAGS has several attractive features. One defines a Bayesian model for a particular problem by writing a short script. One then inputs this script together with data and prior parameter values in a single R function from the runjags package that decides on the appropriate MCMC sampling algorithm for the particular Bayesian model. In addition, this function simulates from the MCMC algorithm for a specified number of samples and collects simulated draws of the parameters of interest.\n\n4.7.1 Normal sampling model\nTo illustrate the use of JAGS, consider the problem of estimating the mean Buffalo snowfall assuming a Normal sampling model with both the mean and standard deviation unknown, and independent priors placed on both parameters. As in Section 9.5.3 one expresses the parameters of the Normal distribution as \\(\\mu\\) and \\(\\phi\\), where the precision \\(\\phi\\) is the reciprocal of the variance \\(\\phi = 1 / \\sigma^2\\). One then writes this Bayesian model as\n\nSampling, for \\(i = 1, \\cdots, n\\): \\[\\begin{equation}\nY_i \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu, \\sqrt{1/\\phi}).\n\\end{equation}\\]\nIndependent priors for \\(\\mu\\) and \\(\\phi\\): \\[\\begin{equation}\n\\mu \\sim \\textrm{Normal}(\\mu_0, \\sqrt{1/\\phi_0}), (\\#eq:muphiprior2a)\n\\end{equation}\\] \\[\\begin{equation}\n\\phi \\sim \\textrm{Gamma}(a, b).\n\\end{equation}\\]\n\nThe JAGS program parametrizes a Normal density in terms of the precision, so the prior precision is equal to \\(\\phi_0 = 1 / \\sigma_0^2\\). As in Section 9.5.3, the parameters of the Normal and Gamma priors are set at \\(\\mu_0 = 10, \\phi_0 = 1 / 3 ^ 2, a = 1, b = 1.\\)\nDescribe the model by a script\nTo begin, one writes the following script defining this model. The model is saved in the character string modelString.\nmodelString = \"\nmodel{\n## sampling\nfor (i in 1:N) {\n   y[i] ~ dnorm(mu, phi)\n}\n## priors\nmu ~ dnorm(mu0, phi0)\nphi ~ dgamma(a, b)\nsigma <- sqrt(pow(phi, -1))\n}\nNote that this script closely resembles the statement of the model. In the sampling part of the script, the loop structure starting with for (i in 1:N) is used to assign the distribution of each value in the data vector y the same Normal distribution, represented by dnorm. The ~ operator is read as “is distributed as”.\nIn the priors part of the script, in addition to setting the Normal prior and Gamma prior for mu and phi respectively, sigma <- sqrt(pow(phi, -1)) is added to help track sigma directly.\nDefine the data and prior parameters\nThe next step is to define the data and provide values for parameters of the prior. In the script below, a list the_data is used to collect the vector of observations y, the number of observations N, and values of the Normal prior parameters mu0, phi0, and of the Gamma prior parameters a and b.\nbuffalo <- read.csv(\"../data/buffalo_snowfall.csv\")\ndata <- buffalo[59:78, c(\"SEASON\", \"JAN\")]\ny <- data$JAN\nN <- length(y)\nthe_data <- list(\"y\" = y, \"N\" = N, \n                 \"mu0\"=10, \"phi0\"=1/3^2, \n                 \"a\"=1,\"b\"=1)\nDefine initial values\nOne needs to supply initial values in the MCMC simulation for all of the parameters in the model. To obtain reproducible results, one can use the initsfunction() function shown below to set the seed for the sequence of simulated parameter values in the MCMC.\ninitsfunction <- function(chain){\n  .RNG.seed <- c(1,2)[chain]\n  .RNG.name <- c(\"base::Super-Duper\",\n                 \"base::Wichmann-Hill\")[chain]\n  return(list(.RNG.seed=.RNG.seed,\n              .RNG.name=.RNG.name))\nAlternatively, one can specify the initial values by means of a function – this will be implemented when multiple chains are discussed. If no initial values are specified, then JAGS will select initial values – these are usually a ``typical” value such as a mean or median from the prior distribution.\nGenerate samples from the posterior distribution\nNow that the model definition and data have been defined, one is ready to draw samples from the posterior distribution. The runjags provides the R interface to the use of the JAGS software. The run.jags() function sets up the Bayesian model defined in modelString. The input n.chains = 1 indicates that one stream of simulated values will be generated. adapt = 1000 says that 1000 simulated iterations are used in “adapt period” to prepare for MCMC, burnin = 1000 indicates 5000 simulated iterations are used in a “burn-in” period where the iterations are approaching the main probability region of the posterior distribution. The sample = 5000 arguments indicates that 5000 additional iterations of the MCMC algorithm will be collected. The monitor arguments says that we are collecting simulated values of the mean mu and the standard deviation sigma. The output variable posterior includes a matrix of the simulated draws. The inits = initsfunction argument indicates that initial parameter values are chosen by the initsfunction() function.\nposterior <- run.jags(modelString,\n                      n.chains = 1,\n                      data = the_data,\n                      monitor = c(\"mu\", \"sigma\"),\n                      adapt = 1000,\n                      burnin = 5000,\n                      sample = 5000,\n                      inits = initsfunction)\nMCMC diagnostics and summarization\nBefore summarizing the simulated sample, some graphical diagnostics methods should be implemented to judge if the sample appears to “mix” or move well across the space of likely values of the parameters. The plot() function in the runjags package constructs a collection of four graphs for a parameter of interest. By running plot() for mu and sigma, we obtain the graphs displayed in Figures 9.14 and 9.15.\nplot(posterior, vars = \"mu\")\nplot(posterior, vars = \"sigma\")\n\n\n\n\n\nDiagnostic plots of simulated draws of mean using the JAGS software with the runjags package.\n\n\n\n\n\n\n\n\n\nDiagnostic plots of simulated draws of standard deviation using the JAGS software with the runjags package.\n\n\n\n\nThe trace and autocorrelation plots in the top left and bottom right sections of the display are helpful for seeing how the sampler moves across the posterior distribution. In Figures 9.14 and 9.15, the trace plots show little autocorrelation in the streams of simulated draws and both simulated samples of \\(\\mu\\) and \\(\\sigma\\) appear to mix well. In the autocorrelation plots, the value of the autocorrelation drops sharply to zero as a function of the lag which confirms that we have modest autocorrelation in these samples. In each display, the bottom left graph is a histogram of the simulated draws and the top right graph is an estimate at the cumulative distribution function of the variable.\nSince we are encouraged by these diagnostic graphs, we go ahead and obtain summaries of the simulated samples of \\(\\mu\\) and \\(\\sigma\\) by the print() function on our MCMC object. The posterior mean of \\(\\mu\\) is 16.5. The standard error of this simulation estimate is the “MCerr” value of 0.0486 – this standard error takes in account the correlated nature of these simulated draws. A 90% probability interval for the mean \\(\\mu\\) is found from the output to be (10.8, 21.4). For \\(\\sigma\\), it has a posterior mean of 17.4, and a 90% probability interval (11.8, 24).\nprint(posterior, digits = 3)\n      Lower95 Median Upper95 Mean   SD Mode  MCerr \nmu       10.8   16.5    21.4 16.5 2.68   -- 0.0486     \nsigma    11.8   17.1      24 17.4 3.18   -- 0.0576    \n\n\n4.7.2 Multiple chains\nIn Section 9.6.1, we explained the benefit of trying different starting values and running several MCMC chains. This is facilitated by arguments in the run.jags() function. Suppose one considers the very different pairs of starting values, \\((\\mu, \\phi) = (2, 1 / 4)\\) and \\((\\mu, \\phi) = (30, 1/ 900)\\). Note that both pair of parameter values are far outside of the region where the posterior density is concentrated. One defines a value InitialValues that is a list containing two lists, each list containing a starting value.\nInitialValues <- list(\n  list(mu = 2, phi = 1 / 4),\n  list(mu = 30, phi = 1 / 900)\n)\nThe run.jags() function is run with two modifications – one chooses n.chains = 2 and the initial values are input through the inits = InitialValues option.\nposterior <- run.jags(modelString,\n                      n.chains = 2,\n                      data = the_data,\n                      monitor = c(\"mu\", \"sigma\"),\n                      adapt = 1000,\n                      burnin = 5000,\n                      sample = 5000,\n                      inits = InitialValues)\nThe output variable posterior contains a component mcmc which is a list of two components where posterior\\$mcmc[[1]] contains the simulated draws from the first chain and posterior\\$mcmc[[2]] contains the simulated draws from the second chain. To see if the MCMC run is sensitive to the choice of starting value, one compares posterior summaries from the two chains. Below, we display posterior quantiles for the parameters \\(\\mu\\) and \\(\\sigma\\) for each chain. Note that these quantiles are very close in value indicating that the MCMC run is insensitive to the choice of starting value.\nsummary(posterior$mcmc[[1]], digits = 3)\n2. Quantiles for each variable:\n\n       2.5%   25%   50%   75% 97.5%\nmu    10.99 14.64 16.49 18.35 21.62\nsigma 12.26 15.15 17.03 19.31 25.07\n\nsummary(posterior$mcmc[[2]], digits = 3)\n2. Quantiles for each variable:\n\n       2.5%   25%   50%   75% 97.5%\nmu    10.97 14.59 16.55 18.33 21.54\nsigma 12.21 15.08 16.96 19.18 24.99\n\n\n4.7.3 Posterior predictive checking\n\nIn Chapter 8 Section 8.7, we illustrated the usefulness of the posterior predictive checking in model checking. The basic idea is to simulate a number of replicated datasets from the posterior predictive distribution and see how the observed sample compares to the replications. If the observed data does resemble the replications, one says that the observed data is consistent with predicted data from the Bayesian model.\nFor our Buffalo snowfall example, suppose one wishes to simulate a replicated sample from the posterior predictive distribution. Since our original sample size was \\(n = 20\\), the intent is to simulate a sample of values \\(\\tilde y_1, ..., \\tilde y_{20}\\) from the posterior predictive distribution. A single replicated sample is simulated in the following two steps.\n\nWe draw a set of parameter values, say \\(\\mu^*, \\sigma^*\\) from the posterior distribution of \\((\\mu, \\sigma)\\).\n\nGiven these parameter values, we simulate \\(\\tilde y_1, ..., \\tilde y_{20}\\) from the Normal sampling density with mean \\(\\mu^*\\) and standard deviation \\(\\sigma^*\\).\n\nRecall that the simulated posterior values are stored in the matrix post. We write a function postpred_sim() to simulate one sample from the predictive distribution.\npost <- data.frame(posterior$mcmc[[1]])\npostpred_sim <- function(j){\n  rnorm(20, mean = post[j, \"mu\"],\n        sd = post[j, \"sigma\"])\n}\nprint(postpred_sim(1), digits = 3)\n [1]   5.37  10.91  40.87  15.94  16.93  43.49  22.48\n [8]  -6.43   3.26   7.30  35.27  20.79  21.47  16.62\n[15]   5.45  44.69  23.10 -18.18  26.51   6.84\nIf this process is repeated for each of the 5000 draws from the posterior distribution, then one obtains 5000 samples of size 20 drawn from the predictive distribution. In R, the function sapply() is used together with postpred_sim() to simulate 5000 samples that are stored in the matrix ypred.\nypred <- t(sapply(1:5000, postpred_sim))\nFigure 9.16 displays histograms of the predicted snowfalls from eight of these simulated samples and the observed snowfall measurements are displayed in the lower right panel. Generally, the center and spread of the observed snowfalls appear to be similar in appearance to the eight predicted snowfall samples from the fitted model. Can we detect any differences between the distribution of observed snowfalls and the distributions of predicted snowfalls? One concern is that some of the predictive samples contain negative snowfall values. Another concern from this inspection is that we observed a snowfall of 65.1 inches in our sample and none of our eight samples had a snowfall this large. Perhaps there is an outlier in our sample that is not consistent with predictions from our model.\n\n\n\n\n\nHistograms of eight simulated predictive samples and the observed sample for the snowfall example.\n\n\n\n\nWhen one notices a possible discrepancy between the observed sample and simulated prediction samples, one thinks of a checking function \\(T()\\) that will distinguish the two types of samples. In this situation since we noticed the extreme snowfall of 65.1 inches, that suggests that we use \\(T(y) = \\max y\\) as a checking function.\nOnce one decides on a checking function \\(T()\\), then one simulates the posterior predictive distribution of \\(T(\\tilde y)\\). This is conveniently done by evaluating the function \\(T()\\) on each simulated sample from the predictive distribution. In R, this is conveniently done using the apply() function and the values of \\(T(\\tilde y)\\) are stored in the vector postpred_max.\npostpred_max <- apply(ypred, 1, max)\nIf the checking function evaluated at the observed sample \\(T(y)\\) is not consistent with the distribution of \\(T(\\tilde y)\\), then predictions from the model are not similar to the observed data and there is some issue with the model assumptions. Figure 9.17 displays a histogram of the predictive distribution of \\(T(y)\\) in our example where \\(T()\\) is the maximum function, and the observed maximum snowfall is shown by a vertical line. Here the observed maximum is in the right tail of the posterior predictive distribution – the interpretation is that this largest snowfall of 65.1 inches is not predicted from the model. In this case, one might want to think about revising the sampling model, say, by assuming that the data follow a distribution with flatter tails than the Normal.\n\n\n\n\n\nHistogram of the posterior predictive distribution of T(y) where T() is the maximum function. The vertical line shows the location of the observed value T(y).\n\n\n\n\n\n\n4.7.4 Comparing two proportions\n\nTo illustrate the usefulness of the JAGS software, we consider a problem comparing two proportions from independent samples. The model is defined in a JAGS script, the data and values of prior parameters are entered through a list, and the run.jags() function is used to simulate from the posterior of the parameters by an MCMC algorithm.\nTo better understand the behavior of Facebook users, a survey was administered in 2011 to 244 students. Each student was asked their gender and the average number of times they visited Facebook in a day. We say that the number of daily visits is “high” if the number of visits is 5 or more; otherwise it is “low”. If we classify the sample by gender and daily visits, one obtains the two by two table of counts as shown in Table 9.1.\nTable 9.1. Two-way table of counts of students by gender and Facebook visits.\n\n\n\n\nHigh\nLow\n\n\nMale\n(y_M)\n(n_M - y_M)\n\n\nFemale\n(y_F)\n(n_F - y_F)\n\n\n\nIn Table 9.1, the random variable \\(Y_M\\) represents the number of males who have a high number of Facebook visits in a sample of \\(n_M\\), and \\(Y_F\\) and \\(n_M\\) are the analogous count and sample size for women. Assuming that the sample survey represents a random sample from all students using Facebook, then it is reasonable to assume that \\(Y_M\\) and \\(Y_F\\) are independent with \\(Y_M\\) distributed Binomial with parameters \\(n_M\\) and \\(p_M\\), and \\(Y_F\\) is Binomial with parameters \\(n_F\\) and \\(p_F\\).\nTable 9.2. Probability structure in two-way table.\n\n\n\n\nHigh\nLow\n\n\nMale\n(p_M)\n(1 - p_M)\n\n\nFemale\n(p_F)\n(1 - p_F)\n\n\n\nThe probabilities \\(p_M\\) and \\(p_F\\) are displayed in Table 9.2. In this type of data structure, one is interested in the association between gender and Facebook visits. Define the odds as the ratio of the probability of “high” to the probability of “low”. The odds of “high” for the men and odds of ’high” for the women are defined by \\[\\begin{equation}\n\\frac{p_M}{1 - p_M},\n\\end{equation}\\] and \\[\\begin{equation}\n\\frac{p_F}{1-p_F},\n\\end{equation}\\] respectively. The odds ratio \\[\\begin{equation}\n\\alpha = \\frac{p_M / (1 - p_M)}{p_F / (1 - p_F)},\n\\end{equation}\\] is a measure of association in this two-way table. If \\(\\alpha = 1\\), this means that \\(p_M = p_L\\) – this says that tendency to have high visits to Facebook does not depend on gender. If \\(\\alpha > 1\\), this indicates that men are more likely to have high visits to Facebook, and a value \\(\\alpha < 1\\) indicates that women are more likely to have high visits. Sometimes association is expressed on a log scale – the log odds ratio \\(\\lambda\\) is written as \\[\\begin{equation}\n\\lambda = \\log \\alpha = \\log\\left(\\frac{p_M} {1 - p_M}\\right) - \\log\\left(\\frac{p_F} {1 - p_F}\\right).\n\\end{equation}\\] That is, the log odds ratio is expressed as the difference in the logits of the men and women probabilities, where the logit of a probability \\(p\\) is equal to \\({\\rm logit}(p) = \\log(p) - \\log(1 - p)\\). If gender is independent of Facebook visits, then \\(\\lambda = 0\\).\nOne’s prior beliefs about association in the two-way table is expressed in terms of logits and the log odds ratio. If one believes that gender and Facebook visits are independent, then the log odds ratio is assigned a Normal prior with mean 0 and standard deviation \\(\\sigma\\). The mean of 0 reflects the prior guess of independence and \\(\\sigma\\) indicates the strength of the belief in independence. If one believed strongly in independence, then one would assign \\(\\sigma\\) a small value.\nIn addition, let \\[\\begin{equation}\n\\theta = \\frac{{\\rm logit}(p_M) + \\rm{logit}(p_F)}{2}\n\\end{equation}\\] be the mean of the logits, and assume that \\(\\theta\\) has a Normal prior with mean \\(\\theta_0\\) and standard deviation \\(\\sigma_0\\) (precision \\(\\phi_0\\)). The prior on \\(\\theta\\) reflects beliefs about the general size of the proportions on the logit scale.\nTo fit this model using JAGS, the following script, saved in modelString, is written defining the model.\nmodelString = \"\nmodel{\n## sampling\nyF ~ dbin(pF, nF)\nyM ~ dbin(pM, nM)\nlogit(pF) <- theta - lambda / 2\nlogit(pM) <- theta + lambda / 2\n## priors\ntheta ~ dnorm(mu0, phi0)\nlambda ~ dnorm(0, phi)\n}\n\"\nIn the sampling part of the script, the two first lines define the Binomial sampling models, and the logits of the probabilities are defined in terms of the log odds ratio lambda and the mean of the logits theta. In the priors part of the script, note that theta is assigned a Normal prior with mean mu0 and precision phi0, and lambda is assigned a Normal prior with mean 0 and precision phi.\nWhen the sample survey is conducted, one observes that 75 of the 151 female students say that they are high visitors of Facebook, and 39 of the 93 male students are high visitors. This data and the values of the prior parameters are entered into R by use of a list. Note that phi = 2 indicating some belief that gender is independent of Facebook visits, and mu0 = 0 and phi0 = 0.001 reflecting little knowledge about the location of the logit proportions. Using the run.jags() function, we take an adapt period of 1000, burn-in period of 5000 iterations and collect 5000 iterations, storing values of pF, pM and the log odds ratio lambda.\nthe_data <- list(\"yF\" = 75, \"nF\" = 151, \n                 \"yM\" = 39, \"nM\" = 93,\n                 \"mu0\" = 0, \"phi0\" = 0.001, \"phi\" = 2)\n\nposterior <- run.jags(modelString,\n                 data = the_data,\n                 n.chains = 1,\n                 monitor = c(\"pF\", \"pM\", \"lambda\"),\n                 adapt = 1000,\n                 burnin = 5000,\n                 sample = 5000)\nSince the main goal is to learn about the association structure in the table, Figure 9.18 displays a density estimate of the posterior draws of the log odds ratio \\(\\lambda\\). A reference line at \\(\\lambda = 0\\) is drawn on the graph which corresponds to the case where \\(p_M = p_L\\). What is the probability that women are more likely than men to have high visits in Facebook? This is directly answered by computing the posterior probability \\(Prob(\\lambda < 0 \\mid data)\\) that is computed to be 0.874. Based on this computation, one concludes that it is very probable that women have a higher tendency than men to have high visits on Facebook.\npost <- data.frame(posterior$mcmc[[1]])\npost %>% \n  summarize(Prob = mean(lambda < 0))\n      Prob\n1 0.874\nIn the end-of-chapter exercises, the reader will be asked to perform further explorations with this two proportion model.\n\n\n\n\n\nPosterior density estimate of simulated draws of log odds ratio for visits to Facebook example. A vertical line is drawn at the value 0 corresponding to no association between gender and visits to Facebook."
  },
  {
    "objectID": "hierarchical.html",
    "href": "hierarchical.html",
    "title": "5  Bayesian Hierarchical Modeling",
    "section": "",
    "text": "Chapters 7, 8, and 9 make an underlying assumption about the source of data: observations are assumed to be identically and independently distributed (i.i.d.) following a single distribution with one or more unknown parameters. In Chapter 7, the Binomial data model is based on the assumptions that a student’s chance of preferring dining out on Friday is the same for all students, and the dining preferences of different students are independent. To refresh your memory, recall the four conditions of a Binomial experiment: a fixed number of trials, only two outcomes, a fixed success probability, and independent trials. In Chapter 8, the Normal sampling model is based on the assumptions that Roger Federer’s time-to-serves are independent observations following a single Normal distribution with an unknown mean \\(\\mu\\) and known standard deviation \\(\\sigma\\). That is, \\(Y_i \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu, \\sigma)\\). Similarly in Chapter 9, the underlying assumption is that the snowfall amounts in Buffalo for the last 20 Januarys follow the same \\(\\textrm{Normal}(\\mu, \\sigma)\\) distribution with both parameters unknown.\nIn many situations, treating observations as i.i.d. from the same distribution with the same parameter(s) is not sensible. In our dining out example, dining preferences for students may be different from dining performances of senior citizens, so it would not make sense to use a single success probability for a combined group of students and senior citizens. In a similar fashion, if one considered time-to-serve data for a group of tennis players, then it would not be reasonable to use a single Normal distribution with a single mean to represent these data – the mean time-to-serve for a quick-serving player would likely be smaller than the mean time-to-serve for a slower player. For many applications, some observations share characteristics, such as age or player, that distinguish them from other observations, therefore multiple distinct groups are observed.\n\n\n\nAs a new example, consider a study in which students’ scores of a standardized test such as the SAT are collected from five different senior high schools in a given year. Suppose a researcher is interested in learning about the mean SAT score. Since five different schools participated in this study and students’ scores might vary from school to school, it makes sense for the researcher to learn about the mean SAT score for each school and compare students’ mean performance across schools.\nTo start modeling this education data, it is inappropriate to use \\(Y_i\\) as the random variable for the SAT score of student \\(i\\) (\\(i = 1, \\cdots, n\\), where \\(n\\) is the total number of students from all five schools) since this ignores the inherent grouping of the observations. Instead, the researcher adds a school label \\(j\\) to \\(Y_i\\) to reflect the grouping. Let \\(Y_{ij}\\) denote the SAT score of student \\(i\\) in school \\(j\\), where \\(j = 1, \\cdots, 5\\), and \\(i = 1, \\cdots, n_j\\), where \\(n_j\\) is the number of students in school \\(j\\), and \\(n = \\sum_{j=1}^{5}n_j\\).\nSince SAT scores are continuous, the Normal sampling model is a reasonable choice for a data distribution. Within school \\(j\\), one assumes that SAT scores are i.i.d. from a Normal data model with a mean and standard deviation depending on the school. Specifically, one assumes a school-specific mean \\(\\mu_j\\) and a school-specific standard deviation \\(\\sigma_j\\) for the Normal data model for school \\(j\\). Combining the information for the five schools, one has\n\\[\\begin{equation}\nY_{ij} \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu_j, \\sigma_j),\n\\label{eq:introLik}\n\\end{equation}\\] where \\(j = 1, \\cdots, 5\\) and \\(j = 1, \\cdots, n_j\\).\n\n\n\nOne approach for handling this group estimation problem is find separate estimates for each school. One focuses on the observations in school \\(j\\),\\(\\{Y_{1j}, Y_{2j}, \\cdots, Y_{n_jj}\\}\\), choose a prior distribution \\(\\pi(\\mu_j, \\sigma_j)\\) for the mean and the standard deviation parameters, follow the Bayesian inference procedure in Chapter 9 and obtain posterior inference on \\(\\mu_j\\) and \\(\\sigma_j\\).\nIf one assumes that the prior distributions on the individual parameters for the schools are independent, one is essentially fitting five separate Bayesian models and one’s inferences about one particular school will be independent of the inferences on the remaining schools.\nThis “separate estimates” approach may be reasonable, especially if the researcher thinks the means and the standard deviations from the five Normal models are completely unrelated to each other. That is, one’s prior beliefs about the parameters of the SAT score distribution in one school are unrelated to the prior beliefs about the distribution parameters in another school.\nTo see if this assumption is reasonable, let us consider a thought experiment for the school testing example. Suppose you are interested in learning about the mean SAT score \\(\\mu_N\\) for school \\(N\\). You may not be familiar with the distribution of SAT scores and it would be difficult to construct an informative prior for \\(\\mu_N\\). But suppose that you are told that the students from another school, call it school \\(M\\), average 1,200 on their SAT scores. That information would likely influence your prior on \\(\\mu_N\\), since now you have some general idea about SAT scores. This means that your prior beliefs about the mean SAT scores \\(\\mu_N\\) and \\(\\mu_M\\) are not independent – some information about one school’s mean SAT scores would change your prior on the second school’s mean SAT score. So in many situations, this independence assumption would be questionable.\n\n\n\nAnother way to handle this group estimation problem is to ignore the fact that there is a grouping variable and estimate the parameters in the combined sample. In our school example, one ignores the school variable and simply assumes that the SAT scores \\(Y_i's\\) are distributed from a single Normal population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Here, \\(i = 1, \\cdots, n\\) where \\(n\\) is the total number of students from all five schools.\nIf ones ignores the grouping variable, then the inference procedure described in Chapter 9 can be used. One constructs a prior for the parameters \\(\\mu\\) and \\(\\sigma\\) and use Gibbs sampling to obtain a simulated sample from the posterior distribution of \\((\\mu, \\sigma)\\).\nUsing this approach, one is effectively ignoring any differences between the five schools. Although it is reasonable to assume some similarity in the SAT scores across different schools, one probably does not believe that the schools are indistinguishable. In fact, state officials assume the schools have distinct features such as student bodies with different socioeconomic statuses so that SAT scores from different schools can be substantially different. In some states in the United States, all schools are ranked on different criteria which reflects the belief that schools are different with respect to student achievement.\n\n\n\nIf one applies the “separate estimates” approach, one performs separate analyses on the different groups, and one ignores any prior knowledge about the similarity between the groups. On the other extreme, the “combined estimates” approach ignores the grouping variable and assumes that the groups are identical with respect to the response variable SAT score. Is there an alternative approach that compromises between the separate and combined estimate methods?\nLet us return to the model \\(\\textrm{Normal}(\\mu_j, \\sigma_j)\\) where \\(\\mu_j\\) is the parameter representing the mean SAT score of students in school \\(j\\). For simplicity of discussion it is assumed the standard deviation \\(\\sigma_j\\) of the \\(j\\)-th school is known. Consider the collection of five mean parameters, \\(\\{\\mu_1, \\mu_2, \\mu_3, \\mu_4, \\mu_5\\}\\) representing the means of the five schools’ SAT scores. One believes that the \\(\\mu_j\\)’s are distinct, because each \\(\\mu_j\\) depends on the characteristics of school \\(j\\), such as size and socioeconomic status. But one also believes that the mean parameters are similar in size. Imagine if you were given some information about the location of one mean, say \\(\\mu_j\\), then this information would influence your beliefs about the location of another mean \\(\\mu_k\\). One wishes to construct a prior distribution for the five mean parameters that reflects the belief that \\(\\mu_1, \\mu_2, \\mu_3, \\mu_4,\\) and \\(\\mu_5\\) are related or similar in size. This type of “similarity” prior ] allows one to combine the SAT scores of the five schools in the posterior distribution in such a way to obtain compromise estimates of the separate mean parameters.\nThe prior belief in similarity of the means is constructed in two stages.\n\n[Stage 1] The prior distribution for the \\(j\\)-th mean, \\(\\mu_j\\) is Normal, where the mean and standard deviation parameters are shared among all \\(\\mu_j\\)’s: \\[\\begin{equation}\n\\mu_j \\mid \\mu, \\tau \\sim \\textrm{Normal}(\\mu, \\tau), \\, \\, j = 1, ..., 5.\n\\label{eq:introPrior}\n\\end{equation}\\]\n[Stage 2] In the Stage 1 specification, the parameters \\(\\mu\\) and \\(\\tau\\) are unknown. So this stage assigns the parameters a prior density \\(\\pi\\). \\[\\begin{equation}\n\\mu, \\tau \\sim \\pi(\\mu, \\tau).\n\\end{equation}\\]\n\nSeveral comments can be made about this two-stage prior.\n\nSpecifying the same prior distribution for all \\(\\mu_j\\)’s at Stage 1 does not say that the \\(\\mu_j\\)’s are the same value. Instead, Stage1 indicates that the \\(\\mu_j\\)’s a priori are related and come from the same distribution. If the prior distribution \\(\\textrm{Normal}(\\mu, \\tau)\\) has a large standard deviation (that is, if \\(\\tau\\) is large), the \\(\\mu_j\\)’s can be very different from each other a priori. On the other hand, if the standard deviation \\(\\tau\\) is small, the \\(\\mu_j\\)’s will be very similar in size.\nTo follow up the previous comment, if one considers the limit of the Stage 1 prior as the standard deviation \\(\\tau\\) approaches zero, the group means \\(\\mu_j\\) will be identical. Then one is in the “combined groups” situation where one is pooling the SAT data to learn about a single population. At the other extreme, if one allows the standard deviation \\(\\tau\\) of the Stage 1 prior to approach infinity, then one is saying that the group means \\(\\mu_1, ..., \\mu_5\\) are unrelated and that leads to the separate estimates situation.\nIn the school testing example, this prior \\(\\textrm{Normal}(\\mu, \\tau)\\) distribution is a model about all \\(\\mu_j\\)’s in the U.S., i.e. the population of SAT score means corresponding to all schools in the United States. The five schools in the dataset represent a sample from all schools in the U.S.\nSince \\(\\mu\\) and \\(\\tau\\) are parameters in the prior distribution, they are called hyperparameters. Learning about \\(\\mu\\) and \\(\\tau\\) provides information about the population of \\(\\mu_j\\)’s. Naturally in Bayesian inference, one learns about \\(\\mu\\) and \\(\\tau\\) by specifying a hyperprior distribution and performing inference based on the posterior distribution. In this example, inferences about \\(\\mu\\) and \\(\\tau\\) tell us about the location and spread of the population of mean SAT scores of schools in the U.S.\n\nTo recap, one models continuous outcomes in groups through the school-specific sampling density in Equation (10.1) and the common Normal prior distribution in Equation (10.2) for the mean parameters. An important and appealing feature of this approach is learning simultaneously about each school (group) and learning about the population of schools (groups). Specifically in the current setup, the model simultaneously estimates the means for the schools (the \\(\\mu_j\\)’s) and the variation among the means (\\(\\mu\\) and \\(\\tau\\)). It will be seen that the hierarchical model posterior estimates for one school borrows information from other schools. This process is often called “partial pooling” information among groups.\nFrom the structural point of view, due to the two stages of the model, this approach is called hierarchical or multilevel modeling. In essence, hierarchical modeling takes into account information from multiple levels, acknowledging differences and similarities among groups. In the posterior analysis, one learns simultaneously about each group and learns about the population of groups by pooling information across groups.\nIn this chapter, hierarchical modeling is described in two situations that extend the Bayesian models for one proportion and one Normal mean described in Chapters 7 and 8, respectively. Section 10.2 introduces hierarchical Normal modeling using a sample of ratings of animation movies released in 2010; and Section 10.3 describes hierarchical Beta-Binomial modeling with an example of deaths after heart attack. In each section, we motivate the consideration of hierarchical models, outline the model structure, and implement model inference through Markov chain Monte Carlo simulation."
  },
  {
    "objectID": "hierarchical.html#hierarchical-normal-modeling",
    "href": "hierarchical.html#hierarchical-normal-modeling",
    "title": "5  Bayesian Hierarchical Modeling",
    "section": "5.2 Hierarchical Normal Modeling",
    "text": "5.2 Hierarchical Normal Modeling\n\n5.2.1 Example: ratings of animation movies\nMovieLens is a website which provides personalized movie recommendations from users who create accounts and rate movies that they have seen. Based on such information, MovieLens works to build a custom preference profile for each user and provide movie recommendations. MovieLens is run by GroupLens Research, a research lab at the University of Minnesota, who has made MovieLens rating datasets available to the public. GroupLens Research regularly updates these datasets on their website and the datasets are useful for new research, education and development initiatives.\nIn one study, a sample from the MovieLens database was collected on movie ratings for eight different animation movies released in 2010. There are a total of 55 movie ratings, where a rating is is for a particular animation movie completed by a MovieLens user. The ratings are likely affected by the quality of the movie itself, as some movies are generally favored by the audience while others might be less favored. Therefore there exists a natural grouping of the 55 ratings by the movie title.\n\n\n\n\n\nJittered dotplot of the ratings for the eight animation movies.\n\n\n\n\nFigure 10.1 displays a jittered dotplot of the ratings grouped by movie title and Table 10.1 lists the sample mean, sample standard deviation, and the number of ratings for each title. Note the variability in the sample sizes – “Toy Story 3’ received 16 ratings and”Legend of the Guardians” and “Batman: Under the Red Hood” only received a single rating. For a movie with only one observed rating, such as “Legend of the Guardians” and “Batman: Under the Red Hood”, it would be difficult to learn much about its mean rating. Here it is desirable to improve the estimate of its mean rating by using rating information from similar movies.\nTable 10.1. The movie title, the mean rating, the standard deviation of the ratings, and the number of ratings.\n\n\n\nMovie Title\nMean\nSD\nN\n\n\n\n\nBatman: Under the Red Hood\n5.00\n\n1\n\n\nDespicable Me\n3.72\n0.62\n9\n\n\nHow to Train Your Dragon\n3.41\n0.86\n11\n\n\nLegend of the Guardians\n4.00\n\n1\n\n\nMegamind\n3.38\n1.31\n4\n\n\nShrek Forever After\n4.00\n1.32\n3\n\n\nTangled\n4.20\n0.89\n10\n\n\nToy Story 3\n3.81\n0.96\n16\n\n\n\n\n\n5.2.2 A hierarchical Normal model with random \\(\\sigma\\)\nIn this situation it is reasonable to develop a model for the movie ratings where the grouping variable is the movie title. We index a ratings by two subscripts, where \\(Y_{ij}\\) denotes the \\(i\\)-th rating for the \\(j\\)-th movie title (\\(j = 1, \\cdots, 8\\)).\nWhat sampling model should be used for the movie ratings? Since the ratings are continuous, it is reasonable to use the Normal data model described in Chapter 8. Recall that a Normal model has two parameters, the mean and the standard deviation. Based on previous reasoning, the mean parameter is assumed to be movie-specific, so \\(\\mu_j\\) will represent the mean of the ratings for movie \\(j\\). Thinking about the standard deviation parameter, should the standard deviation also be movie-specific, where \\(\\sigma_j\\) represents the standard deviation of the ratings for movie \\(j\\)? Or can we assume a common value of the standard deviation, say \\(\\sigma\\), across movies? For simplicity and ease of illustration, a common and shared unknown standard deviation \\(\\sigma\\) is assumed for all Normal models. This is a simplified version of random \\(\\sigma_j\\)’s — the more flexible hierarchical model with random \\(\\sigma_j\\)’s will be left as an end-of-chapter exercise.\nOne begins by writing down the sampling distributions for the ratings of the eight movies. Recall that \\(Y_{ij}\\) denotes the \\(i\\)-th rating of movie \\(j\\), where \\(\\mu_j\\) denote the mean of the Normal model for movie \\(j\\), and \\(\\sigma\\) denote the shared standard deviation of the Normal models across different movies. In our notation, \\(n_j\\) represents the number of ratings for movie \\(j\\).\n\nSampling, for \\(j = 1, \\cdots, 8\\) and \\(i = 1, \\cdots, n_j\\): \\[\\begin{equation}\nY_{ij} \\mid \\mu_j, \\sigma \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu_j, \\sigma).\n\\end{equation}\\]\n\nThe next task is to set up a prior distribution for the eight mean parameters, \\(\\{\\mu_1, \\mu_2, \\cdots, \\mu_8\\}\\) and the shared standard deviation parameter \\(\\sigma\\). Focus first on the prior distribution for the mean parameters. Since these movies are all animations, it is reasonable to believe that the mean ratings are similar across movies. So one assigns each mean rating the same Normal prior distribution at the first stage:\n\nPrior for \\(\\mu_j\\), \\(j = 1, \\cdots, 8\\): \\[\\begin{equation}\n\\mu_j \\mid \\mu, \\tau \\sim \\textrm{Normal}(\\mu, \\tau).\n\\end{equation}\\]\n\nAs discussed in Section 10.1, this prior allows for a flexible method for pooling information across movies. If the prior distribution has a large standard deviation (e.g. a large value of \\(\\tau\\)), the \\(\\mu_j\\)’s are very different from each other a priori, and one would have modest pooling of the eight sets of ratings. If instead this prior has a small standard deviation (e.g. a small value of \\(\\tau\\)), the \\(\\mu_j\\)’s are very similar a priori and one would essentially be pooling the ratings to get an estimate at each of the \\(\\mu_j\\). This shared prior \\(\\textrm{Normal}(\\mu, \\tau)\\) distribution among the \\(\\mu_j\\)’s simultaneously estimates both a mean for each movie (the \\(\\mu_j\\)’s) and also lets us learn about variation among the movies by the parameter \\(\\tau\\).\nThe hyperparameters \\(\\mu\\) and \\(\\tau\\) are treated as random since we are unsure about the degree of pooling of the eight sets of ratings. In typical practice, one specifies weakly informative hyperprior distributions for these “second-stage” parameters, indicating that one has little prior knowledge about the locations of these parameters. After observing data, inference is performed about \\(\\mu\\) and \\(\\tau\\) based on their posterior distributions. The posterior on the mean parameter \\(\\mu\\) is informative about an “average” mean rating and the posterior on \\(\\tau\\) lets one know about the variation among the \\(\\mu_j\\)’s in the posterior.\nTreating \\(\\mu\\) and \\(\\tau\\) as random, one arrives at the following hierarchical model.\n\nSampling: for \\(j = 1, \\cdots, 8\\) and \\(i = 1, \\cdots, n_j\\): \\[\\begin{equation}\nY_{ij} \\mid \\mu_j, \\sigma \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu_j, \\sigma).\n\\label{eq:NormalLik}\n\\end{equation}\\]\nPrior for \\(\\mu_j\\), Stage 1: \\(\\mu_j\\), \\(j = 1, \\cdots, 8\\): \\[\\begin{equation}\n\\mu_j \\mid \\mu, \\tau \\sim \\textrm{Normal}(\\mu, \\tau).\n\\label{eq:NormalMuPrior}\n\\end{equation}\\]\nPrior for \\(\\mu_j\\), Stage 2: \\[\\begin{equation}\n\\mu, \\tau \\sim \\pi(\\mu, \\tau).\n\\label{eq:NormalMuHyperprior}\n\\end{equation}\\]\n\nIn our model \\(\\pi(\\mu, \\tau)\\) denotes an arbitrary joint hyperprior distribution for the “Stage 2” hyperparameters \\(\\mu\\) and \\(\\tau\\). When the MovieLens ratings dataset is analyzed, the specification of this hyperprior distribution will be described.\nTo complete the model, one needs to specify a prior distribution for the standard deviation parameter, \\(\\sigma\\). As discussed in Chapter 9, when making inference about the standard deviation in a Normal model, one uses a Gamma prior on the precision (the inverse of the variance), for example,\n\nPrior for \\(\\sigma\\): \\[\\begin{eqnarray}\n1/\\sigma^2 \\mid a_{\\sigma}, b_{\\sigma}  &\\sim& \\textrm{Gamma}(a_{\\sigma}, b_{\\sigma})\n\\label{eq:NormalSigmaPrior}\n\\end{eqnarray}\\]\n\nOne assigns a known Gamma prior distribution for \\(1/\\sigma^2\\), with fixed hyperparameter values \\(a_{\\sigma}\\) and \\(b_{\\sigma}\\). In some situations, one may consider the situation where \\(a_{\\sigma}\\) and \\(b_{\\sigma}\\) are random and assign hyperprior distributions for these unknown hyperparameters.\nBefore continuing to the graphical representation and simulation by MCMC using JAGS, it is helpful to contrast the two-stage prior distribution for {\\(\\mu_j\\)} and the one-stage prior distribution for \\(\\sigma\\). The hierarchical model specifies a common prior for the means \\(\\mu_j\\)’s which induces sharing of information across ratings from different movies. On the other hand, the model uses a shared \\(\\sigma\\) for all movies which also induces sharing of information, though different from the sharing induced by the two-stage prior distribution for {\\(\\mu_j\\)}.\nWhat is the difference between the two types of sharing? For the means {\\(\\mu_j\\)}, we have discussed that specifying a common prior distribution for different \\(\\mu_j\\)’s pools information across the movies. One is simultaneously estimating both a mean for each movie (the \\(\\mu_j\\)’s) and the variation among the movies (\\(\\mu\\) and \\(\\tau\\)). For the standard deviation \\(\\sigma\\), the hierarchical model also pools information across movies. However, all of the observations are combined in the estimation of \\(\\sigma\\). Since separate values of \\(\\sigma_j\\)’s are not assumed, one cannot learn about the differences and similarities among the \\(\\sigma_j\\)’s. If one is interested in pooling information across movies for the \\(\\sigma_j\\)’s, one needs to allow random \\(\\sigma_j\\)’s, and specify a two-stage prior distribution for these parameters. Interested readers are encouraged to try out this approach as an end-of-chapter exercise.\nGraphical representation of the hierarchical model\nAn alternative way of expressing this hierarchical model uses the following graphical representation.\n\n\n\n\n\nIn the middle section of the graph, \\(\\{Y_{ij}\\}\\) represents the collection of random variables for all ratings of movie \\(j\\), and the label to the left indicates the assumed Normal sampling distribution. The two parameters in the Normal sampling density, \\(\\mu_j\\) and \\(\\sigma\\), are connected from above and below, with arrows pointing from the parameters to the random variables.\nThe upper section of the graph focuses on the \\(\\mu_j\\)’s. All means follow the same prior, a Normal distribution with mean \\(\\mu\\) and standard deviation \\(\\tau\\). Therefore, arrows come from the common hyperparameters \\(\\mu\\) and \\(\\tau\\) to each \\(\\mu_j\\). Since \\(\\mu\\) and \\(\\tau\\) are random, these second-stage parameters are associated with the prior label \\(\\pi(\\mu, \\tau)\\).\nThe lowest section of the graph is about \\(\\sigma\\), or to be precise, \\(1/\\sigma^2\\). If one wants to allow hyperparameters \\(a_{\\sigma}\\) and \\(b_{\\sigma}\\) to be random as well, the lower part of the graph grows further, in a similar manner as the upper section for \\(\\mu_j\\).\nSecond-stage prior\nThe hierarchical Normal model presented in Equations (10.6) through (10.9) has not specified the hyperprior distribution \\(\\pi(\\mu, \\tau)\\). How does one construct a prior on these second-stage hyperparameters?\nRecall that \\(\\mu\\) and \\(\\tau\\) are parameters for the Normal prior distribution for {\\(\\mu_j\\)} the collection of eight different Normal sampling means. The mean \\(\\mu\\) and standard deviation \\(\\tau\\) in this Normal prior distribution reflect respectively the mean and spread of the mean ratings across eight different movies.\nFollowing the discussion in Section 9.5.3, a typical approach for Normal models is to assign two independent prior distributions — a Normal distribution for the mean \\(\\mu\\) and a Gamma distribution for the precision \\(1 / \\tau^2\\). Such a specification facilitates the use of the Gibbs sampling due to the availability of the conditional posterior distributions of both parameters (see the details of this work in Section 9.5.3). Using this approach, the density \\(\\pi(\\mu, \\tau)\\) is replaced by the two hyperprior distributions below.\n\nThe hyperprior for \\(\\mu\\) and \\(\\tau\\): \\[\\begin{equation}\n\\mu \\mid \\mu_0, \\gamma_0 \\sim  \\textrm{Normal}(\\mu_0, \\gamma_0)\n\\end{equation}\\] \\[\\begin{equation}\n1/\\tau^2 \\mid a, b  \\sim \\textrm{Gamma}(a_{\\tau}, b_{\\tau})\n\\end{equation}\\]\n\nThe task of choosing a prior for \\((\\mu, \\tau)\\) reduces to the problem of choosing values for the four hyperparameters \\(\\mu_0, \\gamma_0, a_{\\tau}\\), and \\(b_{\\tau}\\). If one believes that \\(\\mu\\) is located around the value of 3 and she is not very confident of this choice, the set of values \\(\\mu_0 = 3\\) and \\(\\gamma_0 = 1\\) could be chosen. As for \\(\\tau\\), one chooses a weakly informative prior with \\(a_{\\tau} = b_{\\tau} = 1\\), as \\(\\textrm{Gamma}(1, 1)\\). Moreover, to choose a prior for \\(\\sigma\\), let \\(a_{\\sigma} = b_{\\sigma} = 1\\) to have the weakly informative \\(\\textrm{Gamma}(1, 1)\\) prior.\n\n\n5.2.3 Inference through MCMC\nWith the specification of the prior, the complete hierarchical model is described as follows:\n\nSampling: for \\(j = 1, \\cdots, 8\\) and \\(i = 1, \\cdots, n_j\\): \\[\\begin{equation}\nY_{ij} \\mid \\mu_j, \\sigma_j \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu_j, \\sigma_j)\n\\end{equation}\\]\nPrior for \\(\\mu_j\\), Stage 1: for \\(j = 1, \\cdots, 8\\): \\[\\begin{equation}\n\\mu_j \\mid \\mu, \\tau \\sim \\textrm{Normal}(\\mu, \\tau)\n\\end{equation}\\]\nPrior for \\(\\mu_j\\), Stage 2: the hyperpriors: \\[\\begin{equation}\n\\mu \\sim \\textrm{Normal}(3, 1)\n\\end{equation}\\] \\[\\begin{equation}\n1/\\tau^2  \\sim \\textrm{Gamma}(1, 1)\n\\end{equation}\\]\nPrior for \\(\\sigma\\): \\[\\begin{equation}\n1/\\sigma^2  \\sim \\textrm{Gamma}(1, 1)\n\\end{equation}\\]\n\nIf one uses JAGS for simulation by MCMC, one writes out the model section by following the model structure above closely. Review Section 9.7 for an introduction and a description of several examples of JAGS.\nDescribe the model by a script\nThe first step in using the JAGS software is to write the following script defining the hierarchical model. The model is saved in the character string modelString.\n\nmodelString <-\"\nmodel {\n## sampling\nfor (i in 1:N){\n   y[i] ~ dnorm(mu_j[MovieIndex[i]], invsigma2)\n}\n## priors\nfor (j in 1:J){\n   mu_j[j] ~ dnorm(mu, invtau2)\n}\ninvsigma2 ~ dgamma(a_s, b_s)\nsigma <- sqrt(pow(invsigma2, -1))\n## hyperpriors\nmu ~ dnorm(mu0, g0)\ninvtau2 ~ dgamma(a_t, b_t)\ntau <- sqrt(pow(invtau2, -1))\n}\n\"\n\nIn the sampling part of the script, note that the loop goes from 1 to N, where N is the number of observations with index i. However, because now N observations are grouped according to movies, indicated by j, one needs to create one vector, mu_j of length eight, and use MovieIndex[i] to grab the corresponding mu_j based on the movie index.\nIn the priors part of the script, the loop goes from 1 to J, and J = 8 in the current example. Inside the loop, the first line corresponds to the prior distribution for mu_j. Due to a commonly shared sigma, invsigma2 follows dgamma(a_g, b_g) outside of the loop. In addition, sigma <- sqrt(pow(invsigma2, -1)) is added to help track sigma directly.\nFinally in the hyperpriors section of the script, one specifies the Normal hyperprior for mu, a Gamma hyperprior for invtau2. Keep in mind that the arguments in the dnorm in JAGS are the mean and the precision. If one is interested instead in the standard deviation parameter tau, one could return it in the script by using tau <- sqrt(pow(invtau2, -1)), enabling the tracking of its MCMC chain in the posterior inferences.\nDefine the data and prior parameters\nAfter one has defined the model script, the next step is to provide the data and values for parameters of the prior. In the R script below, a list the_data contains the vector of observations, the vector of movie indices, the number of observations, and the number of movies. It also contains the Normal hyperparameters mu0 and g0, and two sets of Gamma hyperparameters (a_t and b_t) for invtau2, and (a_s and b_s) for invsigma2.\n\nlibrary(ProbBayes)\ny <- animation_ratings$rating      \nMovieIndex <- animation_ratings$Group_Number      \nN <- length(y)  \nJ <- length(unique(MovieIndex)) \nthe_data <- list(\"y\" = y, \"MovieIndex\" = MovieIndex, \n                 \"N\" = N, \"J\" = J,\n                 \"mu0\" = 3, \"g0\" = 1,\n                 \"a_t\" = 1, \"b_t\" = 1,\n                 \"a_s\" = 1, \"b_s\" = 1)\n\nOne uses the run.jags() function in the runjags R package to generate posterior samples by using the MCMC algorithms in JAGS. The script below runs one MCMC chain with 1000 iterations in the adapt period (preparing for MCMC), 5000 iterations of burn-in and an additional set of 5000 iterations to be run and collected for inference. By using monitor = c(\"mu\", \"tau\", \"mu_j\", \"sigma\"), one collects the values of all parameters in the model. In the end, the output variable posterior contains a matrix of simulated draws.\n```{r}\nposterior <- run.jags(modelString,\n                      n.chains = 1,\n                      data = the_data,\n                      monitor = c(\"mu\", \"tau\", \"mu_j\", \"sigma\"),\n                      adapt = 1000,\n                      burnin = 5000,\n                      sample = 5000)\n```\nMCMC diagnostics and summarization\nIn any implementation of MCMC sampling, diagnostics are crucial to perform to ensure convergence. To perform some MCMC diagnostics in our example, one uses the plot() function, specifying the variable to be checked by the vars argument. For example, the script below returns four diagnostic plots (trace plot, empirical PDF, histogram, and autocorrelation plot) in Figure 10.2 for the hyperparameter \\(\\tau\\). Note that the trace plot only includes 5000 iterations in sample, although its index starts from adapt (1000 adapt + 5000 burn-in). The trace plot and autocorrelation plot suggest good mixing of the chain, therefore indicating convergence of the MCMC chain for \\(\\tau\\).\nplot(posterior, vars = \"tau\")\n\n\n\n\n\nDiagnostic plots of simulated draws of \\(\\tau\\) using the JAGS software with the runjags package.\n\n\n\n\nIn practice MCMC diagnostics should be performed for all parameters to justify the overall MCMC convergence. In our example, the above diagnostics should be implemented for each of the eleven parameters in the model: \\(\\mu, \\tau, \\mu_1, \\mu_2, \\cdots, \\mu_8\\), and \\(\\sigma\\). Once diagnostics are done, one reports posterior summaries of the parameters using print(). Note that these summaries are based on the 5000 iterations from the sample period, excluding the adapt and burn-in iterations.\nprint(posterior, digits = 3)                                                                                     \n        Lower95 Median Upper95  Mean     SD Mode   MCerr \nmu         3.19   3.78    4.34  3.77  0.286   -- 0.00542     \ntau       0.357  0.638    1.08 0.677    0.2   -- 0.00365  \nmu_j[1]    2.96   3.47    3.99  3.47  0.262   -- 0.00376  \nmu_j[2]    3.38   3.81    4.25  3.82  0.221   -- 0.00313    \nmu_j[3]    3.07   3.91    4.75  3.91  0.425   -- 0.00677    \nmu_j[4]    3.21   3.74    4.31  3.74  0.285   -- 0.00428 \nmu_j[5]    3.09   4.15    5.43  4.18  0.588   --  0.0115   \nmu_j[6]     2.7   3.84    4.99  3.85  0.576   -- 0.00915   \nmu_j[7]    2.74   3.53    4.27  3.51  0.388   -- 0.00595  \nmu_j[8]    3.58   4.12    4.66  4.12  0.276   -- 0.00423  \nsigma     0.763   0.92    1.12  0.93 0.0923   -- 0.00142 \nOne performs various inferential summaries and inferences based on the output. For example, the movies “How to Train Your Dragon” (corresponding to \\(\\mu_1\\)) and “Megamind” (corresponding to \\(\\mu_7\\)) have the lowest average ratings with short 90% credible intervals, (2.96, 3.99) and (2.74, 4.27) respectively, whereas “Legend of the Guardians: The Owls of Ga’Hoole” (corresponding to \\(\\mu_6\\)) also has a low average rating but with a wider 90% credible interval (2.70, 4.99). The differences in the width of the credible intervals stem from the sample sizes: there are eleven ratings for “How to Train Your Dragon”, four ratings for “Megamind”, and only a single rating for “Legend of the Guardians: The Owls of Ga’Hoole”. The smaller the sample size, the larger the variability in the inference, even if one pools information across groups.\nAmong the movies with high average ratings, “Batman: Under the Red Hood” (corresponding to \\(\\mu_5\\)) is worth noting. This movie’s average rating \\(\\mu_5\\) has the largest median value among all \\(\\mu_j\\)’s, at 4.15, and also a wide 90% credible interval, (3.09, 5.43). “Batman: Under the Red Hood” also received one rating in the sample resulting in a wide credible interval.\nShrinkage\nRecall that the two-stage prior in Equations (10.7) to (10.8) specifies a shared prior \\(\\textrm{Normal}(\\mu, \\tau)\\) for all \\(\\mu_j\\)’s which facilitates simultaneous estimation of the movie mean ratings (the \\(\\mu_j\\)’s), and estimation of the variation among the movie mean ratings through the parameters \\(\\mu\\) and \\(\\tau\\). The posterior mean of the rating for a particular movie \\(\\mu_j\\) shrinks the observed mean rating towards an average rating.\nFigure 10.3 displays a “shrinkage plot” which illustrates the movement of the observed sample mean ratings towards an average rating.\n\n\n\n\n\nShrinkage plot of sample means and posterior means of movie ratings for eight movies.\n\n\n\n\nThe left side of Figure 10.3 plots the sample movie rating means and lines connect the sample means to the corresponding posterior means (i.e. means of the posterior draws of \\(\\mu_j\\)). The shrinkage effect is obvious for the movie “Batman: Under the Red Hood” which corresponds to the dot at the value 5.0 on the left. This movie only received one rating of 5.0 and its mean rating \\(\\mu_5\\) shrinks to the value 4.178 on the right, which is still the highest posterior mean among the nine movie posterior means. A large shrinkage is desirable for a movie with a small number of ratings such as “Batman: Under the Red Hood”. For a movie with a small sample size, information about other ratings of similar movies helps to produce a more reasonable estimate at the “true” average movie rating. The amount of shrinkage is more modest for movies with larger sample sizes. Furthermore, by pooling ratings across movies, one is able to estimate the standard deviation \\(\\sigma\\) of the ratings. Without this pooling, one would be unable to estimate the standard deviation for a movie with only one rating.\nSources of variability\nAs discussed in Section 10.1, the prior distribution \\(\\textrm{Normal}(\\mu, \\tau)\\) is shared among the means \\(\\mu_j\\)’s of all groups in a hierarchical Normal model, and the hyperparameters \\(\\mu\\) and \\(\\tau\\) provide information about the population of \\(\\mu_j\\)’s. Specifically, the standard deviation \\(\\tau\\) measures the variability among the \\(\\mu_j\\)’s. When the hierarchical model is estimated through MCMC, summaries from the simulation draws from the posterior of \\(\\tau\\) provide information about this source of variation after analyzing the data.\nThere are actually two sources for the variability among the observed \\(Y_{ij}\\)’s. At the sampling level of the model, the standard deviation \\(\\sigma\\) measures variability of the \\(Y_{ij}\\) within the groups. In contrast, the parameter \\(\\tau\\) measures the variability in the measurements between the groups. When the hierarchical model is fit through MCMC, summaries from the marginal posterior distributions of \\(\\sigma\\) and \\(\\tau\\) provide information about the two sources of variability.\n\\[\\begin{equation}\nY_{ij} \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu_j, \\sigma) \\,\\,\\, \\text{[within-group variability]}\n\\end{equation}\\] \\[\\begin{equation}\n\\mu_j \\mid \\mu, \\tau \\sim \\textrm{Normal}(\\mu, \\tau) \\,\\,\\, \\text{[between-group variability]}\n\\end{equation}\\]\nThe Bayesian posterior inference in the hierarchical model is able to compare these two sources of variability, taking into account the prior belief and the information from the data. One initially provides prior beliefs about the values of the standard deviations \\(\\sigma\\) and \\(\\tau\\) through Gamma distributions. In the MovieLens ratings application, weakly informative priors of \\(\\textrm{Gamma}(1, 1)\\) are assigned to both \\(\\sigma\\) and \\(\\tau\\). These prior distributions assume a priori the within-group variability, measured by \\(\\sigma\\), is believed to be the same size as the between-group variability measured by \\(\\tau\\).\nWhat can be said about these two sources of variability after the estimation of the hierarchical model? As seen in the output of print(posterior, digits = 3), the 90% credible interval for \\(\\sigma\\) is (0.763, 1.12) and the 90% credible interval for \\(\\tau\\) is (0.357, 1.08). After observing the data, the within-group variability in the measurements is estimated to be larger than the between-group variability.\nTo compare these two sources of variation one computes the fraction \\(R = \\frac{\\tau^2}{\\sigma^2 + \\tau^2}\\) from the posterior samples of \\(\\sigma\\) and \\(\\tau\\). The interpretation of \\(R\\) is that it represents the fraction of the total variability in the movie ratings due to the differences between groups. If the value of \\(R\\) is close to 1, most of the total variability is attributed to the between-group variability. On the other side, if \\(R\\) is close to 0, most of the variation is within groups and there is little significant differences between groups.\nSample code shown below computes simulated values of \\(R\\) from the MCMC output. A density plot of \\(R\\) is shown in Figure 10.4.\ntau_draws <- as.mcmc(posterior, vars = \"tau\")\nsigma_draws <- as.mcmc(posterior, vars = \"sigma\")\nR <- tau_draws ^ 2 / (tau_draws ^ 2 + sigma_draws ^ 2)\nA 95% credible interval for \\(R\\) is (0.149, 0.630). Since much of the posterior probability of \\(R\\) is located below the value 0.5, this confirms that the variation between the mean movie rating titles is smaller than the variation of the ratings within the movie titles in this example.\n\n\n\n\n\nDensity plot of the ratio \\(R\\) from the posterior samples of tau and sigma."
  },
  {
    "objectID": "hierarchical.html#hierarchical-beta-binomial-modeling",
    "href": "hierarchical.html#hierarchical-beta-binomial-modeling",
    "title": "5  Bayesian Hierarchical Modeling",
    "section": "5.3 Hierarchical Beta-Binomial Modeling",
    "text": "5.3 Hierarchical Beta-Binomial Modeling\n\n5.3.1 Example: Deaths after heart attack\nThe New York State (NYS) Department of Health collects and releases data on mortality after Acute Myocardial Infarction (AMI), commonly known as a heart attack. Their 2015 report was the initial public data release by the NYS Department of Health on risk-adjusted mortality outcomes for AMI patients at hospitals across the state. We focus on 13 hospitals in Manhattan, New York City, with the goal of learning about the percentages of resulted deaths from heart attack for hospitals in this sample. Table 10.2 records for each hospital the number of heart attack cases, the corresponding number of resulted deaths, and their computed percentage of resulted deaths.\nTable 10.2. The number of heart attack cases, the number of resulted deaths, and the percentage of resulted deaths of 13 hospitals in New York City - Manhattan in 2015. NYP stands for New York Presbyterian.\n\n\n\n\n\n\n\n\n\nHospital\nCases\nDeaths\nDeath %\n\n\n\n\nBellevue Hospital Center\n129\n4\n3.101\n\n\nHarlem Hospital Center\n35\n1\n2.857\n\n\nLenox Hill Hospital\n228\n18\n7.894\n\n\nMetropolitan Hospital Center\n84\n7\n8.333\n\n\nMount Sinai Beth Israel\n291\n24\n8.247\n\n\nMount Sinai Hospital\n270\n16\n5.926\n\n\nMount Sinai Roosevelt\n46\n6\n13.043\n\n\nMount Sinai St. Luke’s\n293\n19\n6.485\n\n\nNYU Hospitals Center\n241\n15\n6.224\n\n\nNYP Hospital - Allen Hospital\n105\n13\n12.381\n\n\nNYP Hospital - Columbia Presbyterian Center\n353\n25\n7.082\n\n\nNYP Hospital - New York Weill Cornell Center\n250\n11\n4.400\n\n\nNYP/Lower Manhattan Hospital\n41\n4\n9.756\n\n\n\n\n\n5.3.2 A hierarchical Beta-Binomial model\nTreating “cases” as trials and “deaths” as successes, the Binomial sampling model is a natural choice for this data, and the objective is to learn about the death probability \\(p\\) of the hospitals. If one looks at the actual death percentages in Table \\(\\ref{table:DeathData}\\), some hospitals have much higher death rates than other hospitals. For example, the highest death rate belongs to Mount Sinai Roosevelt, at 13.043% which is more than four times the rate of Harlem Hospital Center at 2.857%. If one assumes a common probability \\(p\\) for all thirteen hospitals, this model does not allow for possible differences between the death rates among these hospitals.\nOn the other hand, if one creates thirteen separate Binomial sampling models, one for each hospital, and conducts separate inferences, one loses the ability to use potential information about the death rate from hospital \\(j\\) when making inference about that of a different hospital \\(i\\). Since these are all hospitals in Manhattan, New York City, they may share attributes in common related to death rates from heart attack. The separate modeling approach does not allow for the sharing of information across hospitals.\nA hierarchical model provides a compromise between the combined and separate modeling approaches. In Section 10.2, a hierarchical Normal density was used to model mean rating scores from different movies. In this setting, one builds a hierarchical model by assuming the hospital death rate parameters a priori come from a common distribution. Specifically, one builds a hierarchical model based on a common Beta distribution that generalizes the Beta-Binomial conjugate model described in Chapter 7. This modeling setup provides posterior estimates that partially pool information among hospitals\nLet \\(Y_i\\) denote the number of resulted deaths from heart attack, \\(n_i\\) the number of heart attack cases, and \\(p_i\\) the death rate for hospital \\(i\\). The sampling density for \\(Y_i\\) for hospital \\(i\\) is a Binomial distribution with \\(n_i\\) and \\(p_i\\), as in Equation (10.19). Suppose that the proportions {\\(p_i\\)} independently follow the same conjugate Beta prior distribution, as in Equation (10.20). So the sampling and first stage of the prior of our model is written as follows:\n\nSampling, for \\(i, \\cdots, 13\\): \\[\\begin{equation}\nY_i \\sim \\textrm{Binomial}(n_i, p_i)\n\\label{eq:BetaBinomialLik_v1}\n\\end{equation}\\]\nPrior for \\(p_i\\), \\(i = 1, \\cdots, 13\\): \\[\\begin{equation}\np_i \\sim \\textrm{Beta}(a, b)\n\\label{eq:BetaBinomialPrior_v1}\n\\end{equation}\\]\n\nNote that the hyperparameters \\(a\\) and \\(b\\) are shared among all hospitals. If \\(a\\) and \\(b\\) are known values, then the posterior inference for \\(p_i\\) of hospital \\(i\\) is simply another Beta distribution by conjugacy (review material in Chapter 7 if needed): \\[\\begin{equation}\np_i \\mid y_i \\sim \\textrm{Beta}(a + y_i, b + n_i - y_i).\n\\end{equation}\\]\nIn the general situation where the hyperparameters \\(a\\) and \\(b\\) are unknown, a second stage of the prior \\(\\pi(a, b)\\) needs to specified for these hyperparameters. With this specification, one arrives at the hierarchical model below.\n\nSampling, for \\(i, \\cdots, 13\\): \\[\\begin{equation}\nY_i \\sim \\textrm{Binomial}(n_i, p_i)\n\\label{eq:BetaBinomialLik_v2}\n\\end{equation}\\]\nPrior for \\(p_i\\), Stage1: for \\(i = 1, \\cdots, 13\\): \\[\\begin{equation}\np_i \\sim \\textrm{Beta}(a, b)\n\\label{eq:BetaBinomialPrior_v2}\n\\end{equation}\\]\nPrior for \\(p_i\\), Stage 2: the hyperprior: \\[\\begin{eqnarray}\na, b \\sim \\pi(a, b)\n\\label{eq:BetaBinomialHyperprior_v1}\n\\end{eqnarray}\\]\n\nWee use \\(\\pi(a, b)\\) to denote an arbitrary distribution for the joint hyperprior distribution for \\(a\\) and \\(b\\). When we start analyzing the New York State heart attack death rate dataset, the specification of this hyperprior distribution \\(\\pi(a, b)\\) will be described.\nGraphical representations of the hierarchical model\nBelow is a sketch of a graphical representation of the hierarchical Beta-Binomial model.\n\n\n\n\n\nFocusing on the graph on the right, one sees that the upper section of the graph represents the sampling density, with the arrow directing from \\(p_i\\) to \\(Y_i\\). Here the start of the arrow is the parameter and the end of the arrow is the random variable. The lower section of the graph represents the prior, with arrows directing from \\(a\\) and \\(b\\) to \\(p_i\\). In this case, the start of the arrow is the hyperparameter and the end of the arrow is the parameter.\nOn the left side of the display, the sampling density, prior and hyperprior distributional expressions are written next to the graphical representation.\nIn the situation where the Beta parameters \\(a\\) and \\(b\\) are known constants, the graphical representation changes to the Beta-Binomial conjugate model displayed below.\n\n\n\n\n\nTo illustrate another graphical representation, we display below the one for the separate models approach in the hospitals death rate application where a fully specified Beta prior is specified for each death rate. The separate models are represented by thirteen graphs, one for each hospital. This graphical structure shows clearly the separation of the subsamples and the resulting separation of the corresponding Bayesian posterior distributions.\n\n\n\n\n\nIn comparing graphical representations for hierarchical models, the interested reader might notice that the structure for the hierarchical Beta-Binomial model looks different from the ones in Section 10.2 for the hierarchical Normal models. In this chapter, one is dealing with one-parameter models (recall that Beta-Binomial is an example of one-parameter models; other examples include Gamma-Poisson), whereas the Normal models in Section 10.2 involve two parameters. Typically, when working with one-parameter models, one starts from the top with the sampling density, then next writes down the priors and continues with the hyperpriors. When there are multiple parameters, one needs to be careful in describing the graphical structure. In fact, for a large number of parameters, a good graphical representation might not be feasible. In that case, one writes a representation that focuses on the key parts of the model.\nAlso note that there is no unique way of sketching a graphical representation, as long as the representation is clear and shows the relationship among the random variables, parameters and hyperparameters with the arrows in the correct directions.\n\n\n5.3.3 Inference through MCMC\nIn this section the application of JAGS script for simulation by MCMC is illustrated for the hierarchical Beta-Binomial models for the New York State heart attach death rate dataset. Before this is done, we discuss the specification of the hyperprior density \\(\\pi(a, b)\\) for the hyperparameters \\(a\\) and \\(b\\) for the common Beta prior distribution for the proportions \\(p_i\\)’s.\nSecond-stage prior\nIn Chapter 7, the task was to specify the values of \\(a\\) and \\(b\\) for a single Beta curve \\(\\textrm{Beta}(a, b)\\) and the Beta shape parameter values were selected by trial-and-error using the beta.select() function in the ProbBayes package. In this hierarchical model setting, the shape parameters \\(a\\) and \\(b\\) are random and the goal is learn about these parameters from its posterior distribution.\nIn this prior construction, it is helpful to review some facts on Beta curves from Chapter 7. For a \\(\\textrm{Beta}(a, b)\\) prior distribution for a proportion \\(p\\), one considers the parameter \\(a\\) as the prior count of “successes”, the parameter \\(b\\) as the prior count of “failures”, and the sum \\(a + b\\) represents the prior sample size. Also the expectation of \\(\\textrm{Beta}(a, b)\\) is \\(\\frac{a}{a + b}\\). From these facts, a more natural parameterization of the hyperprior distribution \\(\\pi(a, b)\\) is \\(\\pi(\\mu, \\eta)\\), where \\(\\mu = \\frac{a}{a+b}\\) is the hyperprior mean and \\(\\eta = a + b\\) is the hyperprior sample size. One rewrites the hyperprior distribution in terms of the new parameters \\(\\mu\\) and \\(\\eta\\) as follows: \\[\\begin{equation}\n\\mu, \\eta \\sim \\pi(\\mu, \\eta),\n\\label{eq:BetaBinomialHyperprior_v2}\n\\end{equation}\\] where \\(a = \\mu\\eta\\) and \\(b = (1-\\mu)\\eta\\). These expressions are useful in writing the JAGS script for the hierarchical Beta-Binomial Bayesian model.\nA hyperprior is constructed from the \\((\\mu, \\eta)\\) representation. Assume \\(\\mu\\) and \\(\\eta\\) are independent which means that one’s beliefs about the prior mean are independent of the beliefs about the prior sample size. The hyperprior expectation \\(\\mu\\) is the mean measure for \\(p_i\\), the average death rate across 13 hospitals. If one has little prior knowledge about the expectation \\(\\mu\\), one assigns this parameter a Uniform prior which is equivalent to a \\(\\textrm{Beta}(1, 1)\\) prior.\nTo motivate the prior choice for the hyperparameter sample size \\(\\eta\\), consider the case where the hyperparameter values are known. If \\(y^*\\) and \\(n^*\\) are respectively the number of deaths and number of cases for one hospital, then the posterior mean of death rate parameter \\(p^*\\) is given by \\[\\begin{equation}\nE(p^* \\mid y^*) = \\frac{y^* + \\mu \\eta }{n^* + \\eta}.\n\\end{equation}\\] With a little algebra, the posterior mean is rewritten as \\[\\begin{equation}\nE(p^* \\mid y^*) = (1 - \\lambda) \\frac{y^*}{n^*} + \\lambda \\mu,\n\\end{equation}\\] where \\(\\lambda\\) is the shrinkage fraction \\[\\begin{equation}\n\\lambda = \\frac{\\eta}{n^* + \\eta}.\n\\end{equation}\\] The parameter \\(\\lambda\\) falls in the interval (0, 1) and represents the degree of shrinkage of the posterior mean away from the sample proportion \\(y^* / n^*\\) towards the prior mean \\(\\mu\\).\nSuppose one believes a priori that, for a representative sample size \\(n^*\\), the shrinkage \\(\\lambda\\) is Uniformly distributed on (0, 1). By performing a transformation, this implies that the prior density for the prior sample size \\(\\eta\\) has the form \\[\\begin{equation}\n\\pi(\\eta) = \\frac{n^*}{(n^* + \\eta)^2}, \\, \\, \\eta > 0.\n\\end{equation}\\] Equivalently, the logarithm of \\(\\eta\\), \\(\\theta = \\log \\eta\\), has a Logistic distribution with location \\(\\log n^*\\) and scale 1. We represent this distribution as \\(\\textrm{Logistic}(\\log n^*, 1)\\), with pdf: \\[\\begin{equation}\n\\pi(\\theta) = \\frac{e^{-(\\theta - \\log n^*)}}\n{(1 + e^{-(\\theta - \\log n^*)})^2}.\n\\end{equation}\\]\nWith this specification of the hyperparameter distribution, one writes down the complete hierarchical model as follows:\n\nSampling, for \\(i, \\cdots, 13\\): \\[\\begin{equation}\nY_i \\sim \\textrm{Binomial}(n_i, p_i)\n\\label{eq:BetaBinomialLik_v3}\n\\end{equation}\\]\nPrior for \\(p_i\\), Stage 1: for \\(i = 1, \\cdots, 13\\): \\[\\begin{equation}\np_i \\sim \\textrm{Beta}(a, b)\n\\label{eq:BetaBinomialPrior_v3}\n\\end{equation}\\]\nPrior for \\(p_i\\), Stage 2: \\[\\begin{equation}\n\\mu \\sim \\textrm{Beta}(1, 1),\n\\end{equation}\\] \\[\\begin{equation}\n\\log \\eta \\sim \\textrm{Logistic}(\\log n^*, 1)\n\\end{equation}\\] where \\(a = \\mu\\eta\\) and \\(b = (1-\\mu)\\eta\\).\n\nWriting the JAGS script\nFollowing this model structure above, one writes out the model section of the JAGS script for the hierarchical Beta-Binomial model. The model script is saved in modelString.\nmodelString <-\"\nmodel {\n## likelihood\nfor (i in 1:N){\n   y[i] ~ dbin(p[i], n[i])\n}\n## priors\nfor (i in 1:N){\n   p[i] ~ dbeta(a, b)\n}\n## hyperpriors\na <- mu*eta\nb <- (1-mu)*eta\nmu ~ dbeta(mua, mub)\neta <- exp(logeta)\nlogeta ~ dlogis(logn, 1)\n}\n\"\nIn the sampling part of the script, the loop goes from 1 to N, where N is the total number of observations, with index i. Another loop going from 1 to N is needed for the priors as each p[i] follows the same dbeta(a, b) distribution. The hyperpriors section uses the new parameterization of the \\(Beta(a, b)\\) distribution in terms of mu and eta. Here one expresses the hyperparameters a and b in terms of the new hyperparameters mu and eta, and then assigns to the parameters mu and logeta the independent distributions dbeta(mua, mub) and dlogist(logn, 1), respectively. One also needs to transform logeta to eta. The values of mua, mub, and logn are assigned together with the data in the setup of JAGS, following Equation (10.33) and Equation (10.34).\nDefine the data and prior parameters\nFollowing the usual implementation of JAGS, the next step is to define the data and provide values for the parameters of the prior. In the script below, a list the_data contains the vector of death counts in y, the vector of hearth attack cases in n, the number of observations N, the values of mua, mub, and logn. Note that we are setting \\(\\log n^* = \\log(100)\\) which indicates that a priori we believe the shrinkage \\(\\lambda = \\eta / (\\eta + 100)\\) is Uniformly distributed on (0, 1).\ny <- deathdata$Deaths     \nn <- deathdata$Cases      \nN <- length(y) \nthe_data <- list(\"y\" = y, \"n\" = n, \"N\" = N, \n                 \"mua\" = 1, \"mub\" = 1, \n                 \"logn\" = log(100))\nGenerate samples from the posterior distribution\nThe run.jags() function is used to generate samples by MCMC in JAGS following the sample script below. It runs one MCMC chain with 1000 iterations in the adapt period, 5000 iterations of burn-in and an additional set of 5000 iterations to be run and collected for inference. One keeps tracks of all parameters in the model by using the argument monitor = c(\"p\", \"mu\", \"logeta\"). The output of the MCMC runs is the variable posterior containing a matrix of simulated draws.\nposterior <- run.jags(modelString,\n                      n.chains = 1,\n                      data = the_data,\n                      monitor = c(\"p\", \"mu\", \"logeta\"),\n                      adapt = 1000,\n                      burnin = 5000,\n                      sample = 5000)\nMCMC diagnostics and summarization\nAs usual, it is important to perform MCMC diagnostics to ensure convergence of the simulated sample. The plot() function returns diagnostics plots of a designated parameter. For brevity, the diagnostics for \\(\\log \\eta\\) are performed and results shown in Figure 10.5. Readers should implement MCMC diagnostics for all parameters in the model.\nplot(posterior, vars = \"logeta\")\n\n\n\n\n\nDiagnostic plots of simulated draws of log eta using the JAGS software with the run.jags package.\n\n\n\n\nAfter the diagnostics are performed, one reports posterior summaries of the parameters using print(). Note that these summaries are based on the 5000 iterations from the sampling period (excluding the adapt and burn-in periods).\nprint(posterior, digits = 3)\n       Lower95 Median Upper95   Mean      SD Mode    MCerr \np[1]    0.0314 0.0602  0.0847 0.0593  0.0138   -- 0.000619   \np[2]    0.0312  0.066   0.095 0.0654  0.0156   -- 0.000496   \np[3]    0.0515 0.0731     0.1 0.0741  0.0122   -- 0.000398    \np[4]     0.044 0.0726   0.105  0.074  0.0155   -- 0.000486     \np[5]    0.0553 0.0756     0.1 0.0765  0.0116   -- 0.000348       \np[6]    0.0435 0.0655  0.0871 0.0655  0.0111   --  0.00042     \np[7]    0.0466 0.0765   0.119 0.0797  0.0191   -- 0.000717     \np[8]    0.0473 0.0683  0.0889 0.0683  0.0104   -- 0.000277    \np[9]    0.0442 0.0669  0.0879 0.0671  0.0111   -- 0.000301     \np[10]   0.0544 0.0811   0.122 0.0845  0.0178   -- 0.000732     \np[11]   0.0521 0.0704  0.0934 0.0711  0.0103   -- 0.000279    \np[12]   0.0369   0.06  0.0818 0.0596  0.0116   -- 0.000504     \np[13]   0.0444 0.0729   0.113 0.0752  0.0176   -- 0.000593     \nmu      0.0576 0.0705  0.0881 0.0714 0.00788   -- 0.000375     \nlogeta    3.63   5.84    8.38   6.01    1.26   --    0.107     \nFrom the posterior output, one evaluates the effect of information pooling in the hierarchical model. See Figure 10.6 displays a shrinkage plot showing how the sample proportions are shrunk towards the overall death rate. Two of the lines in the figure are labelled corresponding to the death rates for the hospitals Mount Sinai Roosevelt and NYP - Allen Hospital. Mount Sinai Roosevelt’s death rate of \\(6/46 = 0.13043\\) exceeds the rate of NYP - Allen of \\(13 / 105 = 0.12381\\), but the figure shows the posterior death rate of NYP - Allen exceeds the posterior death rate of Mount Sinai Roosevelt. Due to the relatively small sample size, one has less confidence in the 0.13043 death rate of Mount Sinai and this rate is shrunk significantly towards the overall death rate in the hierarchical posterior analysis.\n\n\n\n\n\nShrinkage plot of sample proportions and posterior means of proportions of resulted heart attack deaths of 13 hospitals. The death rates of two particular hospitals are labeled. Due to the varying sample sizes, Mt Sinai Roosevelt has a higher observed death rate than NYP - Allen, but NYP - Allen has a higher posterior proportion than Mt Sinai Roosevelt.\n\n\n\n\nTo compare the posterior densities of the different \\(p_i\\), one displays the density estimates in a single graph as in Figure 10.7. Because of the relatively large number of parameters, such plots are difficult to read. Combining the graph and the output above, one sees that \\(p_7\\) and and \\(p_{10}\\) have the largest median values with large standard deviations. One makes inferential statements such as Mount Sinai Roosevelt’s (corresponding to \\(p_7\\)) death rate of heart attack cases has a posterior 90% credible interval of (0.0466, 0.119), the highest among the 13 hospitals in the dataset.\n\n\n\n\n\nDensity plots of simulated draws of proportions using the JAGS software with the run.jags package.\n\n\n\n\nComparison of hospitals\nOne uses this MCMC output to compare the death rates of two hospitals directly, for example, NYP Hospital - Columbia Presbyterian Center and NYP Hospital - New York Weill Cornell Center corresponding respectively to \\(p_{11}\\) and \\(p_{12}\\). One collects the vector of simulated values of the difference of the death rates (\\(\\delta = p_{11} - p_{12}\\)) by subtracting the sets of simulated proportion draws. From the simulated values of the difference in proportions diff, one estimates the probability that \\(p_{11} > p_{12}\\) is positive.\np11draws <- as.mcmc(posterior, vars = \"p[11]\")\np12draws <- as.mcmc(posterior, vars = \"p[12]\")\ndiff = p11draws - p12draws\nsum(diff > 0)/5000\n[1] 0.7872\nA 78.72% posterior probability of \\(p_{11} > p_{12}\\) indicates strong posterior evidence that the death rate of NYP Hospital - Columbia Presbyterian Center is higher than that of NYP Hospital - New York Weill Cornell Center.\nGenerally, when one presents a table such as Table 10.2, one is interested in ranking the 13 hospitals from best (smallest death rate) to worst (largest death rate). A particular hospital, say Bellevue Hospital Center, is interested in its rank among the 13 hospitals. The probability Bellevue has rank 1 is the posterior probability \\[\\begin{equation}\nP(p_1 < p_2, ..., p_1 < p_{13} | y),\n\\end{equation}\\] and this probability is approximated by collecting the posterior draws where the simulated value of \\(p_1\\) is the smallest among the 13 simulated proportions. Likewise, one computes from the MCMC output the probability that Bellevue has rank 2 through 13. These rank probabilities are displayed in Figure 10.8 for two hospitals. The probability that Bellevue is the best hospital with respect to death rate is 0.25 and by summing several probabilities, the probability that Bellevue is ranked among the top three hospitals is 0.54. In contrast, from Figure 10.8, the rank of Harlem Hospital is less certain since the probability distribution is relatively flat across the 13 possible rank values. This is not surprising since this particular hospital had only 35 cases, compared to 129 cases at Bellevue.\n\n\n\n\n\nPosterior probabilities of rank for two hospitals.\n\n\n\n\nFrom a patient’s perspective, she would be interested in learning the identity of the hospital that is ranked best among the 13. For each simulation draw of \\(p_1, ..., p_{13}\\), one identifies the hospital with the smallest simulated value. By collecting this information over the 5000 draws, one computes the posterior probability that each hospital is ranked first. These probability probabilities are displayed in Figure 10.9. The identity of the best hospital is not certain, but the top three hospitals are Bellevue, NYP, NY Weill Corner, and Harlem with respective probabilities 0.250, 0.220, and 0.137 of being the best.\n\n\n\n\n\nPosterior probabilities of the hospital that was ranked first."
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "6  Simple Linear Regression",
    "section": "",
    "text": "For continuous response variables such as Roger Federer’s time-to-serve data in Chapter 8 and snowfall amounts in Buffalo, New York in Chapter 9, Normal sampling models have been applied. The basic underlying assumption in a Normal sampling model is that observations are identically and independently distributed (i.i.d.) according to a Normal density, as in \\(Y_i \\overset{i.i.d.}{\\sim}\\textrm{Normal}(\\mu, \\sigma)\\).\nAdding a predictor variable\nWhen continuous responses are observed, it is common that other variables are recorded that may be associated with the primary response measure. In the Buffalo snowfall example, one may also observe the average temperature in winter season and one believes that the average season temperature is associated with the corresponding amount of snowfall. For the tennis example, one may believe that the time-to-serve measurement is related to the rally length of the previous point. Specifically, a long rally in the previous point may be associated with a long time-to-serve in the current point.\nIn Chapter 9, a Normal curve was used to model the snowfalls \\(Y_1, ..., Y_n\\) for \\(n\\) winters, \\[\\begin{equation}\nY_i \\mid \\mu, \\sigma \\overset{i.i.d.}{\\sim} \\textrm{Normal}(\\mu, \\sigma), \\, \\, i = 1, \\cdots, n.\n\\label{eq:introLik1}\n\\end{equation}\\] The model in Equation (11.1) assumes that each winter snowfall follows the same Normal density with mean \\(\\mu\\) and \\(\\sigma\\). From a Bayesian viewpoint, one assigns prior distributions for \\(\\mu\\) and \\(\\sigma\\) and bases inferences about these parameters from the posterior distribution.\nHowever when the average temperature in winter \\(i\\), \\(x_i\\), is also available, one might wonder if the snowfall amount \\(Y_i\\) can be explained by the average temperature \\(x_i\\) in the same winter. One typically calls \\(x_i\\) a predictor variable as one is interested in predicting the snowfall amount \\(Y_i\\) from the value of \\(x_i\\). How does one extend the basic Normal sampling model in Equation (11.1) to study the possible relationship between the average temperature and the snowfall amount?\nAn observation-specific mean\nThe model in Equation (11.1) assumes a common mean \\(\\mu\\) for each \\(Y_i\\). Since one wishes to introduce a new variable \\(x_i\\) specific to winter \\(i\\), the model in Equation (11.1) is adjusted to Equation (11.2) where the common mean \\(\\mu\\) is replaced by a winter specific mean \\(\\mu_i\\) . \\[\\begin{equation}\nY_i \\mid \\mu_i, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\mu_i, \\sigma), \\, \\, i = 1, \\cdots, n.\n\\label{eq:introLik2}\n\\end{equation}\\] Note that the observations \\(Y_1, ..., Y_n\\) are no longer identically distributed since they have different means, but the observations are still independent which is indicated by \\(ind\\) written over the distributed \\(\\sim\\) symbol in the formula.\nLinear relationship between the mean and the predictor\nOne basic approach for relating a predictor \\(x_i\\) and the response \\(Y_i\\) is to assume that the mean of \\(Y_i\\), \\(\\mu_i\\), is a linear function of \\(x_i\\). This linear relationship is written as \\[\\begin{equation}\n\\mu_i = \\beta_0 + \\beta_1 x_i,\n\\label{eq:introLink}\n\\end{equation}\\] for \\(i = 1, \\dots, n\\). In Equation (11.3), each \\(x_i\\) is a known constant (that is why a small letter is used for \\(x\\)) and \\(\\beta_0\\) and \\(\\beta_1\\) are unknown parameters. As one might guess, these intercept and slope parameters are random. One assigns a prior distribution to \\((\\beta_0, \\beta_1)\\) and perform inference by summarizing the posterior distribution of these parameters.\nIn this model, the linear function \\(\\beta_0 + \\beta_1 x_i\\) is interpreted as the expected snowfall amount when the average temperature is equal to \\(x_i\\). The intercept \\(\\beta_0\\) represents the expected snowfall when the winter temperature is \\(x_i = 0\\). The slope parameter \\(\\beta_1\\) gives the increase in the expected snowfall when the temperature \\(x_i\\) increases by one degree. It is important to note that the linear relationship in Equation (11.3) with parameters \\(\\beta_0\\) and \\(\\beta_1\\) describes the association between the mean \\(\\mu_i\\) and the predictor \\(x_i\\). This linear relationship is a statement about the expected or average snowfall amount \\(\\mu_i\\), not the actual snowfall amount \\(Y_i\\).\nLinear regression model\nSubstituting Equation (11.3) into the model in Equation (11.2), one obtains the linear regression model. \\[\\begin{equation}\nY_i \\mid \\beta_0, \\beta_1, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\beta_0 + \\beta_1 x_i, \\sigma), \\, \\, i = 1, \\cdots, n.\n\\label{eq:introLik3}\n\\end{equation}\\] This is a special case of a Normal sampling model, where the \\(Y_i\\) independently follow a Normal density with observation specific mean \\(\\beta_0 + \\beta_1 x_i\\) and common standard deviation \\(\\sigma\\). Since there is only a single predictor \\(x_i\\), this model is commonly called the simple linear regression model.\nOne restates this regression model as \\[\\begin{equation}\nY_i  = \\mu_i + \\epsilon_i, i = 1, \\cdots, n,\n\\label{eq:introLik3a}\n\\end{equation}\\] where the mean response \\(\\mu_i = \\beta_0 + \\beta_1 x_i\\) and the residuals \\(\\epsilon_1, ..., \\epsilon_n\\) are \\(i.i.d.\\) from a Normal distribution with mean 0 and standard deviation \\(\\sigma\\). In the context of our example, this model says that the snowfall for a particular season \\(Y_i\\) is a linear function of the average season temperature \\(x_i\\) plus a random error \\(\\epsilon_i\\) that is Normal with mean 0 and standard deviation \\(\\sigma\\).\nThe simple linear regression model is displayed in Figure 11.1. The line in the graph represents the equation \\(\\beta_0 + \\beta_1 x\\) for the mean response \\(\\mu = E(Y)\\). The actual response \\(Y\\) is equal to \\(\\beta_0 + \\beta_1 x + \\epsilon\\) where the random variable \\(\\epsilon\\) is distributed Normal with mean 0 and standard deviation \\(\\sigma\\). The Normal curves (drawn sideways) represent the locations of the response \\(Y\\) for three distinct values of the predictor \\(x\\). The parameter \\(\\sigma\\) represents the deviation of the response \\(Y\\) about the mean value \\(\\beta_0 + \\beta_1 x\\). One is interested in learning about the parameters \\(\\beta_0\\) and \\(\\beta_1\\) that describe the line and the standard deviation \\(\\sigma\\) which describes the deviations of the random response about the line.\n\n\n\n\n\nDisplay of linear regression model. The line represents the unknown regression line \\(b_0 + b_1 x\\) and the Normal curves (drawn sideways) represent the distribution of the response \\(Y\\) about the line.\n\n\n\n\nIn the linear regression model, the observation \\(Y_i\\) is random, the predictor \\(x_i\\) is a fixed constant and the unknown parameters are \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\). Using the Bayesian paradigm, a joint prior distribution is assigned to \\((\\beta_0, \\beta_1, \\sigma)\\). After the response values \\(Y_i = y_i, i = 1, ..., n\\) are observed, one learns about the parameters through the posterior distribution. An MCMC algorithm will be used to simulate a posterior sample, and using the simulation sample, one makes inferences about the expected response \\(\\beta_0 + \\beta_1 x\\) for a specific value of the predictor \\(x\\). Also, one will be able to assess the sizes of the errors by summarizing the posterior density of the standard deviation \\(\\sigma\\).\nIn our snowfall example, one is interested in learning about the relationship between the average temperature and the mean snowfall that is described by the linear model \\(\\mu = \\beta_0 + \\beta_1 x\\). If the posterior probability that \\(\\beta_1 < 0\\) is large, that indicates that lower average temperatures will likely result in larger mean snowfall. Also one is interested in using this model for prediction. If given the average winter temperature in the following season, can one predict the Buffalo snowfall? This question is addressed by use of the posterior predictive distribution of a future snowfall \\(\\tilde Y\\). Using the usual computing strategy, one simulates a large sample of values from the posterior predictive distribution and finds an interval that contains \\(\\tilde Y\\) with a prescribed probability.\nIn this chapter, regression is introduced in Section 11.2 by a dataset containing several characteristics of 24 house sales in an area in Ohio. In this example, one is interested in predicting the price of a house given the house size and Section 11.3 presents a simple linear regression model to explain this relationship. The practice of standardizing variables will be introduced which is helpful in the process of assigning an informative prior on the regression parameters. Inference through MCMC is presented in Section 11.6 and methods for performing Bayesian inferences with simple linear regression are illustrated in Section 11.7."
  },
  {
    "objectID": "regression.html#example-prices-and-areas-of-house-sales",
    "href": "regression.html#example-prices-and-areas-of-house-sales",
    "title": "6  Simple Linear Regression",
    "section": "6.2 Example: Prices and Areas of House Sales",
    "text": "6.2 Example: Prices and Areas of House Sales\nZillow is an online real estate database company that collects information on 110 million homes across the United States. Data is collected from a random sample of 24 houses for sale in the Findlay, Ohio area during October 2018. For each house, the dataset contains the selling price (in $1000) and size (in 1000 square feet). Table 11.1 displays the first five observations of the dataset.\nTable 11.1. The house index, price (in $1000), and size (in 1000 sq feet) of 5 house sales in Findlay, Ohio area during October 2018. The random sample contains 24 house sales.\n\n\n\nIndex\nPrice ($1000)\nSize (1000 sq feet)\n\n\n\n\n1\n167\n1.625\n\n\n2\n236\n1.980\n\n\n3\n355\n2.758\n\n\n4\n148\n1.341\n\n\n5\n93\n1.465\n\n\n\nSuppose one is interested in predicting a house’s selling price from its house size. In this example, one is treating price as the response variable and size as the single predictor. Figure 11.2 constructs a scatterplot of price (y-axis) against the size (x-axis) for the houses in the sample. This figure shows a positive relationship between the size and the price of a house sale, suggesting that the house sale price increases as the house size increases. Can one quantify this relationship through a Bayesian linear regression model? In particular, is there sufficient evidence that there is a positive association among the population of all homes? Can one predict the sale price of a home given its size?\n\n\n\n\n\nScatterplot of price against size of house sales."
  },
  {
    "objectID": "regression.html#a-simple-linear-regression-model",
    "href": "regression.html#a-simple-linear-regression-model",
    "title": "6  Simple Linear Regression",
    "section": "6.3 A Simple Linear Regression Model",
    "text": "6.3 A Simple Linear Regression Model\nThe house sale example can be fit into the linear regression model framework. It is assumed the response variable, the price of a house sale, is a continuous variable is distributed as a Normal random variable. Specifically, the price \\(Y_i\\) for house \\(i\\), is Normally distributed with mean \\(\\mu_i\\) and standard deviation \\(\\sigma\\). \\[\\begin{equation}\nY_i \\mid \\mu_i, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\mu_i, \\sigma),\n\\label{eq:modelLik1}\n\\end{equation}\\] where \\(i = 1, \\cdots, n\\), where \\(n = 24\\) is the number of homes in the dataset. The \\(ind\\) over \\(\\sim\\) in Equation (11.6) indicates that each response \\(Y_i\\) independently follows its own Normal density. Moreover, unlike the house-specific mean \\(\\mu_i\\), a common standard deviation \\(\\sigma\\) is shared among all responses \\(Y_i\\)’s.\nSince one believes the size of the house is helpful in understanding a house’s price,\none represents the mean price \\(\\mu_i\\) as a linear function of the house size \\(x_i\\) depending on two parameters \\(\\beta_0\\) and \\(\\beta_1\\).\n\\[\\begin{equation}\n\\mu_i = \\beta_0 + \\beta_1 x_i\n\\label{eq:modelLink}\n\\end{equation}\\]\nHow does one interpret the intercept and slope parameters? The intercept \\(\\beta_0\\) gives the expected price \\(\\mu_i\\) for a house \\(i\\) that has zero square feet (\\(x_i = 0\\)). This is not a meaningful parameter since no house (not even a tiny house) has zero square feet. The slope parameter \\(\\beta_1\\) gives the change in the expected price \\(\\mu_i\\), when the size \\(x_i\\) of house \\(i\\) increases by 1 unit, i.e., increases by 1000 square feet."
  },
  {
    "objectID": "regression.html#a-weakly-informative-prior",
    "href": "regression.html#a-weakly-informative-prior",
    "title": "6  Simple Linear Regression",
    "section": "6.4 A Weakly Informative Prior",
    "text": "6.4 A Weakly Informative Prior\nIn some situations, the user has limited prior information about the location of the regression parameters or the standard deviation. To implement the Bayesian approach, one has to assign a prior distribution, but it is desirable in this situation to assign a prior that has little impact on the posterior distribution.\nSuppose that one’s beliefs about the regression coefficients \\((\\beta_0, \\beta_1)\\) are independent from one’s opinion about the standard deviation \\(\\sigma\\). Then the joint prior density for the parameters \\((\\beta_0, \\beta_1, \\sigma)\\) is written as \\[\\begin{equation*}\n\\pi(\\beta_0, \\beta_1, \\sigma) = \\pi(\\beta_0, \\beta_1) \\pi(\\sigma).\n\\end{equation*}\\] The choice of weakly informative priors on \\((\\beta_0, \\beta_1)\\) and \\(\\sigma\\) are described in separate sections.\nPrior on the intercept \\(\\beta_0\\) and slope \\(\\beta_1\\)\nIf one assumes independence of one’s opinion about the intercept and the slope, one represents the joint prior \\(\\pi(\\beta_0, \\beta_1)\\) as the product of priors \\(\\pi(\\beta_0) \\pi(\\beta_1)\\), and it is convenient to use Normal priors. So it is assumed \\(\\beta_0 \\sim \\textrm{Normal}(\\mu_0, s_0)\\) and \\(\\beta_1 \\sim \\textrm{Normal}(\\mu_1, s_1)\\).\nThe choice of the standard deviation \\(s_j\\) in the Normal prior reflects how confident the person believes in a prior guess of \\(\\beta_j\\). If one has little information about the location of a regression parameter, then the choice of the prior guess \\(\\mu_j\\) is not that important and one chooses a large value for the prior standard deviation \\(s_j\\). So the regression intercept and slope are each assigned a Normal prior with a mean of 0 and standard deviation equal to the large value of 100.\nPrior on sampling standard deviation \\(\\sigma\\)\nIn the current regression model, one assumes that \\(Y_i \\sim \\textrm{Normal}(\\beta_0 + \\beta_1 x_i, \\sigma)\\) and \\(\\sigma\\) represents the variability of the house price about the regression line. It is typically hard to specify informative beliefs about a standard deviation than a mean parameter such as \\(\\beta_0 + \\beta_1 x\\). So following the suggestions from Chapter 9 and Chapter 10, one assigns a weakly informative prior for the standard deviation \\(\\sigma\\). A Gamma prior for the precision parameter \\(\\phi = 1/\\sigma^2\\) with small values of the shape and rate parameters, say \\(a = 1\\) and \\(b = 1\\), was seen in those chapters to represent weak prior information, and a similar prior is assigned in this regression setting. \\[\\begin{equation*}\n\\phi = 1/\\sigma^2 \\sim \\textrm{Gamma}(1, 1).\n\\end{equation*}\\]"
  },
  {
    "objectID": "regression.html#posterior-analysis",
    "href": "regression.html#posterior-analysis",
    "title": "6  Simple Linear Regression",
    "section": "6.5 Posterior Analysis",
    "text": "6.5 Posterior Analysis\nIn the sampling model one has that \\(Y_1, ..., Y_n\\) are independent with \\(Y_i \\sim \\textrm{Normal}(\\beta_0 + \\beta_1 x_i, \\sigma)\\). Suppose the pairs \\((x_1, y_1), ..., (x_n, y_n)\\) are observed. The likelihood is the joint density of these observations viewed as a function of \\((\\beta_0, \\beta_1, \\sigma)\\). For convenience, the standard deviation \\(\\sigma\\) is reexpressed as the precision \\(\\phi = 1 / \\sigma^2\\).\n\\[\\begin{eqnarray}\nL(\\beta_0, \\beta_1, \\phi) &= & \\prod_{i=1}^n \\left[\\frac{\\sqrt{\\phi}}{\\sqrt{2 \\pi}}\n\\exp\\left\\{-\\frac{\\phi}{2}(y_i - \\beta_0 - \\beta_1 x_i)^2\\right\\}\\right]\n\\nonumber \\\\\n& \\propto & \\phi^{\\frac{n}{2}} \\exp\\left\\{-\\frac{\\phi}{2}\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)^2\\right\\}\n\\end{eqnarray}\\]\nBy multiplying the likelihood by the prior for \\((\\beta_0, \\beta_1, \\phi)\\), one obtains an expression for the posterior density. \\[\\begin{eqnarray}\n\\pi(\\beta_0, \\beta_1, \\phi \\mid y_1, \\cdots, y_n) &\\propto & \\phi^{\\frac{n}{2}} \\exp\\left\\{-\\frac{\\phi}{2}\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)^2\\right\\} \\nonumber \\\\\n& \\times & \\exp\\left\\{-\\frac{1}{2 s_0^2}(\\beta_0 - \\mu_0)^2\\right\\}\n\\exp\\left\\{-\\frac{1}{2 s_1^2}(\\beta_1 - \\mu_1)^2\\right\\} \\nonumber \\\\\n& \\times & \\phi^{a-1} \\exp(-b \\phi)\n\\end{eqnarray}\\] Since this is not a familiar probability distribution, one needs to use an MCMC algorithm to obtain simulated draws from the posterior."
  },
  {
    "objectID": "regression.html#inference-through-mcmc",
    "href": "regression.html#inference-through-mcmc",
    "title": "6  Simple Linear Regression",
    "section": "6.6 Inference through MCMC",
    "text": "6.6 Inference through MCMC\nIt is convenient to draw an MCMC sample from a regression model using the JAGS software. One attractive feature of JAGS is that it is straightforward to transpose the statement of the Bayesian model (sampling density and prior) directly to the JAGS model script.\nDescribe the model by a script\nThe first step in using JAGS is writing the following script defining the linear regression model, saving the script in the character string modelString.\n\nmodelString <-\"\nmodel {\n## sampling\nfor (i in 1:N){\n   y[i] ~ dnorm(beta0 + beta1*x[i], invsigma2)\n}\n## priors\nbeta0 ~ dnorm(mu0, g0)\nbeta1 ~ dnorm(mu1, g1)\ninvsigma2 ~ dgamma(a, b)\nsigma <- sqrt(pow(invsigma2, -1))\n}\"\n\nIn the sampling section of the script, the loop goes from 1 to N, where N is the number of observations with index i. Recall that the Normal distribution dnorm in JAGS is stated in terms of the mean and precision, and so the variable invsigma2 corresponds to the Normal sampling precision. The variable sigma is defined in the prior section of the script so one can track the simulated values of the standard deviation \\(\\sigma\\). Also the variables g0 and g1 correspond to the precisions of the Normal prior densities for beta0 and beta1.\nDefine the data and prior parameters\nThe next step is to provide the observed data and the values for the prior parameters. In the R script below, a list the_data contains the vector of sale prices, the vector of house sizes, and the number of observations. This list also contains the means and precisions of the Normal priors for beta0 and beta1, and the values of the two parameters a and b of the Gamma prior for invsigma2. The prior standard deviations of the Normal priors on beta0 and beta1 are both 100, and so the corresponding precision values of g0 and g1 are both \\(1/100^2 = 0.0001\\).\ny <- PriceAreaData$price  \nx <- PriceAreaData$newsize   \nN <- length(y)  \nthe_data <- list(\"y\" = y, \"x\" = x, \"N\" = N,\n                 \"mu0\" = 0, \"g0\" = 0.0001,\n                 \"mu1\" = 0, \"g1\" = 0.0001,\n                 \"a\" = 1, \"b\" = 1)\nGenerate samples from the posterior distribution\nThe run.jags() function in the runjags package generates posterior samples by the MCMC algorithm using the JAGS software. The script below runs one MCMC chain with an adaption period of 1000 iterations, a burn-in period of 5000 iterations, and an additional set of 5000 iterations to be run and collected for inference. By using the argument monitor = c(\"beta0\", \"beta1\", \"sigma\"), one keeps tracks of all three model parameters. The output variable posterior contains a matrix of simulated draws.\nposterior <- run.jags(modelString,\n                      n.chains = 1,\n                      data = the_data,\n                      monitor = c(\"beta0\", \"beta1\", \"sigma\"),\n                      adapt = 1000,\n                      burnin = 5000,\n                      sample = 5000)\nMCMC diagnostics and summarization\nUsing JAGS one obtains 5000 posterior samples for the vector of parameters. Below the first 10 posterior samples are displayed for the triplet \\((\\beta_0, \\beta_1, \\sigma)\\). Note that the index starts from 6001 since 6000 samples were already generated in the adaption and burn-in periods.\n     beta0 beta1 sigma\n6001 -17.62 103.3 40.68\n6002 -21.35 107.3 44.92\n6003 -34.34 114.0 37.11\n6004 -42.06 110.5 51.84\n6005 -47.71 111.4 62.63\n6006 -47.49 113.9 53.80\n6007 -18.85 106.0 50.92\n6008 -28.50 114.8 42.71\n6009 -32.10 105.1 47.41\n6010 -37.41 119.3 45.88\nTo obtain valid inferences from the posterior draws from the MCMC simulation, convergence of the MCMC chain is necessary. The plot() function with the argument input vars returns four diagnostic plots (trace plot, empirical CDF, histogram and autocorrelation plot) for the specified parameter. For example, Figure 11.3 shows the diagnostic plots for the intercept parameter \\(\\beta_0\\) by the following command.\nplot(posterior, vars = \"beta0\")\n\n\n\n\n\nMCMC diagnostics plots for the regression intercept parameter.\n\n\n\n\nThe upper left trace plot shows good MCMC mixing for the 5000 simulated draws of \\(\\beta_0\\). The lower right autocorrelation plot indicates close to zero correlation between adjacent posterior draws of \\(\\beta_0\\). Overall these indicate convergence of the MCMC chain for \\(\\beta_0\\). In usual practice, one should perform these diagnostics for all three parameters in the model.\nFigure 11.4 displays a scatterplot of the simulated draws of the regression parameters \\(\\beta_0\\) and \\(\\beta_1\\). It is interesting to note the strong negative correlation in these parameters. If one assigned informative independent priors on \\(\\beta_0\\) and \\(\\beta_1\\), these prior beliefs would be counter to the correlation between the two parameters observed in the data.\n\n\n\n\n\nScatterplot of posterior draws of the intercept and slope parameters.\n\n\n\n\nPosterior summaries of the parameters are obtained by use of the print(posterior, digits = 3) command. Note that these summaries are based on the 5000 iterations from the sampling period excluding the samples from the adaption and burn-in periods.\nprint(posterior, digits = 3)\n      Lower95 Median Upper95  Mean   SD Mode MCerr \nbeta0    -122  -46.2    31.4 -45.7 37.6   --  2.98     \nbeta1    78.7    117     159   117   20   --  1.65     \nsigma    33.2     45    59.3  45.7 6.93   -- 0.157  \n\nThen intercept parameter \\(\\beta_0\\) does not have a useful interpretation, so values of these particular posterior summaries will not be interpreted. The summaries of the slope \\(\\beta_1\\) indicate a positive slope with a posterior median of 117 and a 90% credible interval (78.7, 159). That is, with every 1000 square feet increase of the house size, the house price increases by $117,000. In addition, this increase in the house price falls in the interval ($78,700, $159,000) with 90% posterior probability.\nThe posterior median of the standard deviation \\(\\sigma\\) is the large value 45 or $45,000 which indicates that there are likely additional variables than house size that determine the price."
  },
  {
    "objectID": "regression.html#bayesian-inferences-with-simple-linear-regression",
    "href": "regression.html#bayesian-inferences-with-simple-linear-regression",
    "title": "6  Simple Linear Regression",
    "section": "6.7 Bayesian Inferences with Simple Linear Regression",
    "text": "6.7 Bayesian Inferences with Simple Linear Regression\n\n6.7.1 Simulate fits from the regression model\nThe intercept \\(\\beta_0\\) and slope \\(\\beta_1\\) determine the linear relationship between the mean of the response \\(Y\\) and the predictor \\(x\\). \\[\\begin{equation}\nE(Y) = \\beta_0 + \\beta_1 x.\n\\label{eq:ExpLink}\n\\end{equation}\\] Each pair of values (\\(\\beta_0, \\beta_1\\)) corresponds to a line \\(\\beta_0 + \\beta_1 x\\) in the space of values of \\(x\\) and \\(y\\). If one finds the posterior mean of these coefficients, say \\(\\tilde {\\beta_0}\\) and \\(\\tilde {\\beta_1}\\), then the line \\[\\begin{equation*}\ny = \\tilde{\\beta_0} + \\tilde{\\beta_1} x\n\\end{equation*}\\] corresponds to a “best” line of fit through the data.\nThis best line represents a most likely value of the line \\(\\beta_0 + \\beta_1 x\\) from the posterior distribution. One learns about the uncertainty of this line estimate by drawing a sample of \\(J\\) rows from the matrix of posterior draws of \\((\\beta_0, \\beta_1)\\) and collecting the line estimates \\[\\begin{equation*}\n\\tilde{\\beta_0}^{(j)} + \\tilde{\\beta_1}^{(j)} x, j = 1, ..., J.\n\\end{equation*}\\]\nUsing the R script below, one produces a graph showing the best line of fit (solid line) and ten simulated fits from the posterior as in Figure 11.5.\npost <- as.mcmc(posterior)\npost_means <- apply(post, 2, mean)\npost <- as.data.frame(post)\nggplot(PriceAreaData, aes(newsize, price)) +\n  geom_point(size=3) +\n  geom_abline(data=post[1:10, ],\n              aes(intercept=beta0, slope=beta1),\n              alpha = 0.5) +\n  geom_abline(intercept = post_means[1],\n              slope = post_means[2],\n              size = 2) +\n  ylab(\"Price\") + xlab(\"Size\") +\n  theme_grey(base_size = 18, base_family = \"\")\n\n\n\n\n\nScatterplot of the (size, price) data with the best line of fit (solid line) and ten simulated fits \\(b_0 + \b_1 x\\) from the posterior distribution.\n\n\n\n\nFrom Figure 11.5, since there is inferential uncertainty about the intercept \\(\\beta_0\\) and slope \\(\\beta_1\\), one sees variation among the ten fits from the posterior of the linear regression line \\(\\beta_0 + \\beta_1 x\\). This variation about the best-fitting line is understandable since the size of our sample of data is the relatively small value of 24. A larger sample size would help to reduce the posterior variation for the intercept and slope parameters and result in posterior samples of fits that are more tightly clustered about the best fitting line in Figure 11.5.\n\n\n6.7.2 Learning about the expected response\nIn regression modeling, one may be interested in learning about the expected response \\(E(Y)\\) for a specific value of the predictor \\(x\\). In the house sale example, one may wish to learn about the expected house price for a specific value of the house size. Since the expected response \\(E(Y) = \\beta_0 + \\beta_1 x\\) is a linear function of the intercept and slope parameters, one obtains a simulated sample from the posterior of \\(\\beta_0 + \\beta_1 x\\) by computing this function on each of the simulated pairs from the posterior of \\((\\beta_0, \\beta_1)\\).\nFor example, suppose one is interested in the expected price \\(E(Y)\\) for a house with a size of 1, i.e. \\(x = 1\\) (1000 sq feet). In the R script below, one simulates 5000 draws from the posterior of the expected house prices, \\(E[Y]\\) from the 5000 posterior samples of the pair \\((\\beta_0, \\beta_1)\\).\nsize <- 1\nmean_response <- post[, \"beta0\"] + size * post[, \"beta1\"]\nThis process is repeated for the four sizes \\(x = 1.2, 1.6, 2.0, 2.4\\) (1200 sq feet, 1600 sq feet, 2000 sq feet, and 2400 sq feet). Let \\(E(Y \\mid x)\\) denotes the expected price for a house with size \\(x\\). Figure 11.6 displays density plots of the simulated posterior samples for the expected prices \\(E(Y \\mid 1.2)\\), \\(E(Y \\mid 1.6)\\), \\(E(Y \\mid 2.0)\\), \\(E(Y \\mid 2.4)\\) for these four house sizes.\n\n\n\n\n\nDensity plots of the simulated draws of the posterior expected house price for four different values of the house size.\n\n\n\n\nThe R output below provides summaries of the posterior of the expected price for each of the four values of the house size. From this output, one sees that, for a house of size of 1.2 (1200 sq feet), the posterior median of the expected price is 94.5 thousand dollars, and the probability that the expected price falls between $69,800 and $121,000 is 90%.\n  Value        P05   P50   P95\n  <chr>      <dbl> <dbl> <dbl>\n1 Size = 1.2  69.8  94.5  121\n2 Size = 1.6 125  142   159\n3 Size = 2   172  189   205\n4 Size = 2.4 211  236   260\n\n\n6.7.3 Prediction of future response\nLearning about the regression model and values of the expected response values focus on the deterministic linear relationship between \\(x\\) and \\(E[Y]\\) through the intercept \\(\\beta_0\\) and the slope \\(\\beta_1\\), as shown in Equation (11.10). The variability among the fitted lines in Figure 11.5 and the variability among the simulated house price for fixed size in Figure 11.6 reflects the variability in the posterior draws of \\(\\beta_0\\) and \\(\\beta_1\\).\nHowever, if one wants to predict future values for a house sale price \\(Y\\) given its size \\(x\\), one needs to go one step further to incorporate the sampling model in the simulation process. \\[\\begin{equation}\nY_i \\mid \\beta_0, \\beta_1, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\beta_0 + \\beta_1 x_i, \\sigma)\n\\label{eq:modelLik5}\n\\end{equation}\\] As shown in Equation (11.11), the sampling model of \\(Y\\) is a Normal with a mean expressed as a linear combination of \\(\\beta_0\\) and \\(\\beta_1\\) and a standard deviation \\(\\sigma\\). To obtain a predicted value of \\(Y\\) given \\(x = x_i\\), one first simulates the expected response from \\(\\beta_0 + \\beta_1 x_i\\), and then simulates the predicted value of \\(Y_i\\) from the sampling model: \\(Y_i \\sim \\textrm{Normal}(E[Y_i], \\sigma)\\). Below is a diagram for the prediction process for an observation where its house size is given as \\(x\\), and predicted value denoted as \\(\\tilde{y}^{(s)}\\) for iteration \\(s\\). Here the simulation size \\(S\\) is 5000 as there are 5000 posterior samples of each of the three parameters.\n\\[\\begin{eqnarray*}\n\\text{simulate}\\,\\, E[y]^{(1)} = \\beta_0^{(1)} + \\beta_1^{(1)} x &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(1)} \\sim {\\rm{Normal}}(E[y]^{(1)}, \\sigma^{(1)})\\\\\n\\text{simulate}\\,\\, E[y]^{(2)} = \\beta_0^{(2)} + \\beta_1^{(2)} x &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(2)} \\sim {\\rm{Normal}}(E[y]^{(2)}, \\sigma^{(2)})\\\\\n&\\vdots& \\\\\n\\text{simulate}\\,\\, E[y]^{(S)} = \\beta_0^{(S)} + \\beta_1^{(S)} x &\\rightarrow& \\text{sample}\\,\\, \\tilde{y}^{(S)} \\sim {\\rm{Normal}}(E[y]^{(S)}, \\sigma^{(S)})\\\\\n\\end{eqnarray*}\\]\nThe R function one_predicted() obtains a simulated sample of the predictive distribution of the house price given a value of the house size. First one uses the posterior sample of \\((\\beta_0, \\beta_1)\\) to obtain a posterior sample of the “linear response” \\(\\beta_0 + \\beta_1 x\\). Then it simulates draws of the future observation by simulating from a Normal distribution with mean \\(\\beta_0 + \\beta_1 x\\) and standard deviation \\(\\sigma\\), where draws of \\(\\sigma\\) are taken from its posterior distribution.\none_predicted <- function(x){\n  lp <- post[ , \"beta0\"] +  x * post[ , \"beta1\"]\n  y <- rnorm(5000, lp, post[, \"sigma\"])\n  data.frame(Value = paste(\"Price =\", x),\n             Predicted_Price = y)\n}\nThis process is repeated for each of the house sizes \\(x = 1.2, 1.6, 2.0, 2.4\\) (1200 sq feet, 1600 sq feet, 2000 sq feet, and 2400 sq feet). Figure 11.7 displays density estimates of these simulated samples from the predictive distributions of the house price. Comparing Figure 11.6 with Figure 11.7, note that the predictive distributions are much wider than the posterior distributions on the expected response. This is what one would anticipate, since the predictive distribution incorporates two types of uncertainty – the inferential uncertainty in the values of the regression line \\(\\beta_0 + \\beta_1 x\\) and the predictive uncertainty expressed in the sampling density of the response \\(y\\) with standard deviation \\(\\sigma\\).\n\n\n\n\n\nDensity plots of the simulated draws of the predicted house price for four different values of the house size.\n\n\n\n\nTo reinforce this last point, the R output below displays the 5th, 50th, and 95th percentiles of the predictive distribution of the house price for each of the four values of the house size. One saw earlier that a 90% interval estimate for the expected price for a house with \\(x = 1.2\\) was given by (69.8, 121). Below one sees that a 90% prediction interval for the price of the same house size is \\((15.5, 175)\\). The prediction interval is substantially wider than the posterior interval estimate. This is true since the predictive distribution incorporates the sizable uncertainty in the house price given the house size represented by the sampling standard deviation \\(\\sigma\\).\n  Value        P05   P50   P95\n  <chr>      <dbl> <dbl> <dbl>\n1 Size = 1.2  15.5  94.4   175\n2 Size = 1.6  64.5 142     219\n3 Size = 2   110   189     266\n4 Size = 2.4 157   234     315\n\n\n6.7.4 Posterior predictive model checking\n Simulating replicated datasets\nThe posterior predictive distribution is used to predict the value of a house’s price for a particular house size. It is also helpful in judging the suitability of the linear regression model. The basic idea is that the observed response values should be consistent with predicted responses generated from the fitted model.\nIn our example, one observed the house size \\(x\\) and the house price \\(y\\) for a sample of 24 houses. Suppose one simulates a sample of prices for a sample of 24 houses with the same sizes from the posterior predictive distribution. This is implemented in two steps.\n\nValues of the parameters \\((\\beta_0, \\beta_1, \\sigma)\\) are simulated from the posterior distribution – call these simulated values \\((\\beta^*_0, \\beta^*_1, \\sigma^*)\\).\nA sample \\(\\{y_1^R, ..., y_n^R\\}\\) is simulated where the sample size is \\(n = 24\\) and \\(y_i^R\\) is Normal(\\(\\mu^*_i, \\sigma^*)\\), where \\(\\mu^*_i = \\beta^*_0 + \\beta^*_1 x_i\\).\n\nThis is called a replicated sample from the posterior predictive distribution since one is using the same sample size and covariate values as the original dataset.\nFor our example, this simulation process was repeated eight times, where each iteration produces a sample \\((x_i, y_i^R), i = 1, ..., 24\\). Scatterplots of these eight replicated samples are displayed in Figure 11.8. The observed sample is also displayed in this figure.\nThe question one wants to ask is: Do the scatterplots of the simulated replicated samples resemble the scatterplot of the observed data? Since the \\(x\\) values are the same for the observed and replicated datasets, one focuses on possible differences in the observed and replicated response values. Possibly, the sample prices display more variation than the replicated prices, or perhaps the sample prices have a particular outlier or other feature that is not present in the replicated prices.\nIn the examination of these scatterplots, the distribution of the observed responses does not seem markably different from the distribution of the response in the simulated replicated datasets. Therefore in this brief examination, one does not see any indication of model misfit – the observed \\((x, y)\\) data seems consistent with replicated data generated from the posterior predictive distribution.\n\n\n\n\n\nScatterplots of observed and eight replicated datasets from the posterior predictive distribution.\n\n\n\n\nPredictive residuals\nIn linear regression, one typically explores the residuals that are the deviations of the observations \\(\\{y_i\\}\\) from the fitted regression model. The posterior prediction distribution is used to define a suitable Bayesian residual.\nConsider the observed point (\\(x_i, y_i\\)). One asks the question – is the observed response value \\(y_i\\) consistent with predictions \\(\\tilde{y}_i\\) of this observation from the fitted model? One simulates predictions \\(\\tilde{y}_i\\) from the posterior predictive distribution in two steps:\n\nOne simulates \\((\\beta_0, \\beta_1, \\sigma)\\) from the posterior distribution.\nOne simulates \\(\\tilde{y}_i\\) from a Normal distribution with mean \\(\\beta_0 + \\beta_1 x_i\\) and standard deviation \\(\\sigma\\).\n\nBy repeating this process many times, one has a sample of values {\\(\\tilde{y}_i\\)} from the posterior predictive distribution.\nTo see how close the observed response \\(y_i\\) is to the predictions {\\(\\tilde{y}_i\\)}, one computes the predictive residual \\[\\begin{equation}\nr_i = y_i - \\tilde{y}_i.\n\\end{equation}\\] If this predictive residual is away from zero, that indicates that the observation is not consistent with the linear regression model. Remember that \\(\\tilde{y}_i\\), and therefore the predictive residual \\(r_i\\) is random. So one constructs a 90% interval estimate for the predictive residual \\(r_i\\) and says that the observation is unusual if the predictive residual interval estimate does not include zero.\nFigure 11.9 displays a graph of the 90% interval estimates for the predictive residuals {\\(r_i\\)} plotted against the size variable. A horizontal line at the value 0 is displayed and we look for intervals that are located on one side of zero. One notices that a few of the intervals barely overlap zero – this indicates that the corresponding points \\((x_i, y_i)\\) are somewhat inconsistent with the fitted regression model.\n\n\n\n\n\nDisplay of predictive residuals. Each line covers 90% of the probability of the predictive residual."
  },
  {
    "objectID": "regression.html#informative-prior",
    "href": "regression.html#informative-prior",
    "title": "6  Simple Linear Regression",
    "section": "6.8 Informative Prior",
    "text": "6.8 Informative Prior\nOne challenge in a Bayesian analysis is the construction of a prior that reflects beliefs about the parameters. In the usual linear function representation in Equation (11.7), thinking about prior beliefs can be difficult since the intercept \\(\\beta_0\\) does not have a meaningful interpretation. To make the regression parameters \\(\\beta_0\\) and \\(\\beta_1\\) easier to interpret, one considers standardizing the response and predictor variables. With this standardization, the task of constructing informative priors will be facilitated.\n\n6.8.1 Standardization\nStandardization is the process of putting different variables on similar scales. As we can see in Figure 11.2, the house size variable ranges from 1.0 to over 2.5 (in 1000 sq feet), while the price variable ranges from below 50 to over 350 (in $1000). The standardization process works as follows: for each variable, calculate the sample mean and the sample standard deviation, and then for each observed value of the variable, subtract the sample mean and divide by the sample standard deviation.\nFor example, let \\(y_i\\) be the observed sale price and \\(x_i\\) be the size of a house. Let \\(\\bar{y}\\) and \\(\\bar{x}\\) denote the sample means and \\(s_y\\) and \\(s_x\\) denote the sample standard deviations for the \\(y_i\\)’s and \\(x_i\\)’s, respectively. Then the standardized variables \\(y_i^*\\) and \\(x_i^*\\) are defined by the following formula. \\[\\begin{equation}\ny_i^* = \\frac{y_i - \\bar{y}}{s_y},  \\, \\, x_i^* = \\frac{x_i - \\bar{x}}{s_x}.\n\\end{equation}\\]\nIn R, the function scale() performs standardization.\nPriceAreaData$price_standardized <- scale(PriceAreaData$price)\nPriceAreaData$size_standardized <- scale(PriceAreaData$newsize)\n\n\n\n\n\nTwo scatterplots of price against size of house sales: both variables unstandardized (top) and both variables standardized (bottom).\n\n\n\n\nA standardized value represents the number of standard deviations that the value falls above or below the mean. For example, if \\(x_i^* = -2\\), then this house size is two standard deviations below the mean of all house sizes, and a value \\(y_i = 1\\) indicates a sale price that is one standard deviation larger than the mean. Figure 11.10 constructs a scatterplot of the original \\((x, y)\\) data (top) and the standardized \\((x^*, y^*)\\) data (bottom). Note that the ranges of the standardized scores for the \\(x^*\\) and \\(y^*\\) are similar – both sets of standardized scores fall between \\(-2\\) and 2. Also note that the association pattern of the two graphs agree which indicates that the standardization procedure has no impact on the relationship of house size with the sale price.\nOne advantage of standardization of the variables is that it provides more meaningful interpretations of the regression parameters \\(\\beta_0\\) and \\(\\beta_1\\). The linear regression model with the standardized variables is written as follows:\n\\[\\begin{equation}\nY_i^* \\mid \\mu_i^*, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\mu_i^*, \\sigma),\n\\end{equation}\\] \\[\\begin{equation}\n\\mu_i^* = \\beta_0 + \\beta_1 x_i^*.\n\\end{equation}\\]\nThe intercept parameter \\(\\beta_0\\) now is the expected standardized sale price for a house where \\(x_i^* = 0\\) corresponding to a house of average size. The slope \\(\\beta_1\\) gives the change in the expected standardized sale price \\(\\mu_i^*\\) when the standardized size \\(x_i^*\\) increases by 1 unit, or when the size variable increases by one standard deviation. In addition, when the variables are standardized, the slope \\(\\beta_1\\) can be shown equal to the correlation between \\(x_i\\) and \\(y_i\\). So this slope provides a meaningful measure of the linear relationship between the standardized predictor \\(x_i^*\\) and the expected standardized response \\(\\mu_i^*\\). A positive value \\(\\beta_1\\) indicates a positive linear relationship between the two variables, and the absolute value of \\(\\beta_1\\) indicates the strength of the relationship.\n\n\n6.8.2 Prior distributions\nAs in the weakly informative prior case, assume that the three parameters \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma\\) are independent so the joint prior is factored into the marginal components. \\[\\begin{equation*}\n\\pi(\\beta_0, \\beta_1, \\sigma) = \\pi(\\beta_0) \\pi(\\beta_1) \\pi(\\sigma).\n\\end{equation*}\\] Then the task of assigning a joint prior simplifies to the task of assigning priors separately to each of the three parameters. The process of assigning an informative prior is described for each parameter.\nPrior on the intercept \\(\\beta_0\\)\nAfter the data is standardized, recall that the intercept \\(\\beta_0\\) represents the expected standardized sale price given a house of average size (i.e. \\(x_i^* = 0\\)). If one believes a house of average size will also have an average price, then a reasonable guess of \\(\\beta_0\\) is zero. One can give a Normal prior for \\(\\beta_0\\) with mean \\(\\mu_0 = 0\\) and standard deviation \\(s_0\\): \\[\\begin{equation*}\n\\beta_0 \\sim \\textrm{Normal}(0, s_0).\n\\end{equation*}\\]\nThe standard deviation \\(s_0\\) in the Normal prior reflects how confident the person believes in the guess of \\(\\beta_0 = 0\\). For example, if one specifies \\(\\beta_0 \\sim \\textrm{Normal}(0, 1)\\), this indicates that a price of a house of average size could range from one standard deviation below to one standard deviation above the average price. Since this is a wide range, one is stating that he or she is unsure that a house of average size will have an average price. If one instead is very sure of the guess that \\(\\beta_0 = 0\\), one could choose a smaller value of \\(s_0\\).\nPrior on the slope \\(\\beta_1\\)\nFor standardized data, the slope \\(\\beta_1\\) represents the correlation between the house size and the sale price. One represents one’s belief about the location of \\(\\beta_1\\) by means of a Normal prior. \\[\\begin{equation*}\n\\beta_1 \\sim \\textrm{Normal}(\\mu_1, s_1),\n\\end{equation*}\\] For this prior, \\(\\mu_1\\) represents one’s best guess of the correlation and \\(s_1\\) represents the sureness of this guess. For example, if one lets \\(\\beta_1\\) be \\(\\textrm{Normal}(0.7, 0.15)\\), this means that one’s “best guess” of the correlation is 0.7 and one is pretty certain that the correlation falls between \\(0.7 - 0.15\\) and \\(0.7 + 0.15\\). If one is not very sure of the guess of 0.7, one could choose a larger value of \\(s_1\\).\nPrior on \\(\\sigma\\)\nIt is typically harder to specify informative beliefs about a standard deviation than a mean parameter such as \\(\\beta_0 + \\beta_1 x\\). So it seems reasonable to assign a weakly informative prior for the sampling error standard deviation \\(\\sigma\\). A Gamma prior for the precision parameter \\(\\phi = 1/\\sigma^2\\) with small values of the shape and rate parameters, say \\(a = 1\\) and \\(b = 1\\), can represent weak prior information in this regression setting. \\[\\begin{equation*}\n1/\\sigma^2 \\sim \\textrm{Gamma}(1, 1).\n\\end{equation*}\\]\nTo summarize, the informative prior distribution for (\\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\)) is defined as follows. \\[\\begin{equation}\n\\pi(\\beta_0, \\beta_1, \\sigma) = \\pi(\\beta_0)\n\\pi(\\beta_1) \\pi(\\sigma),\n\\end{equation}\\]\n\\[\\begin{equation}\n\\beta_0 \\sim \\textrm{Normal}(0, 1),\n\\end{equation}\\]\n\\[\\begin{equation}\n\\beta_1 \\sim \\textrm{Normal}(0.7, 0.15),\n\\end{equation}\\]\n\\[\\begin{equation}\n1/\\sigma^2 \\sim \\textrm{Gamma}(1, 1).\n\\end{equation}\\]\n\n\n6.8.3 Posterior Analysis\n\nOne again uses the JAGS software to simulate from the posterior distribution of the parameters. The modelString is written in the same way as in Section 11.6.\nSince the data have been standardized, one needs to do some initial preliminary work before the MCMC implementation.\nFirst, in R, one defines new variables price_standardized and size_standardized that are standardized versions of the original price and newsize variables.\nPriceAreaData$price_standardized <- scale(PriceAreaData$price)\nPriceAreaData$size_standardized <- scale(PriceAreaData$newsize)\nThen the variables y and x in modelString now correspond to the standardized data. Also in the definition of the the_data list, we enter the mean and precision values of the informative priors placed on the regression intercept and slope. Remember that one needs to convert the prior standard deviations \\(s_0\\) and \\(s_1\\) to the corresponding precision values.\ny <- as.vector(PriceAreaData$price_standardized)  \nx <- as.vector(PriceAreaData$size_standardized)\nN <- length(y)  \nthe_data <- list(\"y\" = y, \"x\" = x, \"N\" = N,\n                 \"mu0\" = 0, \"g0\" = 1,\n                 \"mu1\" = 0.7, \"g1\" = 44.4,\n                 \"a\" = 1, \"b\" = 1)\nWith the redefinition of the standardized variables y and x, the same JAGS script modelString is used to define the posterior distribution. As before, the run.jags() function is run, collecting a sample of 5000 draws from \\((\\beta_0, \\beta_1, \\sigma)\\).\nposterior2 <- run.jags(modelString,\n                       n.chains = 1,\n                       data = the_data,\n                       monitor = c(\"beta0\", \"beta1\", \"sigma\"),\n                       adapt = 1000,\n                       burnin = 5000,\n                       sample = 5000)\nComparing posteriors for two priors\nTo understand the influence of the informative prior, one can contrast this posterior distribution with a posterior using a weakly informative prior. Suppose one assumes that \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\) are independent with \\(\\beta_0 \\sim \\textrm{Normal}(0, 100)\\), \\(\\beta_1 \\sim \\textrm{Normal}(0.7, 100)\\) and \\(\\phi = 1 / \\sigma^2 \\sim \\textrm{Gamma}(1, 1)\\). This prior differs from the informative prior in that large values are assigned to the standard deviations, reflecting weak information about the location of the regression intercept and slope.\nthe_data <- list(\"y\" = y, \"x\" = x, \"N\" = N,\n                 \"mu0\" = 0, \"g0\" = 0.0001,\n                 \"mu1\" = 0.7, \"g1\" = 0.0001,\n                 \"a\" = 1, \"b\" = 1)\nposterior3 <- run.jags(modelString,\n                       n.chains = 1,\n                       data = the_data,\n                       monitor = c(\"beta0\", \"beta1\", \"sigma\"),\n                       adapt = 1000,\n                       burnin = 5000,\n                       sample = 5000)\nFigure 11.11 displays density estimates of the simulated posterior draws of the slope parameter \\(\\beta_1\\) under the informative and weakly informative prior distributions. Note that the “informative prior” posterior has less spread than the “weakly informative prior” posterior. This is to be expected since the informative prior adds more information about the location of the slope parameter. In addition, the “informative prior” posterior shifts the “weakly informative prior” posterior towards the prior belief that the slope is close to the value 0.7.\n\n\n\n\n\nDensity plots of posterior distributions of regression slope parameter using informative and weakly informative prior distributions.\n\n\n\n\nAfter viewing Figure 11.11, one would expect the posterior interval estimate for the slope \\(\\beta_1\\) to be shorter with the informative prior. We had earlier found that the 90% interval estimate for \\(\\beta_1\\) to be (0.551, 0.959) with the informative prior. The 90% interval for the slope with the weakly informative prior is (0.501, 1.08) which is about 40% longer than the interval using the informative prior.\nprint(posterior2, digits = 3)\n      Lower95   Median Upper95     Mean    SD Mode   MCerr \nbeta0  -0.267 0.000358   0.276 0.000372 0.138   -- 0.00195   \nbeta1   0.551    0.751   0.959    0.749 0.104   -- 0.00147   \nsigma   0.498     0.67   0.878    0.682 0.102   -- 0.00154\nprint(posterior3, digits = 3)\n      Lower95   Median Upper95     Mean    SD Mode   MCerr \nbeta0  -0.273 0.000362   0.281 0.000421 0.141   -- 0.00199    \nbeta1   0.501    0.794    1.08    0.792 0.146   -- 0.00207     \nsigma   0.502    0.677   0.894    0.688 0.105   -- 0.00163"
  },
  {
    "objectID": "regression.html#a-conditional-means-prior",
    "href": "regression.html#a-conditional-means-prior",
    "title": "6  Simple Linear Regression",
    "section": "6.9 A Conditional Means Prior",
    "text": "6.9 A Conditional Means Prior\n\nIn this chapter, we have illustrated two methods for constructing a prior on the parameters of a regression model. The first method reflects weakly informative prior beliefs about the parameters, and the second method assesses an informative prior on the regression parameters on a model on standardized data. In this section, a third method is described for representing prior beliefs on a regression model on the original data. This approach assesses a prior on \\((\\beta_0, \\beta_1, \\sigma)\\) indirectly by stating prior beliefs about the expected response value conditional on specific values of the predictor variable.\nLearning about a gas bill from the outside temperature\nA homeowner will typically have monthly payments on basic utilities such as water, natural gas, and electricity. One particular homeowner observes that her monthly natural gas bill seems to vary across the year. The bill is larger for colder months and smaller for warmer months. That raises the question: can one accurately predict one’s monthly natural gas bill from the outside temperature?\nTo address this question, the homeowner collects the monthly gas bill in dollars and the average monthly outside temperature for all twelve months in a particular year. Figure 11.12 displays a scatterplot of the temperatures and bill amounts. Note that the month bill appears to decrease as a function of the temperature. This motivates consideration of the linear regression model \\[\\begin{equation}\nY_i \\mid \\beta_0, \\beta_1, \\sigma \\sim {\\rm Normal}(\\beta_0 + \\beta_1 x_i, \\sigma),\n\\end{equation}\\] where \\(x_i\\) and \\(y_i\\) are respectively the average temperature (degrees in Fahrenheit) and the bill amount (in dollars) in month \\(i\\), and \\((\\beta_0, \\beta_1, \\sigma)\\) are the unknown regression parameters.\n\n\n\n\n\nScatterplot of average temperature and gas bill for twelve payments.\n\n\n\n\nA conditional means prior\nTo construct a prior, first assume that one’s beliefs about the regression parameters \\((\\beta_0, \\beta_1)\\) are independent of the beliefs on the standard deviation \\(\\sigma\\) and so the joint prior can be factored into the marginal densities: \\[\\begin{equation*}\n\\pi(\\beta_0, \\beta_1, \\sigma) = \\pi(\\beta_0, \\beta_1) \\pi(\\sigma).\n\\end{equation*}\\] With the unstandardized data, it is difficult to think directly about plausible values of the intercept \\(\\beta_0\\) and slope \\(\\beta_1\\) and also how these regression parameters are related. But it may be easier to formulate prior opinion about the mean values \\[\\begin{equation}\n\\mu_i^* = \\beta_0 + \\beta_1 x_i^*,\n\\end{equation}\\] for two specified values of the predictor \\(x_1^*\\) and \\(x_2^*\\). The conditional means approach proceeds in two steps.\n\nFor the first predictor value \\(x_1^*\\) construct a Normal prior for the mean value \\(\\mu_1^*\\). Let the mean and standard deviation values of this prior be denoted by \\(m_1\\) and \\(s_1\\), respectively.\nSimilarly, for the second predictor value \\(x_2^*\\) construct a Normal prior for the mean value \\(\\mu_2^*\\) with respective mean and standard deviation \\(m_2\\) and \\(s_2\\).\n\nIf one assumes that one’s beliefs about the conditional means are independent, then the joint prior for the vector \\((\\mu_1^*, \\mu_2^*)\\) has the form \\[\\begin{equation*}\n\\pi(\\mu_1^*, \\mu_2^*) = \\pi(\\mu_1^*) \\pi(\\mu_2^*).\n\\end{equation*}\\]\nThis prior on the two conditional means implies a Bivariate Normal prior on the regression parameters. The two conditional means \\(\\mu_1^*\\) and \\(\\mu_2^*\\) were written above as a function of the regression parameters \\(\\beta_0\\) and \\(\\beta_1\\). By solving these two equations for the regression parameters, one expresses each parameter as a function of the conditional means: \\[\\begin{equation}\n\\beta_1 = \\frac{\\mu_2^* - \\mu_1^*}{x_2 - x_1},\n\\label{eq:cmp:beta1}\n\\end{equation}\\] \\[\\begin{equation}\n\\beta_0 = \\mu_1^* - x_1 \\left(\\frac{\\mu_2^* - \\mu_1^*}{x_2 - x_1}\\right).\n\\label{eq:cmp:beta0}\n\\end{equation}\\] Note that both the slope \\(\\beta_0\\) and \\(\\beta_1\\) are linear functions of the two conditional means \\(\\mu_1^*\\) and \\(\\mu_2^*\\) and this implies that \\(\\beta_0, \\beta_1\\) will have a Bivariate Normal distribution.\nRegression analysis of the gas bill example\nThe process of constructing a conditional means prior is illustrated for our gas bill example. Consider two different temperature values, say 40 degrees and 60 degrees, and, for each temperature, construct a Normal prior for the expected monthly bill. After some thought, the following priors are assigned.\n\nIf \\(x = 40\\), the mean bill \\(\\mu_1^* = \\beta_0 + \\beta_1 (40)\\) is Normal with mean $100 and standard deviation $20. This statement indicates that one believes the average gas bill will be relatively high during a cold month averaging 40 degrees.\nIf \\(x = 60\\), the mean bill \\(\\mu_2^* = \\beta_0 + \\beta_1 (100)\\) is Normal with mean $50 and standard deviation $15. Here the month’s average temperature is warmer and one believes the gas cost will average $50 lower than in the first scenario.\n\nBy assuming independence of our prior beliefs about the two means, we have \\[\\begin{equation}\n\\pi(\\mu_1^*, \\mu_2^*) = \\phi(\\mu_1^*, 100, 20) \\phi(\\mu_2^*, 50, 15),\n\\end{equation}\\] where \\(\\phi(y, \\mu, \\sigma)\\) denotes the Normal density with mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\nThe prior on the two means is an indirect way of assessing a prior on the regression parameters \\(\\beta_0\\) and \\(\\beta_1\\). One simulate pairs \\((\\beta_0, \\beta_1)\\) from the prior distribution by simulating values of the means \\(\\mu_1^*\\) and \\(\\mu_2^*\\) from independent Normal distributions and applying Equation (11.22) and Equation (11.23).\nSimulated draws from the prior are conveniently produced using the JAGS software. The prior is specified for the conditional means by two applications of the dnorm() function and the regression parameters are defined as functions of the conditional means. The prior standard deviations of beta0 and beta1 are 20 and 15 and so the corresponding precisions are 1 / 20 ^ 2 and 1 / 15 ^ 2. These precision values s1 and s2 (not the standard deviations) are used in the JAGS script.\nmodelString = \"\nmodel{\nbeta1 <- (mu2 - mu1) / (x2 - x1)\nbeta0 <- mu1 - x1 * (mu2 - mu1) / (x2 - x1)\nmu1 ~ dnorm(m1, s1)\nmu2 ~ dnorm(m2, s2)\n}\"\nFigure 11.13 displays 1000 simulated draws of \\((\\beta_0, \\beta_1)\\) from the the conditional means prior. It is interesting to note that although the conditional means \\(\\mu_1^*\\) and \\(\\mu_2^*\\) are independent, the implied prior on the regression coefficients indicates that \\(\\beta_0\\) and \\(\\beta_1\\) are strongly negatively correlated.\n\n\n\n\n\nScatterplot of simulated draws of the regression parameters from the conditional means prior.\n\n\n\n\nThe conditional means approach is used to indirectly specify a prior on the regression vector \\(\\beta = (\\beta_0, \\beta_1)\\). To complete the prior, one assigns the precision parameter \\(\\phi = 1 / \\sigma^2\\) a Gamma prior with parameters \\(a\\) and \\(b\\). Then the prior density on all parameters has the form \\[\\begin{equation*}\n\\pi(\\beta_0, \\beta_1, \\sigma)  = \\pi_{CM}(\\beta_0, \\beta_1) \\pi(\\sigma),\n\\end{equation*}\\] where \\(\\pi_{CM}\\) is the conditional means prior.\nUsing this conditional means prior and the gas bill data, one also uses JAGS to simulate from the posterior distribution of \\((\\beta_0, \\beta_1, \\sigma)\\). In the exercises, the reader will have the opportunity to perform inference about the regression line. In addition, there will be an opportunity to compare inferences using conditional means and weakly informative priors."
  },
  {
    "objectID": "multipleregression.html",
    "href": "multipleregression.html",
    "title": "7  Bayesian Multiple Regression and Logistic Models",
    "section": "",
    "text": "In Chapter 11, we introduced simple linear regression where the mean of a continuous response variable was represented as a linear function of a single predictor variable. In this chapter, this regression scenario is generalized in several ways. In Section 12.2, the multiple regression setting is considered where the mean of a continuous response is written as a function of several predictor variables. Methodology for comparing different regression models is described in Section 12.2. The second generalization considers the case where the response variable is binary with two possible responses in Section 12.3. Here one is interested in modeling the probability of a particular response as a function of an predictor variable. Although these situations are more sophisticated, the Bayesian methodology for inference and prediction follows the general approach described in the previous chapters."
  },
  {
    "objectID": "multipleregression.html#bayesian-multiple-linear-regression",
    "href": "multipleregression.html#bayesian-multiple-linear-regression",
    "title": "7  Bayesian Multiple Regression and Logistic Models",
    "section": "7.2 Bayesian Multiple Linear Regression",
    "text": "7.2 Bayesian Multiple Linear Regression\n\n7.2.1 Example: expenditures of U.S. households\nThe U.S. Bureau of Labor Statistics (BLS) conducts the Consumer Expenditure Surveys (CE) through which the BLS collects data on expenditures, income, and tax statistics about households across the United States. Specifically, this survey provides information on the buying habits of U.S. consumers. The summary, domain-level statistics published by the CE are used for both policy-making and research, including the most widely used measure of inflation, the Consumer Price Index (CPI). In addition, the CE has measurements of poverty that determine thresholds for the U.S. Government’s Supplemental Poverty Measure.\nThe CE consists of two surveys. The Quarterly Interview Survey, taken each quarter, aims to capture large purchases (such as rent, utilities, and vehicles), containing approximately 7000 interviews. The Diary Survey, administrated on an annual basis, focuses on capturing small purchases (such as food, beverages, tobacco), containing approximately 14,000 interviews of households.\nThe CE publishes public-use microdata (PUMD), and a sample of the Quarterly Interview Survey in 2017 1st quarter is collected from the PUMD. This sample contains 1000 consumer units (CU), and provides information of the CU’s total expenditures in last quarter, the amount of CU income before taxes in past 12 months, and the CU’s urban/rural status. Table 12.1 provides the description of each variable in the CE sample.\nTable 12.1. The variable description for the CE sample.\n\n\n\nVariable\nDescription\n\n\n\n\nExpenditure\nContinuous; CU’s total expenditures in last quarter\n\n\nIncome\nContinuous; the amount of CU income before taxes in\n\n\n\npast 12 months\n\n\nUrbanRural\nBinary; the urban/rural status of CU: 1 = Urban,\n\n\n\n2 = Rural\n\n\n\nSuppose someone is interested in predicting a CU’s expenditure from its urban/rural status and its income before taxes. In this example, one is treating expenditure as the response variable and the other two variables as predictors. To proceed, one needs to develop a model to express the relationship between expenditure and the other two predictors jointly. This requires extending the simple linear regression model introduced in Chapter 11 to the case with multiple predictors. This extension is known as multiple linear regression – the word multiple indicates two or more predictors are present in the regression model. This section describes how to set up a multiple linear regression model, how to specify prior distributions for regression coefficients of multiple predictors, and how to make Bayesian inferences and predictions in this setting.\nRecall in Chapter 11, the mean response \\(\\mu_i\\) was expressed as a linear function of the single continuous predictor \\(x_i\\) depending on an intercept parameter \\(\\beta_0\\) and a slope parameter \\(\\beta_1\\):\n\\[\\begin{equation*}\n\\mu_i = \\beta_0 + \\beta_1 x_i.\n\\end{equation*}\\]\nIn particular, the slope parameter \\(\\beta_1\\) is interpreted as the change in the expected response \\(\\mu_i\\), when the predictor \\(x_i\\) of record \\(i\\) increases by a single unit. In the household expenditures example, not only there are multiple predictors, but the predictors are of different types including one continuous predictor (income), and one binary categorical (rural/urban status) predictor. As Chapter 11 focused on continuous-valued predictors, the interpretation of a regression coefficient for a binary categorical predictor is an important topic for discussion in this section.\n\n\n7.2.2 A multiple linear regression model\nSimilar to a simple linear regression model, a multiple linear regression model assumes a observation specific mean \\(\\mu_i\\) for the \\(i\\)-th response variable \\(Y_i\\). \\[\\begin{equation}\nY_i \\mid \\mu_i, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\mu_i, \\sigma), \\, \\, i = 1, \\cdots, n.\n\\end{equation}\\] In addition, it assumes that the mean of \\(Y_i\\), \\(\\mu_i\\), is a linear function of all predictors. In general, one writes \\[\\begin{equation}\n\\mu_i = \\beta_0 + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\cdots + \\beta_r x_{i,r},\n\\end{equation}\\] where \\(\\mathbf{x}_i = (x_{i,1}, x_{i,2}, \\cdots, x_{i,r})\\) is a vector of \\(r\\) known predictors for observation \\(i\\), and \\(\\mathbf{\\beta} = (\\beta_0, \\beta_1, \\cdots, \\beta_r)\\) is a vector of unknown regression parameters (coefficients), shared among all observations.\nFor studies where all \\(r\\) predictors are continuous, one interprets the intercept parameter \\(\\beta_0\\) as the expected response \\(\\mu_i\\) for observation \\(i\\), where all of its predictors take values of 0 (i.e. \\(x_{i,1} = x_{i,2} = \\cdots = x_{i,r} = 0\\)). One can also interpret the slope parameter \\(\\beta_i\\) (\\(j = 1, 2, \\cdots, r\\)) as the change in the expected response \\(\\mu_i\\), when the \\(j\\)-th predictor, \\(x_{i,j}\\), of observation \\(i\\) increases by a single unit while all remaining \\((r-1)\\) predictors stay constant.\nHowever in the household expenditures example from the CE data sample, not all predictors are continuous. The urban/rural status variable is a binary categorical variable, taking a value of 1 if the CU is in an urban area, and taking value of 2 if the CU is in a rural area. It is possible to consider the variable as continuous and interpret the associated regression coefficient as the change in the expected response \\(\\mu_i\\) when the CU’s urban/rural status changes by one unit from urban to rural (corresponding to change from one to two). But it is much more common to consider this variable as a binary categorical variable that classifies the observations into two distinct groups: the urban group and the rural group. It will be seen that this classification puts an emphasis on the difference of the expected responses between the two distinct groups.\nConsequently, consider the construction of a new indicator variable in place of the binary variable. This new indicator variable takes a value of 0 if the CU is in an urban area, and a value of 1 if the CU is in a rural area. To understand the implication of this indictor variable, it is helpful to consider a simplified regression model with a single predictor, the binary indicator for rural area \\(x_i\\). This simple linear regression model expresses the linear relationship as \\[\\begin{equation}\n\\mu_i = \\beta_0 + \\beta_1 x_i  =\n\\begin{cases}\n  \\beta_0, & \\text{ the urban group}; \\\\\n  \\beta_0 + \\beta_1, & \\text{ the rural group}.  \\\\\n  \\end{cases}\n\\end{equation}\\] The expected response \\(\\mu_i\\) for CUs in the urban group is given by \\(\\beta_0\\), and the expected response \\(\\mu_i\\) for CUs in the rural group is \\(\\beta_0 + \\beta_1\\). In this case \\(\\beta_1\\) represents the change in the expected response \\(\\mu_i\\) from the urban group to the rural group. That is, \\(\\beta_1\\) represents the effect of being a member of the rural group.\nBefore continuing, there is a need for some data transformation. Both the expenditure and income variables are highly skewed, and both variables have more even distributions if we apply logarithm transformations. So the response variable will be the logarithm of the CU’s total expenditure and the continuous predictor will be the logarithm of the CU 12-month income. Figure 12.1 displays scatterplots of log income and log expenditure where the two panels correspond to urban and rural residents. Note that in each panel there appears to be a positive association between log income and log expenditure.\n\n\n\n\n\nScatterplot of log total income and log total expenditure for the urban and rural groups.\n\n\n\n\nNow that the data transformations are completed, one is ready to set up a multiple linear regression model for the log expenditure response including one continuous predictor and one binary categorical predictor. The expected response \\(\\mu_i\\) is expressed as a linear combination of the log income variable and the rural indicator variable. \\[\\begin{eqnarray}\n\\mu_i = \\beta_0 &+& \\beta_1 x_{i, income} + \\beta_2 x_{i, rural}.\n\\end{eqnarray}\\] The multiple linear regression model is written as \\[\\begin{eqnarray}\nY_i \\mid \\beta_0, \\beta_1, \\beta_2, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\beta_0 &+& \\beta_1 x_{i, income} + \\beta_2 x_{i, rural}, \\sigma), \\nonumber \\\\\n\\end{eqnarray}\\] where \\(\\mathbf{x}_i = (x_{i, income}, x_{i, rural})\\) is a vector of predictors and \\(\\sigma\\) is the standard deviation in the Normal model shared among all responses \\(Y_i\\)’s.\nThe regression parameters have clear interpretations. The intercept parameter \\(\\beta_0\\) is the expected log expenditure when both the remaining variables are 0’s: \\(x_{i, income} = x_{i, rural} = 0\\). This intercept represents the mean log expenditure for an urban CU with a log income of 0.\nThe regression slope coefficient \\(\\beta_1\\) is associated with the continuous predictor variable, log income. This slope \\(\\beta_1\\) can be interpreted as the change in the expected log expenditure when the predictor log income of record \\(i\\) increases by one unit, while all other predictors stay unchanged.\nThe remaining regression coefficient \\(\\beta_2\\) represents the change in the expected log expenditure compared relative to the expected log expenditure of the associated reference category, while all other predictors stay unchanged. In other words, \\(\\beta_2\\) is the change in the expected log expenditure of a rural CU comparing to an urban CU, when the two CUs have the same log income.\nWith an understanding of the meaning of the regression coefficients, one can now proceed to a description of a prior and MCMC algorithm of this multiple linear regression model. Note that one needs to construct a prior distribution for the set of parameters \\((\\beta_0, \\beta_1, \\beta_2, \\sigma)\\). We begin by describing the weakly informative prior approach and the subsequent MCMC inference.\n\n\n7.2.3 Weakly informative priors and inference through MCMC\nIn situations where the data analyst has limited prior information about the regression parameters or the standard deviation, it is desirable to assign a prior that has little impact on the posterior. Similar to the weakly informative prior for simple linear regression described in Chapter 11, one assigns a weakly informative prior for a multiple linear regression model using standard functional forms. Assuming independence, the prior density for the set of parameters \\((\\beta_0, \\beta_1, \\beta_2, \\sigma)\\) is written as a product of the component densities:\n\\[\\begin{equation*}\n\\pi(\\beta_0, \\beta_1, \\beta_2, \\sigma) = \\pi(\\beta_0) \\pi(\\beta_1) \\pi(\\beta_2) \\pi(\\sigma),\n\\end{equation*}\\] where \\(\\beta_0\\) is \\(\\textrm{Normal}(m_0, s_0)\\), \\(\\beta_1\\) is \\(\\textrm{Normal}(m_1, s_1)\\), \\(\\beta_2\\) is \\(\\textrm{Normal}(m_2, s_2)\\), and the precision parameter \\(\\phi = 1/\\sigma^2\\), the inverse of the variance \\(\\sigma^2\\), is \\(\\textrm{Gamma}(a, b)\\).\nIf one has little information about the location of the regression parameters \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\), one assigns the respective prior means to be 0 and the prior standard deviations to be large values, say 20. In similar fashion, if little knowledge exists about the location of the sampling standard deviation \\(\\sigma\\), one assigns small values for the hyperparameters, \\(a\\) and \\(b\\), say \\(a = b = 0.001\\), for the Gamma prior placed on the precision \\(\\phi = 1/\\sigma^2\\).\nOne uses the JAGS software to draw MCMC samples from this multiple linear regression model. The process of using JAGS mimics the general approach used in earlier chapters.\nDescribe the model by a script\n The first step in using JAGS writes the following script defining the multiple linear regression model, saving the script in the character string modelString.\nmodelString <-\"\nmodel {\n## sampling\nfor (i in 1:N){\n   y[i] ~ dnorm(beta0 + beta1*x_income[i] +\n              beta2*x_rural[i], invsigma2)\n}\n## priors\nbeta0 ~ dnorm(mu0, g0)\nbeta1 ~ dnorm(mu1, g1)\nbeta2 ~ dnorm(mu2, g2)\ninvsigma2 ~ dgamma(a, b)\nsigma <- sqrt(pow(invsigma2, -1))\n}\n\"\nIn the sampling section of the script, the iterative loop goes from 1 to N, where N is the number of observations with index i. Recall that the Normal distribution dnorm in JAGS is stated in terms of the mean and the precision and the variable invsigma2 corresponds to the Normal sampling precision. The variable sigma is defined in the prior section of the script so one can track the simulated values of the standard deviation \\(\\sigma\\). Also the variables m0, m1, m2 correspond to the means, and g0, g1, g2 correspond to the precisions of the Normal prior densities for the three regression parameters.\nDefine the data and prior parameters\nThe next step is to provide the observed data and the values for the prior parameters. In the R script below, a list the_data contains the vector of log expenditures, the vector of log incomes, the indicator variables for the categories of the binary categorical variable, and the number of observations. This list also contains the means and precisions of the Normal priors for beta0 through beta2 and the values of the two parameters a and b of the Gamma prior for invsigma2. The prior mean of the Normal priors on the individual regression coefficients is 0, for mu0 through mu2. The prior standard deviations of the Normal priors on the individual regression coefficients are 20, and so the corresponding precision values are \\(1/20^2 = 0.0025\\) for g0 through g2.\ny <- as.vector(CEsample$log_TotalExp)\nx_income <- as.vector(CEsample$log_TotalIncome)\nx_rural <- as.vector(CEsample$Rural)\nN <- length(y)\nthe_data <- list(\"y\" = y, \"x_income\" = x_income,\n                 \"x_rural\" = x_rural, \"N\" = N,\n                 \"mu0\" = 0, \"g0\" = 0.0025,\n                 \"mu1\" = 0, \"g1\" = 0.0025,\n                 \"mu2\" = 0, \"g2\" = 0.0025,\n                 \"a\" = 0.001, \"b\" = 0.001)\nGenerate samples from the posterior distribution\nThe run.jags() function in the runjags package generates posterior samples by the MCMC algorithm using the JAGS software. The script below runs one MCMC chain with an adaption period of 1000 iterations, a burn-in period of 5000 iterations, and an additional set of 20,000 iterations to be run and collected for inference. By using the argument monitor = c(\"beta0\", \"beta1\", \"beta2\", \"sigma\"), one keeps tracks of all four model parameters. The output variable posterior contains a matrix of simulated draws.\nposterior <- run.jags(modelString,\n                      n.chains = 1,\n                      data = the_data,\n                      monitor = c(\"beta0\", \"beta1\",\n                                  \"beta2\", \"sigma\"),\n                      adapt = 1000,\n                      burnin = 5000,\n                      sample = 20000)\nMCMC diagnostics\nTo obtain valid inferences from the posterior draws from the MCMC simulation, one should assess convergence of the MCMC chain. The plot() function with the argument input vars returns four diagnostic plots (trace plot, empirical CDF, histogram and autocorrelation plot) for the specified parameter. For example, Figure 12.2 shows the diagnostic plots for the slope parameter \\(\\beta_1\\) for the log income predictor using the following code.\nplot(posterior, vars = \"beta1\")\n\n\n\n\n\nMCMC diagnostics plots for the regression slope parameter \\(\beta_1\\) for the log income predictor.\n\n\n\n\nThe upper left trace plot shows MCMC mixing for the 20,000 simulated draws of \\(\\beta_1\\). In this example, the lower right autocorrelation plot indicates relatively large correlation values between adjacent posterior draws of \\(\\beta_1\\). In this particular example, since the mixing was not great, it was decided to take a larger sample of 20,000 draws to get good estimates of the posterior distribution. In usual practice, one should perform these diagnostics for all parameters in the model.\nSummarization of the posterior\nPosterior summaries of the parameters are obtained by use of the print(posterior, digits = 3) command. Note that these summaries are based on the 20,000 iterations from the sampling period excluding the samples from the adaption and burn-in periods.\nprint(posterior, digits = 3)\n      Lower95 Median Upper95   Mean     SD Mode    MCerr \nbeta0    4.59   4.95    5.36   4.95  0.201   --   0.0166  \nbeta1   0.328  0.365     0.4  0.365 0.0188   --  0.00155    \nbeta2  -0.482 -0.267 -0.0476 -0.269  0.112   --  0.00112    \nsigma   0.735  0.769   0.802  0.769 0.0172   -- 0.000172    \n\nOne way to determine if the two variables are useful predictors is to inspect the location of the 90% probability intervals. The interval estimate for \\(\\beta_1\\) (corresponding to log income) is (0.328, 0.400) and the corresponding estimate for \\(\\beta_2\\) (corresponding to the rural variable ) is (\\(-0.482, -0.048\\)). Since both intervals do not cover zero, this indicates that both log income and the rural variables are helpful in predicting log expenditure.\nSeveral types of summaries of the posterior distribution are illustrated. Suppose one is interested in learning about the expected log expenditure. From the regression model, the mean log expenditure is equal to \\[\\begin{equation}\n\\beta_0 + \\beta_1 x_{income}\n\\end{equation}\\] for urban CUs, and equal to \\[\\begin{equation}\n\\beta_0 + \\beta_1 x_{income} + \\beta_2\n\\end{equation}\\] for rural CUs. Figure 12.3 displays simulated draws from the posterior of the expected log expenditure superposed over the scatterplots of log income and log expenditure for the urban and rural cases. Note that there is more variation in the posterior draws for the rural units – this is reasonable since only a small portion of the data came from rural units.\n\n\n\n\n\nScatterplot of log income and log expenditure for the urban and rural groups. The superposed lines represent draws from the posterior distribution of the expected response.\n\n\n\n\nFigure 12.4 displays the posterior density of the mean log expenditure for the predictor pairs (log Income = 9, Rural = 1), (log Income = 9, Rural = 0), (log Income = 12, Rural = 1), and (log Income = 12, Rural = 0). It is pretty clear from this graph that log income is the more important predictor. For both urban and rural CUs, the log total expenditure is much larger for log income = 12 than for log income = 9. Given a particular value of log expenditure, the log expenditure is slightly higher for urban (Rural = 0) compared to rural units.\n\n\n\n\n\nPosterior distributions of the expected log expenditure for units with different income and rural variables.\n\n\n\n\n\n\n7.2.4 Prediction\nA related problem is to predict a CU’s log expenditure for a particular set of predictor values. Let \\(\\tilde{Y}\\) denote the future response value for the expenditure for given values of income \\(x^*_{income}\\) and rural value \\(x^*_{rural}\\). One represents the posterior predictive density of \\(\\tilde{Y}\\) as \\[\\begin{equation}\nf(\\tilde{Y} = \\tilde{y} \\mid y) = \\int f(\\tilde{y} \\mid y, \\beta, \\sigma) \\pi(\\beta, \\sigma   \\mid  y) d\\beta,\n\\end{equation}\\] where \\(\\pi(\\beta, \\sigma | y)\\) is the posterior density and \\(f(\\tilde{Y} = \\tilde{y} \\mid y, \\beta, \\sigma)\\) is the Normal sampling density which depends on the predictor values.\nR Work Since we have already produced simulated draws from the posterior distribution, it is straightforward to simulate from the posterior predictive distribution. One simulates a single draw from \\(f(\\tilde{Y} = \\tilde{y} \\mid y)\\) by first simulating a value of \\(({\\mathbf{\\beta}}, \\sigma)\\) from the posterior – call this draw \\((\\beta^{(s)}, \\sigma^{(s)})\\). Then one simulates a draw of \\(\\tilde{Y}\\) from a Normal density with mean \\(\\beta_0^{(s)} + \\beta_1^{(s)} x^*_{income} + \\beta_2^{(s)} x^*_{rural}\\) and standard deviation \\(\\sigma^{(s)}\\). By repeating this process for a large number of iterations, the function one_predicted() simulates a sample from the posterior prediction distribution for particular predictor values \\(x^*_{income}\\) and \\(x^*_{rural}\\).\none_predicted <- function(x1, x2){\n  lp <- post[ , \"beta0\"] +  x1 * post[ , \"beta1\"] +\n    x2 * post[, \"beta2\"]\n  y <- rnorm(5000, lp, post[, \"sigma\"])\n  data.frame(Value = paste(\"Log Income =\", x1,\n                           \"Rural =\", x2),\n             Predicted_log_TotalExp = y)\n}\ndf <- map2_df(c(12, 12),\n              c(0, 1), one_predicted)\nThis procedure is implemented for the two sets of predictor values (log income, rural) = (12, 1) and (log income, rural) = (12, 0). Figure 12.5 displays density estimates of the posterior predictive distributions for the two cases. Comparing Figures 12.4 and 12.5, note the increased width of the prediction densities relative to the expected response densities. One confirms this by computing interval estimates. For example, for the values (log income, rural) = (12, 1), a 90% interval for the expected log expenditure is (8.88, 9.25) and the 90% interval for the predicted log expenditure for the same predictor values is (7.81, 10.34).\n\n\n\n\n\nPredictive distributions of the log expenditure for units with different income and rural variables."
  },
  {
    "objectID": "multipleregression.html#comparing-regression-models",
    "href": "multipleregression.html#comparing-regression-models",
    "title": "7  Bayesian Multiple Regression and Logistic Models",
    "section": "7.3 Comparing Regression Models",
    "text": "7.3 Comparing Regression Models\nWhen one fits a multiple regression model, there is a list of inputs, i.e. potential predictor variables, and there are many possible regression models to fit depending on what inputs are included in the model. In the household expenditures example, there are two possible inputs, the log total income and the rural/urban status and there are 2 x 2 = 4 possible models depending on the inclusion or exclusion of each input. When there are many inputs, the number of possible regression models can be quite large and so there needs to be some method for choosing the “best” regression model. A simple example to used to describe what is meant by a best model and then a general method is outlined for selecting between models.\nLearning about a career trajectory\nTo discuss model selection in a simple context, consider a baseball modeling problem that will be more thoroughly discussed in Chapter 13. One is interested in seeing how a professional athlete ages during his or her career. In many sports, an athletic enters his/her professional career at a modest level of performance, gets better until a particular age when peak performance is achieved, and then decreases in the level of performance until retirement. One can use a regression model to explore the pattern of performance over age – this pattern is typically called the athletic’s career trajectory.\nWe focus on a particular great historical baseball player Mike Schmidt who played in Major League Baseball from 1972 through 1989. Figure 12.6 first displays a scatterplot of the rate that Schmidt hit home runs as a function of his age. If \\(y_i\\) denotes Schmidt’s home run rate during the \\(i\\)-th season when his age was \\(x_i\\), Figure 12.6 further overlays fits from the following three career trajectory models:\n\nModel 1 - Linear: \\[\\begin{equation*}\nY_i \\mid \\beta_0, \\beta_1, x_i, \\sigma \\sim \\textrm{Normal}(\\beta_0 + \\beta_1 (x_i - 30), \\sigma).\n\\end{equation*}\\]\nModel 2 - Quadratic: \\[\\begin{equation*}\nY_i \\mid \\beta_0, \\beta_1, \\beta_2, x_i, \\sigma \\sim \\textrm{Normal}(\\beta_0 + \\beta_1 (x_i - 30) + \\beta_2 (x_i - 30)^2, \\sigma).\n\\end{equation*}\\]\nModel 3 - Cubic:\n\n\\[\nY_i \\mid \\beta_0, \\beta_1, \\beta_2, \\beta_3, x_i, \\sigma \\sim \\textrm{Normal}(\\beta_0 + \\beta_1 (x_i - 30)+ \\beta_2 (x_i - 30)^2\n+ \\beta_3 (x_i - 30)^3,  \\sigma).\n\\]\n\n\n\n\n\nScatterplot of age and home run rate for Mike Schmidt. Fits from linear, quadratic, and cubic models are overlaid.\n\n\n\n\nModel 1 says that Schmidt’s true home run performance is a linear function of his age, Model 2 says that his home run performance follows a parabolic shape, and Model 3 indicates that his performance follows a cubic curve. Based on the earlier comments about the knowledge of shapes of career trajectories, the linear function of age given in Model 1 does not appear suitable in reflecting the “down, up, down” trend that we see in the scatterplot. The fits of Models 2 and 3 appear to be similar in appearance, but there are differences in the interpretation of the fits. The quadratic fit (Model 2) indicates that Schmidt’s peak performance occurs about the age of 30 while the cubic fit (Model 3) indicates that his peak performance occurs around the age of 33. How can we choose between the two models?\nUnderfitting and overfitting\nIn model building, there are two ways of misspecifying a model that we call “underfitting” and “overfitting” that is described in the context of this career trajectory example. First, it is important that the model includes all inputs is helpful in explaining the variation in the response variable. Failure to include relevant inputs in the model will result in underfitting. In our example, age is the predictor variable and the possible inputs are age, age\\(^2\\), and age\\(^3\\). If we use Model 1 which includes only the input age, this particular model appears to underfit the data since this model does not reflect the increasing and decreasing pattern in the home run rates that we see in Figure 12.6.\nAt the other extreme, one should be careful not to include too many inputs in the model. When one includes more inputs in our regression model than needed, one has overfitting. Model 3 possibly overfits the data, since it may not be necessary to represent a player’s trajectory by a cubic curve – perhaps a quadratic curve is sufficient. In an extreme situation, by increasing the degree of the polynomial function of age, one can find a fitted curve that goes through most of the points in the scatterplot. This would be a severe case of overfitting since it is unlikely that a player’s true career trajectory is represented by a polynomial of a high degree.\nCross-validation\nHow does one choose a suitable regression model that avoids the underfitting and overfitting problems described above? A general method of comparing models is called cross-validation. In this method, one partitions the dataset into two parts – the “training” and “testing” components. One initially fits each regression model to the training dataset. Then one uses each fitted model to predict the response variable in the testing dataset. The model that is better in predicting observations in the future testing dataset is the preferred model.\nLet’s describe how one implements cross-validation for our career trajectory example. In the example, Mike Schmidt had a total of 8170 at-bats for 13 seasons. One randomly divides these 8170 at-bats into two datasets – 4085 of the at-bats (and the associated home run and age variables) are placed in a training dataset and the remaining at-bats become the testing dataset. Let \\(\\{(x_i^{(1)}, y_i^{(1)})\\}\\) denote the age and home run rate variables from the training dataset and \\(\\{(x_i^{(2)}, y_i^{(2)})\\}\\) denote the corresponding variables from the testing dataset.\nSuppose one considers the use of Model 1 where the home run rate \\(Y_i^{(1)} \\sim \\textrm{Normal}(\\mu_i, \\sigma)\\) where the mean rate is \\(\\mu_i = \\beta_0 + (\\beta_1 - 30) x_i^{(1)}\\). One places a weakly informative prior on the vector of parameters \\((\\beta_0, \\beta_1, \\sigma)\\) and define the likelihood using the training data. One uses JAGS to simulate from the posterior distribution and obtain the fitted regression \\[\\begin{equation*}\n\\mu = \\tilde{\\beta}_0 + (\\tilde{\\beta}_1 - 30) x,\n\\end{equation*}\\] where \\(\\tilde{\\beta}_0\\) and \\(\\tilde{\\beta}_1\\) are the posterior means of the regression intercept and slope respectively.\nOne now uses this fitted regression to predict values of the home run rate from the testing dataset. One could simulate predictions from the posterior predictive distribution, but for simplicity, suppose one is interested in making a single prediction. For the \\(i\\)-th value of age \\(x_i^{(2)}\\) in the testing dataset, our “best” prediction of the \\(i\\)-th home run rate from Model 1 would be \\(\\tilde{y}_i^{(2)}\\) where \\[\\begin{equation*}\n\\tilde{y}_i^{(2)} = \\tilde{\\beta}_0 + (\\tilde{\\beta}_1 - 30) x_i^{(2)}.\n\\end{equation*}\\] If one performs this computation for all ages, one obtains a set of predictions {\\(\\tilde{y}_i^{(2)}\\}\\) that one would like to be close to the actual home run rates {\\(y_i^{(2)}\\}\\) in the training dataset. It is unlikely that the prediction will be on target so one considers the prediction error that is the difference between the prediction and the response \\(|\\tilde{y}_i^{(2)} - y_i^{(2)}|\\). One measures the closeness of the predictions by computing the sum of squared prediction errors (SSPE): \\[\\begin{equation}\nSSPE = \\sum (\\tilde{y}_i^{(2)} - y_i^{(2)})^2.\n\\end{equation}\\]\nThe measure \\(SSPE\\) describes how well the fitted model predicts home run rates from the training dataset. One uses this measure to compare predictions from alternative regression models. Specifically, suppose each of the regression models (Model 1, Model 2, and Model 3) is fit to the training dataset and each of the fitted models is used to predict the home run rates of the testing dataset. Suppose the sum of squared prediction errors for the three fitted models are \\(SSPE_1\\), \\(SSPE_2\\) and \\(SSPE_3\\). The best model is the model corresponding to the smallest value of \\(SSPE\\). If this model turns out to be Model 2, then we say that Model 2 is best in that it is best in predicting home run rates in a future or “out-of-sample” dataset.\nApproximating cross-validation by DIC\nThe cross validation method of assessing model performance can be generally applied in many situations. However, there are complications in implementing cross validation in practice. One issue is how the data should be divided into the training and testing components. In our example, the data was divided into two datasets of equal size, but it is unclear if this division scheme is best in practice. Another issue is that the two datasets were divided using a random mechanism. The problem is that the predictions and the sum of squared prediction errors can depend on the random assignment of the two groups. That raises the question – is it necessary to perform cross validation to compare the predictive performance of two models?\nA best regression model is the one that provides the best predictions of the response variable in an out-of-sample or future dataset. Fortunately, it is not necessary in practice to go through the cross-validation process. It is possible to compute a measure, called the or DIC, from the simulated draws from the posterior distribution that approximates a model’s out-of-sample predictive performance. The description and derivation of the DIC measure is outside of the scope of this text – a brief description of this method is contained in the appendix. But we illustrate the use of DIC measure for the career trajectory example. It can be applied generally and is helpful for comparing the predictive performance of several Bayesian models.\nExample of model comparison\nTo illustrate the application of DIC, let’s return to the career trajectory example. As usual practice, JAGS will be used to fit a specific Bayesian model. To fit the quadratic model \\(M_2\\), one writes the following JAGS model description.\nAt the sampling stage, the home run rates y[i] are assumed to be a quadratic function of the ages x[i], and at the prior stage, the regression coefficients beta0, beta1, beta2, and the precision phi are assigned weakly informative priors. The variable the_data is a list containing the observed home run rates, ages, and sample size.\nmodelString = \"\nmodel {\nfor (i in 1:N){\n   y[i] ~ dnorm(mu[i], phi)\n   mu[i] <- beta0 + beta1 * (x[i] - 30) +\n            beta2 * pow(x[i] - 30, 2)\n}\nbeta0 ~ dnorm(0, 0.001)\nbeta1 ~ dnorm(0, 0.001)\nbeta2 ~ dnorm(0, 0.001)\nphi ~ dgamma(0.001, 0.001)\n}\n\"\nd <- filter(sluggerdata,\n            Player == \"Schmidt\", AB >= 200)\nthe_data <- list(y = d$HR / d$AB,\n                 x = d$Age,\n                 N = 16)\nThe model is fit by the run.jags() function. To compute DIC, it is necessary to run multiple chains, which is indicated by the argument n.chains = 2 that two chains will be used.\npost2 <- run.jags(modelString,\n                      n.chains = 2,\n                      data = the_data,\n                      monitor = c(\"beta0\", \"beta1\",\n                                  \"beta2\", \"phi\"))\nTo compute DIC, the extract.runjags() function is applied on the runjags object post2. The “Penalized deviation” output is the value of DIC computed on the simulated MCMC output.\nextract.runjags(post2, \"dic\") \nMean deviance:  -88.98 \npenalty 4.817 \nPenalized deviance: -84.17\nThe value of DIC = \\(-84.17\\) for this single quadratic regression model is not meaningful, but one compares values of DIC for competing models. Suppose one wishes to compare models \\(M_1, M_2, M_3\\) and a quartic regression where one represents the home run rate as a polynomial of fourth degree of the age. For each model, a JAGS script is written where the regression coefficients and the precision parameter are assigned weakly informative priors. The run.jags() function is applied to produce a posterior sample and the extract.runjags() with the dic argument to extract the value of DIC. Table 12.2 displays the values of DIC for the four regression models. The “best” model is the model with the smallest value of DIC. Looking at the values in Table 12.2, one sees that the quadratic model has the smallest value of \\(-84.2\\). The interpretation is that the quadratic model is best in the sense that it will provide the best out-of-sample predictions.\nTable 12.2. DIC values for four regression models fit to Mike Schmidt’s home run rates.\n\n\n\nModel\nDIC\n\n\n\n\nLinear\n(-80.4)\n\n\nQuadratic\n(-84.2)\n\n\nCubic\n(-82.1)\n\n\nQuartic\n(-79.0)"
  },
  {
    "objectID": "multipleregression.html#bayesian-logistic-regression",
    "href": "multipleregression.html#bayesian-logistic-regression",
    "title": "7  Bayesian Multiple Regression and Logistic Models",
    "section": "7.4 Bayesian Logistic Regression ",
    "text": "7.4 Bayesian Logistic Regression \n\n7.4.1 Example: U.S. women labor participation\nThe University of Michigan Panel Study of Income Dynamics (PSID) is the longest running longitudinal household survey in the world. The study began in 1968 with a nationally representative sample of over 18,000 individuals living in 5000 families in the United States. Information on these individuals and their descendants has been collected continuously, including data covering employment, income, wealth, expenditures, health, marriage, childbearing, child development, philanthropy, education, and numerous other topics.\nThe PSID 1976 survey has attracted particular attention since it interviewed wives in the households directly in the previous year. The survey provides helpful self-reporting data sources for studies of married women’s labor supply. A sample includes information on family income exclusive of wife’s income (in $1000) and the wife’s labor participation (yes or no). This PSID sample contains 753 observations and two variables. Table 12.3 provides the description of each variable in the PSID sample.\nTable 12.3. The variable description for hte PSID sample.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nLaborParticipation\nBinary; the labor participation status of the wife:\n\n\n\n1 = yes, 0 = no\n\n\nFamilyIncome\nContinuous; the family income exclusive of wife’s\n\n\n\nincome, in $1000, 1975 U.S. dollars\n\n\n\nSuppose one is interested in predicting a wife’s labor participation status from the family income exclusive of her income. In this example, one is treating labor participation as the response variable and the income variable as a predictor. Furthermore, the response variable is not continuous, but binary – either the wife is working or she is not. To analyze a binary response such as labor participation, one is interested in estimating the probability of a labor participation (yes) as a function of the predictor variable, family income exclusive of her income. This requires a new model that can express the probability of a yes as a function of the predictor variable.\nFigure 12.7 displays a scatterplot of the family income against the labor participation status. Since the labor participation variable is binary, the points are jittered in the vertical direction. From this graph, we see that roughly half of the wives are working and it is difficult to see if the family income is predictive of the participation status.\n\n\n\n\n\nScatterplot of the family income against the wife’s labor participation. Since the participation value is binary, the points have been jittered in the vertical direction.\n\n\n\n\nRecall in Chapter 11, when one had a continuous-valued response variable and a single continuous predictor, the mean response \\(\\mu_i\\) was be expressed as a linear function of the predictor through an intercept parameter \\(\\beta_0\\) and a slope parameter \\(\\beta_1\\): \\[\\begin{equation}\n\\mu_i = \\beta_0 + \\beta_1 x_i.\n\\end{equation}\\] Moreover it is reasonable to use a Normal regression model where the response \\(Y_i\\) is Normally distributed where the mean \\(\\mu_i\\) with a linear function as in Equation (12.10). \\[\\begin{equation*}\nY_i \\mid \\mu_i, \\sigma \\overset{ind}{\\sim} \\textrm{Normal}(\\mu_i, \\sigma), \\,\\,\\, i = 1, \\cdots, n.\n\\end{equation*}\\]\nHowever, such a Normal density setup is not sensible for this labor participation example. For a binary response \\(Y_i\\), the mean is a probability \\(\\mu_i\\) that falls in the interval from 0 to 1. Thus the model \\(\\mu_i = \\beta_0 + \\beta_1 x_i\\) is not sensible since the linear component \\(\\beta_0 + \\beta_1 x_i\\) is on the real line, not in the interval [0, 1].\nIn the upcoming subsections, it is described how to construct a regression model for binary responses using a linear function. In addition, this section describes how to interpret regression coefficients, how to specify prior distributions for these coefficients, and simulate posterior samples for these models.\n\n\n7.4.2 A logistic regression model\nRecall in Chapter 1 and Chapter 7, the definition of odds was introduced – an odds is the ratio of the probability of some event will take place over the probability of the event will not take place. The notion of odds will be used in how one represents the probability of the response in the regression model.\nIn the PSID example, let \\(p_i\\) be the probability of labor participation of married woman \\(i\\), and the corresponding odds of participation is \\(\\frac{p_i}{1 - p_i}\\). The probability \\(p_i\\) falls in the interval [0, 1] and the odds is a positive real number. If one applies the logarithm transformation on the odds, one obtains a quantity, called a log odds or logit, that can take both negative and positive values on the real line. One obtains a linear regression model for a binary response by writing the logit in terms of the linear predictor.\nThe binary response \\(Y_i\\) is assumed to have a Bernoulli distribution with probability of success \\(p_i\\).\n\\[\\begin{equation}\nY_i \\mid p_i \\overset{ind}{\\sim} \\textrm{Bernoulli}(p_i), \\,\\,\\, i = 1, \\cdots, n.\n\\end{equation}\\] The logistic regression model writes that the logit of the probability \\(p_i\\) is a linear function of the predictor variable \\(x_i\\): \\[\\begin{equation}\n\\textrm{logit}(p_i) = \\textrm{log}\\left(\\frac{p_i}{1 - p_i}\\right) = \\beta_0 + \\beta_1 x_i.\n\\end{equation}\\]\nIt is more challenging to interpret the regression coefficients in a logistic model. In simple linear regression with one predictor, the interpretation of the intercept and the slope is relatively straightforward, as the linear function is directly assigned to the mean \\(\\mu_i\\). With the logit function as in Equation (12.12), one sees that the regression coefficients \\(\\beta_0\\) and \\(\\beta_1\\) are directly related to the log odds \\(\\textrm{log}\\left(\\frac{p_i}{1 - p_i}\\right)\\) instead of \\(p_i\\).\nFor example, the intercept \\(\\beta_0\\) is the log odds \\(\\textrm{log}\\left(\\frac{p_i}{1 - p_i}\\right)\\) for observation \\(i\\) when the predictor takes a value of 0. In the PSID example, it refers to the log odds of labor participation of a married woman, whose family has 0 family income exclusive of her income.\nThe slope \\(\\beta_1\\) refers to the change in the expected log odds of labor participation of a married woman who has an additional $1000 family income exclusive of her own income.\nBy rearranging the logistic regression Equation (12.12), one expresses the regression as a nonlinear equation for the probability of success \\(p_i\\): \\[\\begin{eqnarray}\n\\textrm{log}\\left(\\frac{p_i}{1 - p_i}\\right) &=&  \\beta_0 + \\beta_1 x_i \\nonumber \\\\\n\\frac{p_i}{1 - p_i} &=& \\exp(\\beta_0 + \\beta_1 x_i)  \\nonumber \\\\\n\\end{eqnarray}\\] \\[\\begin{equation}\np_i = \\frac{\\exp(\\beta_0 + \\beta_1 x_i)}{1 + \\exp(\\beta_0 + \\beta_1 x_i)}.\n\\end{equation}\\] Equation (12.13) shows that the logit function guarantees that the probability \\(p_i\\) lies in the interval [0, 1].\nWith these building blocks, one proceeds to prior specification and MCMC posterior inference of this logistic regression model. Note that a prior distribution is needed for the set of regression coefficient parameters: \\((\\beta_0, \\beta_1)\\). In the next subsections, a conditional means prior approach is explored in this prior construction and the subsequent MCMC inference.\n\n\n7.4.3 Conditional means priors and inference through MCMC\nA conditional means prior can be constructed in a straightforward manner for logistic regression with a single predictor. This type of prior was previously constructed in Chapter 11 for a Normal regression problem in the gas bill example. A weakly informative prior can always be used when little prior information is available. In contrast, the conditional means prior allows the data analyst to incorporate useful prior information about the probabilities at particular observation values.\nThe task is to construct a prior on the vector of regression coefficients \\(\\beta = (\\beta_0, \\beta_1)\\).\nSince the linear component \\(\\beta_0 + \\beta_1 x\\) is indirectly related to the probability \\(p\\), it is generally difficult to think directly about plausible values of the intercept \\(\\beta_0\\) and slope \\(\\beta_1\\) and think about the relationship between these regression parameters. Instead of constructing a prior on \\(\\beta\\) directly, a conditional means prior indirectly specifies a prior by constructing priors on the probability values \\(p_1\\) and \\(p_2\\) corresponding to two predictor values \\(x_1^*\\) and \\(x_2^*\\). By assuming independence of one’s beliefs about \\(p_1^*\\) and \\(p_2^*\\), this implies a prior on the probability vector \\((p_1^*, p_2^*)\\). Since the regression coefficients \\(\\beta_0\\) and \\(\\beta_1\\) are functions of the probability values, this process essentially specifies a prior on the vector \\(\\beta\\).\nA conditional means prior\nTo construct a conditional means prior, one considers two values of the predictor \\(x_1^*\\) and \\(x_2^*\\) and constructs independent Beta priors for the corresponding probabilities of success.\n\nFor the first predictor value \\(x_1^*\\), construct a Beta prior for the probability \\(p^*_1\\) with shape parameters \\(a_1\\) and \\(b_1\\).\nSimilarly, for the second predictor value \\(x_2^*\\), construct a Beta prior for the probability \\(p^*_2\\) with shape parameters \\(a_2\\) and \\(b_2\\).\n\nIf one’s beliefs about the probabilities \\(p^*_1\\) and \\(p^*_2\\) are independent, the joint prior for the vector \\((p^*_1, p^*_2)\\) has the form \\[\\begin{equation*}\n\\pi(p^*_1, p^*_2) = \\pi(p^*_1) \\pi(p^*_2).\n\\end{equation*}\\]\nThe prior on \\((p^*_1, p^*_2)\\) implies a prior on the regression coefficient vector (\\(\\beta_0, \\beta_1)\\). First write the two conditional probabilities \\(p^*_1\\) and \\(p^*_2\\) as function of the regression coefficient parameters \\(\\beta_0\\) and \\(\\beta_1\\), as in Equation (12.13). By solving these two equations for the regression coefficient parameters, one expresses each regression parameter as a function of the conditional probabilities.\n\\[\\begin{equation}\n\\beta_1\n= \\frac{\\textrm{logit}(p_1^*) - \\textrm{logit}(p_2^*)}{x_1^* - x_2^*},\n\\end{equation}\\]\n\\[\\begin{equation}\n\\beta_0 = \\textrm{log}\\left(\\frac{p^*_1}{1-p^*_1}\\right) - \\beta_1 x_1^*.\n\\end{equation}\\]\nLet’s illustrate constructing a conditional means prior for our example. Consider two different family income (exclusive of the wife’s income), say $20,000 and $80,000 (predictor is in $1000 units). For each family income, a Beta prior is constructed for the probability of the wife’s labor participation. As in Chapter 7, a Beta prior is assessed by specifying two quantiles of the prior distribution and finding the values of the shape parameters that match those specific quantile values.\n\nConsider the labor participation probability \\(p_1^*\\) for the value \\(x = 20\\), corresponding to a $20,000 family income. Suppose one believes the median of this probability is 0.10 and the 90th percentile is equal to 0.2. Using the R function beta_select() this belief is matched to a Beta prior with shape parameters 2.52 and 20.08.\nNext the participation probability \\(p_2^*\\) for the value \\(x = 80\\), corresponding to a $80,000 family income. The median and 90th percentile of this probability are thought to be 0.7 and 0.8, respectively, and this information is matched to a Beta prior with shape parameters 20.59 and 9.01.\n\nFigure 12.8 illustrates the conditional means prior for this example. Each bar displays the 90% interval estimate for the participation probability for a particular value of the family income.\n\n\n\n\n\nIllustration of the conditional means prior. Each line represents the limits of a 90% interval for the prior for the probability of participation for a specific family income value.\n\n\n\n\nAssuming independence of the prior beliefs about the two probabilities, one represents the joint prior density function for (\\(p_1^*, p_2^*\\)) as the product of densities \\[\\begin{equation}\n\\pi(p_1^*, p_2^*) = \\pi_B(p_1^*, 2.52, 20.08)\\pi_B(p_2^*, 20.59, 9.01),\n\\end{equation}\\] where \\(\\pi_B(y, a, b)\\) denotes the Beta density with shape parameters \\(a\\) and \\(b\\).\nAs said earlier, this prior distribution on the two probabilities implies a prior distribution on the regression coefficients. To simulate pairs \\((\\beta_0, \\beta_1)\\) from the prior distribution, one simulates values of the means \\(p_1^*\\) and \\(p_2^*\\) from independent Beta distributions in Equation (12.16), and apply the expressions in Equation (12.14) and Equation (12.15). One then obtains prior draws of the regression coefficient pair \\((\\beta_0, \\beta_1)\\). Figure 12.9 displays a scatterplot of the simulated pairs \\((\\beta_0, \\beta_1)\\) from the prior. Note that, although the two probabilities \\(p_1^*\\) and \\(p_2^*\\) have independent priors, the implied prior on the regression coefficient vector \\(\\beta\\) indicates strong negative dependence between the intercept \\(\\beta_0\\) and the slope \\(\\beta_1\\).\n\n\n\n\n\nScatterplot of simulated draws of the regression parameters for the conditional means prior for the logistic model.\n\n\n\n\nInference using MCMC\nOnce the prior on the regression coefficients is defined, it is straightforward to simulate from the Bayesian logistic model by MCMC and the JAGS software.\nThe JAGS script\nAs usual, the first step in using JAGS is writing a script defining the logistic regression model, and saving the script in the character string modelString.\nmodelString <-\"\nmodel {\n## sampling\nfor (i in 1:N){\n   y[i] ~ dbern(p[i])\n   logit(p[i]) <- beta0 + beta1*x[i]\n}\n## priors\nbeta1 <- (logit(p1) - logit(p2)) / (x1 - x2)\nbeta0 <- logit(p1) - beta1 * x1\np1 ~ dbeta(a1, b1)\np2 ~ dbeta(a2, b2)\n}\nIn the sampling section of the script, the loop goes from 1 to N, where N is the number of observations with index i. Since \\(Y_i \\mid p_i \\overset{ind}{\\sim} \\textrm{Bernoulli}(p_i)\\), one uses dbern() for y[i]. In addition, since \\(\\textrm{logit}(p_i) = \\beta_0 + \\beta_1 x_i\\), logit() is written for establishing this linear relationship.\nIn the prior section of the script, one expresses beta0 and beta1 according to the expressions in Equation (12.14) and Equation (12.15), in terms of p1, p2, x1, and x2. One also assigns Beta priors to p1 and p2, according to the conditional means prior discussed previously. Recall that the Beta distribution is represented by dbeta() in the JAGS code where the arguments are the associated shape parameters.\nDefine the data and prior parameters\nThe next step is to provide the observed data and the values for the prior parameters. In the R script below, a list the_data contains the vector of binary labor participation status values, the vector of family incomes (in $1000), and the number of observations. It also contains the shape parameters for the Beta priors on \\(p_1^*\\) and \\(p_2^*\\) and the values of the two incomes, \\(x_1^*\\) and \\(x_2^*\\).\ny <- as.vector(LaborParticipation$Participation)\nx <- as.vector(LaborParticipation$FamilyIncome)\nN <- length(y)\nthe_data <- list(\"y\" = y, \"x\" = x, \"N\" = N,\n                 \"a1\" = 2.52, \"b1\" = 20.08,\n                 \"a2\" = 20.59, \"b2\" = 9.01,\n                 \"x1\" = 20, \"x2\" = 80)\nGenerate samples from the posterior distribution\nThe run.jags() function in the runjags package generates posterior samples by the MCMC algorithm using the JAGS software. The script below runs one MCMC chain with an adaption period of 1000 iterations, a burn-in period of 5000 iterations, and an additional set of 5000 iterations to be simulated. By using the argument monitor = c(\"beta0\", \"beta1\"), one keeps tracks of the two regression coefficient parameters. The output variable ```posterior} contains a matrix of simulated draws.\nposterior <- run.jags(modelString,\n                      n.chains = 1,\n                      data = the_data,\n                      monitor = c(\"beta0\", \"beta1\"),\n                      adapt = 1000,\n                      burnin = 5000,\n                      sample = 5000)\nMCMC diagnostics and summarization\nOnce the simulated values are found, one applies several diagnostic procedures to check if the simulations appear to converge to the posterior distribution. Figures 12.10 and 12.11 display MCMC diagnostic plots for the regression parameters \\(\\beta_0\\) and \\(\\beta_1\\). From viewing these graphs, it appears that there is a small amount of autocorrelation in the simulated draws and the draws appear to have converged to the posterior distributions.\n\n\n\n\n\nMCMC diagnostics plots for the logistic regression intercept parameter.\n\n\n\n\n\n\n\n\n\nMCMC diagnostics plots for the logistic regression intercept parameter.\n\n\n\n\nBy use of the print() function, posterior summaries are displayed for the regression parameters. One primary question is whether the family income is predictive of the labor participation status and so the key parameter of interest is the regression slope \\(\\beta_1\\). From the output, one sees that the posterior median for \\(\\beta_1\\) is \\(-0.0052\\) and a 90% interval estimate is \\((-0.0143, 0.0029)\\). This tells us several things. First, since the regression slope is negative, there is a negative relationship between family income and labor participation – wives from families with larger income (exclusive of the wife’s income) tend not to work. Second, this relationship does not appear to be strong since the value 0 is included in the 90% interval estimate.\nprint(posterior, digits = 3)\n      Lower95   Median Upper95     Mean      SD Mode    MCerr \nbeta0   0.101    0.358    0.59     0.36   0.125   --  0.00214  \nbeta1 -0.0143 -0.00524 0.00285 -0.00532 0.00438   -- 7.69e-05\nOne difficulty in interpreting a logistic regression model is that the linear component \\(\\beta_0 + \\beta_1 x\\) is on the logit scale. It is easier to understand the fitted model when one expresses the model in terms of the probability of participation \\(p_i\\): \\[\\begin{equation}\np_i = \\frac{\\exp(\\beta_0 + \\beta_1 x_i)}{1 + \\exp(\\beta_0 + \\beta_1 x_i)}.\n\\end{equation}\\] For a specific value of the predictor \\(x_i\\), it is straightforward to simulate the posterior distribution of the probability \\(p_i\\). If \\((\\beta_0^{(s)}, \\beta_1^{(s)})\\) represents a simulated draw from the posterior of \\(\\beta\\), and one computes \\(p_i^{(s)}\\) using Equation (12.13) from the simulated draw, then \\(p_i^{(s)}\\) is a simulated draw from the posterior of \\(p_i\\).\nThis process was used to obtain simulated samples from the posterior distribution of the probability \\(p_i\\) for the income variable values 10, 20, …, 70. In Figure 12.12 the posterior medians of the probabilities \\(p_i\\) are displayed as a line graph and 90% posterior interval estimates are shown as vertical bars. The takeaway message from this figure is that the probability of labor participation is close to one-half and this probability slightly decreases as the family income increases. Also note that the length of the posterior interval estimate increases for larger family incomes – this is expected since much of the data is for small income values.\n\n\n\n\n\nPosterior interval estimates for the probability of labor participation for seven values of the income variable.\n\n\n\n\n\n\n7.4.4 Prediction\nWe have considered learning about the probability \\(p_i\\) of labor participation for a specific income value \\(x^*_i\\). A related problem is to predict the fraction of labor participation for a sample of \\(n\\) women with a specific family income. If \\(\\tilde{y}_i\\) represents the number of women who work among a sample of \\(n\\) with family income \\(x_i\\), then one would be interested in the posterior predictive distribution of the fraction \\(\\tilde{y}_i / n\\).\nOne represents this predictive density of \\(\\tilde{y}_i\\) as \\[\\begin{equation}\nf(\\tilde{Y}_i = \\tilde{y}_i \\mid y) = \\int \\pi(\\beta \\mid y) f(\\tilde{y}_i, \\beta) d\\beta,\n\\end{equation}\\] where \\(\\pi(\\beta \\mid y)\\) is the posterior density of \\(\\beta = (\\beta_0, \\beta_1)\\) and \\(f(\\tilde{y}_i, \\beta)\\) is the Binomial sampling density of \\(\\tilde{y}_i\\) conditional on the regression vector \\(\\beta\\).\nA strategy for simulating the predictive density is implemented similar to what was done in the linear regression setting. Suppose that one focuses on the predictor value \\(x^*_i\\) and one wishes to consider a future sample of \\(n = 50\\) of women with that income level. The simulated draws from the posterior distribution of \\(\\beta\\) are stored in a matrix post. For each of the simulated parameter draws, one computes the probability of labor participation \\(p^{(s)}\\) for that income level – these values represent posterior draws of the probability \\(\\{p^{(s)}\\}\\). Given those probability values, one simulates Binomial samples of size \\(n = 50\\) where the probability of successes are given by the simulated \\(\\{p^{(s)}\\}\\) – the variable \\(\\tilde{y}\\) represents the simulated Binomial variable. By dividing \\(\\tilde{y}\\) by \\(n\\), one obtains simulated proportions of labor participation for that income level. Each group of simulated draws from the predictive distribution of the labor proportion is summarized by the median, 5th, and 95th percentiles.\nIn the following R script, the function prediction_interval() obtains the quantiles of the prediction distribution of \\(\\tilde{y}/ n\\) for a fixed income level, and the sapply() function computes these predictive quantities for a range of income levels. Figure 12.13 graphs the predictive median and interval bounds against the income variable. By comparing Figure 12.12 and Figure 12.13, note that one is much more certain about the probability of labor participation than the fraction of labor participation in a future sample of 50.\nprediction_interval <- function(x, post, n = 20){\n    lp <- post[, 1] + x * post[, 2]\n    p <- exp(lp) / (1 + exp(lp))\n    y <- rbinom(length(p), size = n, prob = p)\n    quantile(y / n,\n             c(.05, .50, .95))\n  }\nout <- sapply(seq(10, 70, by = 10),\n                prediction_interval, post, n = 50)\n\n\n\n\n\nPrediction intervals for the fraction of labor participation of a sample of size \\(n = 50\\) for seven values of the income variable."
  },
  {
    "objectID": "casestudies.html",
    "href": "casestudies.html",
    "title": "7  Case Studies",
    "section": "",
    "text": "This chapter provides several illustrations of Bayesian modeling that extend some of the models described in earlier chapters.\nMosteller and Wallace (1963), in one of the early significant Bayesian applications, explore the frequencies of word use in the well-known Federalist Papers to determine the authorship between Alexander Hamilton and James Madison. Section 13.2 revisits this word use application. This study raises several interesting explorations such as determining a suitable sampling distribution and finding suitable ways of comparing the word use of several authors.\nIn sports, teams are very interested in learning about the pattern of increase and decrease in the performance of a player, commonly called a career trajectory. A baseball player is believed to reach a level of peak performance at age of 30, although this “peak age” may vary between players. Section 13.3 illustrates the use of a hierarchical model to simultaneously estimate the career trajectories for a group of baseball players using on-base percentage as the measure of performance.\nSuppose a class is taking a multiple choice exam where there are two groups of students. Some students are well-prepared and are familiar with the exam content and other students have not studied and will essentially guess at the answers to the exam questions. Section 13.4 introduces a latent class model that assumes that the class consists of two groups of students with different success rates and the group identifications of the students are unknown. In the posterior analysis, one learns about the location of the two success rates and the group classifications of the students. Using this latent class framework, the Federalist Papers example is revisited and the frequencies of particular filler words is used to learn about the true author identity of some disputed authorship Federalist Papers."
  },
  {
    "objectID": "casestudies.html#federalist-papers-study",
    "href": "casestudies.html#federalist-papers-study",
    "title": "7  Case Studies",
    "section": "7.2 Federalist Papers Study",
    "text": "7.2 Federalist Papers Study\n\n\n7.2.1 Introduction\nThe Federalist Papers were a collection of articles written in the late 18th century by Alexander Hamilton, James Madison and John Jay to promote the ratification of the United States Constitution. Some of these papers are known to be written by Hamilton, other papers were clearly written by Madison, and the true authorship of some of the remaining papers has been in doubt.\nIn one of the early significant applied Bayesian papers, Mosteller and Wallace (1963) illustrate the use of Bayesian reasoning in solving the authorship problem. They focused on the frequencies of word counts. Since the topic of the article may influence the frequencies of words used, Mosteller and Wallace were careful to focus on counts of so-called filler words such as “an”, “of”, and “upon” that are not influenced by the topics of the articles.\nIn this case study, the use of different sampling distributions is described to model word counts in a group of Federalist Papers. The Poisson distribution is perhaps a natural choice for modeling a group of word counts, but it will be seen that the Poisson can not accommodate the spread of the distribution of word counts. This motivates the use of a Negative Binomial sampling distribution and this model will be used to compare rates of use of some filler words by Hamilton and Madison.\n\n\n7.2.2 Data on word use\nTo begin our study, let’s look at the occurrences of the word “can” in all of the Federalist Papers authored by Alexander Hamilton or James Madison. Table 13.1 shows the format of the data. For each paper, the total number of words, the number of occurrences of the word “can” and the rate of this word per 1000 words are recorded.\nTable 13.1. Portion of the data table counting the number of words and occurrences of the word “can” in 74 Federalist papers.\n\n\n\n\nName\nTotal\nword\ny\nRate\nAuthorship\n\n\n\n\n1\nFederalist No. 1\n1622\ncan\n3\n1.85\nHamilton\n\n\n2\nFederalist No. 10\n3008\ncan\n4\n1.33\nMadison\n\n\n3\nFederalist No. 11\n2511\ncan\n5\n1.99\nHamilton\n\n\n4\nFederalist No. 12\n2171\ncan\n2\n0.92\nHamilton\n\n\n5\nFederalist No. 13\n970\ncan\n4\n4.12\nHamilton\n\n\n6\nFederalist No. 14\n2159\ncan\n9\n4.17\nMadison\n\n\n\nFigure 13.1 displays parallel jittered dotplots of the rates (per 1000 words) of “can” for the Madison and Hamilton papers. Note the substantial variability in the rates across papers. But it appears that this is a slight tendency for Hamilton to use this particular word more frequently than Madison. Later in this section we will formally perform inference about the ratio of the true rates of use of “can” for the two authors.\n\n\n\n\n\nObserved rates of the word can in Federalist Papers authored by Hamilton and Madison.\n\n\n\n\n\n\n7.2.3 Poisson density sampling\nConsider first the word use of all of the Federalist Papers written by Hamilton. The initial task is to find a suitable sampling distribution for the counts of a particular function word such as “can”. Since Poisson is a popular sampling distribution for counts, it is initially assumed that for the \\(i\\)-th paper the count \\(y_i\\) of the word “can” has a Poisson density with mean \\(n_i \\lambda /1000\\) where \\(n_i\\) is the total number of words and \\(\\lambda\\) is the true rate of the word among 1000 words. There are \\(N\\) papers in total. Using the Poisson density expression, one writes \\[\\begin{equation}\nf(Y_i = y_i \\mid \\lambda) = \\frac{(n_i \\lambda / 1000)^{y_i} \\exp(-n_i \\lambda / 1000)}{y_i!}.\n\\end{equation}\\] Assuming independence of word use between papers, the likelihood function is the product of Poisson densities \\[\\begin{equation}\nL(\\lambda) = \\prod_{i = 1}^N f(y_i \\mid \\lambda),\n\\end{equation}\\] and the posterior density of \\(\\lambda\\) is given by \\[\\begin{equation}\n\\pi(\\lambda \\mid y_1, \\cdots, y_N) \\propto  L(\\lambda) \\pi(\\lambda),\n\\end{equation}\\] where \\(\\pi()\\) is the prior density.\nR Work Suppose one knows little about the true rate of “can”s and to reflect this lack of information, one assigns \\(\\lambda\\) a Gamma density with parameters \\(\\alpha = 0.001\\) and \\(\\beta = 0.001\\). Recall in Chapter 8 Section 8.8, a Gamma prior is conjugate to a Poisson sampling model. A JAGS script is written to specify this Bayesian model and by use of the run.jags() function, one obtains a simulated sample of 5000 draws from the posterior distribution.\nmodelString = \"\nmodel{\n## sampling\nfor (i in 1:N) {\n   y[i] ~ dpois(n[i] * lambda / 1000)\n}\n## prior\nlambda ~ dgamma(0.001, 0.001)\n}\n\"\nWhen one observes count data such as these, one general concern is . Do the observed counts display more variability than one would anticipate with the use of this Poisson sampling model? One can check for overdispersion by use of a posterior predictive check. First one simulates one replicated dataset from the posterior predictive distribution. This is done in two steps: 1) one simulates a value of \\(\\lambda\\) from the posterior distribution; 2) given the simulated value \\(\\lambda = \\lambda^*\\), one simulates counts \\(y^{R}_1, ..., y^{R}_N\\) from independent Poisson distribution with means \\(n_1 \\lambda^* / 1000, ..., n_N \\lambda^* / 1000\\). Given a replicated dataset of counts {\\(y^{R}_i\\)}, one computes the standard deviation. In this setting a standard deviation is a reasonable choice of a testing function since one is concerned about the variation or spread in the data.\none_rep <- function(i){\n  lambda <- post[i]\n  sd(rpois(length(y), n * lambda / 1000))\n}\nsapply(1:5000, one_rep) -> SD\nOne repeats this process 5000 times, obtaining 5000 replicated datasets from the posterior predictive distribution and 5000 values of the standard deviation. Figure 13.2 displays a histogram of the standard deviations from the predictive distribution and the standard deviation of the observed counts {\\(y_i\\)} is displayed as a vertical line. Note that the observed standard deviation is very large relative to the standard deviations of the counts from the predictive distribution. The takeaway is that there is more variability in the observed counts of “can”s than one would predict from the Poisson sampling model.\n\n\n\n\n\nHistogram of standard deviations from 5000 replicates from the posterior predictive distribution from the Poisson sampling model. The observed standard deviation is displayed as a vertical line.\n\n\n\n\n\n\n7.2.4 Negative Binomial sampling\nIn the previous section, we presented evidence that the observed counts of “can” from a group of Federalist Papers of Alexander Hamilton were overdispersed in that there was more variability in the counts than predicted by the Poisson sampling model. One way of handling this overdispersion issue to find an alternative sampling density for the counts that is able to accommodate this additional variation.\nOne popular alternative density is the Negative Binomial density. Recall that \\(y_i\\) represents the number of “can”s in the \\(i\\)-th Federalist Papers. Conditional on parameters \\(\\alpha\\) and \\(\\beta\\), one assigns \\(y_i\\) the Negative Binomial density defined as \\[\\begin{equation}\nf(Y_i = y_i \\mid \\alpha, \\beta) = \\frac{\\Gamma(y_i + \\alpha)}{\\Gamma(\\alpha)} p_i^\\alpha (1 - p_i)^{y_i},\n\\end{equation}\\] where \\[\\begin{equation}\np_i = \\frac{\\beta}{\\beta + n_i / 1000}.\n\\end{equation}\\] One can show that this density is a natural generalization of the Poisson density. The mean count is given by \\(E(y_i) = \\mu_i\\) where \\[\\begin{equation}\n\\mu_i = \\frac{n_i}{1000}\\frac{\\alpha}{\\beta}.\n\\end{equation}\\] Recall that the mean count for \\(y_i\\) the Poisson model was \\(n_i \\lambda / 1000\\), so the ratio \\(\\alpha / \\beta\\) is playing the same role as \\(\\lambda\\) – one can regard \\(\\alpha / \\beta\\) as the true rate of the particular word per 1000 words.\nOne can show that the variance of the count \\(y_j\\) is given by \\[\\begin{equation}\nVar(y_i) = \\mu_i \\left(1 + \\frac{n_i}{1000 \\beta}\\right).\n\\end{equation}\\] The variance for the Poisson model is equal to \\(\\mu_i\\), so the Negative Binomial model has the extra multiplicative term \\(\\left(1 + \\frac{n_i}{1000 \\beta}\\right)\\). So the Negative Binomial family is able to accommodate the additional variability in the counts {\\(y_i\\)}.\nThe posterior analysis using a Negative Binomial density is straightforward. The counts \\(y_1, ..., y_N\\) are independent Negative Binomial with parameters \\(\\alpha\\) and \\(\\beta\\) and the likelihood function is equal to \\[\\begin{equation}\nL(\\alpha, \\beta) = \\prod_{i=1}^N f(y_i \\mid \\alpha, \\beta).\n\\end{equation}\\] If little is known a priori about the locations of the positive parameter values \\(\\alpha\\) and \\(\\beta\\), then it reasonable to assume the two parameters are independent and assign to each \\(\\alpha\\) and \\(\\beta\\) a Gamma density with parameters 0.001 and 0.001. Then the posterior density is given by \\[\\begin{equation}\n\\pi(\\alpha, \\beta \\mid y_1, \\cdots, y_N) \\propto L(\\alpha, \\beta) \\pi(\\alpha, \\beta)\n\\end{equation}\\] where \\(\\pi(\\alpha, \\beta)\\) is the product of Gamma densities.\nR Work One simulates the posterior with Negative Binomial sampling using JAGS. The Negative Binomial density is represented by the JAGS function dnegbin() with parameters p[i] and alpha. In the JAGS script below, note that one first defines p[i] in terms of the parameter beta and the sample size n[i], and then expresses the Negative Binomial density in terms of p[i] and alpha.\nmodelString = \"\nmodel{\n## sampling\nfor(i in 1:N){\n   p[i] <- beta / (beta + n[i] / 1000)\n   y[i] ~ dnegbin(p[i], alpha)\n}\n## priors\nmu <- alpha / beta\nalpha ~ dgamma(.001, .001)\nbeta ~ dgamma(.001, .001)\n}\n\"\nWe earlier made a statement that the Negative Binomial density can accommodate the extra variability in the word counts. One can check this statement by a posterior predictive check. One replication of the posterior predictive checking method is implemented in the R function one_rep(). We start with a simulated value \\((\\alpha^*, \\beta^*)\\) from the posterior distribution. Then we simulated a replicated dataset \\(y^{R}_1, ..., y^{R}_N\\) where \\(y^{R}_i\\) has a Negative Binomial distribution with parameters \\(\\alpha^*\\) and \\(\\beta^* / (\\beta^* + n_i / 1000)\\). Then we compute the standard deviation of the {\\(y^{R}_i\\)}.\none_rep <- function(i){\n  p <- post$beta[i] / (post$beta[i] + n / 1000)\n  sd(rnbinom(length(y), size = post$alpha[i], prob = p))\n}\nBy repeating this algorithm for 5000 iterations, one has 5000 draws of the standard deviation of samples from the predictive distribution stored in the R vector\nsapply(1:5000, one_rep) -> SD\nFigure 13.3 displays a histogram of the standard deviations of samples from the predictive distribution and the observed standard deviation of the counts is shown as a vertical line. In this case the observed standard deviation value is in the middle of the predictive distribution. The interpretation is that predictions with a Negative Binomial sampling model are consistent with the spread in the observed word counts.\n\n\n\n\n\nHistogram of standard deviations from 5000 replicates from the posterior predictive distribution in the Negative Binomial sampling model. The observed standard deviation is displayed as a vertical line.\n\n\n\n\nNow that the Negative Binomial model seems reasonable, one performs inferences about the mean use of the word “can” in Hamilton essays. The parameter \\(\\mu = \\alpha / \\beta\\) represents the true rate of use of this word per 1000 words. Figure 13.4 displays MCMC diagnostic plots for the parameter \\(\\mu\\). The trace plot and autocorrelation plot indicate good mixing and so one believes the histogram in the lower-left section represents the marginal posterior density for \\(\\mu\\). A 90% posterior interval estimate for the rate of “can” is (2.20, 3.29).\n\n\n\n\n\nMCMC diagnostic plots for the rate \\(\\mu\\) of use of the word can in Hamilton essays.\n\n\n\n\n\n\n7.2.5 Comparison of rates for two authors\nRecall that the original problem was to compare the word use of Alexander Hamilton with that of James Madison. Suppose we collect the counts {\\(y_{1i}\\)} of the word “can” in the Federalist Papers authored by Hamilton and the counts {\\(y_{2i}\\)} of “can” in the Federalist Papers authored by Madison. The general problem is to compare the true rates per 1000 words of the two authors.\nSince a Negative Binomial sampling model appears to be suitable in the one-sample situation, we extend this in a straightforward away to the two-sample case. The Hamilton counts \\(y_{11}, ..., y_{1N_1}\\), conditional on parameters \\(\\alpha_1\\) and \\(\\beta_1\\) are assumed to be independent Negative Binomial, where \\(y_{1i}\\) is Negative Binomial(\\(p_{1i}, \\alpha_1\\)) with \\[\\begin{equation}\np_{1i} = \\frac{\\beta_1}{\\beta_1 + n_{1i}/1000},\n\\end{equation}\\] and \\(\\{n_{1i}\\}\\) are the word counts for the Hamilton essays. Similarly, the Madison counts \\(y_{21}, ..., y_{2N_2}\\), conditional on parameters \\(\\alpha_2\\) and \\(\\beta_2\\) are assumed to be independent Negative Binomial, where \\(y_{2i}\\) is Negative Binomial(\\(p_{2i}, \\alpha_2\\)) with \\[\\begin{equation}\np_{2i} = \\frac{\\beta_2}{\\beta_2 + n_{2i}/1000},\n\\end{equation}\\] and {\\(n_{2i}\\)} are the word counts for the Madison essays. The focus will be to learn about \\(\\mu_M / \\mu_H\\), the ratio of the rates (per 1000 words) of use of the word “can” of the two authors, where \\(\\mu_M = \\alpha_2 / \\beta_2\\) and \\(\\mu_H = \\alpha_1 / \\beta_1\\).\nAssume that the observed counts of word “can” of the two authors are independent. Moreover, assume that the prior distributions of the parameters \\((\\alpha_1, \\beta_1)\\) and \\((\\alpha_2, \\beta_2)\\) are independent. Then the posterior distribution is given, up to an unknown proportionality constant, by \\[\\begin{equation}\n\\pi(\\alpha_1, \\beta_1, \\alpha_2, \\beta_2 \\mid \\{y_{1i}\\}, \\{y_{12}\\}) \\propto \\prod_{k=1}^2 \\left(\n\\prod_{i=1}^{n_{ki}} f(y_{ki} \\mid \\alpha_k, \\beta_k) \\pi(\\alpha_k, \\beta_k) \\right).\n\\end{equation}\\] We assume that the user has little prior information about the location of the Negative Binomial parameters and we assume they are independent with each parameter assigned a Gamma prior with parameters 0.001 and 0.001.\nR Work The posterior sampling is implemented using the JAGS software. The model description script is an extension of the previous script for a single Negative Binomial sample. Note that the ratio parameter is defined to be the ratio of the word rates for the two samples.\nmodelString = \"\nmodel{\n## sampling\nfor(i in 1:N1){\n   p1[i] <- beta1 / (beta1 + n1[i] / 1000)\n   y1[i] ~ dnegbin(p1[i], alpha1)\n}\nfor(i in 1:N2){\n   p2[i] <- beta2 / (beta2 + n2[i] / 1000)\n   y2[i] ~ dnegbin(p2[i], alpha2)\n}\n## priors\nalpha1 ~ dgamma(.001, .001)\nbeta1 ~ dgamma(.001, .001)\nalpha2 ~ dgamma(.001, .001)\nbeta2 ~ dgamma(.001, .001)\nratio <- (alpha2 / beta2) / (alpha1 / beta1)\n}\"\nSince the focus is to compare the word use of the two authors, Figure 13.5 displays MCMC diagnostics for the ratio of “can” rates \\(R = \\mu_M / \\mu_H\\). Note that most of the posterior probability of \\(R\\) is found in an interval about the value one. From the simulated draws, one finds the posterior median is 0.92 and a 95% probability interval for \\(R\\) is found to be (0.71, 1.19). Since this interval contains the value one, there is no significant evidence to conclude that Hamilton and Madison have different rates of the word “can”.\n\n\n\n\n\nMCMC diagnostic plots for the ratio of rates of use of the word can in Federalist Papers essays written by Hamilton and Madison.\n\n\n\n\n\n\n7.2.6 Which words distinguish the two authors?\nIn the previous section, it was found that the word “can” was not a helpful discriminator between the essays written by Hamilton and the essays written by Madison. However, other words may be useful in this discrimination task. Following suggestions in Mosteller and Wallace (1963), the previous two-sample analysis was repeated for each of the following words: also, an, any, by, can, from, his, may, of, on, there, this, to, and upon. For a given word, the counts of occurrence of that word was collected for each of the essays authored by Hamilton and Madison. For each word, we focus on inferences about the parameter \\(R\\), the ratio of mean rates of the particular word by Madison and Hamilton. A ratio value of \\(R > 1\\) indicates that Madison was a more frequent user of the word, and a ratio value \\(R < 1\\) indicates that Hamilton used a higher rate of that word. Fourteen separate two-sample analyses were conducted and the posterior distributions of \\(R\\) were summarized by posterior medians and 95% probability intervals.\nFigure 13.6 displays the locations of the posterior medians and interval estimates for all of the 14 analyses. Intervals that are completely on one side of the value \\(R = 1\\) indicate that one author was more likely to use that particular word. Looking at the figure, one sees that the words upon, to, this, there, any, and an were more likely be used by Hamilton, and the words on, by, and also were more likely be used by Madison. The posterior intervals for the remaining words (may, his, from, can, and also) cover the value one, and so one cannot say from these data that one author was more likely to use those particular words.\n\n\n\n\n\nDisplay of posterior median and 95% interval estimates for the ratio of rates for 14 different words in Federalist Papers essays written by Hamilton and Madison."
  },
  {
    "objectID": "casestudies.html#career-trajectories",
    "href": "casestudies.html#career-trajectories",
    "title": "7  Case Studies",
    "section": "7.3 Career Trajectories",
    "text": "7.3 Career Trajectories\n\n\n7.3.1 Introduction\nFor an athlete in a professional sport, his or her performance typically begins at a small level, increases to a level in the middle of his or her career where the player has peak performance, and then decreases until the player’s retirement. This pattern of performance over a player’s career is called the career trajectory. A general problem in sports is to predict future performance of a player and one relevant variable in this prediction is the player’s age. Due to the ready availability of baseball data, it is convenient to study career trajectories for baseball players, although the methodology will apply to athletes in other sports.\n\n\n7.3.2 Measuring hitting performance in baseball\nBaseball is a bat and ball game first played professionally in the United States in the mid 19th century. Players are measured by their ability to hit, pitch, and field, and a wide variety of statistical measures have been developed. One of the more popular measures of batting performance is the on-base percentage or OBP. A player comes to bat during a plate appearance and it is desirable for the batter to get on base. The OBP is defined to be the fraction of plate appearances where the batter reaches a base. As an example, during the 2003 season, Chase Utley had 49 on-base events in 152 plate appearances and his OBP was \\(49 / 152 = 0.322\\).\n\n\n7.3.3 A hitter’s career trajectory\nA baseball player typically plays between 5 to 20 years in Major League Baseball (MLB), the top-tier professional baseball league in the United States. In this case study, we explore career trajectories of the OBP measure of baseball players as a function of their ages. To illustrate a career trajectory, consider Chase Utley who played in the Major Leagues from 2003 through 2018. Figure 13.7 displays Utley’s OBP as a function of his age for all of the seasons of his career. A quadratic smoothing curve is added to the scatterplot. One sees that Utley’s OBP measure increases until about age 30 and then steadily decreases towards the end of his career.\n\n\n\n\n\nCareer trajectory of Chase Utley’s on-base percentages. A quadratic smoothing curve is added to the plot.\n\n\n\n\nFigure 13.8 displays the career trajectory of OBP for another player Josh Phelps who had a relatively short baseball career. In contrast, Phelps does not have a clearly defined career trajectory. In fact, Phelps’ OBP values appear to be relatively constant from ages 24 to 30 and the quadratic smoothing curve indicates that Phelps had a minimum OBP at age 26. The purpose of this case study is to see if one can improve the career trajectory smooth of this player by a hierarchical Bayesian model that combines data from a number of baseball players. Recall in Chapter 10, we have seen how hierarchical Bayesian models have the pooling effect that could borrow information from other groups to improve the estimation of one group, especially for groups with small sample size.\n\n\n\n\n\nCareer trajectory of Josh Phelps’ on-base percentages. A quadratic smoothing curve is added to the plot.\n\n\n\n\n\n\n7.3.4 Estimating a single trajectory\n\nFirst we consider learning about a single hitter’s OBP career trajectory. Let \\(y_j\\) denote the number of on-base events in \\(n_j\\) plate appearances during a hitter’s \\(j\\)-th season. It is reasonable to assume that \\(y_j\\) has a Binomial distribution with parameters \\(n_j\\) and probability of success \\(p_j\\). One represents the logit of the success probability as a quadratic function of the player’s age: \\[\\begin{equation}\n\\log \\left(\\frac{p_j}{1-p_j}\\right) = \\beta_0 + \\beta_1 (x_j - 30) + \\beta_2 (x_j - 30)^2,\n\\end{equation}\\] where \\(x_j\\) represents the age of the player in the \\(j\\)-th season.\nNote that the age value is centered by 30 in the logistic model – this is done for ease of interpretation. The intercept \\(\\beta_0\\) is an estimate of the player’s OBP performance at age 30. Specific functions of the regression vector \\(\\beta = (\\beta_0, \\beta_1, \\beta_2)\\) are of specific interest in this application.\n\nThe quadratic function reaches its largest value at \\[\\begin{equation*}\nh_1(\\beta) = 30 -  \\frac{\\beta_1}{2 \\beta_2}.\n\\end{equation*}\\] This is the age where the player is estimated to have his peak on-base performance during his career.\nThe maximum value of the curve, on the logistic scale, is \\[\\begin{equation*}\nh_2(\\beta) = \\beta_0 - \\frac{\\beta_1^2}{4 \\beta_2}.\n\\end{equation*}\\] The maximum value of the curve on the probability scale is \\[\\begin{equation}\np_{max} = \\exp(h_2(\\beta)) / (1 +  \\exp(h_2(\\beta))).\n\\end{equation}\\] The parameter \\(p_{max}\\) is the estimated largest OBP of the player over his career.\nThe coefficient \\(\\beta_2\\), typically a negative value, tells us about the degree of curvature in the quadratic function.\nIf a player has a “large” value of \\(\\beta_2\\), this indicates that he more rapidly reaches his peak level and more rapidly decreases in ability until retirement. One simple interpretation is that \\(\\beta_2\\) represents the change in OBP from his peak age to one year later.\n\nIt is straightforward to fit this Bayesian logistic model using the JAGS software. Suppose one has little prior information about the location of the regression vector \\(\\beta\\). Then one assumes the regression coefficients are independent with each coefficient assigned a Normal prior with mean 0 and precision 0.0001. The posterior density of \\(\\beta\\) is given, up to an unknown proportionality constant, by \\[\\begin{equation}\n\\pi(\\beta \\mid \\{y_j\\}) \\propto \\prod_j \\left( p_j ^{y_j}(1 - p_j)^{n_j - y_j} \\right) \\pi(\\beta),\n\\end{equation}\\] where \\(p_j\\) is defined by the logistic model and \\(\\pi(\\beta)\\) is the prior density.\nR Work The JAGS model script is shown below. The dbin() function is used to define the Binomial distribution and the logit() function describes the log odds reexpression.\nmodelString = \"\nmodel {\n## sampling\nfor (j in 1:N){\n   y[j] ~ dbin(p[j], n[j])\n   logit(p[j]) <- beta0 + beta1 * (x[j] - 30) +\n            beta2 * (x[j] - 30) * (x[j] - 30)\n}\n## priors\nbeta0 ~ dnorm(0, 0.0001)\nbeta1 ~ dnorm(0, 0.0001)\nbeta2 ~ dnorm(0, 0.0001)\n}\n\"\nThe JAGS software is used to simulate a sample from the posterior distribution of the regression vector \\(\\beta\\). From this sample, it is straightforward to learn about any function of the regression vector of interest. To illustrate, one performs inference about the peak age function \\(h_1(\\beta)\\) by computing this function on the simulated \\(\\beta\\) draws – the output is a posterior sample from the peak age function. In a similar fashion, one obtains a sample from the posterior of the maximum value function \\(p_{max}\\) by computing this function on the simulated \\(\\beta\\) values. Figure 13.9 displays density estimates of the simulated values of \\(h_1(\\beta)\\) and \\(p_{max}\\). From this graph, one sees that Utley’s peak performance was most likely achieved at age 29, although there is uncertainty about this most likely peak age. Also the posterior of the peak value \\(p_{max}\\) indicates that Utley’s peak on-base probability ranged from 0.38 and 0.40.\n\n\n\n\n\nDensity estimates of the peak age and peak for logistic model on Chase Utley’s trajectory.\n\n\n\n\n\n\n7.3.5 Estimating many trajectories by a hierarchical model\nWe have focused on estimating the career trajectory of a single baseball player such as Chase Utley. But there are many baseball players and it is reasonable to want to simultaneously estimate the career trajectories for a group of players. As an example, suppose one focuses on the Major League players who were born in the year 1978 and had at least 1000 career at-bats. Figure 13.10 displays scatterplots of age and OBP with quadratic smoothing curves for the 36 players in this group. Looking at these curves, one notices that many of the curves follow a familiar concave down shape with the player achieving peak performance near an age of 30. But for some players, especially for those players who played a small number of seasons, note that the trajectories have different shapes. Some trajectories are relatively constant over the age variable and other trajectories have an unusual concave up appearance.\n\n\n\n\n\nCareer trajectories and individual quadratic fits for all players born in the year 1978 and having at least 1000 career at-bats.\n\n\n\n\nIn this situation, it may be desirable to partially pool the data from the 36 players using a hierarchical model to obtain improved trajectory estimates for all players. For the \\(i\\)-th player, one observes the on-base events {\\(y_{ij}\\)} where \\(y_{ij}\\) is Binomial with sample size \\(n_{ij}\\) and probability of on-base success \\(p_{ij}\\). The logit of the on-base probability for the \\(i\\)-th player during the \\(j\\)-th season is given by \\[\\begin{equation}\n\\log \\left(\\frac{p_{ij}}{1-p_{ij}}\\right) = \\beta_{i0} + \\beta_{i1} (x_{ij} - 30) + \\beta_{i2} (x_{ij} - 30)^2,\n\\end{equation}\\] where \\(x_{ij}\\) is the age of the \\(i\\)-th player during the \\(j\\)-th season. If \\(\\beta_i = (\\beta_{i0}, \\beta_{i1}, \\beta_{i2})\\) represents the vector regression coefficients for the \\(i\\)-th player, then one is interested in estimating the regression vectors \\((\\beta_1, ..., \\beta_N)\\) for the \\(N\\) players in the study.\nOne constructs a two-stage prior on these regression vectors. In Chapter 10, one assumed that the Normal means were distributed according to a common normal distribution. In this setting, since each regression vector has three components, at the first stage of the prior, one assumes that \\(\\beta_1, ..., \\beta_N\\) are independent distributed from a common multivariate Normal distribution with mean vector \\(\\mu_\\beta\\) and precision matrix \\(\\tau_\\beta\\). Then, at the second stage, vague prior distributions are assigned to the unknown values of \\(\\mu_\\beta\\) and \\(\\tau_\\beta\\).\nR Work In our application, there are \\(N = 36\\) players, so one is estimating 36 \\(\\times\\) 3 = 108 regression parameters together with unknown parameters in the prior distributions of \\(\\mu_\\beta\\) and \\(\\tau_\\beta\\) at the second stage. Fortunately the JAGS script defining this model is a straightforward extension of the JAGS script for a logistic regression model for a single career trajectory. The variable player indicates the player number, and the variables beta0[i], beta1[i], and beta2[i] represent the logistic regression parameters for the \\(i\\)-th player. The vector B[j, 1:3] represents a vector of parameters for one player and mu.beta and Tau.B represent respectively the second-stage prior mean vector and precision matrix values. The variables mean, prec, Omega are specified parameters that indicate weak information about the parameters at the second stage.\nmodelString = \"\nmodel {\n## sampling\nfor (i in 1:N){\n   y[i] ~ dbin(p[i], n[i])\n   logit(p[i]) <- beta0[player[i]] + \n                beta1[player[i]] * (x[i] - 30) +\n                beta2[player[i]] * (x[i] - 30) * (x[i] - 30)\n}\n## priors\nfor (j in 1:J){\n   beta0[j] <- B[j,1]\n   beta1[j] <- B[j,2]\n   beta2[j] <- B[j,3]\n   B[j,1:3] ~ dmnorm (mu.beta[], Tau.B[,])\n}\nmu.beta[1:3] ~ dmnorm(mean[1:3],prec[1:3 ,1:3 ])\nTau.B[1:3 , 1:3] ~ dwish(Omega[1:3 ,1:3 ], 3)\n}\n\"\nAfter JAGS is used to simulate from the posterior distribution of this hierarchical model, a variety of inferences are possible. The player trajectories \\(\\beta_1, ..., \\beta_{36}\\) are a sample from a Normal distribution with mean \\(\\mu_\\beta\\). Figure 13.11 displays draws of the posterior of the mean peak age \\(h_1(\\mu_\\beta)\\) expressed as probabilities over a grid of age values from 23 to 37. The takeaway if that the career trajectories appear to be centered about 29.5 – a typical MLB player in this group peaks in on-base performance about age 29.5.\n\n\n\n\n\nSamples from the posterior distribution of the mean peak age.\n\n\n\n\nBy combining data across players, the Bayesian hierarchical model is helpful in borrowing information for estimating the career trajectories of players with limited career data. This is illustrated in Figure 13.12 that shows individual and hierarchical posterior mean fits of the career trajectories for two players. For Chase Utley, the two fits are very similar since Utley’s career trajectory was well-estimated just using his data. In contrast, we saw that Phelps had an unrealistic concave up individual estimated trajectory. In the hierarchical model, this career trajectory is corrected to be more similar to the concave down trajectory for most players.\n\n\n\n\n\nIndividual (solid line) and hierarchical (dashed line) fits of the career trajectories for Josh Phelps and Chase Utley."
  },
  {
    "objectID": "casestudies.html#latent-class-modeling",
    "href": "casestudies.html#latent-class-modeling",
    "title": "7  Case Studies",
    "section": "7.4 Latent Class Modeling",
    "text": "7.4 Latent Class Modeling\n\n\n7.4.1 Two classes of test takers\nSuppose thirty people are given a 20-question true/false exam and the number of correct responses for all people are graphed in Figure 13.13. From this figure note that test takers 1 through 10 appear to have a low level of knowledge about the subject matter as their scores are centered around 10. The remaining test takers 11 through 30 seem to have a higher level of knowledge as their scores range from 15 to 20.\n\n\n\n\n\nScatterplot of test scores of 20 test takers. The number next to each point is the person index.\n\n\n\n\nAre there really two groups of test takers, a random-guessing group and a knowledgeable group? If so, how can one separate the people in the two ability groups, and how can one make inferences about the correct rate for each group? Furthermore, can one be sure that there exists only two ability groups? Is it possible to have more than two groups of people by ability level?\nThe above questions relate to the classification of observations and the number of classes. In the introduction of hierarchical models in Chapter 10, there was a natural grouping of the observations. For example, in the animation movie ratings example in Chapter 10, each rating was made on one animation movie, so grouping based on movie is natural, and the group assignment of the observations was known. It was then reasonable to specify a two-stage prior where the rating means shared the same prior distribution at the first stage.\nIn contrast, in the true/false exam example, since the group assignment is not known, it not possible to proceed with a hierarchical model with a common prior at the first stage. In this testing example one believes the people fall in two ability groups, however one does not observe the actual classification of the people into groups. So it is assumed that there exists latent or unobserved classification of observations. The class assignments of the individuals are unknown and can be treated as random parameters in our Bayesian approach.\nIf there exists two classes, the class assignment parameter for the \\(i\\)-th observation \\(z_i\\) is unknown and assumed to follow a Bernoulli distribution with probability \\(\\pi\\) belonging to the first class, i.e. \\(z_i = 1\\). With probability \\(1 - \\pi\\) the \\(i\\)-th observation belongs to the second class, i.e. \\(z_i = 0\\). \\[\\begin{equation}\nz_i \\mid \\pi \\sim \\textrm{Bernoulli}(\\pi).\n\\end{equation}\\] If one believes there are more than two classes, the class assignment parameter follows a Multinomial distribution. For ease of description of the model, we focus on the two classes situation.\nOnce the class assignment \\(z_i\\) is known for observation \\(i\\), the response variable \\(Y_i\\) follows a data model with a group-specific parameter. In the case of a true/false exam where the outcome variable \\(Y_i\\) is the number of correct answers, the Binomial model is a good choice for a sampling model. The response variable \\(Y_i\\) conditional on the class assignment variable \\(z_i\\) is assigned a Binomial distribution with probability of success \\(p_{z_i}\\). \\[\\begin{equation}\nY_i = y_i \\mid z_i, p_{z_i} \\sim \\textrm{Binomial}(20, p_{z_i}).\n\\end{equation}\\] One writes the success probability \\(p_{z_i}\\) with subscript \\(z_i\\) since this probability is class-specific. For the guessing group, the number of correct answers is Binomial with parameter \\(p_1\\), and for the knowledgeable group the number of correct answers is Binomial with parameter \\(p_0\\).\nThis model for responses to a true/false with unknown ability levels illustrates latent class modeling. The fundamental assumption is that there exists unobserved two latent classes of observations, and each latent class has its own sampling model with class-specific parameters. All \\(n\\) observations belong to one of the two latent classes and each observations is assigned to the latent classes one and two with respective probabilities \\(\\pi\\) and \\((1 - \\pi)\\). From Equation (13.17), once the latent class assignment is determined, the outcome variable \\(y_i\\) follows a class-specific data model as in Equation (13.18).\nThe tree diagram below illustrates the latent class model.\n\n\n\n\n\nTo better understand this latent class model, consider in a thought experiment where one simulates outcomes \\(y_1, \\cdots, y_n\\) from this model.\n\nStep 1: First simulate the latent class assignments of the \\(n\\) test takers. One samples \\(n\\) values, \\(z_1, \\cdots, z_n\\), from a Bernoulli distribution with probability \\(\\pi\\). Once the latent class assignments are simulated, one has partitioned the test takers into the random-guessing group where \\(z_i = 1\\) and the knowledgeable group where \\(z_i = 0\\).\nStep 2: Now that the test takers’ classifications are known, the outcomes are simulated by the use of Binomial distributions. If a test taker’s classification is \\(z_i = 1\\), she guesses at each question with success probability \\(p_1\\) and one observes the test score which is the Binomial outcome \\(Y_i \\sim \\textrm{Binomial}(20, p_1)\\). Otherwise if the classification is \\(z_i = 0\\), she answers a question correctly with probability \\(p_0\\) and one observes the test score \\(Y_i \\sim \\textrm{Binomial}(20, p_0)\\).\n\nLatent class models provide the flexibility of allowing unknown class assignments of observations and the ability to cluster observations with similar characteristics. In the true/false exam example, the fitted latent class model will pool one class of observations with a lower success rate and pool other class with a higher success rate. This fitted model also estimates model parameters for each class, providing insight of features of each latent class.\n\n\n7.4.2 A latent class model with two classes\nThis section builds on the previous section to describe the details of the model specification of a latent class model with two classes for the true/false exam example. The JAGS software is used for MCMC simulation and several inferences are described such as identifying the class for each test taker and learning about the success rate for each class.\nSuppose the true/false exam has \\(m\\) questions and \\(y_i\\) denotes the score of observation \\(i\\), \\(i = 1, \\cdots, n\\). Assume there are two latent classes and each observation belongs to one of the two latent classes. Let \\(z_i\\) be the class assignment for observation \\(i\\) and \\(\\pi\\) be the probability of being assigned to class 1. Given the latent class assignment \\(z_i\\) for observation \\(i\\), the score \\(Y_i\\) follows a Binomial distribution with \\(m\\) trials and a class-specific success probability. Since there are only two possible class assignments, all observations assigned to class 1 share the same correct success parameter \\(p_1\\) and all observations assigned to class 0 share the same success rate parameter \\(p_0\\). The specification of the data model is expressed as follows: \\[\\begin{equation}\nY_i = y_i \\mid z_i, p_{z_i} \\sim \\textrm{Binomial}(m, p_{z_i}),\n\\end{equation}\\] \\[\\begin{equation}\n\\label{eq:Bern2} z_i \\mid \\pi \\sim \\textrm{Bernoulli}(\\pi).\n\\end{equation}\\]\nIn this latent class model there are many unknown parameters. One does not know the class assignment probability \\(\\pi\\), the class assignments \\(z_1, ..., z_n\\), and the probabilities \\(p_1\\) and \\(p_0\\) for the two Binomial distributions. Some possible choices for prior distributions are discussed in this section.\n\nThe parameters \\(\\pi\\) and \\((1 - \\pi)\\) are the latent class assignment probabilities for the two classes. If additional information is available which indicates, for example, that 1/3 of the observations belonging to class 1, then \\(\\pi\\) is considered as fixed and set to the value of 1/3. If no such information is available, one can consider \\(\\pi\\) as unknown and assign this parameter a prior distribution. A natural choice for prior on a success probability is a Beta prior distribution with shape parameters \\(a\\) and \\(b\\).\nThe parameters \\(p_1\\) and \\(p_0\\) are the success rates in the Binomial model in the two classes. If one believes that the test takers in class 1 are simply random guessers, then one fixes \\(p_1\\) to the value of 0.5. Similarly, if one believes that test takers in class 0 have a higher success rate of 0.9, then one sets \\(p_0\\) to the value 0.9. However, if one is uncertain about the values of \\(p_1\\) and \\(p_0\\), one lets either or both success rates be random and assigned prior distributions.\n\nScenario 1: known parameter values\nWe begin with a simplified version of this latent class model. Consider the use of the fixed values \\(\\pi = 1/3\\) and \\(p_1 = 0.5\\), and a random \\(p_0\\) from a Uniform distribution between 0.5 and 1. This setup indicates that one believes strongly that one third of the test takers belong to the random-guessing class, while the remaining two thirds of the test takers belong to the knowledgeable class. One is certain about the success rate of the guessing class, but the location of the correct rate of the knowledgeable class is unknown in the interval (0.5, 1).\nR Work The JAGS model script is shown below. One introduces a new variable theta[i] that indicates the correct rate value for observation i. In the sampling section of the JAGS script, the first block is a loop over all observations, where one first determines the rate theta[i] based on the classification value z[i]. The equals command evaluates equality, for example, equals(z[i], 0) returns 1 if z[i] equals to 0, and returns 0 otherwise. This indicates that the rate theta[i] will either be equal to p1 or p0 depending on the value z[i].\nOne should note in JAGS, the classification variable z[i] takes values of 0 and 1, corresponding to the knowledgeable and guessing classes, respectively. As \\(\\pi\\) is considered fixed and set to 1/3, the variable z[i] is assigned a Bernoulli distribution with probability 1/3. To conclude the script, in the prior section the guessing rate parameter p1 is assigned the value 0.5 and the rate parameter p0 is assigned a Beta(1, 1) distribution truncated to the interval (0.5, 1) using T(0.5, 1).\nmodelString<-\"\nmodel {\n## sampling\nfor (i in 1:N){\n   theta[i] <- equals(z[i], 1) * p1 + equals(z[i], 0) * p0\ny[i] ~ dbin(theta[i], m)\n}\nfor (i in 1:N){\n   z[i] ~ dbern(1/3)\n}\n## priors\np1 <- 0.5\np0 ~ dbeta(1,1) T(0.5, 1)\n}\"\nOne performs inference for theta and p0 in JAGS by looking at their posterior summaries. Note that there are \\(n = 30\\) test takers, each with an associated theta indicating the correct success rate of test taker i. The variable p0 is the estimate of the correct rate of the knowledgeable class.\nHow are the correct rates estimated for different test takers by the latent class model? Before looking at the results, let’s revisit the dataset as shown in Figure 13.13. Among the test takers with lower scores, it is obvious that test taker # 6 with a score of 6 is likely to be assigned to the random-guessing class, whereas test takers # 4 and # 5 with a score of 13 are probably assigned to the knowledgeable class. Among test takers with higher scores, test takers # 15 and # 17 with respective scores of 20 and 19 are most likely to be assigned to the knowledgeable class, and test taker # 24 with a score of 14 is also likely assigned to the knowledgeable class.\nTable 13.2. Posterior summaries of the correct rates \\(\\theta_i\\) of six selected test takers.\n\n\n\nTest Taker\nScore\nMean\nMedian\n90% Credible Interval\n\n\n\n\n# 4\n13\n0.553\n0.500\n(0.500, 0.876)\n\n\n# 5\n13\n0.555\n0.500\n(0.500, 0.875)\n\n\n# 6\n6\n0.500\n0.500\n(0.500, 0.500)\n\n\n# 15\n20\n0.879\n0.879\n(0.841, 0.917)\n\n\n# 17\n19\n0.878\n0.879\n(0.841, 0.917)\n\n\n# 24\n14\n0.690\n0.831\n(0.500, 0.897)\n\n\n\n\n\n\n\n\nMCMC diagnostic plots for correct rate of the knowledgeable class, \\(p_0\\).\n\n\n\n\nThe latent class model assigns observations to one of the two latent classes at each MCMC iteration, and the posterior summaries of theta provide estimates of the correct rate of each test taker. Table 13.2 provides posterior summaries for six specific test takers. The posterior summaries of the correct rate of test taker # 6 indicate that the model assigns this test taker to the random-guessing group and the posterior mean and median of the correct rate is at 0.5. Test takers # 4 and # 5 have similar posterior summaries and are classified as random-guessing most of the time with posterior mean of correct rate around 0.55. Test taker # 24 has a higher posterior mean than the test takers # 4 and # 5. But with a posterior mean 0.69, the posterior probability for the true rate for # 24 is somewhat split between random guessing and knowledgeable states. Test takers # 15 and # 17 are always classified as knowledgeable with posterior mean and median of correct rate around 0.88.\nOne also summarizes the posterior draws of \\(p_0\\) corresponding to the success rate for the knowledgeable students. Figure 13.14 provides MCMC diagnostics of \\(p_0\\). Its posterior mean, median, and 90% credible interval are 0.879, 0.879, and (0.841, 0.917). These estimates are very close to the correct rate of test takers # 15 and # 17. These test takers are always classified in the knowledgeable class and their correct rate estimates are the same as \\(p_0\\).\nScenario 2: all parameters unknown\nIt is straightforward to generalize this latent class model relaxing some of the fixed parameter assumptions in Scenario 1. It was originally assumed that the class assignment parameter \\(\\pi = 1/3\\). It is more realistic to assume that the probability of assigning an individual into the first class \\(\\pi\\) is unknown and assign this parameter a Beta distribution with specific shape parameters. Here one assumes little is known about this classification parameter and so \\(\\pi\\) is assigned a \\(\\textrm{Beta}(1, 1)\\), i.e. a Uniform distribution on (0, 1). In addition, previously it was assumed that it was known that the success rate for the “guessing” group \\(p_1\\) was equal to 1/2. Here this assumption is relaxed by assigning the success rate \\(p_1\\) a Uniform prior on the interval (0.4, 0.6). If one knows only that that the success rate for the “knowing” group is \\(p_0\\) is larger than \\(p_1\\), then one assumes \\(p_0\\) is Uniform in the interval (\\(p_1, 1\\)).\nR Work The JAGS script for this more general model follows. We introduce the parameter q as \\(\\pi\\), that is the class assignment parameter and assign it a Beta distribution with parameters 1 and 1. The prior distributions for p1 and p0 are modified to reflect the new assumptions.\nmodelString<-\"\nmodel {\n## sampling\nfor (i in 1:N){\n   theta[i] <- equals(z[i], 1) * p1 + equals(z[i], 0) * p0\n   y[i] ~ dbin(theta[i], m)\n}\nfor (i in 1:N){\n   z[i] ~ dbern(q)\n}\n## priors\np1 ~ dbeta(1, 1) T(0.4, 0.6)\np0 ~ dbeta(1,1) T(p1, 1)\nq ~ dbeta(1, 1)\n}\n\"\nIn Scenario 1, the posterior distributions of the correct rates theta[i] were summarized for all individuals. Here we instead focus on the classification parameters z[i] where z[i] = 1 indicates a person classified into the random-guessing group. Figure 13.15 displays the posterior means of the \\(z_i\\) for all individuals. As expected, individuals #1 through # 10 are classified as guessers and most individuals with labels 12 and higher are classified as knowledgeable. Individuals # 11 and # 24 have posterior classification means between 0.25 and 0.75 indicating some uncertainty about the correct classification for these people.\n\n\n\n\n\nPosterior means of classification parameters for all test takers\n\n\n\n\nFigure 13.16 displays density estimates of the simulated draws from the posterior distributions of the class assignment parameter \\(\\pi\\) and the rate parameters \\(p_1\\) and \\(p_0\\). As one might expect, the posterior distributions of \\(p_1\\) and \\(p_0\\) are centered about values of 0.54 and 0.89. There is some uncertainty about the class assignment parameter as reflected in a wide density estimate for \\(\\pi\\) (\\(q\\) in the figure).\n\n\n\n\n\nPosterior density plots of class assignment and rate parameters.\n\n\n\n\n\n\n7.4.3 Disputed authorship of the Federalist Papers\n\nReturning to the Federalist Papers example of Section 13.2, the discussion focused on learning about the true rates of filler words for papers written by Alexander Hamilton and James Madison. But actually the true authorship of some of the papers was in doubt, and the primary task in Mosteller and Wallace (1963) was to learn about the true authorship of these disputed authorship papers from the data. This problem of disputed authorship can be considered a special case of latent data modeling where the latent variable is the authorship of a disputed paper. We describe how the Bayesian model of Section 13.3 can be generalized to learn about both the rates of a particular filler word and the identity of the papers of disputed authorship.\nIn our sample there are a total of 74 Federalist Papers. We assume that 49 of these papers are known to be written by Hamilton, 15 of the papers are known to be written by Madison, and the authorship of the remaining 10 papers is disputed between the two authors. We focus on the use of the filler word “can” in these papers. Let {\\((y_{1i}, n_{1i})\\)} denote the frequencies of “can” and total words in the Hamilton papers, {\\((y_{2i}, n_{2i}\\))} denote the frequencies and total words in the Madison papers, and {\\((y_{i}, n_{i}\\))} denote the corresponding quantities in the disputed papers. As in Section 13.2, we assume {\\(y_{1i}\\)} are Negative Binomial(\\(p_{1i}, \\alpha_1\\)) where \\(p_{1i} = \\beta_1 / (\\beta_1 + n_{1i}/1000)\\), and {\\(y_{2i}\\)} are Negative Binomial(\\(p_{2i}, \\alpha_2\\)) where \\(p_{2i} = \\beta_2 / (\\beta_2 + n_{2i}/1000)\\).\nThe distribution of the frequencies {\\(y_{i}\\)} is unknown (out of the total number of words {\\(n_{i}\\)}) since these correspond to the papers of disputed authorship. Let \\(z_i\\) denote the unknown authorship of paper \\(i\\) among the disputed papers – if \\(z_i = 0\\), the paper was written by Hamilton and if \\(z_i = 1\\), the paper was written by Madison. If one knows the value of \\(z_i\\), the distribution of the frequency \\(y_i\\) is known. If \\(z_i = 0\\), then \\(y_i\\) is Negative Binomial(\\(p_{i}, \\alpha_1\\)) where \\(p_{i} = \\beta_1 / (\\beta_1 + n_{i}/1000)\\), and \\(z_i = 1\\), then \\(y_i\\) is Negative Binomial(\\(p_{i}, \\alpha_2\\)) where \\(p_{i} = \\beta_2 / (\\beta_2 + n_{i}/1000)\\). To complete the model, one needs to assign a prior distribution to the latent authorship indicators {\\(z_i\\)}. It is assumed \\(z_i \\sim \\textrm{Bernoulli}(0.5)\\) which means that \\(z_i\\) from the prior is equally likely to be 0 or 1.\nThe JAGS script for the disputed authorship problem is shown below. The data is structured so that N1 papers are known to be written by Hamilton, N2 papers are known to be written by Madison, and the authorship of the remaining N3 papers are in doubt. The data includes the number of occurrences of the word “can” and the total number or words in each group of papers. Note that, as in Section 13.3, weakly informative priors are placed on the Gamma priors for \\(\\alpha_1, \\beta_1, \\alpha_2\\) and \\(\\beta_2\\).\nmodelString = \"\nmodel{\nfor(i in 1:N1){\n   p1[i] <- beta1 / (beta1 + n1[i] / 1000)\n   y1[i] ~ dnegbin(p1[i], alpha1)\n}\nfor(i in 1:N2){\n   p2[i] <- beta2 / (beta2 + n2[i] / 1000)\n   y2[i] ~ dnegbin(p2[i], alpha2)\n}\nfor(i in 1:N3){\n   theta[i] <- equals(z[i], 0) * alpha1 +\n            equals(z[i], 1) * alpha2\n   gamma[i] <- equals(z[i], 0) * beta1 +\n            equals(z[i], 1) * beta2\n   p[i] <- gamma[i] / (gamma[i] + n[i] / 1000)\n   y[i] ~ dnegbin(p[i], theta[i])\n   z[i] ~ dbern(0.5)\n}\nalpha1 ~ dgamma(.001, .001)\nbeta1 ~ dgamma(.001, .001)\nalpha2 ~ dgamma(.001, .001)\nbeta2 ~ dgamma(.001, .001)\n}\nUsing this script, a sample of 5000 draws were taken from the posterior distribution and Figure 13.17 displays posterior means of the classification parameters \\(z_1, ..., z_{10}\\) for the ten disputed authorship parameters. Since \\(z_i = 1\\) if the author is Madison, this graph is showing the posterior probability the author is James Madison for each paper. Note that most of these posterior means are located near 0.5, with the one exception of Paper 4 where the posterior probability of Madison authorship is 0.174. So really one has not learned much about the identity of the true author from this data.\n\n\n\n\n\nPosterior means of classification parameters for authorship problem using rates of the filler word can.\n\n\n\n\nBut we have only looked at the frequencies of one particular filler word in our analysis. In a typical study such as the one done by Mosteller and Wallace (1963), a number of filler words are used. One can extend the analysis to include a number of filler words; the approach is outlined below and the implementation details are left to the end-of-chapter exercises.\nSuppose \\(y_{1i}^w\\) denotes the number of occurrences of the word \\(w\\) in the \\(i\\)-th paper written by Hamilton. Similarly, \\(y_{2i}^w\\) denotes the word count of \\(w\\) in the \\(i\\)-th paper written by Madison and \\(y_i^w\\) denotes the word count of \\(w\\) in the \\(i\\)-th paper of disputed authorship. It is assumed that each word count follows a Negative Binomial distribution where the parameters of the distribution depend on the author and the word. So, for example, for a Hamilton paper, \\(y_{1i}^w\\) is distributed Negative Binomial(\\(p_1^w, \\alpha_1^w\\)) where \\(p_1^w = \\beta_1^w / (\\beta_1^w + n_{1i}/1000)\\). For a Madison paper, \\(y_{2i}^w\\) is distributed Negative Binomial(\\(p_2^w, \\alpha_2^w\\)) where \\(p_2^w = \\beta_2^w / (\\beta_2^w + n_{2i}/1000)\\). For a paper of disputed authorship, the count \\(y_i^w\\) will either be distributed according to one of the Negative Binomial distributions where the distribution depends on the value of the classification variable \\(z_i\\).\nA JAGS script can be written to fit this model with multiple filler words. In the script, one defines the matrix variable y1 where y1[i, j] is defined to be the number of words of type \\(j\\) in the \\(i\\)-th paper of Hamilton. In a similar fashion one defines the matrices y2 and y where y2[i, j] and y[i, j] denote respectively the counts of the \\(j\\)-th word of the \\(i\\)-th Madison and \\(i\\)-th disputed authorship paper. One will be learning about vectors \\(\\alpha_1, \\beta_1, \\alpha_2, \\beta_2\\) where each vector has \\(W\\) values where \\(W\\) is the number of words in the study. As before z[i] denotes the classification variable where z[i] = 1 denotes authorship of the \\(i\\)-th disputed paper by Madison. In an end-of-chapter exercise, the reader will be asked to implement the model fitting using a selection of filler words. One would anticipate that one would be able to discriminate between the two authors on the basis of a large group of filler words."
  },
  {
    "objectID": "proportion.html#exercises",
    "href": "proportion.html#exercises",
    "title": "2  Learning About a Binomial Probability",
    "section": "2.7 Exercises",
    "text": "2.7 Exercises\n\nLaymen’s Prior in the Dining Preference Example\n\nRevisit Section 7.2.1 for the laymen’s prior in Equation (7.2) and the expert’s prior in Equation (7.3). Follow the example R code (functions data.frame(), mutate() and ggplot()) to obtain the Bayes table and graph of the laymen’s prior distribution. Compare the similarities and differences between the laymen’s prior and the expert’s prior.\n\nInference for the Dining Preference (Discrete Priors)\n\nRevisit Section 7.2.5 where we show how to find the posterior probability that over half of the students prefer eating out on Friday. Find the following posterior probabilities. (Be careful about the end points.)\n\nThe probability that more than 60% of the students prefer eating out on Friday.\nThe probability that less than 40% of the students prefer eating out on Friday.\nThe probability that between 20% and 40% of the students prefer eating out on Friday.\nNo more than 50% of the students prefer eating out on Friday.\n\n\nAnother Dining Survey (Discrete Priors)\n\nSuppose the restaurant owner in the college town gives another survey to a different group of students. This time he gives the survey to 30 students – among these responses 10 of them say that Friday is their preferred day to eat out. Use the owner’s prior (restated below) to calculate the following posterior probabilities. \\[\\begin{eqnarray}\np &=& \\{0.3, 0.4, 0.5, 0.6, 0.7, 0.8\\} \\nonumber \\\\\n\\pi_e(p) &=& (0.125, 0.125, 0.250, 0.250, 0.125, 0.125) \\nonumber\n\\end{eqnarray}\\]\n\nThe probability that 30% of the students prefer eating out on Friday.\nThe probability that more than half of the students prefer eating out on Friday.\nThe probability that between 20% and 40% of the students prefer eating out on Friday.\n\n\nInterpreting A Beta Curve\n\nRevisit Figure 7.4 where nine different Beta curves are displayed. In the context of students’ dining preference example where \\(p\\) is the proportion of students preferring Friday, interpret the following prior choices in terms of the opinion of \\(p\\). For example, \\(\\textrm{Beta}(0.5, 0.5)\\) represents the prior belief the extreme values \\(p = 0\\) and \\(p = 1\\) are more probable and \\(p = 0.5\\) is the least probable. In the students’ dining preference example, specifying a \\(\\textrm{Beta}(0.5, 0.5)\\) prior indicates the owner thinks the students’ preference of dining out on Friday is either very strong or very weak.\n\nInterpret the \\(\\textrm{Beta}(1, 1)\\) curve.\nInterpret the \\(\\textrm{Beta}(0.5, 1)\\) curve.\nInterpret the \\(\\textrm{Beta}(4, 2)\\) curve.\nCompare the opinion about \\(p\\) expressed by the two Beta curves: \\(\\textrm{Beta}(4, 1)\\) and \\(\\textrm{Beta}(4, 2)\\).\n\n\nBeta Probabilities\n\nUse the functions dbeta(), pbeta(), qbeta(), rbeta(), beta_area(), and beta_quantile() to answer the following questions about Beta probabilities.\n\nCompute the density of \\(\\textrm{Beta}(0.5, 0.5)\\) at the values \\(p = \\{0.1, 0.5, 0.9, 1.5\\}\\). Check your answers with the \\(\\textrm{Beta}(0.5, 0.5)\\) curve in Figure 7.4.\nIf \\(p \\sim \\textrm{Beta}(6, 3)\\), compute the probability \\(Prob(0.2 \\le p \\le 0.6)\\) if .\nCompute the quantiles of the \\(\\textrm{Beta}(10, 10)\\) distribution at the probability values in the set $ {0.1, 0.5, 0.9, 1.5}$.\nSimulate a sample of 100 random values from \\(\\textrm{Beta}(4, 2)\\).\n\n\nComparing Beta Distributions\n\nConsider four Beta curves: (1) (5, 5), (2) (10, 10), (3) (50, 50) and (4) (100, 100). Think of the shape parameters \\(a\\) and \\(b\\) as counts of successes\" andfailures” in a prior sample. Use one of the R beta functions (e.g. rbeta(), beta_area(), among others) to discuss the similarities and differences between these four Beta curves.\n\nSpecifying A Continuous Beta Prior\n\nConsider another dining survey conducted by a restaurant owner in New York. The owner is also interested in knowing about the proportion \\(p\\) of students prefer eating out on Friday. He believes that its \\(0.4\\) quantile is \\(0.7\\) and \\(0.8\\) quantile is \\(0.9\\). Suppose the owner plans on using a Beta prior distribution.\n\nFind the values of the Beta shape parameters \\(a\\) and \\(b\\) to represent the restaurant owner’s belief.\nConfirm the choice of Beta prior by taking a simulated sample from the prior predictive simulation. [Hint: use the rbeta() function to simulate a sample from the selected Beta distribution, and then simulate new \\(\\tilde{y}\\) values from the Binomial data model (function rbinom()) with a sample size of 20. Graph and/or calculate a few quantiles of the simulated \\(\\tilde{y}\\) sample from the predictive distribution to check the restaurant owner’s prior belief.]\n\n\nDeriving the Beta Posterior\n\nFollowing the derivation process of the dining preference example in Section 7.4.1, derive this more general result. If the proportion has a (\\(a, b\\)) prior and one samples \\(Y\\) from a distribution with parameters \\(n\\) and \\(p\\), then if one observes \\(Y = y\\), then the posterior density of \\(p\\) is (\\(a + y, b + n - y\\)).\n\nPrior Sample Size and Strength of Priors\n\nAnother way of specifying a \\({\\rm{Beta}}(a, b)\\) prior is to imagine a pre-survey with the same question and represent the Beta shape parameters in the form of \\(a\\) successes and \\(b\\) failures in the pre-survey. This exercise explores this prior specification method.\nTable 7.3. Updating the Beta prior.\n\n\n\nSource\nSuccesses\nFailures\n\n\n\n\nPrior\n(a)\n(b)\n\n\nData/Likelihood\n(y)\n(n-y)\n\n\nPosterior\n(a + y)\n(b + n - y)\n\n\n\n\nRecall from Section 7.3 that the mean of the \\({\\rm{Beta}}(a, b)\\) distribution is \\(\\frac{a}{a+b}\\). Define the prior sample size to be \\(n_p = a + b\\). Consider two Beta prior distributions: \\({\\rm{Beta}}(2, 2)\\) and \\({\\rm{Beta}}(20, 20)\\). Find the prior means and prior sample sizes of these two prior distributions and compare the prior beliefs of these two Beta distributions.\nSuppose a survey yields \\(4\\) successes out of \\(10\\) responses. Suppose one wishes to compare the posterior inference obtained by the two different Beta priors \\({\\rm{Beta}}(2, 2)\\) and \\({\\rm{Beta}}(20, 20)\\). Find and compare the two posterior distributions corresponding to these two priors.\nConsider the use of the \\({\\rm{Beta}}(2, 2)\\) and \\({\\rm{Beta}}(20, 20)\\) prior distributions. Show these two priors have the same prior mean, but different strengths of belief about the location of the proportion. Assuming the survey results in (b), use simulation and graphs to show how different prior sample sizes affect the posterior inference.\nSuppose a survey yields \\(40\\) successes out of \\(100\\) responses. Find the two posterior distributions corresponding to the two prior distributions \\({\\rm{Beta}}(2, 2)\\) and \\({\\rm{Beta}}(20, 20)\\). Contrast the two posterior distributions and compare with your answer to part (c).\nConsider the two prior distributions \\({\\rm{Beta}}(9, 1)\\) and \\({\\rm{Beta}}(45, 5)\\). Contrast these these two Beta prior distributions with respect to the mean and strength of belief. Compare the two posterior distributions with data \\(n = 20, y = 5\\), and with the data \\(n = 200, y = 50\\).\n\n\nBeta Posterior Mean is a Weighted Mean\n\nIf the proportion has a \\(\\textrm{Beta}\\)(\\(a, b\\)) prior and one observes \\(Y\\) from a \\(\\textrm{Binomial}\\) distribution with parameters \\(n\\) and \\(p\\), then if one observes \\(Y = y\\), then the posterior density of \\(p\\) is \\(\\textrm{Beta}\\)(\\(a + y, b + n - y\\)).\nRecall that the mean of a \\({\\textrm Beta}(a, b)\\) random variable following is \\(\\frac{a}{a+b}\\). Show that the posterior mean of \\(p \\mid Y = y \\sim {\\rm Beta}(a + y, b + n - y)\\) is a weighted average of the prior mean of \\(p \\sim {\\rm Beta}(a, b)\\) and the sample mean \\(\\hat{p} = \\frac{y}{n}\\). Find the two weights and explain their implication for the posterior being a combination of prior and data.\n\nSequential Updating\n\nThe restaurant owner’s belief about the proportion of students’ favorite dining day being Friday is represented by a \\({\\rm{Beta}}(15.06, 10.56)\\) distribution. Recall that he obtained this posterior distribution from a \\({\\rm{Beta}}(3.06, 2.56)\\) prior and a survey of \\(12\\) yes’s out of \\(20\\) responses. The owner is interested in conducting another dining survey a few months later with the same question and the owner is still interested in \\(p\\), the proportion of all students who say Friday.\n\nThe second survey gives a result of \\(8\\) yes’s out of \\(20\\) responses. Use the owner’s current beliefs and this information to update the restaurant owner’s belief about the proportion \\(p\\).\nSuppose the two surveys are conducted at the same time and the results are \\(20\\) yes’s (\\(12 + 8\\)) out of \\(40\\) responses (\\(20 + 20\\)). Starting with the \\({\\rm{Beta}}(3.06, 2.56)\\) prior, update the owner’s belief about the proportion of interest.\nAre the two posterior distribution the same in parts (a) and (b)? Why or why not?\nSuppose the two survey results are reversed. That is, the first survey gives \\(8\\) yes’s and second survey gives \\(12\\) yes’s. Do you still observe the same posterior as in part (b)? What does this tell you about the order of different pieces of information shaping the belief about a parameter?\nWhat if the two survey results are slightly different? e.g., first survey gives \\(15\\) yes’s and second survey gives \\(5\\) yes’s. What is the posterior distribution in this case?\nShould we combine the two survey results together? Describe a scenario where you it would be inappropriate to combine the survey results.\n\n\nBayesian Hypothesis Testing\n\nIn the dining preference example, the restaurant owner’s posterior distribution of proportion \\(p\\) of students preferring Friday to eat out is \\(\\textrm{Beta}(15.06, 10.56)\\). Suppose the owner’s wife claims that between 50% and 60% of the students prefer to eat out on Friday. Conduct a Bayesian hypothesis test of this claim.\n\nSimulation Sample Size\n\nRevisit Section 7.5.2. Use R to simulate random samples of sizes \\(S = \\{10, 100, 500, 1000, 5000\\}\\) of \\(p\\) from the \\(\\textrm{Beta}(15.06, 10.56)\\) distribution. Use the quantile() function to find the approximate 90% credible interval of \\(p\\) for each value of \\(S\\). Comment on the effect of the simulation size \\(S\\) on the accuracy of the simulation results. Recall that the exact middle 90% posterior interval estimate is [0.427, 0.741].\n\nBayesian Credible Intervals\n\nIn the dining preference example, the restaurant owner’s posterior distribution of proportion \\(p\\) of students preferring Friday to eat out is \\(\\textrm{Beta}(15.06, 10.56)\\). Find the exact Bayesian credible intervals for the following cases.\n\nThe middle 95% credible interval.\nThe middle 98% credible interval.\nThe 90% credible interval of the form \\((0, B)\\).\nThe 99% credible interval of the form \\((A, 1)\\)\n\n\nSimulating the Posterior of the Log Odds \n\nSince one is able to compute exact posterior summaries using the pbeta() and qbeta() functions, what is the point of using simulation computations? To illustrate the advantage of simulation, suppose one is interested in finding a 90% probability interval about the logit or log odds \\(\\textrm{log}\\left(\\frac{p}{1-p}\\right)\\). One can approximate the posterior of the logit by simulation. First simulate \\(S = 1000\\) values from the Beta posterior for \\(p\\), and then for each simulated value of \\(p\\), compute a value of the logit. The resulting vector will be a random sample from the posterior distribution of the logit.\n\nIf the posterior distribution for \\(p\\) is Beta(12, 20), use R to simulate 1000 draws from the posterior of the logit \\(\\textrm{log}\\left(\\frac{p}{1-p}\\right)\\).\nConstruct a 90% interval estimate for the logit parameter.\n\n\nSimulating the Odds\n\nRevisit Exercise 15. Instead of the logit or log odds of the proportion \\(p\\), suppose we are interested in the odds \\(\\frac{p}{1-p}\\). If the posterior distribution for \\(p\\) is Beta(12, 20), use R to simulate 1000 values from the posterior distribution of the odds. Construct a histogram of the simulated odds and construct a \\(90%\\) interval estimate. Experiment with different values of the simulation sample size \\(S\\) and comment on the effect of the value of \\(S\\) on the width of the \\(90%\\) interval estimates.\n\nTeenagers and Televisions \n\nIn 1998, the New York Times and CBS News polled \\(1048\\) randomly selected \\(13 - 17\\) year olds to ask them if they had a television in their room. Among this group of teenagers, \\(692\\) of them said they had a television in their room. Alex and Benedict both want to use the Binomial model for this dataset, but they have different prior believes about \\(p\\), the proportion of teenagers having a television in their room.\n\nAlex asks \\(10\\) friends the same question and \\(8\\) of them have a television in their room. Alex decides to use this information to construct his prior. Design a continuous Beta prior reflecting Alex’s belief.\nBenedict thinks the \\(0.2\\) quantile is \\(0.3\\) and the \\(0.9\\) quantile is \\(0.4\\). Design a continuous Beta prior reflecting Benedict’s belief.\nCalculate Alex’s posterior and Benedict’s posterior distributions. Plot the two priors on one graph, and plot the corresponding posteriors on another graph. In addition, obtain \\(95\\%\\) credible intervals for Alex and Benedict.\nConduct prior predictive checks for Alex and Benedict. For each person, is the prior consistent with the television data? Explain.\n\n\nTeenagers and Televisions (continued)\n\nRevisit Exercise 17. Consider the odds of having a television in the room. Recall that if \\(p\\) is the probability of having a television in room, then the odds is \\(\\frac{p}{1-p}\\).\n\nFind the mean, median and 95% posterior interval of Alex’s analysis of the odds of teenagers having a television in their room.\nFind the mean, median and 95% posterior interval of Benedict’s analysis of the odds of teenagers having a television in their room.\nCompare the two posterior summaries from parts (a) and (b).\n\n\nComparing Two Proportions - Science Majors at Liberal Arts Colleges\n\nMany liberal arts colleges and other organizations have been promoting science majors in recent years because of their value on the job market. One wishes to evaluate whether such promotion has any effect on student major preference. A college student Clara is interested in this question and collects data from three liberal arts colleges.\nTable 7.4. Data from three liberal arts colleges on science majors in 2005 and 2015.\n\n\n\nYear\nScience\nNon-Science\n\n\n\n\n2005\n264\n1496\n\n\n2015\n437\n1495\n\n\n\n\nLet \\(p_{2005}\\) and \\(p_{2015}\\) denote the proportions of science majors in 2005 and 2015, respectively. Assuming that \\(p_{2005}\\) and \\(p_{2015}\\) have independent uniform priors, obtain the joint posterior distribution of \\(p_{2005}\\) and \\(p_{2015}\\). Recall that the \\({\\rm{Beta}}(1, 1)\\) distribution is equivalent to the \\(\\rm{Uniform}(0, 1)\\) distribution.\nSuppose one uses the parameter \\(\\delta = p_{2015} - p_{2005}\\) to measure the difference in proportions. Use simulation from the posterior distribution to answer the question ``have the proportions of science majors changed from 2005 to 2015?“. [Hint: simulate a vector \\(s_{2005}\\) of posterior samples of \\(p_{2005}\\) and another vector \\(s_{2015}\\) of posterior samples of \\(p_{2015}\\) (make sure to use the same number of samples) and subtract \\(s_{2005}\\) from \\(s_{2015}\\) which yields a vector of simulated values from the posterior of \\(\\delta\\).]\nDid the proportion of science majors change from 2005 to 2015? Answer this question by a posterior computation.\nCompile a similar dataset for your school type, and answer parts (a) through (c).\nWhat assumption is made about the proportions \\(p_{2005}\\) and \\(p_{2015}\\) in our assignment of priors? Do you think such assumption is justified? If not, how do you think one can adjust the approach to be more realistic?\n\n\nComparing Two Proportions - Number of Depression Cases at a Hospital\n\nData are collected on depression cases at hospitals. For a particular hospital, in the year of 1992, there were 306 diagnosed with depression among 651 patients; in the year of 1993, there were 300 diagnosed with depression among 705 patients. One is interested in learning whether the probability of being diagnosed with depression changed between 1992 and 1993. Conduct a. Bayesian analysis of this question. State clearly the inference procedure, the choice of prior distributions, the choice of data model, the posterior distributions and the conclusions.\n\nPrior Predictive Checking - Pizza Popularity \n\nSuppose a restaurant is serving pizza of two varieties, cheese and pepperoni, and a manager is interested in the proportion \\(p\\) of customers who prefer pepperoni. After some thought, the manager’s prior beliefs about \\(p\\) are represented by a Beta(6, 12) distribution.\n\nSuppose a random sample of 20 customers is surveyed on their pizza preference and let \\(Y\\) denote the number that prefer pepperoni. Compute and graph the prior predictive density of \\(Y\\).\nSuppose 20 customers are sampled and 14 prefer pepperoni. Is the value \\(y = 14\\) consistent with the Bayesian model where \\(p\\) has a Beta(6, 12) distribution? Explain why or why not.\n\n\nBayes Factor - Pizza Popularity \n\nIn the restaurant example of Exercise 21, suppose one of the waiters has a different opinion about the popularity of pepperoni pizza. His prior belief about the proportion \\(p\\) preferring pizza is described by a Beta(12, 6) distribution.\n\nFind and graph the prior predictive density of the number \\(y\\) who prefer pizza in a sample of 20 customers.\nIf 14 out of 20 customers prefer pepperoni, is this result consistent with the predictive distribution?\nCompare the two Bayesian models where (1) \\(p\\) is distributed Beta(12, 6) and (2) \\(p\\) is distributed Beta(6, 12) by a Bayes factor. Interpret the value that you compute.\n\n\nPosterior Predictive Checking - Pizza Popularity\n\nConsider the same problem as in Exercise 22 where \\(p\\) is the proportion of customers who prefer pepperoni and the manager’s prior beliefs are given by a Beta(6, 12) distribution.\n\nSuppose 14 out of 20 customers prefer pepperoni. Using the algorithm described in Section 7.6, simulate 1000 values of \\(\\tilde y\\) (out of 20 customers) from the posterior predictive distribution. Construct a histogram of these values.\nIs the observation (14 preferring pepperoni) consistent with this predictive distribution? Explain.\nRepeat parts (a) and (b) using the waiter’s Beta(12, 6) distribution.\n\n\nLearning from a Multinomial Experiment\n\nIn Chapter 6 Section 6.3, we discussed the Multinomial distribution, an extension of the Binomial distribution where each trial has more than two outcomes. As an application of a Multinomial experiment, in an analysis of an election poll, suppose that one wants inferences for three probabilities: \\(\\theta_A\\) = probability of a vote for a candidate from Party A, \\(\\theta_B\\) = probability of a vote for a candidate from Party B and \\(\\theta_C\\) = probability of a vote for a candidate from Party C. One assumes \\(\\theta_A + \\theta_B + \\theta_C = 1\\) as people can vote for only one party. If a random sample of \\(n\\) potential voters is taken, the respective voter counts \\(Y_A, Y_B, Y_C\\) has the probability mass function\n\\[\\begin{equation}\np(Y_A = y_A, Y_B = y_B, Y_C = y_C) = \\frac{n!}{y_A! y_B! y_C!}\\theta_A^{y_A}\\theta_B^{y_B}\\theta_C^{y_C},\n(\\#eq:multinomial)\n\\end{equation}\\] where \\(y_A + y_B + y_C = n\\) and \\(y_A, y_B, y_C \\geq 0\\). This is written \\(\\textrm{Multinomial}(n; \\theta_A, \\theta_B, \\theta_C)\\).\n\nA convenient prior distribution for \\((\\theta_A, \\theta_B, \\theta_C)\\) is the Dirichlet distribution, which has the density function \\[\\begin{eqnarray*}\np(\\theta_A, \\theta_B, \\theta_C) = K \\theta_A^{\\alpha_A - 1}\n\\theta_B^{\\alpha_B - 1} \\theta_C^{\\alpha_C - 1},\n\\end{eqnarray*}\\] where \\((\\alpha_A, \\alpha_B, \\alpha_C)\\) are positive constants, and $K = $ is a normalizing constant. This is written \\(\\textrm{Dirichlet}(\\alpha_A,\\alpha_B, \\alpha_C)\\). Install the gtools R package and explore ddirichlet() and rdirichlet() functions to evaluate the pdf and generate random samples from \\(\\textrm{Dirichlet}(\\alpha_A = 2,\\alpha_B = 1, \\alpha_C = 1)\\).\nSuppose the prior distribution is \\(\\text{Dirichlet}(\\alpha_A, \\alpha_B, \\alpha_C)\\) and one collects from \\(n\\) sampled voters, where \\((Y_A, Y_B, Y_C) \\sim \\textrm{Multinomial}(n; \\theta_A, \\theta_B, \\theta_C)\\). Find the posterior distribution of \\((\\theta_A, \\theta_B,  \\theta_C)\\) and show that this is a Dirichlet distribution with updated parameters.\nSuppose in the sample of \\(n = 100\\) voters, 53 voted for Party A, 18 voted for Party B, and 29 voted for Party C \\((y_A = 53, y_B = 18, y_C = 29)\\). Using the prior distribution \\(\\text{Dirichlet}(\\alpha_A = 2, \\alpha_B = 1, \\alpha_C = 1)\\) and the generic results from part (b), obtain the posterior distribution for \\((\\theta_A, \\theta_B, \\theta_C)\\). Plot the prior and the posterior distributions for \\((\\theta_A, \\theta_B, \\theta_C)\\) and discuss your findings.\nSuppose one wants to compute the ratio of odds of voting for Party A to the odds of voting for Party B, \\(\\frac{\\theta_A/(1 - \\theta_A)}{\\theta_B/(1 - \\theta_B)}\\). Compute a 95% posterior interval for this odds ratio.\n\nE1. How Good is the Shooter?\nSuppose you are interested in learning about \\(p\\), the probability that a high school basketball player will succeed in a free-throw attempt. You believe before observing any data that \\(p\\) is equal to 0.5, 0.6, 0.7, or 0.8 and each value has the same probability. Suppose she is going to take three shots and let \\(Y\\) denote the number of shots she makes.\n\nFind the joint distribution of \\(p\\) and \\(Y\\).\nCompute the predictive (marginal) distribution of \\(Y\\).\nFind the probability that she makes at least two shots.\nFind the expected number of shots she will make.\n\nE2. How Good is the Shooter? (continued)\nSuppose that you observe the shooter make two of her three shot attempts.\n\nBy use of a Bayes’ table, perform all of the Bayesian calculations include values of the Likelihood, Product, and Posterior.\nGraph the posterior distribution for \\(P\\).\nIf you define an “excellent” shooter as values of \\(p\\) of 0.7 or 0.8, what is the posterior probability she is an excellent shooter.\nFind the posterior mean of \\(p\\).\n\nE3. Does Frank Have ESP?\nFrank claims to have extra sensory perception (ESP). You are skeptical and so you ask Frank to participate in a card reading experiment. You have a deck of cards with equal numbers of \\(\\diamondsuit\\)’s, \\(\\heartsuit\\)’s, \\(\\clubsuit\\)’s, and \\(\\spadesuit\\)’s. You shuffle the deck and hold a card up with the face away from Frank. Frank will then tell you the suit of the card. For the next trial of the experiment, you put the card back into the deck, reshuffle, and draw a new card. The experiment is completed when ten cards have been used. Let \\(p\\) be the proportion of cards in which he correctly identifies the suit. There are two models of interest: \\(p=.25\\), which says that Frank does not have ESP and is essentially guessing at the suit of the card, and \\(p=.5\\) which says that Frank does have some ability to detect the suit.\n\nSuppose you will test Frank using 10 cards and let \\(Y\\) denote the number of cards that are correctly identified. Suppose you are skeptical of Frank’s ability so you define the following prior.\n\n\n\n\nP\nPrior\n\n\n\n\n0.25\n0.8\n\n\n0.50\n0.2\n\n\n\n\nFind the marginal (predictive) pmf for \\(Y\\).\nBefore you observe any results, find the probability that Frank will guess 5 or more correct (that is, \\(Y \\ge 5\\)).\nNow the experiment is run and Frank correctly identifies \\(Y = 5\\) of the 10 cards. By constructing a Bayes’ table, find the posterior distribution for \\(p\\).\nBased on your experiment, do you think it is likely that Frank has ESP? Explain.\n\nE4. Sampling Students\nSuppose you are interested in learning about the proportion \\(p\\) of undergraduate students who own Macintosh laptops. You place the following prior on the values of \\(p\\). (Note the prior weights, not the prior probabilities are shown.)\n\n\n\nP\nPrior\n\n\n\n\n0.1\n1\n\n\n0.2\n1\n\n\n0.3\n2\n\n\n0.4\n4\n\n\n0.5\n2\n\n\n0.6\n1\n\n\n0.7\n1\n\n\n0.8\n1\n\n\n0.9\n1\n\n\n\n\nYou plan on sampling 20 students. Based on your prior, find the (predictive) probability that 10 or more students will own Macs. [HINT: Compute this probability by a “model/data” simulation where you simulate values \\(p\\) and \\(y\\).]\nSuppose you now take your sample and 12 out of the 20 students own Macs. Find the posterior probability distribution for \\(p\\) and find the posterior mean.\nFind an interval that you believe contains \\(p\\) with probability 0.9."
  },
  {
    "objectID": "mean.html#exercises",
    "href": "mean.html#exercises",
    "title": "3  Modeling Measurement and Count Data",
    "section": "3.9 Exercises",
    "text": "3.9 Exercises\n\nAnother Set of Federer’s Time-to-Serve Measurements (Discrete Priors)\n\nSuppose another set of thirty Federer’s time-to-serve measurements are collected with an observed mean of 19 seconds. Assume the same Uniform discrete prior on the values \\(\\mu\\) = 15, 16, …, 22. The prior and the likelihood function are displayed below.\n\\[\\begin{equation*}\n\\pi(\\mu) = \\frac{1}{8}, \\, \\, \\, \\, \\mu = 15, 16, ..., 22,\n\\end{equation*}\\]\n\\[\\begin{equation*}\nL(\\mu) \\propto \\exp\\left(-\\frac{n}{2 \\sigma^2}(\\bar y - \\mu)^2\\right).\n\\end{equation*}\\]\n\nAssuming \\(\\sigma = 4\\), perform the Bayes’ rule calculation to find the posterior distribution for \\(\\mu\\).\n\nUsing the posterior, find a ``best” estimate at \\(\\mu\\) and an interval of values that contains \\(\\mu\\) with probability at least 0.5.\n\n\nTemperature in Bismarck\n\nSuppose one is interested in learning about the average January daily temperature (in degrees Fahrenheit) in Bismarck, North Dakota. One assumes that the daily temperature \\(Y\\) is Normally distributed with mean \\(\\mu\\) and known standard deviation \\(\\sigma = 10\\). Suppose that one’s prior is Uniformly distribution over the values \\(\\mu = 5, 10, 15, 20, 25, 30, 35\\). Suppose one observes the temperature for one January day to be 28 degrees. Find the posterior distribution of \\(\\mu\\) and compute the posterior probability the mean is at least as large as 30 degrees.\n\nChoosing A Normal Prior\n\n\nSuppose Sam believes that the 0.25 quantile of the mean of Federer’s time-to-serve \\(\\mu\\) is 14 seconds and the 0.8 quantile is 21 seconds. Using the normal.select() function, construct a Normal prior distribution to match this belief.\nSuppose Sam also believes that the 0.10 quantile of his prior is equal to 10.5 seconds. Is this statement consistent with the Normal prior chosen in part (a)? If not, how could you adjust the prior to reconcile this statement about the 0.10 quantile?\n\n\nChoosing A Normal Prior\n\nAnother way of choosing a Normal prior for Federer’s mean time-to-serve \\(\\mu\\) is to specify statements about the prior predictive distribution for a future time-to-serve measurement \\(\\tilde Y\\). Using results from Section 8.5.2, if \\(\\mu\\) has a Normal prior with mean \\(\\mu_0\\) and \\(\\sigma_0\\), then the predictive density of \\(\\tilde Y\\) is Normal with mean \\(\\mu_0\\) and standard deviation \\(\\sqrt{\\sigma^2 + \\sigma_0^2}\\), where we are assuming that the sampling standard deviation \\(\\sigma = 4\\) seconds.\n\nSuppose your best guess at \\(\\tilde Y\\) is 15 seconds, and you are 90 percent confident that \\(\\tilde Y\\) is smaller than 25 seconds. Find the Normal prior for \\(\\mu\\) that matches this prior information about the future time-to-serve.\nSuppose instead that you are 90% confident that the future time-to-serve is between 18 and 24 seconds. Find the Normal prior for \\(\\mu\\) that matches this prior belief.\n\n\nBayesian Hypothesis Testing\n\nThe posterior distribution for the mean time-to-serve \\(\\mu\\) for Federer is Normal with mean 17.4 seconds and standard deviation 0.77 seconds.\n\nUsing this posterior, evaluate the plausibility of the statement “Federer’s mean time-to-serve is at least 16.5 seconds.”\nIs it reasonable to say that Federer’s mean time-to-serve falls between 17 and 18 seconds? Explain.\n\n\nBayesian Credible Interval\n\nThe posterior distribution for the mean time-to-serve \\(\\mu\\) for Federer is Normal with mean 17.4 seconds and standard deviation 0.77 seconds.\n\nConstruct a central 98% credible interval for \\(\\mu\\).\nCan you use the credible interval to test the hypothesis “Federer’s mean time-to-serve is 16.5 seconds”? Explain.\n\n\nPosterior Predictive Distribution\n\nWrite an R script to generate \\(S = 1000\\) predictions of a single time-to-serve of Federer based on the posterior predictive distribution using the results given in Equation (8.31) and Equation (8.32).\n\nCompare the exact posterior predictive distribution (Equation (8.30)) with the density estimate of the simulated predictions.\nConstruct a 90% prediction interval for the future time-to-serve.\n\n\nPosterior Predictive Checking\n\nThe posterior predictive distribution can be used to check the suitability of the Normal sampling/Normal prior model for Federer’s time-to-serve data. The function post_pred_check() simulates samples of \\(n = 20\\) from the posterior predictive function, and for each sample, computes a value of the checking function \\(T(\\tilde y)\\).\npost_pred_check <- function(test_function){\n  mu_n <- 17.4\n  sigma_n <- 0.77\n  sigma <- 4\n  n <- 20\n  one_sim <- function(){\n    mu <- rnorm(1, mu_n, sigma_n)\n    test_function(rnorm(n, mu, sigma))\n  }\n  replicate(1000, one_sim())\n}\nThe output of the function is 1000 draws from the posterior predictive distribution of \\(T\\). If the checking function is \\(\\max (y)\\), then one would obtain 1000 draws from the posterior predictive distribution by typing\npost_pred_check(max)\nIf the value of the checking function on the observed time-to-serves \\(T(y)\\) is unusual relative to this posterior predictive distribution of \\(T\\), this would cast doubt on the model. The observed times-to-serve for Federer are displayed in Section 8.3.1. and repeated below.\n15.1 11.8 21.0 22.7 18.6 16.2 11.1 13.2 20.4 19.2 21.2 14.3 18.6 16.8 20.3 19.9 15.0 13.4 19.9 15.3\n\nUse the function post_pred_check() with the checking function \\(T(y) = \\max (y)\\) to check the suitability of the Bayesian model.\nUse the function post_pred_check() with the checking function \\(T(y) = \\textrm{sd}(y)\\) to check the suitability of the Bayesian model.\n\n\nTaxi Cab Fares \n\nSuppose a city manager is interested in learning about the mean fare \\(\\mu\\) for taxi cabs in New York City.\n\nSuppose the manager believes that \\(\\mu\\) is smaller than $8 with probability 0.25, and that \\(\\mu\\) is smaller than $12 with probability 0.75. Find a Normal prior that matches this prior information.\nThe manager collects the fares for twenty fares and observes the values (in dollars): 7.5, 8.5, 9.5, 6.5, 7.0, 6.0, 7.0, 16.0, 8.0, 8.5, 9.5, 13.5, 4.5, 8.5, 7.5, 13.0, 6.5, 9.5, 21.0, 6.5. Assuming these fares are Normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma = 4\\), find the posterior distribution for the mean \\(\\mu\\).\nConstruct a 90% interval estimate for the mean fare \\(\\mu\\).\n\n\nTaxi Cab Fares (continued)\n\nSuppose that a visitor to New York City has little knowledge about the mean taxi cab fare.\n\nConstruct a weakly informative prior for \\(\\mu\\).\nUse the data from Exercise 9 to compute the posterior distribution for the mean fare.\nConstruct a 90% interval estimate for the mean fare and compare your interval with the interval computed in Exercise 9 using an informative prior.\n\n\nTaxi Cab Fares (continued)\n\n\nIn Exercise 9, one finds the posterior distribution for the mean fare \\(\\mu\\). Write an R function to simulate a sample of twenty fares from the posterior predictive distribution.\nLooking at the observed data, one sees an unusually large fare of $21. To see if this fare is unusual for our model, first revise your function in part (a) to simulate the maximum fare of a sample of twenty fares from the posterior predictive distribution. Then repeat this process 1000 times, collecting the maximum fares for 1000 predictive samples.\nConstruct a graph of the maximum fares. Is the fare of $21 large relative to the prediction distribution of maximum fares?\n\nBased on the answer to part (c), what does that say about the suitability of our model?\n\n\nStudent Sleeping Times \n\nHow many hours do college students sleep, on the average? Recently, some introductory students were asked when they went to bed and when they woke the following morning. A following random sample of 14 sleeping times (in hours) were recorded: 9.0, 7.5, 7.0, 8.0, 5.0, 6.5, 8.5, 7.0, 9.0, 7.0, 5.5, 6.0, 8.5, 7.5. Assume that these measurements follow a Normal sampling distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), where we are given that \\(\\sigma = 1.5\\).\n\nSuppose that John believes a priori that the mean amount of sleep \\(\\mu\\) is Normal with mean 8 hours and standard deviation 1 hour. Find the posterior distribution of \\(\\mu\\).\nConstruct a 90% interval estimate for the mean \\(\\mu\\).\nLet \\(y^*\\) denote the sleeping time for a randomly selected student. Find the predictive distribution for \\(y^*\\) and use this to construct a 90% prediction interval.\n\n\nStudent Sleeping Times (continued)\n\nSuppose two other people are interested in learning about the mean sleeping times of college students. Mary’s prior is Normal with mean 8 hours and standard deviation 0.1 – she is pretty confident that the mean sleeping time is close to 8 hours. In contrast, Larry is very uncertain about the location of \\(\\mu\\) and assigns a Normal prior with mean 8 hours and standard deviation 3 hours.\n\nFind the posterior distributions of \\(\\mu\\) using Mary’s prior and using Larry’s prior.\nConstruct 90% interval estimates for \\(\\mu\\) using Mary’s and Larry’s priors.\nCompare the interval estimates with the interval estimates constructed in Exercise 12(b) using Mary’s prior. Is the location of the interval estimate sensitive to the choice of prior? If so, explain the differences.\n\n\nComparing Two Means - IQ Tests on School Children \n\nDo teachers’ expectations impact academic development of children? To find out, researchers gave an IQ test to a group of 12 elementary school children. They randomly picked six children and told teachers that the test predicts them to have high potential for accelerated growth (accelerated group); for the other six students in the group, the researchers told teachers that the test predicts them to have no potential for growth (no growth group). At the end of school year, they gave IQ tests again to all 12 students, and the change in IQ scores of each student is recorded. The following table shows the IQ score change of students in the accelerated group and the no growth group.\n\n\n\nGroup\nIQ score change\n\n\n\n\nAccelerated\n20, 10, 19, 15, 9, 18\n\n\nNo growth\n3, 2, 6, 10, 11, 5\n\n\n\nThe sample means of the accelerated group and the no growth group are respectively \\(\\bar{y}_A = 15.2\\) and \\(\\bar{y}_N = 6.2\\). Consider independent sampling models, where the IQ scores for the accelerated group (no growth group) are assumed Normal with mean \\(\\mu_A\\) (\\(\\mu_N\\)) with known standard deviation \\(\\sigma = 4\\).\n\\[\\begin{eqnarray*}\nY_{A, i} &\\overset{i.i.d.}{\\sim}& \\textrm{Normal}(\\mu_A, 4), \\,\\,\\, \\text{for}\\,\\, i = 1, \\cdots n_A, \\\\\nY_{N, i} &\\overset{i.i.d.}{\\sim}& \\textrm{Normal}(\\mu_N, 4), \\,\\,\\, \\text{for}\\,\\, i = 1, \\cdots n_N,\n\\end{eqnarray*}\\] where \\(n_A = n_N = 6\\).\n\nAssuming independent sampling, write down the likelihood function of the means \\((\\mu_A, \\mu_B)\\).\nAssume that one’s prior beliefs about \\(\\mu_A\\) and \\(\\mu_N\\) are independent, where \\(\\mu_A \\sim \\textrm{Normal}(\\gamma_A, \\tau_A)\\) and \\(\\mu_N \\sim \\textrm{Normal}(\\gamma_N, \\tau_N)\\). Show that the posterior distributions for \\(\\mu_A\\) and \\(\\mu_N\\) are independent Normal and find the mean and standard deviation parameters for each distribution.\n\n\nComparing Two Means - IQ Tests on School Children (continued)\n\nIn Exercise 14, you should have established that the mean IQ score changes \\(\\mu_A\\) and \\(\\mu_N\\) have independent Normal posterior distributions. Assume that one has vague prior beliefs and \\(\\mu_A \\sim \\textrm{Normal}(0, 20)\\) and \\(\\mu_N \\sim \\textrm{Normal}(0, 20)\\).\n\nIs the average improvement for the accelerated group larger than that for the no growth group? Consider the parameter \\(\\delta = \\mu_A - \\mu_N\\) to measure the difference in means. The question now becomes finding the posterior probability of \\(\\delta > 0\\), i.e. \\(p(\\mu_A - \\mu_N > 0 \\mid y_A, y_N)\\), where \\(y_A\\) and \\(y_N\\) are the vectors of recorded IQ score change. [Hint: simulate a vector \\(s_A\\) of posterior samples of \\(\\mu_A\\) and another vector \\(s_N\\) of posterior samples of \\(\\mu_N\\) (make sure to use the same number of samples) and subtract \\(s_N\\) from \\(s_A\\), which gives us a vector of posterior differences between \\(s_N\\) and \\(s_A\\). This vector of posterior differences serves as an approximation to the posterior distribution of \\(\\delta\\).]\nWhat is the probability that a randomly selected child assigned to the accelerated group will have larger improvement than a randomly selected child assigned to the no growth group? Consider \\(\\tilde{Y}_A\\) and \\(\\tilde{Y}_N\\) to be random variables for predicted IQ score change for the accelerated group and the no growth group, respectively. The question now becomes finding the posterior predictive probability of \\(\\tilde{Y}_A > \\tilde{Y}_N\\), i.e. \\(p(\\tilde{Y}_A > \\tilde{Y}_N \\mid y_A, y_N)\\), where \\(y_A\\) and \\(y_N\\) are the vectors of recorded IQ score change, each of length 6. [Hint: Show that the posterior predictive distributions of \\(\\tilde{Y}_A\\) and \\(\\tilde{Y}_N\\) are independent. Simulate predicted IQ score changes from the posterior predictive distributions for the two groups, then simulate the posterior predictive distribution of \\(\\tilde{Y}_A - \\tilde{Y}_N\\) by taking the difference of simulated draws.]\n\n\nComparing Two Means - Prices of Diamonds\n\nWeights of diamonds are measured in carats. The difference between the size of a 0.99 carat diamond and a 1 carat diamond is most likely undetectable to the naked human eye, but the price of a 1 carat diamond tends to be much higher than the price of a 0.99 carat diamond. To find out if it is truly the case, data on point prices (the prices of 0.99 carat diamonds divided by 99, and the prices of 1 carat diamonds divided by 100) of \\(n_{99} = 23\\) of 0.99 carat diamonds and \\(n_{100} = 25\\) of 1 carat diamonds were collected and stored in the files pt99price.csv and pt100price.csv.\n\nExplore the two datasets by making plots and computing summary statistics. What are the findings?\nConsider independent Normal sampling models for these datasets with a fixed and known value of the standard deviation. From your exploratory work, choose a value for the standard deviation.\nChoose appropriate weakly informative prior distributions, and use posterior simulation to answer whether the average point price of the 1 carat diamonds is higher than that of the 0.99 diamonds.\nPerform posterior predictive checks of the Bayesian inferences obtained in part (c).\n\n\nGamma-Poisson Conjugacy Derivation\n\nSection 8.8.3 presents the Bayesian update results for Poisson sampling with the use of the Gamma conjugate prior.\n\nVerify the equation for the likelihood in Equation (8.37). [Hint:\n\n\\[\\begin{eqnarray*}\nf( Y_1 = y_1, ..., Y_n = y_n \\mid \\lambda ) &=& \\prod_{i=1}^{n}f(y_i \\mid \\lambda) \\nonumber \\\\\n                                       &=& \\prod_{i=1}^{n} \\frac{1}{y_i!} \\lambda^{y_i} e^{-\\lambda},\n\\end{eqnarray*}\\] the joint sampling density of \\(n\\) \\(i.i.d.\\) Poisson distributed random variables.]\n\nAssuming that the Poisson parameter \\(\\lambda\\) has a Gamma prior with shape \\(\\alpha\\) and rate \\(\\beta\\), show that the posterior distribution of \\(\\lambda\\) has a Gamma functional form and find the parameters of this Gamma distribution.\n\n\nThe Number of ER Visits: the Prior\n\nSuppose two people, Pedro and Mia, have different prior beliefs about the average number of ER visits during the 10pm - 11pm time period. Pedro’s prior information is matched to a Gamma distribution with parameters \\(\\alpha = 70\\) and \\(\\beta = 10\\), and Mia’s beliefs are matched to a Gamma distribution with \\(\\alpha = 33.3\\) and \\(\\beta = 3.3\\). The two Gamma priors are displayed in Figure 8.12.\n\n\n\n\n\nTwo Gamma priors for the average number of visits to ER during a particular hour in the evening.\n\n\n\n\n\nCompare the priors of Pedro and Mia with respect to average value and spread. Which person believes that there will be more ER visits, on average? Which person is more confident of his/her ``best guess” at the average number of ER visits?\nUsing the qgamma() function, construct 90% interval estimates for \\(\\lambda\\) using Pedro’s prior and Mia’s prior.\nAfter some thought, Pedro believes that his best prior guess at \\(\\lambda\\) is correct, but he is less confident in this guess. Explain how Pedro can adjust the parameters of his Gamma prior to reflect this new prior belief.\nMia also revisits her prior. Her best guess at the average number of ER visits is now 3 larger than her previous best guess, but the degree of confidence in this guess hasn’t changed. Explain how Mia can adjust the parameters of her Gamma prior to reflect this new prior belief.\n\n\nThe Number of ER Visits\n\nA hospital collects the number of patients in the emergency room (ER) admitted between 10 pm and 11 pm for each day of a week. Table 8.8 records the day and the number of ER visits for the given day.\nTable 8.8 Number of ER visits during the period 10 pm to 11 pm for each day for a particular week at a hospital.\n\n\n\nDay\nNumber of ER visits\n\n\n\n\nSunday\n8\n\n\nMonday\n6\n\n\nTuesday\n6\n\n\nWednesday\n9\n\n\nThursday\n8\n\n\nFriday\n9\n\n\nSaturday\n7\n\n\n\nSuppose one assumes Poisson sampling for the counts, and a conjugate Gamma prior with parameters \\(\\alpha = 70\\) and \\(\\beta = 10\\) for the Poisson rate parameter \\(\\lambda\\).\n\nGiven the sample shown in Table \\(\\ref{table:ERvisits}\\), obtain the posterior distribution for \\(\\lambda\\) through the Gamma-Poisson conjugacy. Obtain a 95% posterior credible interval for \\(\\lambda\\).\nSuppose a hospital administrator states that the average number of ER visits during any evening hour does not exceed 6. By computing a posterior probability, evaluate the validity of the administrator’s statement.\nThe hospital is interested in predicting the number of ER visits between 10 pm and 11 pm for another week. Use simulations to generate posterior predictions of the number of ER visits for another week (seven days).\n\n\nTimes Between Traffic Accidents\n\nThe Exponential distribution is often used as a model to describe the time between events, such as traffic accidents. A random variable \\(Y\\) has an Exponential distribution if its pdf is as follows.\n\\[\\begin{equation}\n  f(y \\mid \\lambda) =\\begin{cases}\n    \\lambda \\exp(-\\lambda y), & \\text{if $y \\geq 0$}.\\\\\n    0, & \\text{if $y < 0$}.\n  \\end{cases}\n(\\#eq:exponential)\n\\end{equation}\\] Here, the parameter \\(\\lambda > 0\\), considered as the rate of event occurrences. This is a one-parameter model.\n\nThe Gamma distribution is a conjugate prior distribution for the rate parameter \\(\\lambda\\) in the Exponential data model. Use the prior distribution \\(\\lambda \\sim \\textrm{Gamma}(a, b)\\), and find its posterior distribution \\(\\pi(\\lambda \\mid y_1, \\cdots, y_n)\\), where \\(y_i \\overset{i.i.d.}{\\sim} \\textrm{Exponential}(\\lambda)\\) for \\(i = 1, \\cdots, n\\).\nSuppose 10 times between traffic accidents are collected: 1.5, 15, 60.3, 30.5, 2.8, 56.4, 27, 6.4, 110.7, 25.4 (in minutes). With the posterior distribution derived in part (a), use Monte Carlo approximation to calculate the posterior mean, median, and a middle 95% credible interval for the rate \\(\\lambda\\). [Hint: choose the appropriate R functions from dgamma(), pgamma()\\index{pgamma(), qgamma(), and rgamma().]\nUse Monte Carlo approximation to generate another set of 10 predicted times between events. [Hint: rexp() generates random draws from an Exponential distribution.]\n\n\nModeling Survival Times\n\nThe Weibull distribution is often used as a model for survival times in biomedical, demographic, and engineering analyses. A random variable \\(Y\\) has a Weibull distribution if its pdf is as follows. \\[\\begin{eqnarray}\nf(y \\mid \\alpha, \\lambda) = \\lambda \\alpha y^{\\alpha -1}\n\\exp(-\\lambda y^\\alpha) \\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{for } y > 0.\n(\\#eq:weibull)\n\\end{eqnarray}\\] Here, \\(\\alpha>0\\) and \\(\\lambda>0\\) are parameters of the distribution. For this problem, assume that \\(\\alpha = \\alpha_0\\) is known, but \\(\\lambda\\) is not known, i.e. a simplified case of a one-parameter model. Also assume that software routines for simulating from Weibull distributions are available (e.g. ```rweibull()})\n\nAssuming a prior distribution \\(\\pi(\\lambda \\mid \\alpha  = \\alpha_0) \\propto 1\\), find its posterior \\(\\pi(\\lambda \\mid y_1, \\dots, y_n, \\alpha = \\alpha_0)\\), where \\(y_i \\overset{i.i.d.}{\\sim} \\textrm{Weibull}(\\lambda, \\alpha = \\alpha_0)\\) for \\(i = 1, \\cdots, n\\). Write the name of the distribution and expressions for its parameter values.\nUsing the posterior distribution derived in part (a), explain step-by-step how you would use Monte Carlo simulation to approximate the posterior median survival time, assuming that \\(\\alpha = \\alpha_0\\).\nWhat family of distributions represents the conjugate prior distributions for \\(\\lambda\\), assuming that \\(\\alpha = \\alpha_0\\)."
  },
  {
    "objectID": "mcmc.html#exercises",
    "href": "mcmc.html#exercises",
    "title": "4  Simulation by Markov Chain Monte Carlo",
    "section": "4.8 Exercises",
    "text": "4.8 Exercises\n\nNormal and Cauchy Priors\n\nIn the example in Section 9.1.2, it was assumed that the prior for the average snowfall \\(\\mu\\) was Normal with mean 10 inches and standard deviation 3 inches.\n\nConfirm that the 25th and 75th percentiles of this prior are equal to 8 and 12 inches, respectively.\nShow that under this Normal prior, it is unlikely that the mean \\(\\mu\\) is at least as large as 26.75 inches.\nConfirm that a Cauchy distribution with location 10 inches and scale parameter 2 inches also have 25th and 75th percentiles equal to 8 and 12 inches, respectively.\n\n\nA Random Walk \n\nThe following matrix represents the transition matrix for a random walk on the integers {1, 2, 3, 4, 5}.\n\\[\nP = \\begin{bmatrix}\n.2 &.8& 0& 0& 0 \\\\\n.2 &.2& .6& 0& 0\\\\\n0 &.2& .6& .2& 0\\\\\n0 &0& .6& .2& .2\\\\\n0 &0& 0& .8& .2\\\\\n\\end{bmatrix}\n\\]\n\nSuppose one starts walking at the state value 4. Find the probability of landing at each location after a single step.\nStarting at value 4, find the probability of landing at each location after three steps.\nExplain what is means for this Markov Chain to be irreducible and aperiodic.\n\n\nA Random Walk (continued)\n\nConsider the random walk Markov chain described in Exercise 2.\n\nSuppose one starts at the location 1. Using an R script with the ```sample()} function (see example script Section 9.2.3), simulate 1000 steps of the Markov chain using the probabilities given in the transition matrix. Store the locations of the walk in a vector.\nCompute the relative frequencies of the walker in the five states from the simulation output. From this computation, guess at the value of the stationary distribution vector \\(w\\).\nConfirm that your guess is indeed the stationary distribution by using the matrix computation \\(w\\) %*% \\(P\\).\n\n\nWeird Weather\n\nSuppose a city in Alaska has interesting weather. The four possible weather states are “sunny” (\\(SU\\)), “rainy” (\\(R\\)), “cloudy” (\\(C\\)), and “snow” (\\(SN\\)). If it is sunny one day, it is equally likely to be rainy, cloudy, and snow on the next day. If is currently rainy, then the probabilities of sunny, rain, cloudy, and snow on the next day are respectively 1/2, 1/6, 1/6, and 1/6. The following matrix gives the transitions of weather from one day to the next day.\n\\[\n\\begin{bmatrix}\n& SU & R & C &  SN \\\\\n  SU & 0 & 1/3 & 1/3 & 1/3 \\\\\n  R & 1/2 & 1/6 & 1/6 & 1/6  \\\\\n  C & 0 & 1/4 & 1/2 & 1/4  \\\\\n  SN & 0 & 1/4 & 1/4 & 1/2  \\\\\n\\end{bmatrix}\n\\]\n\nIf the weather is rainy today, find the probability that is rainy two days later.\nStarting with a sunny day, write an R script to simulate 1000 days of weather using this Markov Chain.\nFind the relative frequencies of the four states. Are these values approximately the stationary distribution of the Markov chain?\n\n\nEhrenfest Urn Model\n\nGrinstead and Snell (2006) describe a model used to explain diffusion of gases. One version of this model is described in the setting of two urns that, between them, contains four balls. A state is the number of balls in the first urn. There are five possible states 0, 1, 2, 3, and 4. At each step, one ball is chosen at random and moved from the urn it is located to the other urn. The transition matrix for this Markov chain is shown below:\n\\[\nP = \\begin{bmatrix}\n0 &1 & 0& 0& 0 \\\\\n1/4 & 0 & 3/4 & 0& 0\\\\\n0 & 1/2& 0& 1/2& 0\\\\\n0 &0& 3/4 & 0& 1/4\\\\\n0 &0& 0& 1& 0\\\\\n\\end{bmatrix}\n\\]\n\nStarting at state 1, find the probabilities of each state after two steps.\nStarting at state 1, find the probabilities of each state after three steps.\nExplain why this Markov Chain is not aperiodic.\nDoes a stationary distribution exist for this Markov Chain? Why or why not?\n\n\nMetropolis Sampling in a Random Walk\n\nSuppose the variable \\(X\\) takes on values from 1 to 9 with respective probabilities that are proportional to the values 9, 7, 5, 3, 1, 3, 5, 7, 9. This probability distribution displayed in Figure 9.19 has a “bathtub” shape.\n\n\n\n\n\nBathtub shaped probability distribution.\n\n\n\n\n\nWrite an R function that computes this probability distribution for any value of \\(X\\).\nUsing the Metropolis algorithm described in Section 9.3.1 as programmed in the function random_walk(), simulate 10,000 draws from this probability distribution starting at the value \\(X = 2\\).\nCollect the simulated draws and find the relative frequencies of the values 1 through 9. Compare these approximate probabilities with the exact probabilities.\n\n\nMetropolis Sampling of a Binomial Distribution\n\n\nUsing the Metropolis algorithm described in Section 9.3 as programmed in the function random_walk(), simulate 1000 draws from a Binomial distribution with parameters \\(n = 20\\) and \\(p = 0.3\\).\nCollect the simulated draws and find the relative frequencies of the values 0 through 20. Compare these approximate probabilities with the exact probabilities.\nUsing the simulated values, estimate the mean \\(\\mu\\) and standard deviation \\(\\sigma\\) of the distribution and compare these estimates with the known values of \\(\\mu\\) and \\(\\sigma\\) of a binomial distribution.\n\n\nMetropolis Sampling - Poisson-Gamma Model\n\nSuppose we observe \\(y_1, ..., y_n\\) from a Poisson distribution with mean \\(\\lambda\\), and the parameter \\(\\lambda\\) has a Gamma(\\(a, b\\)) distribution. The posterior density is proportional to \\[\\begin{equation*}\n\\pi(\\lambda \\mid y_1, \\cdots, y_n) \\propto \\left[\\prod_{i = 1}^n \\exp(-\\lambda) \\lambda^{y_i} \\right]\n\\left[ \\lambda^{a-1} \\exp(-b \\lambda) \\right].\n\\end{equation*}\\]\n\nWrite a function to compute the logarithm of the posterior density. Assume that one observes the sample 2, 5, 10, 5, 6, and the prior parameters are \\(a = b = 1\\).\nUse the metropolis() function in Section 9.3.3 to collect 1000 draws from the posterior distribution. Use a starting value of \\(\\lambda = 5\\) and a neighborhood scale value of \\(C = 2\\).\nInspect MCMC diagnostic graphs to assess if the simulated sample approximates the posterior density of \\(\\lambda\\).\n\n\nMetropolis Sampling from a Bimodal Distribution\n\nSuppose we observe a random sample \\(y_1, ..., y_n\\) from a Cauchy distribution with location \\(\\theta\\) and scale parameter 1 with density \\[\\begin{equation}\nf(y_i \\mid \\theta) = \\frac{1}{\\pi  \\left[1 + (y_i - \\theta)^2\\right]}.\n(\\#eq:cauchy)\n\\end{equation}\\] If a Uniform prior is placed on \\(\\theta\\), then the posterior density of \\(\\theta\\) is proportional to \\[\\begin{equation}\n\\pi(\\theta \\mid y_1, \\cdots, y_n) \\propto \\prod_{i = 1}^n \\frac{1}{\\pi  \\left[1 + (y_i - \\theta)^2\\right]}\n(\\#eq:cauchypost)\n\\end{equation}\\] If we observe the values 3, 6, 7, 8, 15, 14, 16, 17, Figure 9.20 displays the bimodal shape of the posterior density.\n\n\n\n\n\nPosterior density of location parameter with Cauchy sampling.\n\n\n\n\n\nWrite a function to compute the logarithm of the posterior density.\nUsing the metropolis() function in Section 9.3.3, collect a simulated sample of 1000 from the posterior distribution. Run the sampler twice, once using a starting value of \\(\\theta = 10\\) and a neighborhood scale value of \\(C = 3\\), and a second time with the same starting value and a scale value of \\(C = 0.2\\).\nBy inspecting MCMC diagnostic graphs, which value of \\(C\\) appears to result in a simulated sample that is a better approximation to the posterior distribution? Explain.\n\n\nGibbs Sampling - Poisson-Gamma Model\n\nSuppose a single observation \\(Y\\) conditional on \\(\\lambda\\) is Poisson with mean \\(\\lambda\\), and \\(\\lambda\\) has a Gamma(\\(a, b\\)) prior with density equal to \\[\\begin{equation*}\n\\pi(\\lambda) = \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b \\lambda).\n\\end{equation*}\\]\n\nWrite down the joint density of \\(Y\\) and \\(\\lambda\\).\nIdentify the conditional distribution \\(Y\\) conditional on \\(\\lambda\\), and the conditional distribution of \\(\\lambda\\) conditional on \\(Y = y\\).\nUse the information from part (b) to construct a Gibbs sampling algorithm to sample from the joint distribution of \\((Y, \\lambda)\\).\nWrite an R function to implement one cycle of Gibbs sampling, and run 1000 iterations of Gibbs sampling for the case where \\(a = 3\\) and \\(b = 3\\).\nBy integration, find the marginal density of \\(Y\\). Compare the exact values of the marginal density with the simulated draws of \\(Y\\) found using Gibbs sampling.\n\n\nGibbs Sampling - Coin Flips\n\nSuppose one observes the outcomes of four fair coin flips \\(W_1, ..., W_4\\) where \\(W_i = 1\\) if the outcome is heads and \\(W_i = 0\\) otherwise. Let \\(X = W_1 + W_2 +W_3\\) denote the number of heads in the first three flips and \\(Y = W_2 + W_3 + W_4\\) is the number of heads in the last three flips. The joint probability of \\(X\\) and \\(Y\\) is given in Table 9.3.\nTable 9.3. Table of number of heads \\(X\\) in the first three flips and number of heads \\(Y\\) in last three flips in four flips of a fair coin.\n\n\n\n\n\n(Y)\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n0\n1/16\n1/16\n0\n0\n\n\n(X)\n1\n1/16\n3/16\n2/16\n0\n\n\n\n2\n0\n2/16\n3/16\n1/16\n\n\n\n3\n0\n0\n1/16\n1/16\n\n\n\nThe joint probability mass function (f(x, y)) of the number of heads in the first three flips (X) and the number of heads in the last three flips (Y) in four tosses of a fair coin.\n\nFind the conditional distribution \\(f(x \\mid Y = 1)\\).\nFind the conditional distribution \\(f(y \\mid X = 2)\\).\nDescribe how Gibbs sampling can be used to simulate from the joint distribution of \\(X\\) and \\(Y\\).\nUsing the gibbs_discrete() function in Section 9.5.1, simulate 1000 iterations of Gibbs sampling using this probability distribution. By tabulating the \\((X, Y)\\) output and computing relative frequencies, confirm that the relative frequencies are good approximations to the actual probabilities.\n\n\nNormal Sampling with Both Parameters Unknown \n\nThe heights in inches of 20 college women were collected, observing the following measurements:\n\n\n\n47\n64\n61\n61\n63\n61\n64\n66\n63\n67\n\n\n63.5\n65\n62\n64\n61\n56\n63\n65\n64\n59\n\n\n\nSuppose one assumes that the Normal mean and precision parameters are independent with \\(\\mu\\) distributed \\(\\textrm{Normal}(62, 1)\\) and \\(\\phi\\) distributed Gamma with parameters \\(a = 1\\) and \\(b = 1\\).\n\nUsing the gibbs_normal() function in Section 9.5.3, collect a sample of 5000 from the joint posterior distribution of \\((\\mu, \\phi)\\).\nFind a 90% interval estimate for the standard deviation \\(\\sigma = 1 / \\sqrt{\\phi}\\).\nSuppose one is interested in estimating the 90th percentile of the height distribution \\(P_{90} = \\mu + 1.645 \\sigma\\). Collect simulated draws from the posterior of \\(P_{90}\\) and construct a density estimate.\n\n\nNormal Sampling with Both Parameters Unknown (continued)\n\nIn Exercise 12, one learned about the mean and precision of the heights by use of a Gibbs sampling algorithm. Use JAGS and the runjags package to collect MCMC draws from this model. Write a JAGS script for this Normal sampling problem and use the run.jags() function. Answer questions from parts (c) and (d) from Exercise 12. (Note that the sample JAGS script in Section 9.7.1 returns samples of \\(\\mu\\) and \\(\\sigma\\).)\n\nNormal Sampling with Both Parameters Unknown (continued)\n\nIf one graphs the height data from Exercise 12, one notes that there is one unusually small height value, 47. One wonders if this minimum height is consistent with the fitted model.\n\nWrite a function to simulate a sample of size 20 from the posterior predictive distribution. You can use either the gibbs_normal() function in Section 9.5.3 or the JAGS sample script in Section 9.7.1 to generate a sample from the posterior distribution of (\\(\\mu, \\phi\\)) or (\\(\\mu, \\sigma\\)). For each sample, compute the minimum value \\(T(\\tilde y)\\).\nRepeat the procedure 1000 times, collecting a sample of the predictive distribution of the minimum observation.\nGraph the predictive distribution. From comparing the observed minimum height with this distribution, what can you conclude about the suitability of the model?\n\n\nComparing Proportions\n\nIn Section 9.7.4, the problem of comparing proportions of high visits to Facebook from male and female students was considered.\n\nUsing the same prior, use JAGS to take a simulated sample of size 5000 from the posterior of \\(p_F\\) and \\(p_M\\). Construct a 90% probability interval estimate for the difference is proportions \\(\\delta = p_W - p_M\\).\nUse the same simulated sample to perform inferences about the ratio of proportions \\(R = p_W / p_M\\). Construct a density estimate of \\(R\\) and construct a 90% probability interval estimate.\n\n\nComparing Poisson Rates\n\nSuppose the number of customers \\(y_j\\) arriving at a bank during a half-hour period in the morning is Poisson with mean \\(\\lambda_M\\), and the number of customers \\(w_j\\) arriving in an afternoon half-hour period is Poisson with mean \\(\\lambda_A\\). Suppose one observes the counts 3, 3, 6, 3, 2, 3, 7, 6 for the morning periods, and the counts 11, 3, 9, 10, 10, 5, 8, 7 for the afternoon periods. Assume that \\(\\lambda_M\\) and \\(\\lambda_A\\) have independent Gamma(1, 1) priors. Use JAGS to obtain a simulated sample from the joint posterior of \\((\\lambda_M, \\lambda_A)\\) and use the output to obtain a 90% posterior interval estimate for the ratio of means \\(R = \\lambda_A / \\lambda_M\\).\n\nNormal Sampling with a Cauchy Prior \n\nIn Section 9.4, we considered the problem of estimating the mean snowfall amount in Buffalo with a Cauchy prior. The sample mean \\(\\bar y\\) is Normal with mean \\(\\mu\\) and standard error \\(se\\) and \\(\\mu\\) is Cauchy with location 10 and scale 2. In our problem, \\(\\bar y= 26.785\\) and \\(se = 3.236\\). Write a JAGS script for this Bayesian model. Use the run.jags() function to simulate 1000 draws of the posterior distribution for \\(\\mu\\). Compute the posterior mean and posterior standard deviation for \\(\\mu\\).\n\nNormal Sampling with a Cauchy Prior (continued)\n\nIn Exercise 17, one used JAGS to simulate values from the posterior of \\(\\mu\\) from a single MCMC chain. Instead use two chains with the different starting values of \\(\\mu = 0\\) and \\(\\mu = 50\\). Run JAGS with two chains and estimate the posterior mean and posterior standard deviation using output from each of the two chains. Based on the output, comment on the sensitivity of the MCMC run with the choice of the starting value.\n\nBivariate Normal\n\nSection 6.7 introduced the Bivariate Normal distribution. Suppose we wish to use Gibbs sampling to simulate from this distribution. In the following assume \\((X, Y)\\) is Bivariate Normal with parameters \\((\\mu_X, \\mu_Y, \\sigma_X, \\sigma_Y, \\rho)\\).\n\nUsing results from Section 6.7, identify the two conditional distributions \\(f(x \\mid y)\\) and \\(f(y \\mid x)\\) and write down a Gibbs sampling algorithm for simulating from the joint distribution of \\((X, Y)\\).\nWrite an R function to simulate a sample from the distribution using Gibbs sampling.\nAssume \\(\\mu_X = 0, \\mu_Y = 0, \\sigma_X = 1, \\sigma_Y = 1, \\rho = 0.5\\) and run the simulation for 1000 iterations. Compare the means, standard deviations, and correlation computed from the simulation with the true values of the parameters.\nRepeat part (c) using the correlation value \\(\\rho= 0.95\\) and again compare the simulation estimates with the true values. Explain why Gibbs sampling does not appear to work as well in this situation.\n\n\nA Normal Mixture Model\n\nConsider a three-component mixture distribution, where the density for \\(x\\) has the form \\[\\begin{equation}\n    f(x) =  0.45 \\times \\phi(x, -3, 1/3) + 0.1 \\times \\phi(x, 0, 1/3) + 0.45 \\times \\phi(x, 3, 1/3),  \\\\\n(\\#eq:normalmix)\n\\end{equation}\\] where \\(\\phi(x, \\mu, \\sigma)\\) is the Normal density with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Consider the following two ways of simulating from this mixture density.\nApproach 1: Monte Carlo: Introduce a “mixture component indicator”, \\(\\delta\\), an unobserved latent variable. The variable \\(z\\) is equal to 1, 2, and 3 with respective probabilities 0.45, 0.1, and 0.45. The density for \\(x\\) conditional on \\(z\\) is normal where \\([x \\mid z = 1] \\sim \\textrm{Normal}(-3, 1/3)\\), \\([x \\mid z = 2] \\sim \\textrm{Normal}(0, 1/3)\\), and \\([x \\mid z = 3] \\sim \\textrm{Normal}(3, 1/3)\\).\nOne simulates \\(x\\) by first simulating a value of \\(z\\) from its discrete distribution and then simulating a value of \\(x\\) from the corresponding conditional distribution. By repeating this method, one obtains a Monte Carlo simulated sample from the exact mixture distribution.\nApproach 2: Gibbs Sampling: An alternative way of simulating from the mixture density is based on Gibbs sampling. Introduce the latent variable \\(z\\) and consider the two conditional distributions \\([x \\mid z]\\) and \\([z \\mid x]\\). The conditional distribution \\([x \\mid z]\\) will be a Normal density where the Normal parameters depend on the value of the latent variable. The conditional distribution \\([z \\mid x]\\) is discrete on the values 1, 2, 3 where the probabilities are proportional to \\(0.45 \\times \\phi(x, -3, 1/3)\\), \\(0.1 \\times \\phi(x, 0, 1/3)\\), \\(0.45 \\times \\phi(x, 3, 1/3)\\) respectively.\nWrite R scripts to use both the Monte Carlo and Gibbs sampling methods to simulate 1000 draws from this mixture density.\n\nA Normal Mixture Model – MCMC Diagnostics\n\nFigure 9.21 displays histograms of simulated draws from the mixture distribution using the Monte Carlo and Gibbs sampling algorithms, and the exact mixture density is overlaid on top. It is clear from the figure that the Gibbs sampling does not appear to perform as well as the Monte Carlo method in simulating from this distribution. Using MCMC diagnostic graphs, explore the Gibbs sampling output. Are there particular features in these diagnostic graphs that would indicate problems in the convergence of the Gibbs sampling algorithm?\n\n\n\n\n\nHistogram of 1000 samples of mean from the Monte Carlo and Gibbs sampling algorithms.\n\n\n\n\n\nChange Point Analysis\n\nThe World Meteorological Association collects data on tropical storms, and scientists want to find out whether the distribution of storms changed over time, and if so, when. Data on the number of storms per year has been collected for \\(n\\) years, and let \\(y_i\\) be the number of storms in year \\(i\\), where \\(i = 1, \\cdots, n\\). Let \\(M\\) be the year in which the distribution of \\(Y\\) changes, where \\(M \\in \\{1, \\cdots, n-1\\}\\).\nA reasonable sampling model for \\(Y\\) is: \\[\\begin{eqnarray*}\ny_i \\mid \\lambda_1, M &\\sim& \\textrm{Poisson}(\\lambda_1), \\,\\,\\, i = 1, \\cdots, M; \\\\\ny_i \\mid \\lambda_2, M &\\sim& \\textrm{Poisson}(\\lambda_2), \\,\\,\\, i = M+1, \\cdots, n.\n\\end{eqnarray*}\\]\nSuppose one gives a Uniform prior for \\(M\\) over integers from \\(1\\) to \\(n-1\\) to represent complete uncertainty about change point: \\[\\begin{equation*}\nM \\mid \\lambda_1, \\lambda_2 \\sim \\textrm{Discrete}(\\frac{1}{n-1}, \\cdots, \\frac{1}{n-1}), \\,\\,\\, M \\in \\{1, \\cdots, n-1\\}.\n\\end{equation*}\\] Equivalently, you can think of the Uniform prior as: \\[\\begin{equation*}\nProb(M = m) = \\frac{1}{n-1}, \\,\\,\\, M \\in \\{1, \\cdots, n-1\\}.\n\\end{equation*}\\]\nRecall that Gamma distributions are conjugate prior distributions for Poisson data model. Suppose one uses independent conjugate Gamma priors for \\(\\lambda_1\\) and \\(\\lambda_2\\): \\[\\begin{eqnarray*}\n\\lambda_1 \\mid a_1, b_1 &\\sim& \\textrm{Gamma}(a_1, b_1), \\\\\n\\lambda_2 \\mid a_2, b_2 &\\sim& \\textrm{Gamma}(a_2, b_2).\n\\end{eqnarray*}\\]\n\nWrite the joint posterior distribution, \\(\\pi(\\lambda_1, \\lambda_2, M \\mid y_1, \\cdots, y_n)\\), up to a constant.\nFind the full conditional posterior distribution for \\(\\lambda_1\\) and \\(\\lambda_2\\). Write the name of the distributions and expressions for their parameter values.\nFind the full conditional posterior distribution for \\(M\\), which should be a discrete distribution over \\(m = 1, \\cdots, n-1\\).\nDescribe how you would design a Gibbs sampling to simulate posterior draws of the set of parameters, \\((\\lambda_1, \\lambda_2, M)\\)."
  }
]