<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.309">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bayesian Modeling - 3&nbsp; Simulation by Markov Chain Monte Carlo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<link href="./hierarchical.html" rel="next">
<link href="./mean.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link id="quarto-text-highlighting-styles" href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation by Markov Chain Monte Carlo</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Modeling</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./proportion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Learning About a Binomial Probability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Modeling Measurement and Count Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mcmc.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation by Markov Chain Monte Carlo</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hierarchical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayesian Hierarchical Modeling</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"> <span class="header-section-number">3.1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#the-bayesian-computation-problem" id="toc-the-bayesian-computation-problem" class="nav-link" data-scroll-target="#the-bayesian-computation-problem"> <span class="header-section-number">3.1.1</span> The Bayesian computation problem</a></li>
  <li><a href="#choosing-a-prior" id="toc-choosing-a-prior" class="nav-link" data-scroll-target="#choosing-a-prior"> <span class="header-section-number">3.1.2</span> Choosing a prior</a></li>
  <li><a href="#the-two-parameter-normal-problem" id="toc-the-two-parameter-normal-problem" class="nav-link" data-scroll-target="#the-two-parameter-normal-problem"> <span class="header-section-number">3.1.3</span> The two-parameter Normal problem</a></li>
  <li><a href="#overview-of-the-chapter" id="toc-overview-of-the-chapter" class="nav-link" data-scroll-target="#overview-of-the-chapter"> <span class="header-section-number">3.1.4</span> Overview of the chapter</a></li>
  </ul></li>
  <li><a href="#markov-chains" id="toc-markov-chains" class="nav-link" data-scroll-target="#markov-chains"> <span class="header-section-number">3.2</span> Markov Chains</a>
  <ul class="collapse">
  <li><a href="#definition" id="toc-definition" class="nav-link" data-scroll-target="#definition"> <span class="header-section-number">3.2.1</span> Definition</a></li>
  <li><a href="#some-properties" id="toc-some-properties" class="nav-link" data-scroll-target="#some-properties"> <span class="header-section-number">3.2.2</span> Some properties</a></li>
  <li><a href="#simulating-a-markov-chain" id="toc-simulating-a-markov-chain" class="nav-link" data-scroll-target="#simulating-a-markov-chain"> <span class="header-section-number">3.2.3</span> Simulating a Markov chain</a></li>
  </ul></li>
  <li><a href="#the-metropolis-algorithm" id="toc-the-metropolis-algorithm" class="nav-link" data-scroll-target="#the-metropolis-algorithm"> <span class="header-section-number">3.3</span> The Metropolis Algorithm</a>
  <ul class="collapse">
  <li><a href="#example-walking-on-a-number-line" id="toc-example-walking-on-a-number-line" class="nav-link" data-scroll-target="#example-walking-on-a-number-line"> <span class="header-section-number">3.3.1</span> Example: Walking on a number line</a></li>
  <li><a href="#the-general-algorithm" id="toc-the-general-algorithm" class="nav-link" data-scroll-target="#the-general-algorithm"> <span class="header-section-number">3.3.2</span> The general algorithm</a></li>
  <li><a href="#a-general-function-for-the-metropolis-algorithm" id="toc-a-general-function-for-the-metropolis-algorithm" class="nav-link" data-scroll-target="#a-general-function-for-the-metropolis-algorithm"> <span class="header-section-number">3.3.3</span> A general function for the Metropolis algorithm</a></li>
  </ul></li>
  <li><a href="#example-cauchy-normal-problem" id="toc-example-cauchy-normal-problem" class="nav-link" data-scroll-target="#example-cauchy-normal-problem"> <span class="header-section-number">3.4</span> Example: Cauchy-Normal problem</a>
  <ul class="collapse">
  <li><a href="#choice-of-starting-value-and-proposal-region" id="toc-choice-of-starting-value-and-proposal-region" class="nav-link" data-scroll-target="#choice-of-starting-value-and-proposal-region"> <span class="header-section-number">3.4.1</span> Choice of starting value and proposal region</a></li>
  <li><a href="#collecting-the-simulated-draws" id="toc-collecting-the-simulated-draws" class="nav-link" data-scroll-target="#collecting-the-simulated-draws"> <span class="header-section-number">3.4.2</span> Collecting the simulated draws</a></li>
  </ul></li>
  <li><a href="#gibbs-sampling" id="toc-gibbs-sampling" class="nav-link" data-scroll-target="#gibbs-sampling"> <span class="header-section-number">3.5</span> Gibbs Sampling</a>
  <ul class="collapse">
  <li><a href="#bivariate-discrete-distribution" id="toc-bivariate-discrete-distribution" class="nav-link" data-scroll-target="#bivariate-discrete-distribution"> <span class="header-section-number">3.5.1</span> Bivariate discrete distribution}</a></li>
  <li><a href="#beta-binomial-sampling" id="toc-beta-binomial-sampling" class="nav-link" data-scroll-target="#beta-binomial-sampling"> <span class="header-section-number">3.5.2</span> Beta-binomial sampling</a></li>
  <li><a href="#normal-sampling-both-parameters-unknown" id="toc-normal-sampling-both-parameters-unknown" class="nav-link" data-scroll-target="#normal-sampling-both-parameters-unknown"> <span class="header-section-number">3.5.3</span> Normal sampling – both parameters unknown</a></li>
  </ul></li>
  <li><a href="#mcmc-inputs-and-diagnostics" id="toc-mcmc-inputs-and-diagnostics" class="nav-link" data-scroll-target="#mcmc-inputs-and-diagnostics"> <span class="header-section-number">3.6</span> MCMC Inputs and Diagnostics</a>
  <ul class="collapse">
  <li><a href="#burn-in-starting-values-and-multiple-chains" id="toc-burn-in-starting-values-and-multiple-chains" class="nav-link" data-scroll-target="#burn-in-starting-values-and-multiple-chains"> <span class="header-section-number">3.6.1</span> Burn-in, starting values, and multiple chains</a></li>
  <li><a href="#diagnostics" id="toc-diagnostics" class="nav-link" data-scroll-target="#diagnostics"> <span class="header-section-number">3.6.2</span> Diagnostics</a></li>
  <li><a href="#graphs-and-summaries" id="toc-graphs-and-summaries" class="nav-link" data-scroll-target="#graphs-and-summaries"> <span class="header-section-number">3.6.3</span> Graphs and summaries</a></li>
  </ul></li>
  <li><a href="#using-jags" id="toc-using-jags" class="nav-link" data-scroll-target="#using-jags"> <span class="header-section-number">3.7</span> Using JAGS</a>
  <ul class="collapse">
  <li><a href="#normal-sampling-model" id="toc-normal-sampling-model" class="nav-link" data-scroll-target="#normal-sampling-model"> <span class="header-section-number">3.7.1</span> Normal sampling model</a></li>
  <li><a href="#multiple-chains" id="toc-multiple-chains" class="nav-link" data-scroll-target="#multiple-chains"> <span class="header-section-number">3.7.2</span> Multiple chains</a></li>
  <li><a href="#posterior-predictive-checking" id="toc-posterior-predictive-checking" class="nav-link" data-scroll-target="#posterior-predictive-checking"> <span class="header-section-number">3.7.3</span> Posterior predictive checking</a></li>
  <li><a href="#comparing-two-proportions" id="toc-comparing-two-proportions" class="nav-link" data-scroll-target="#comparing-two-proportions"> <span class="header-section-number">3.7.4</span> Comparing two proportions</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation by Markov Chain Monte Carlo</span></h1>
</div>





<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="introduction" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">3.1</span> Introduction</h2>
<p></p>
<section id="the-bayesian-computation-problem" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="the-bayesian-computation-problem"><span class="header-section-number">3.1.1</span> The Bayesian computation problem</h3>
<p></p>
<p>The Bayesian models in Chapters 7 and 8 describe the application of conjugate priors where the prior and posterior belong to the same family of distributions. In these cases, the posterior distribution has a convenient functional form such as a Beta density or Normal density, and the posterior distributions are easy to summarize. For example, if the posterior density has a Normal form, one uses the R functions <code>pnorm()</code> and <code>qnorm()</code> to compute posterior probabilities and quantiles.</p>
<p>In a general Bayesian problem, the data <span class="math inline">\(Y\)</span> comes from a sampling density <span class="math inline">\(f(y \mid \theta)\)</span> and the parameter <span class="math inline">\(\theta\)</span> is assigned a prior density <span class="math inline">\(\pi(\theta)\)</span>. After <span class="math inline">\(Y = y\)</span> has been observed, the likelihood function is equal to <span class="math inline">\(L(\theta) = f(y \mid \theta)\)</span> and the posterior density is written as <span class="math display">\[\begin{equation}
\pi(\theta \mid y) = \frac{\pi(\theta) L(\theta)}
{\int \pi(\theta) L(\theta) d\theta}.
\end{equation}\]</span> If the prior and likelihood function do not combine in a helpful way, the normalizing constant <span class="math inline">\(\int \pi(\theta) L(\theta) d\theta\)</span> can not be evaluated analytically. In addition, summaries of the posterior distribution are expressed as ratios of integrals. For example, the posterior mean of <span class="math inline">\(\theta\)</span> is given by <span class="math display">\[\begin{equation}
E(\theta \mid y) = \frac{\int \theta \pi(\theta) L(\theta) d\theta}
{\int \pi(\theta) L(\theta) d\theta}.
\end{equation}\]</span> Computation of the posterior mean requires the evaluation of two integrals, each not expressible in closed-form.</p>
<p>The following sections illustrate this general problem where integrals of the product of the likelihood and prior can not be evaluated analytically and so there are challenges in summarizing the posterior distribution.</p>
</section>
<section id="choosing-a-prior" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="choosing-a-prior"><span class="header-section-number">3.1.2</span> Choosing a prior</h3>
<p></p>
<p>Suppose you are planning to move to Buffalo, New York. You currently live on the west coast of the United States where the weather is warm and you are wondering about the snowfall you will encounter in Buffalo in the following winter season.</p>
<p>Suppose you focus on the quantity <span class="math inline">\(\mu\)</span>, the average snowfall during the month of January. After some reflection, you are 50 percent confident that <span class="math inline">\(\mu\)</span> falls between 8 and 12 inches. That is, the 25th percentile of your prior for <span class="math inline">\(\mu\)</span> is 8 inches and the 75th percentile is 12 inches.</p>
<p><strong>A Normal prior</strong></p>
<p>Once you have figured out your prior information, you construct a prior density for <span class="math inline">\(\mu\)</span> that matches this information. In one of the end-of-chapter exercises, you can confirm that one possible density matching this information is a Normal density with mean 10 and standard deviation 3.</p>
<p>We collect data for the last 20 seasons in January. Assume that these observations of January snowfall are Normally distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. For simplicity we assume that the sampling standard deviation <span class="math inline">\(\sigma\)</span> is equal to the observed standard deviation <span class="math inline">\(s\)</span>. The observed sample mean <span class="math inline">\(\bar y\)</span> and corresponding standard error are given by <span class="math inline">\(\bar y = 26.785\)</span> and <span class="math inline">\(se = s / \sqrt{n} = 3.236\)</span>.</p>
<p>With this Normal prior and Normal sampling, results from Chapter 8 are applied to find the posterior distribution of <span class="math inline">\(\mu\)</span>.<br>
The <code>normal_update()</code> function is used to find the mean and standard deviation of the Normal posterior distribution.</p>
<pre><code>(post1 &lt;- normal_update(c(10, 3), c(ybar, se)))
[1] 17.75676  2.20020</code></pre>
<p>In Figure 9.1 the prior, likelihood, and posterior are displayed on the same graph. Initially you believed that <span class="math inline">\(\mu\)</span> was close to 10 inches, the data says that the mean is in the neighborhood of 26.75 inches, and the posterior is a compromise, where <span class="math inline">\(\mu\)</span> is in an interval about 17.75 inches.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/triplot.png" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Prior, likelihood, and posterior of a Normal mean with a Normal prior.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><strong>An alternative prior</strong></p>
<p>Looking at Figure 9.1, there is some concern about this particular Bayesian analysis. Since the main probability contents of the prior and likelihood functions have little overlap, there is serious conflict between the information in your prior and the information from the data.</p>
<p>Since we have a prior-data conflict, it would make sense to revisit our choice for a prior density on <span class="math inline">\(\mu\)</span>. Remember you specified the quartiles for <span class="math inline">\(\mu\)</span> to be 8 and 12 inches. Another symmetric density that matches this information is a Cauchy density with location 10 inches and scale parameter 2 inches. The reader can confirm that the quantiles of a Cauchy(10, 2) do match your prior information. [Hint: use the <code>qcauchy()</code> R command.]</p>
<p>In Figure 9.2 we compare the Normal and Cauchy priors graphically. Remember these two densities have the same quartiles at 8 and 12 inches. But the two priors have different shapes – the Cauchy prior is more peaked near the median value 10 and has tails that decrease to zero at a slower rate than the Normal. In other words, the Cauchy curve has flatter tails than the Normal curve.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/twopriors.png" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Two priors for representing prior opinion about a Normal mean.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>With the use of a <span class="math inline">\(\textrm{Cauchy}(10, 2)\)</span> prior and the same Normal likelihood, the posterior density of <span class="math inline">\(\mu\)</span> is</p>
<p><span class="math display">\[\begin{equation}
\pi(\mu \mid y) \propto  \pi(\mu)L(\mu) \propto  
\frac{1}{1 + \left(\frac{\mu - 10}{2}\right)^2} \times \exp\left\{-\frac{n}{2 \sigma^2}(\bar y - \mu)^2\right\}.
\end{equation}\]</span></p>
<p>In contrast with a Normal prior, one can not algebraically simplify this likelihood times prior product to obtain a “nice” functional expression for the posterior density in terms of the mean <span class="math inline">\(\mu\)</span>. That raises the question – how does one implement a Bayesian analysis when one can not easily express the posterior density in a convenient functional form?</p>
</section>
<section id="the-two-parameter-normal-problem" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="the-two-parameter-normal-problem"><span class="header-section-number">3.1.3</span> The two-parameter Normal problem</h3>
<p></p>
<p>In the problem in learning about a Normal mean <span class="math inline">\(\mu\)</span> in Chapter 8, it was assumed that the sampling standard deviation <span class="math inline">\(\sigma\)</span> was known. This is unrealistic – in most settings, if one is uncertain about the mean of the population, then likely the population standard deviation will also be unknown. From a Bayesian perspective, since we have two unknown parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, this situation presents new challenges. One needs to construct a joint prior <span class="math inline">\(\pi(\mu, \sigma)\)</span> for the two parameters – up to this point, we have only discussed constructing a prior distribution for a single parameter. Also, although one can compute the posterior density by the usual ``prior times likelihood” recipe, it may be difficult to get nice analytic answers with this posterior to obtain particular inferences of interest.</p>
</section>
<section id="overview-of-the-chapter" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="overview-of-the-chapter"><span class="header-section-number">3.1.4</span> Overview of the chapter</h3>
<p></p>
<p>In Chapters 7 and 8, we illustrated the use of simulation to summarize posterior distributions of a specific functional form such as the Beta and Normal. In this chapter, we introduce a general class of algorithms, collectively called Markov chain Monte Carlo (MCMC), that can be used to simulate the posterior from general Bayesian models. These algorithms are based on a general probability model called a Markov chain and Section 9.2 describes this probability model for situations where the possible models are finite. Section 9.3 introduces the Metropolis sampler, a general algorithm for simulating from an arbitrary posterior distribution. Section 9.4 describes the implementation of this simulation algorithm for the Normal sampling problem with a Cauchy prior. Section 9.5 introduces another MCMC simulation algorithm, Gibbs sampling, that is well-suited for simulation from posterior distributions of many parameters. One issue in the implementation of these MCMC algorithms is that the simulation draws represent an approximate sample from the posterior distribution. Section 9.6 describes some common diagnostic methods for seeing if the simulated sample is a suitable exploration of the posterior distribution. Finally in Section 9.7, we describe the use of a general-purpose software program Just Another Gibbs Sampler (JAGS) and R interface for implementing these MCMC algorithms.</p>
</section>
</section>
<section id="markov-chains" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="markov-chains"><span class="header-section-number">3.2</span> Markov Chains</h2>
<p></p>
<section id="definition" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="definition"><span class="header-section-number">3.2.1</span> Definition</h3>
<p></p>
<p>Since our simulation algorithms are based on Markov chains, we begin by defining this class of probability models in the situation where the possible outcomes are finite. Suppose a person takes a random walk on a number line on the values 1, 2, 3, 4, 5, 6. If the person is currently at an interior value (2, 3, 4, or 5), in the next second she is equally likely to remain at that number or move to an adjacent number. If she does move, she is equally likely to move left or right. If the person is currently at one of the end values (1 or 6), in the next second she is equally likely to stay still or move to the adjacent location.</p>
<p>This is a simple example of a discrete Markov chain. A Markov chain describes probabilistic movement between a number of states. Here there are six possible states, 1 through 6, corresponding to the possible locations of the walker. Given that the person is at a current location, she moves to other locations with specified probabilities. The probability that she moves to another location depends only on her current location and not on previous locations visited. We describe movement between states in terms of transition probabilities – they describe the likelihoods of moving between all possible states in a single step in a Markov chain. We summarize the transition probabilities by means of a transition matrix <span class="math inline">\(P\)</span>: <span class="math display">\[
P = \begin{bmatrix}
.50 &amp;.50&amp; 0&amp; 0&amp; 0&amp; 0 \\
.25 &amp;.50&amp; .25&amp; 0&amp; 0&amp; 0\\
0 &amp;.25&amp; .50&amp; .25&amp; 0&amp; 0\\
0 &amp;0&amp; .25&amp; .50&amp; .25&amp; 0\\
0 &amp;0&amp; 0&amp; .25&amp; .50&amp; .25\\
0 &amp;0&amp; 0&amp; 0&amp; .50&amp; .50\\
\end{bmatrix}
\]</span> The first row in <span class="math inline">\(P\)</span> gives the probabilities of moving to all states 1 through 6 in a single step from location 1, the second row gives the transition probabilities in a single step from location 2, and so on.</p>
<p>There are several important properties of this particular Markov chain. It is possible to go from every state to every state in one or more steps – a Markov chain with this property is said to be <strong>irreducible</strong>. Given that the person is in a particular state, if the person can only return to this state at regular intervals, then the Markov chain is said to be <strong>periodic</strong>. This example is aperiodic since the walker cannot return to the current state at regular intervals.</p>
</section>
<section id="some-properties" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="some-properties"><span class="header-section-number">3.2.2</span> Some properties</h3>
<p></p>
<p>We represent one’s current location as a probability row vector of the form <span class="math display">\[\begin{equation*}
p = (p_1, p_2, p_3, p_4, p_5, p_6),
\end{equation*}\]</span> where <span class="math inline">\(p_i\)</span> represents the probability that the person is currently in state <span class="math inline">\(i\)</span>. If <span class="math inline">\(p^{(j)}\)</span> represents the location of the traveler at step <span class="math inline">\(j\)</span>, then the location of the traveler at the <span class="math inline">\(j + 1\)</span> step is given by the matrix product <span class="math display">\[\begin{equation*}
p^{(j+1)} = p^{(j)} P.
\end{equation*}\]</span> Moreover, if <span class="math inline">\(p^{(j)}\)</span> represents the location at step <span class="math inline">\(j\)</span>, then the location of the traveler after <span class="math inline">\(m\)</span> additional steps, <span class="math inline">\(p^{(j+m)}\)</span>, is given by the matrix product <span class="math display">\[\begin{equation*}
p^{(j+m)} = p^{(j)} P^m,
\end{equation*}\]</span> where <span class="math inline">\(P^m\)</span> indicates the matrix multiplication <span class="math inline">\(P \times P \times ... \times P\)</span> (the matrix <span class="math inline">\(P\)</span> multiplied by itself <span class="math inline">\(m\)</span> times).</p>
<p>To illustrate for our example using R, suppose that the person begins at state 3 that is represented in R by the vector <code>p</code> with a 1 in the third entry:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We also define the transition matrix by use of the <code>matrix()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(.<span class="dv">5</span>, .<span class="dv">5</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>              .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">25</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>              <span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">25</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>              <span class="dv">0</span>, <span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">25</span>, <span class="dv">0</span>,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>              <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">25</span>,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>              <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, .<span class="dv">5</span>, .<span class="dv">5</span>),</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">nrow=</span><span class="dv">6</span>, <span class="at">ncol=</span><span class="dv">6</span>, <span class="at">byrow=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If one multiplies this vector by the matrix ```P, one obtains the probabilities of being in all six states after one move.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(p <span class="sc">%*%</span> P, <span class="at">digits =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0 0.25  0.5 0.25    0    0</code></pre>
</div>
</div>
<p>After one move (starting at state 3), our walker will be at states 2, 3, and 4 with respective probabilities 0.25, 0.5, and 0.25. If one multiplies <code>p</code> by the matrix <code>P</code> four times, one obtains the probabilities of being in the different states after four moves.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(p <span class="sc">%*%</span> P <span class="sc">%*%</span> P <span class="sc">%*%</span> P <span class="sc">%*%</span> P, <span class="at">digits =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        [,1] [,2]    [,3]    [,4]    [,5]    [,6]
[1,] 0.10938 0.25 0.27734 0.21875 0.11328 0.03125</code></pre>
</div>
</div>
<p>Starting from state 3, this particular person is most likely will be in states 2, 3, and 4 after four moves.</p>
<p>For an irreducible, aperiodic Markov chain, there is a limiting behavior of the matrix power <span class="math inline">\(P^m\)</span> as <span class="math inline">\(m\)</span> approaches infinity. Specifically, this limit is equal to <span class="math display">\[\begin{equation}
W = \lim_{m \rightarrow \infty} P^m,
\end{equation}\]</span> where <span class="math inline">\(W\)</span> has common rows equal to <span class="math inline">\(w\)</span>. The implication of this result is that, as one takes an infinite number of moves, the probability of landing at a particular state does not depend on the initial starting state.</p>
<p>One can demonstrate this result empirically for our example. Using a loop, we take the transition matrix <span class="math inline">\(P\)</span> to the 100th power by repeatedly multiplying the transition matrix by itself. From this calculation below, note that the rows of the matrix ```Pm} appear to be approaching a constant vector. Specifically, it appears the constant vector <span class="math inline">\(w\)</span> is equal to (0.1, 0.2, 0.2, 0.2, 0.2, 0.1).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>Pm <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">6</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  Pm <span class="ot">&lt;-</span> Pm <span class="sc">%*%</span> P</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(Pm, <span class="at">digits =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         [,1]    [,2]    [,3]    [,4]    [,5]     [,6]
[1,] 0.100009 0.20001 0.20001 0.19999 0.19999 0.099991
[2,] 0.100007 0.20001 0.20000 0.20000 0.19999 0.099993
[3,] 0.100003 0.20000 0.20000 0.20000 0.20000 0.099997
[4,] 0.099997 0.20000 0.20000 0.20000 0.20000 0.100003
[5,] 0.099993 0.19999 0.20000 0.20000 0.20001 0.100007
[6,] 0.099991 0.19999 0.19999 0.20001 0.20001 0.100009</code></pre>
</div>
</div>
<p>From this result about the limiting behavior of the matrix power <span class="math inline">\(P^m\)</span>, one can derive a rule for determining this constant vector. Suppose we can find a probability vector <span class="math inline">\(w\)</span> such that <span class="math inline">\(wP = w\)</span>. This vector <span class="math inline">\(w\)</span> is said to be the <strong>stationary distribution</strong>. If a Markov chain is irreducible and aperiodic, then it has a unique stationary distribution. Moreover, as illustrated above, the limiting distribution of this Markov chain, as the number of steps approaches infinity, will be equal to this stationary distribution.</p>
</section>
<section id="simulating-a-markov-chain" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="simulating-a-markov-chain"><span class="header-section-number">3.2.3</span> Simulating a Markov chain</h3>
<p></p>
<p>Another method for demonstrating the existence of the stationary distribution of our Markov chain by running a simulation experiment. We start our random walk at a particular state, say location 3, and then simulate many steps of the Markov chain using the transition matrix <span class="math inline">\(P\)</span>. The relative frequencies of our traveler in the six locations after many steps will eventually approach the stationary distribution <span class="math inline">\(w\)</span>.</p>
<p>In R we have already defined the transition matrix <code>P</code>. To begin the simulation exercise, we set up a storage vector <code>s</code> for the locations of our traveler in the random walk. We indicate that the starting location for our traveler is state 3 and perform a loop to simulate 10,000 draws from the Markov chain. We use the <code>sample()</code> function to simulate one step – the arguments to this function indicate that we are sampling a single value from the set {1, 2, 3, 4, 5, 6} with probabilities given by the <span class="math inline">\(s_j^1\)</span> row of the transition matrix <span class="math inline">\(P\)</span>, where <span class="math inline">\(s_j^1\)</span> is the current location of our traveler.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">"numeric"</span>, <span class="dv">10000</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>s[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">10000</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>s[j] <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">size=</span><span class="dv">1</span>, <span class="at">prob=</span>P[s[j <span class="sc">-</span> <span class="dv">1</span>], ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Suppose that we record the relative frequencies of each of the outcomes 1, 2, …, 6 after each iteration of the simulation. Figure 9.3 graphs the relative frequencies of each of the outcomes as a function of the iteration number.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/markovchainrun.png" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Relative frequencies of the states 1 through 6 as a function of the number of iterations for Markov chain simulation. As the number of iterations increases, the relative frequencies appear to approach the probabilities in the stationary distribution <span class="math inline">\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1)\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>It appears from Figure 9.3 that the relative frequencies of the states are converging to the stationary distribution <span class="math inline">\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1).\)</span> One confirms that this specific vector <span class="math inline">\(w\)</span> is indeed the stationary distribution of this chain by multiplying <span class="math inline">\(w\)</span> by the transition matrix <span class="math inline">\(P\)</span> and noticing that the product is equal to <span class="math inline">\(w\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(.<span class="dv">1</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">1</span>), <span class="at">nrow=</span><span class="dv">1</span>, <span class="at">ncol=</span><span class="dv">6</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a> w <span class="sc">%*%</span> P</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]  0.1  0.2  0.2  0.2  0.2  0.1</code></pre>
</div>
</div>
</section>
</section>
<section id="the-metropolis-algorithm" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="the-metropolis-algorithm"><span class="header-section-number">3.3</span> The Metropolis Algorithm</h2>
<p></p>
<section id="example-walking-on-a-number-line" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="example-walking-on-a-number-line"><span class="header-section-number">3.3.1</span> Example: Walking on a number line</h3>
<p></p>
<p>Markov chains can be used to sample from an arbitrary probability distribution. To introduce a general Markov chain sampling algorithm, we illustrate sampling from a discrete distribution. Suppose one defines a discrete probability distribution on the integers 1, …, <span class="math inline">\(K\)</span>.</p>
<p>As an example, we write a short function <code>pd()</code> in R taking on the values 1, …, 8 with probabilities proportional to the values 5, 10, 4, 4, 20, 20, 12, and 5. Note that these probabilities don’t sum to one, but we will shortly see that only the relative sizes of these values are relevant in this algorithm. A line graph of this probability distribution is displayed in Figure 9.4.</p>
<pre><code>pd &lt;- function(x){
  values &lt;- c(5, 10, 4, 4, 20, 20, 12, 5)
  ifelse(x %in% 1:length(values), values[x], 0)
}
prob_dist &lt;- data.frame(x = 1:8, 
                        prob = pd(1:8))</code></pre>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/mcmc1.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">A discrete probability distribution on the values 1, …, 8.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>To simulate from this probability distribution, we will take a simple random walk described as follows.</p>
<ol type="1">
<li><p>We start at any possible location of our random variable from 1 to <span class="math inline">\(K = 8\)</span>.</p></li>
<li><p>To decide where to visit next, a fair coin is flipped. If the coin lands heads, we think about visiting the location one value to the left, and if coin lands tails, we consider visiting the location one value to right. We call this location the “candidate” location.</p></li>
<li><p>We compute <span class="math display">\[\begin{equation}
R = \frac{pd(candidate)}{pd(current)},
\end{equation}\]</span> the ratio of the probabilities at the candidate and current locations.</p></li>
<li><p>We spin a continuous spinner that lands anywhere from 0 to 1 – call the random spin <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> is smaller than <span class="math inline">\(R\)</span>, we move to the candidate location, and otherwise we remain at the current location.</p></li>
</ol>
<p>Steps 1 through 4 define an irreducible, aperiodic Markov chain on the state values {1, 2, …, 8} where Step 1 gives the starting location and the transition matrix <span class="math inline">\(P\)</span> is defined by Steps 2 through 4. One way of ``discovering” the discrete probability distribution <span class="math inline">\(pd\)</span> is by starting at any location and walking through the distribution many times repeating Steps 2, 3, and 4 (propose a candidate location, compute the ratio, and decide whether to visit the candidate location). If this process is repeated for a large number of steps, the distribution of our actual visits should approximate the probability distribution <span class="math inline">\(pd\)</span>.</p>
<p>A R function <code>random_walk()</code> is written implementing this random walk algorithm. There are three inputs to this function, the probability distribution <code>pd</code>, the starting location <code>start</code> and the number of steps of the algorithm <code>s</code>.</p>
<pre><code>random_walk &lt;- function(pd, start, num_steps){
  y &lt;- rep(0, num_steps)
  current &lt;- start
  for (j in 1:num_steps){
    candidate &lt;- current + sample(c(-1, 1), 1)
    prob &lt;- pd(candidate) / pd(current)
    if (runif(1) &lt; prob) current &lt;- candidate
    y[j] &lt;- current
  }
  return(y)
}</code></pre>
<p>We have already defined the probability distribution by use of the function <code>pd()</code>. Below, we implement the random walk algorithm by inputting this probability function, starting at the value <span class="math inline">\(X = 4\)</span> and running the algorithm for <span class="math inline">\(s\)</span> = 10,000 iterations.</p>
<pre><code>out &lt;- random_walk(pd, 4, 10000)
data.frame(out) %&gt;% group_by(out) %&gt;% 
  summarize(N = n(), Prob = N / 10000) -&gt; S</code></pre>
<p>In Figure 9.5 a histogram of the simulated values from the random walk is compared with the actual probability distribution. Note that the collection of simulated draws appears to be a close match to the true probabilities.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/mcmc2.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Histogram of simulated draws from the random walk compared with the actual probabilities of the distribution.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-general-algorithm" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="the-general-algorithm"><span class="header-section-number">3.3.2</span> The general algorithm</h3>
<p></p>
<p>A popular way of simulating from a general continuous posterior distribution is by using a generalization of the discrete Markov chain setup described in the random walk example in the previous section. The Markov chain Monte Carlo sampling strategy sets up an irreducible, aperiodic Markov chain for which the stationary distribution equals the posterior distribution of interest. This method, called the Metropolis algorithm, is applicable to a wide range of Bayesian inference problems.</p>
<p>Here the Metropolis algorithm is presented and illustrated. This algorithm is a special case of the Metropolis-Hastings algorithm, where the proposal distribution is symmetric (e.g.&nbsp;Uniform or Normal).</p>
<p>Suppose the posterior density is written as <span class="math display">\[\begin{equation*}
\pi_n(\theta) \propto  \pi(\theta) L(\theta),
\end{equation*}\]</span> where <span class="math inline">\(\pi(\theta)\)</span> is the prior and <span class="math inline">\(L(\theta)\)</span> is the likelihood function. In this algorithm, it is not necessary to compute the normalizing constant – only the product of likelihood and prior is needed.</p>
<ol type="1">
<li><p>(START) As in the random walk algorithm, we begin by selecting any <span class="math inline">\(\theta\)</span> value where the posterior density is positive – the value we select <span class="math inline">\(\theta^{(0)}\)</span> is the starting value.</p></li>
<li><p>(PROPOSE) Given the current simulated value <span class="math inline">\(\theta^{(j)}\)</span> we propose a new value <span class="math inline">\(\theta^P\)</span> which is selected at random in the interval (<span class="math inline">\(\theta^{(j)} - C, \theta^{(j)} + C)\)</span> where <span class="math inline">\(C\)</span> is a preselected constant.</p></li>
<li><p>(ACCEPTANCE PROBABILITY) One computes the ratio <span class="math inline">\(R\)</span> of the posterior density at the proposed value and the current value: <span class="math display">\[\begin{equation}
R = \frac{\pi_n(\theta^{P})}{\pi_n(\theta^{(j)})}.
\end{equation}\]</span> The acceptance probability is the minimum of <span class="math inline">\(R\)</span> and 1: <span class="math display">\[\begin{equation}
PROB = \min\{R, 1\}.
\end{equation}\]</span></p></li>
<li><p>(MOVE OR STAY?) One simulates a Uniform random variable <span class="math inline">\(U\)</span>. If <span class="math inline">\(U\)</span> is smaller than the acceptance probability <span class="math inline">\(PROB\)</span>, one moves to the proposed value <span class="math inline">\(\theta^P\)</span>; otherwise one stays at the current value <span class="math inline">\(\theta^{(j)}\)</span>. In other words, the next simulated draw <span class="math inline">\(\theta^{(j+1)}\)</span> <span class="math display">\[\begin{equation}
\theta^{(j+1)} =
\begin{cases}
  \theta^{p} &amp; \mbox{if} \, \, U &lt; PROB, \\
  \theta^{(j)} &amp; \mbox{elsewhere}.
\end{cases}
\end{equation}\]</span></p></li>
<li><p>(CONTINUE) One continues by returning to Step 2 – propose a new simulated value, compute an acceptance probability, decide to move to the proposed value or stay, and so on.</p></li>
</ol>
<p>Figure 9.6 illustrates how the Metropolis algorithm works. The bell-shaped curve is the posterior density of interest. In the top-left panel, the solid dot represents the current simulated draw and the black bar represents the proposal region. One simulates the proposed value represented by the “P” symbol. One computes the probability of accepting this proposed value – in this case, this probability is 0.02. By simulating a Uniform draw, one decides not to accept this proposal and the new simulated draw is the current value shown in the top-right panel. A different scenario is shown in the bottom panels. One proposes a value corresponding to a higher posterior density value. The probability of accepting this proposal is 1 and the bottom left graph shows that the new simulated draw is the proposed value.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/showmetrop.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Illustration of the Metropolis algorithm. The left graphs show the proposal region and two possible proposal values and the right graphs show the result of either accepting or rejecting the proposal.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="a-general-function-for-the-metropolis-algorithm" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="a-general-function-for-the-metropolis-algorithm"><span class="header-section-number">3.3.3</span> A general function for the Metropolis algorithm</h3>
<p></p>
<p>Since the Metropolis is a relatively simple algorithm, one writes a short function in R to implement this sampling for an arbitrary probability distribution.</p>
<p>The function <code>metropolis()</code> has five inputs: <code>logpost</code> is a function defining the logarithm of the density, <code>current</code> is the starting value, <code>C</code> defines the neighborhood where one looks for a proposal value, <code>iter</code> is the number of iterations of the algorithm, and <code>...</code> denotes any data or parameters needed in the function <code>logpost()</code>.</p>
<pre><code>metropolis &lt;- function(logpost, current, C, iter, ...){
  S &lt;- rep(0, iter) 
  n_accept &lt;- 0
  for(j in 1:iter){
  candidate &lt;- runif(1, min=current - C, 
                       max=current + C)
  prob &lt;- exp(logpost(candidate, ...) - 
             logpost(current, ...))
  accept &lt;- ifelse(runif(1) &lt; prob, "yes", "no")
  current &lt;- ifelse(accept == "yes", 
                    candidate, current)
  S[j] &lt;- current
  n_accept &lt;- n_accept + (accept == "yes")
  }
  list(S=S, accept_rate=n_accept / iter)
}</code></pre>
</section>
</section>
<section id="example-cauchy-normal-problem" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="example-cauchy-normal-problem"><span class="header-section-number">3.4</span> Example: Cauchy-Normal problem</h2>
<p></p>
<p>To illustrate using the <code>metropolis()</code> function, suppose we wish to simulate 1000 values from the posterior distribution in our Buffalo snowfall problem where one uses a Cauchy prior to model one’s prior opinion about the mean snowfall amount. Recall that the posterior density of <span class="math inline">\(\mu\)</span> is proportional to <span class="math display">\[\begin{equation}
\pi(\mu \mid y) \propto \frac{1}{1 + \left(\frac{\mu - 10}{2}\right)^2} \times \exp\left\{-\frac{n}{2 \sigma^2}(\bar y - \mu)^2\right\}.
\end{equation}\]</span> There are four inputs to this posterior – the mean <span class="math inline">\(\bar y\)</span> and corresponding standard error <span class="math inline">\(\sigma / \sqrt{n}\)</span>, and the location parameter 10 and the scale parameter 2 for the Cauchy prior. Recall that for the Buffalo snowfall, we observed <span class="math inline">\(\bar y = 26.785\)</span> and <span class="math inline">\(\sigma / \sqrt{n} = 3.236\)</span>.</p>
<p>First we need to define a short function defining the logarithm of the posterior density function. Ignoring constants, the logarithm of this density is given by <span class="math display">\[\begin{equation}
\log \pi(\mu \mid y) =  -
\log\left\{1 + \left(\frac{\mu - 10}{2}\right)^2\right\} -\frac{n}{2 \sigma^2}(\bar y - \mu)^2.
\end{equation}\]</span></p>
<p>The function <code>lpost()</code> returns the value of the logarithm of the posterior where <code>s</code> is a list containing the four inputs <code>ybar</code>, <code>se</code>, <code>loc</code>, and <code>scale</code>.</p>
<pre><code>lpost &lt;- function(theta, s){
    dcauchy(theta, s$loc, s$scale, log = TRUE) +
    dnorm(s$ybar, theta, s$se, log = TRUE)
}</code></pre>
<p>A list named <code>s</code> is defined that contains these inputs for this particular problem.</p>
<pre><code>s &lt;- list(loc = 10, scale = 2,
          ybar = mean(data$JAN),
          se = sd(data$JAN) / sqrt(20))</code></pre>
<p>Now we are ready to apply the Metropolis algorithm as coded in the function <code>metropolis()</code>. The inputs to this function are the log posterior function <code>lpost</code>, the starting value <span class="math inline">\(\mu = 5\)</span>, the width of the proposal density <span class="math inline">\(C = 20\)</span>, the number of iterations 10,000, and the list <code>s</code> that contains the inputs to the log posterior function.</p>
<pre><code>out &lt;- metropolis(lpost, 5, 20, 10000, s)</code></pre>
<p>The output variable <code>out</code> has two components – <code>S</code> is a vector of the simulated draws and <code>accept_rate</code> gives the acceptance rate of the algorithm.</p>
<section id="choice-of-starting-value-and-proposal-region" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="choice-of-starting-value-and-proposal-region"><span class="header-section-number">3.4.1</span> Choice of starting value and proposal region</h3>
<p></p>
<p>In implementing this Metropolis algorithm, the user has to make two choices. One needs to select a starting value for the algorithm and select a value of <span class="math inline">\(C\)</span> which determines the width of the proposal region.</p>
<p>Assuming that the starting value is a place where the density is positive, then this particular choice in usual practice is not critical. In the event where the probability density at the starting value is small, the algorithm will move towards the region where the density is more probable.</p>
<p>The choice of the constant <span class="math inline">\(C\)</span> is more critical. If one chooses a very small value of <span class="math inline">\(C\)</span>, then the simulated values from the algorithm tend to be strongly correlated and it takes a relatively long time to explore the entire probability distribution. In contrast, if <span class="math inline">\(C\)</span> is chosen too large, then it is more likely that proposal values will not be accepted and the simulated values tend to get stuck at the current values. One monitors the choice of <span class="math inline">\(C\)</span> by computing the acceptance rate, the proportion of proposal values that are accepted. If the acceptance rate is large, that indicates that the simulated values are highly correlated and the algorithm is not efficiently exploring the distribution. If the acceptance rate is low, then few candidate values are accepted and the algorithm tends to be ``sticky” or stuck at current draws.</p>
<p>We illustrate different choices of <span class="math inline">\(C\)</span> for the mean amount of Buffalo snowfall problem. In each case, we start with the value <span class="math inline">\(\mu = 20\)</span> and try the <span class="math inline">\(C\)</span> values 0.3, 3, 30, and 200. In each case, we simulate 5000 values of the MCMC chain. Figure 9.7 shows in each case a line graph of the simulated draws against the iteration number and the acceptance rate of the algorithm is displayed.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/mcmc4.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Trace plots of simulated draws using different choices of the constant <span class="math inline">\(C\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>When one chooses a small value <span class="math inline">\(C = 0.3\)</span> (top-left panel in Figure 9.7), note that the graph of simulated draws has a snake-like appearance. Due to the strong autocorrelation of the simulated draws, the sampler does a relatively poor job of exploring the posterior distribution. One measure that this sampler is not working well is the large acceptance rate of 0.9702. On the other hand, if one uses a large value <span class="math inline">\(C = 200\)</span> (bottom-right panel in Figure 9.7), the flat-portions in the graph indicates there are many occurrences where the chain will not move from the current value. The low acceptance rate of 0.0272 indicates this problem. The more moderate values of <span class="math inline">\(C = 3\)</span> and <span class="math inline">\(C = 30\)</span> (top-right and bottom-left panels in Figure 9.7) produce more acceptable streams of simulated values, although the respectively acceptance rates (0.8158 and 0.179) are very different.</p>
<p>In practice, it is recommended that the Metropolis algorithm has an acceptance rate between 20% and 40%. For this example, this would suggest trying an alternative choice of <span class="math inline">\(C\)</span> between 2 and 20.</p>
</section>
<section id="collecting-the-simulated-draws" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="collecting-the-simulated-draws"><span class="header-section-number">3.4.2</span> Collecting the simulated draws</h3>
<p>Using MCMC diagnostic methods that will be described in Section 9.6, one sees that the simulated draws are a reasonable approximation to the posterior density of <span class="math inline">\(\mu\)</span>. One displays the posterior density by computing a density estimate of the simulated sample. In Figure 9.8, we plot the prior, likelihood, and posterior density for the mean amount of Buffalo snowfall <span class="math inline">\(\mu\)</span> using the Cauchy prior. Recall that we have prior-data conflict, the prior says that the mean snowfall is about 10 inches and the likelihood indicates that the mean snowfall was around 27 inches. When a Normal prior was applied, we found that the posterior mean was 17.75 inches – actually the posterior density has little overlap with the prior or the likelihood in Figure 9.1. In contrast, it is seen from Figure 9.8 that the posterior density using the Cauchy density resembles the likelihood. Essentially this posterior analysis says that our prior information was off the mark and the posterior is most influenced by the data.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/cauchypost.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Prior, likelihood, and posterior of a Normal mean with a Cauchy prior.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="gibbs-sampling" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="gibbs-sampling"><span class="header-section-number">3.5</span> Gibbs Sampling</h2>
<p></p>
<p>In our examples, we have focused on the use of the Metropolis sampler in simulating from a probability distribution of a single variable. Here we introduce an MCMC algorithm for simulating from a probability distribution of several variables based on conditional distributions: the Gibbs sampling algorithm. As we will see, it facilitates parameter estimation in Bayesian models with more than one parameter, providing data analysts much flexibility in specifying Bayesian models.</p>
<section id="bivariate-discrete-distribution" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="bivariate-discrete-distribution"><span class="header-section-number">3.5.1</span> Bivariate discrete distribution}</h3>
<p></p>
<p>To introduce the Gibbs sampling method, suppose that the random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> each take on the values 1, 2, 3, 4, and the joint probability distribution is given in the following table.</p>
<table class="table">
<tbody>
<tr class="odd">
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">(Y)</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.075</td>
<td style="text-align: right;">0.050</td>
<td style="text-align: right;">0.025</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.075</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.075</td>
<td style="text-align: right;">0.050</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">0.050</td>
<td style="text-align: right;">0.075</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.075</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: right;">0.025</td>
<td style="text-align: right;">0.050</td>
<td style="text-align: right;">0.075</td>
<td style="text-align: right;">0.100</td>
</tr>
</tbody>
</table>
<p>Suppose it is of interest to simulate from this joint distribution of <span class="math inline">\((X, Y)\)</span>. We set up a Markov chain by taking simulated draws from the conditional distributions <span class="math inline">\(f(x \mid y)\)</span> and <span class="math inline">\(f(y \mid x)\)</span>. Let’s describe this Markov chain by example. Suppose the algorithm starts at the value <span class="math inline">\(X = 1\)</span>.</p>
<ol type="1">
<li>[Step 1] One simulates <span class="math inline">\(Y\)</span> from the conditional distribution <span class="math inline">\(f(y \mid X = 1)\)</span>. This conditional distribution is represented by the probabilities in the first column of the probability matrix.</li>
</ol>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: right;">(Y)</th>
<th style="text-align: right;">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.100</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.075</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">0.050</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: right;">0.025</td>
</tr>
</tbody>
</table>
<p>(Actually these values are proportional to the distribution <span class="math inline">\(f(y \mid X = 1)\)</span>.) Suppose we perform this simulation and obtain <span class="math inline">\(Y = 2\)</span>.</p>
<ol start="2" type="1">
<li>[Step 2] Next one simulates <span class="math inline">\(X\)</span> from the conditional distribution of <span class="math inline">\(f(x \mid Y = 2).\)</span> This distribution is found by looking at the probabilities in the second row of the probability matrix.</li>
</ol>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">(X)</th>
<th style="text-align: right;">1</th>
<th style="text-align: right;">2</th>
<th style="text-align: right;">3</th>
<th style="text-align: right;">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Probability</td>
<td style="text-align: right;">0.075</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">0.075</td>
<td style="text-align: right;">0.050</td>
</tr>
</tbody>
</table>
<p>Suppose the simulated draw from this distribution is <span class="math inline">\(X = 3\)</span>.</p>
<p>By implementing Steps 1 and 2, we have one iteration of Gibbs sampling, obtaining the simulated pair <span class="math inline">\((X, Y) = (3, 2)\)</span>. To continue this algorithm, we repeat Steps 1 and 2 many times where we condition in each case on the most recently simulated values of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span>.</p>
<p>By simulating successively from the distributions <span class="math inline">\(f(y \mid x)\)</span> and <span class="math inline">\(f(x \mid y)\)</span>, one defines a Markov chain that moves from one simulated pair <span class="math inline">\((X^{(j)}, Y^{(j)})\)</span> to the next simulated pair <span class="math inline">\((X^{(j+1)}, Y^{(j+1)})\)</span>. In theory, after simulating from these two conditional distributions a large number of times, the distribution will converge to the joint probability distribution of <span class="math inline">\((X, Y)\)</span>.</p>
<p>We write a short R function <code>gibbs_discrete()</code> to implement Gibbs sampling for a two-parameter discrete distribution where the probabilities are represented in a matrix. One inputs the matrix <code>p</code> and the output is a matrix of simulated draws of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> where each row corresponds to a simulated pair. By default, the sampler starts at the value <span class="math inline">\(X = 1\)</span> and 1000 iterations of the algorithm will be taken.</p>
<pre><code>gibbs_discrete &lt;- function(p, i = 1, iter = 1000){
  x &lt;- matrix(0, iter, 2)
  nX &lt;- dim(p)[1]
  nY &lt;- dim(p)[2]
  for(k in 1:iter){
    j &lt;- sample(1:nY, 1, prob = p[i, ])
    i &lt;- sample(1:nX, 1, prob = p[, j])
    x[k, ] &lt;- c(i, j)
  }
  x
}</code></pre>
<p>The function <code>gibbs_discrete()</code> is run using the probability matrix for our example. The output is converted to a data frame and we tally the counts for each possible pair of values of <span class="math inline">\((X, Y)\)</span>, and then divide the counts by the simulation sample size of 1000. One can check that the relative frequencies of these pairs are good approximations to the joint probabilities.</p>
<pre><code>sp &lt;- data.frame(gibbs_discrete(p))
names(sp) &lt;- c("X", "Y")
table(sp) / 1000
    Y
X       1     2     3     4
  1 0.086 0.058 0.050 0.020
  2 0.061 0.081 0.079 0.048
  3 0.046 0.070 0.090 0.079
  4 0.017 0.036 0.068 0.111</code></pre>
</section>
<section id="beta-binomial-sampling" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="beta-binomial-sampling"><span class="header-section-number">3.5.2</span> Beta-binomial sampling</h3>
<p></p>
<p>The previous example demonstrated Gibbs sampling for a two-parameter discrete distribution. In fact, the Gibbs sampling algorithm works for any two-parameter distribution. To illustrate, consider a familiar Bayesian model discussed in Chapter 7. Suppose we flip a coin <span class="math inline">\(n\)</span> times and observe <span class="math inline">\(y\)</span> heads where the probability of heads is <span class="math inline">\(p\)</span>, and our prior for the heads probability is described by a Beta curve with shape parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. It is convenient to write <span class="math inline">\(X \mid Y = y\)</span> as the conditional distribution of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span>. Using this notation we have</p>
<p><span class="math display">\[\begin{equation}
Y \mid p \sim  \textrm{Binomial}(n, p),
\end{equation}\]</span> <span class="math display">\[\begin{equation}
p \sim \textrm{Beta}(a, b).
\end{equation}\]</span></p>
<p>To implement Gibbs sampling for this situation, one needs to identify the two conditional distributions <span class="math inline">\(Y \mid p\)</span> and <span class="math inline">\(p \mid Y\)</span>. First write down the joint density of <span class="math inline">\((Y, p)\)</span> which is found by multiplying the marginal density <span class="math inline">\(\pi(p)\)</span> with the conditional density <span class="math inline">\(f(y \mid p)\)</span>.</p>
<p><span class="math display">\[\begin{eqnarray}
f(Y = y, p) &amp;=&amp; \pi(p)f(Y = y \mid p) \nonumber \\
&amp;=&amp;  \left[\frac{1}{B(a, b)} p^{a - 1} (1-p)^{b-1}\right] \left[{n \choose y} p^y (1 - p)^{n-y}\right]. \nonumber \\
\end{eqnarray}\]</span></p>
<ol type="1">
<li><p>The conditional density <span class="math inline">\(f(Y = y \mid p)\)</span> is found by fixing a value of the proportion <span class="math inline">\(p\)</span> and then the only random variable is <span class="math inline">\(Y\)</span>. This distribution is <span class="math inline">\(\textrm{Binomial}(n, p)\)</span> which actually was given in the statement of the problem.</p></li>
<li><p>Turning things around, the conditional density <span class="math inline">\(\pi(p \mid y)\)</span> takes the number of successes <span class="math inline">\(y\)</span> and views the joint density as a function only of the random variable <span class="math inline">\(p\)</span>. Ignoring constants, we see this conditional density is proportional to <span class="math display">\[\begin{equation}
p^{y + a - 1} (1 - p)^{n - y + b - 1},
\end{equation}\]</span> which we recognize as a Beta distribution with shape parameters <span class="math inline">\(y + a\)</span> and <span class="math inline">\(n - y + b\)</span>. Using our notation, we have <span class="math inline">\(p \mid y \sim \textrm{Beta}(y + a, n - y + b)\)</span>.</p></li>
</ol>
<p>Once these conditional distributions are identified, it is straightforward to write an algorithm to implement Gibbs sampling. For example, suppose <span class="math inline">\(n = 20\)</span> and the prior density for <span class="math inline">\(p\)</span> is <span class="math inline">\(\textrm{Beta}(5, 5)\)</span>. Suppose that the current simulated value of <span class="math inline">\(p\)</span> is <span class="math inline">\(p^{(j)}\)</span>.</p>
<ol type="1">
<li>Simulate <span class="math inline">\(Y^{(j)}\)</span> from a <span class="math inline">\(\textrm{Binomial}(20, p^{(j)})\)</span> distribution.</li>
</ol>
<pre><code>y &lt;- rbinom(1, size = 20, prob = p)</code></pre>
<ol start="2" type="1">
<li>Given the current simulated value <span class="math inline">\(y^{(j)}\)</span>, simulate <span class="math inline">\(p^{(j+1)}\)</span> from a Beta distribution with shape parameters <span class="math inline">\(y^{(j)} + 5\)</span> and <span class="math inline">\(20 - y^{(j)} + 5\)</span>.</li>
</ol>
<pre><code>p &lt;- rbeta(1, y + a, n - y + b)</code></pre>
<p>The R function <code>gibbs_betabin()</code> will implement Gibbs sampling for this problem. One inputs the sample size <span class="math inline">\(n\)</span> and the shape parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. By default, one starts the algorithm at the proportion value <span class="math inline">\(p = 0.5\)</span> and one takes 1000 iterations of the algorithm.</p>
<pre><code>gibbs_betabin &lt;- function(n, a, b, p = 0.5, iter = 1000){
  x &lt;- matrix(0, iter, 2)
  for(k in 1:iter){
    y &lt;- rbinom(1, size = n, prob = p)
    p &lt;- rbeta(1, y + a, n - y + b )
    x[k, ] &lt;- c(y, p)
  }
  x
}</code></pre>
<p>Below we run Gibbs sampling for this Beta-Binomial model with <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(a = 5\)</span>, and <span class="math inline">\(b = 5\)</span>. After performing 1000 iterations, one regards the matrix <code>sp</code> as an approximate simulated sample from the joint distribution of <span class="math inline">\(Y\)</span> and <span class="math inline">\(p\)</span>. A histogram is constructed of the simulated draws of <span class="math inline">\(Y\)</span> in Figure 9.9. This graph represents an approximate sample from the marginal distribution <span class="math inline">\(f(y)\)</span> of <span class="math inline">\(Y\)</span>.</p>
<pre><code>sp &lt;- data.frame(gibbs_betabin(20, 5, 5))</code></pre>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/mcmc5.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Histogram of simulated draws of <span class="math inline">\(Y\)</span> from Gibbs sampling for the Beta-Binomial model with <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(a = 5\)</span>, and <span class="math inline">\(b = 5\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="normal-sampling-both-parameters-unknown" class="level3" data-number="3.5.3">
<h3 data-number="3.5.3" class="anchored" data-anchor-id="normal-sampling-both-parameters-unknown"><span class="header-section-number">3.5.3</span> Normal sampling – both parameters unknown</h3>
<p></p>
<p>In Chapter 8, we considered the situation of sampling from a Normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. To simplify this to a one-parameter model, we assumed that the value of <span class="math inline">\(\sigma\)</span> was known and focused on the problem of learning about the mean <span class="math inline">\(\mu\)</span>. Since Gibbs sampling provides us to simulate from posterior distributions of more than one parameter, we can generalize to the more realistic situation where both the mean and the standard deviation are unknown.</p>
<p>Suppose we take a sample of <span class="math inline">\(n\)</span> observations <span class="math inline">\(Y_1, .., Y_n\)</span> from a Normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Recall the sampling density of <span class="math inline">\(Y_i\)</span> has the form <span class="math display">\[\begin{equation}
f(y_i \mid \mu, \sigma) = \frac{1}{\sqrt{2 \pi} \sigma} \exp\left\{- \frac{1}{2 \sigma^2}(y_i - \mu)^2\right\}.
\end{equation}\]</span> It will be convenient to reexpress the variance <span class="math inline">\(\sigma\)</span> by the <em>precision</em> <span class="math inline">\(\phi\)</span> where <span class="math display">\[\begin{equation}
\phi = \frac{1}{\sigma^2}.
\end{equation}\]</span> The precision <span class="math inline">\(\phi\)</span> reflects the strength in knowledge about the location of the observation <span class="math inline">\(Y_i\)</span>. If <span class="math inline">\(Y_i\)</span> is likely to be close to the mean <span class="math inline">\(\mu\)</span>, then the variance <span class="math inline">\(\sigma^2\)</span> would be small and so the precision <span class="math inline">\(\phi\)</span> would be large. So we restate the sampling model as follows. The observations <span class="math inline">\(Y_1, .., Y_n\)</span> are a random sample from a Normal density with mean <span class="math inline">\(\mu\)</span> and precision <span class="math inline">\(\phi\)</span>, where the sampling density of <span class="math inline">\(Y_i\)</span> is given by <span class="math display">\[\begin{equation}
f(y_i \mid \mu, \phi) = \frac{\sqrt{\phi}}{\sqrt{2 \pi}} \exp\left\{- \frac{\phi}{2}(y_i - \mu)^2\right\}.
\end{equation}\]</span></p>
<p>The next step is to construct a prior density on the parameter vector <span class="math inline">\((\mu, \phi)\)</span>. A convenient choice for this prior is to assume that one’s opinion about the location of the mean <span class="math inline">\(\mu\)</span> is independent of one’s belief about the location of the precision <span class="math inline">\(\phi\)</span>. So we assume that <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span> are independent, so one writes the joint prior density as <span class="math display">\[\begin{equation}
\pi(\mu, \phi) = \pi_{\mu}(\mu) \pi_{\phi}(\phi),
\end{equation}\]</span> where <span class="math inline">\(\pi_{\mu}()\)</span> and <span class="math inline">\(\pi_{\phi}()\)</span> are marginal densities. For convenience, each of these marginal priors are assigned conjugate forms: we assume that <span class="math inline">\(\mu\)</span> is Normal with mean <span class="math inline">\(\mu_0\)</span> and precision <span class="math inline">\(\phi_0\)</span>: <span class="math display">\[\begin{equation}
\pi_{\mu}(\mu) = \frac{\sqrt{\phi_0}}{\sqrt{2 \pi}} \exp\left\{-\frac{\phi_0}{2}(\mu - \mu_0)^2\right\}.
\end{equation}\]</span> The prior for the precision parameter <span class="math inline">\(\phi\)</span> is assumed Gamma with parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>: <span class="math display">\[\begin{equation}
\pi_{\phi}(\phi) = \frac{b^a}{\Gamma(a)} \phi^{a-1} \exp(-b \phi), \, \, \phi  &gt; 0.
\end{equation}\]</span></p>
<p>Once values of <span class="math inline">\(y_1, ..., y_n\)</span> are observed, the likelihood is the density of these Normal observations viewed as a function of the mean <span class="math inline">\(\mu\)</span> and the precision parameter <span class="math inline">\(\phi\)</span>. Simplifying the expression and removing constants, one obtains: <span class="math display">\[\begin{align}
        L(\mu, \phi) &amp;=\prod_{i=1}^n \frac{\sqrt{\phi}}{\sqrt{2 \pi}} \exp\left\{-\frac{\phi}{2}(y_i - \mu)^2\right\} \nonumber \\
        &amp; \propto \phi^{n/2} \exp\left\{-\frac{\phi}{2}\sum_{i=1}^n (y_i - \mu)^2\right\}.
\end{align}\]</span></p>
<p>To implement Gibbs sampling, one first writes down the expression for the posterior density as the product of the likelihood and prior where any constants not involving the parameters are removed.</p>
<p><span class="math display">\[\begin{eqnarray}
\pi(\mu, \phi \mid y_1, \cdots, y_n ) &amp;\propto &amp; \phi^{n/2} \exp\left\{-\frac{\phi}{2}\sum_{i=1}^n (y_i - \mu)^2\right\} \nonumber \\
&amp; \times &amp; \exp\left\{-\frac{\phi_0}{2}(\mu - \mu_0)^2\right\}  \phi^{a-1} \exp(-b \phi).
\end{eqnarray}\]</span></p>
<p>Next, the two conditional posterior distributions <span class="math inline">\(\pi(\mu \mid \phi, y_1, \cdots, y_n)\)</span> and <span class="math inline">\(\pi(\phi \mid \mu, y_1, \cdots, y_n)\)</span> are identified.</p>
<ol type="1">
<li>The first conditional density <span class="math inline">\(\pi(\mu \mid \phi, y_1, \cdots, y_n)\)</span> follows from the work in Chapter 8 on Bayesian inference about a mean with a conjugate prior when the sampling standard deviation was assumed known. One obtains that this conditional distribution <span class="math inline">\(\pi(\mu \mid \phi, y_1, \cdots, y_n)\)</span> is Normal with mean <span class="math display">\[\begin{equation}
\mu_n = \frac{\phi_0 \mu_0  + n \phi \bar y }{\phi_0  + n \phi}.
\end{equation}\]</span> and standard deviation <span class="math display">\[\begin{equation}
\sigma_n = \sqrt{\frac{1}{\phi_0  + n \phi}}.
\end{equation}\]</span></li>
<li>Collecting terms, the second conditional density <span class="math inline">\(\pi(\phi \mid \mu, y_1, \cdots, y_n)\)</span> is proportional to <span class="math display">\[\begin{equation}
\pi(\phi \mid \mu, y_1, \cdots y_n) \propto \phi^{n/2 + a - 1} \exp\left\{-\phi\left[\frac{1}{2}\sum_{i=1}^n (y_i- \mu)^2 + b\right]\right\}. \\
\end{equation}\]</span> The second conditional distribution <span class="math inline">\(\pi(\phi \mid \mu, y_1, \cdots, y_n)\)</span> is seen to be a Gamma density with parameters <span class="math display">\[\begin{equation}
a_n = \frac{n}{2} + a,
\end{equation}\]</span> <span class="math display">\[\begin{equation}
b_n = \frac{1}{2}\sum_{i=1}^n (y_i - \mu)^2 + b.
\end{equation}\]</span></li>
</ol>
<p>An R function <code>gibbs_normal()</code> is written to implement this Gibbs sampling simulation. The inputs to this function are a list <code>s</code> containing the vector of observations <code>y</code> and the prior parameters <code>mu0</code>, <code>phi0</code>, <code>a</code>, and <code>b</code>, the starting value of the precision parameter <span class="math inline">\(\phi\)</span>, <code>phi</code>, and the number of Gibbs sampling iterations <code>S</code>. This function is similar in structure to the <code>gibbs_betabin()</code> function – the two simulations in the Gibbs sampling are accomplished by use of the <code>rnorm()</code> and ```rgamma()} functions.</p>
<pre><code>gibbs_normal &lt;- function(s, phi = 0.002, iter = 1000){
  ybar &lt;- mean(s$y)
  n &lt;- length(s$y)
  mu0 &lt;- s$mu0
  phi0 &lt;- s$phi0
  a &lt;- s$a
  b &lt;- s$b
  x &lt;- matrix(0, iter, 2)
  for(k in 1:iter){
   mun &lt;- (phi0 * mu0 + n * phi * ybar) /
      (phi0 + n * phi)
    sigman &lt;- sqrt(1 / (phi0 + n * phi))
    mu &lt;- rnorm(1, mean = mun, sd = sigman)
    an &lt;- n / 2 + a
    bn &lt;- sum((s$y - mu) ^ 2) / 2 + b
    phi &lt;- rgamma(1, shape = an, rate = bn)
    x[k, ] &lt;- c(mu, phi)
  }
  x
}</code></pre>
<p>We run this function for our Buffalo snowfall example where now the sampling model is Normal with both the mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> unknown. The prior distribution assumes that <span class="math inline">\(\mu\)</span> and the precision <span class="math inline">\(\phi\)</span> are independent, where <span class="math inline">\(\mu\)</span> is Normal with mean 10 and standard deviation 3 (i.e.&nbsp;precision <span class="math inline">\(1/3^2\)</span>), and <span class="math inline">\(\phi\)</span> is Gamma with <span class="math inline">\(a = b = 1\)</span>. The output of this function is a matrix ```out} where the two columns of the matrix correspond to random draws of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span> from the posterior distribution.</p>
<pre><code>s &lt;- list(y = data$JAN, mu0 = 10, phi0 = 1/3^2, a = 1, b = 1)
out &lt;- gibbs_normal(s, iter=10000)</code></pre>
<p>By performing the transformation <span class="math inline">\(\sigma = \sqrt{1 / \phi}\)</span>, one obtains a sample of the simulated draws of the standard deviation <span class="math inline">\(\sigma\)</span>. Figure 9.10 <span class="math inline">\(\ref{fig:mcmc9}\)</span> displays a scatterplot of the posterior draws of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/mcmc9.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Scatterplot of simulated draws of the posterior distribution of mean and standard deviation from Gibbs sampling for the Normal sampling model with independent priors on the mean and the precision.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="mcmc-inputs-and-diagnostics" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="mcmc-inputs-and-diagnostics"><span class="header-section-number">3.6</span> MCMC Inputs and Diagnostics</h2>
<p></p>
<section id="burn-in-starting-values-and-multiple-chains" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="burn-in-starting-values-and-multiple-chains"><span class="header-section-number">3.6.1</span> Burn-in, starting values, and multiple chains</h3>
<p></p>
<p>In theory, the Metropolis and Gibbs sampling algorithms will produce simulated draws that converge to the posterior distribution of interest. But in typical practice, it may take a number of iterations before the simulation values are close to the posterior distribution. So in general it is recommended that one run the algorithm for a number of “burn-in” iterations before one collects iterations for inference. The JAGS software that is introduced in Section 9.7 will allow the user to specify the number of burn-in iterations.</p>
<p>In the examples, we have illustrated running a single “chain” where one has a single starting value and one collects simulated draws from many iterations. It is possible that the MCMC sample will depend on the choice of starting value. So a general recommendation is to run the MCMC algorithm several times using different starting values. In this case, one will have multiple MCMC chains. By comparing the inferential summaries from the different chains one explores the sensitivity of the inference to the choice of starting value. Although we will focus on the use of a single chain, we will explore the use of different starting values and multiple chains in an example in this chapter. The JAGS software and other programs to implement MCMC will allow for different starting values and several chains.</p>
</section>
<section id="diagnostics" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="diagnostics"><span class="header-section-number">3.6.2</span> Diagnostics</h3>
<p>The output of a single chain from the Metropolis and Gibbs algorithms is a vector or matrix of simulated draws. Before one believes that a collection of simulated draws is a close approximation to the posterior distribution, some special diagnostic methods should be initially performed.</p>
<p><strong>Trace plot</strong></p>
<p>It is helpful to construct a trace plot which is a line plot of the simulated draws of the parameter of interest graphed against the iteration number. Figure 9.11 displays a trace plot of the simulated draws of <span class="math inline">\(\mu\)</span> from the Metropolis algorithm for our Buffalo snowfall example for Normal sampling (known standard deviation) with a Cauchy prior. Section 9.4.1 shows some sample trace plots for Metropolis sampler. As discussed in that section, it is undesirable to have a snack-like appearance in the trace plot indicating a high acceptance rate. Also, Section 9.4.1 displays a trace plot with many flat portions that indicates a sampler with a low acceptance rate. From the authors’ experience, the trace plot in Figure 9.11 indicates that the sampler is using a good value of the constant <span class="math inline">\(C\)</span> and efficiently sampling from the posterior distribution.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/mcmc6.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Trace plot of simulated draws of normal mean using the Metropolis algorithm with <span class="math inline">\(C = 20\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><strong>Autocorrelation plot</strong></p>
<p>Since one is simulating a dependent sequence of values of the parameter, one is concerned about the possible strong correlation between successive draws of the sampler. One visualizes this dependence by computing the correlation of the pairs {<span class="math inline">\(\theta^{(j)}, \theta^{(j + l)}\)</span>} and plotting this ``lag-correlation” as a function of the lag value <span class="math inline">\(l\)</span>. This autocorrelation plot of the simulated draws from our example is displayed in Figure 9.12. If there is a strong degree of autocorrelation in the sequence, then there will be a large correlation of these pairs even for large values of the lag value. Figure 9.12 is an example of a suitable autocorrelation graph where the lag correlation values quickly drop to zero as a function of the lag value. This autocorrelation graph is another indication that the Metropolis algorithm is providing an efficient sampler of the posterior.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/mcmc7.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Autocorrelation plot of simulated draws of normal mean using the Metropolis algorithm with <span class="math inline">\(C = 20\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="graphs-and-summaries" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="graphs-and-summaries"><span class="header-section-number">3.6.3</span> Graphs and summaries</h3>
<p>If the trace plot or autocorrelation plot indicate issues with the Metropolis sampler, then the width of the proposal <span class="math inline">\(C\)</span> should be adjusted and the algorithm run again. Since we believe that the Metropolis simulation stream is reasonable with the use of the value <span class="math inline">\(C = 20\)</span> , then one uses a histogram of simulated draws, as displayed in Figure 9.13 to represent the posterior distribution. Alternatively, a density estimate of the simulated draws can be used to show a smoothed representation of the posterior density. Figure <span class="math inline">\(\ref{fig:mcmc8}\)</span> places a density estimate on top of the histogram of the simulated values of the parameter <span class="math inline">\(\mu\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/mcmc8.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Histogram of simulated draws of the normal mean using the Metropolis algorithm with <span class="math inline">\(C = 20\)</span>. The solid curve is a density estimate of the simulated values.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>One estimates different summaries of the posterior distribution by computing different summaries of the simulated sample. In our Cauchy-Normal model, one estimates, for example, the posterior mean of <span class="math inline">\(\mu\)</span> by computing the mean of the simulated posterior draws: <span class="math display">\[\begin{equation}
E(\mu \mid y) \approx \frac{\sum_{j = 1}^S \mu^{(j)}}{S}.
\end{equation}\]</span> One typically wants to estimate the simulation standard error of this MCMC estimate. If the draws from the posterior were independent, then the Monte Carlo standard error of this posterior mean estimate would be given by the standard deviation of the draws divided by the square root of the simulation sample size: <span class="math display">\[\begin{equation}
se = \frac{sd(\{\mu^{(j)}\})}{\sqrt{S}}.
\end{equation}\]</span> However, this estimate of the standard error is not correct since the MCMC sample is not independent (the simulated value <span class="math inline">\(\mu^{(j)}\)</span> depends on the value of the previous simulated value <span class="math inline">\(\mu^{(j-1)}\)</span>). One obtains a more accurate estimate of Monte Carlo standard error by using time-series methods. As we will see in the examples of Section 9.7, this standard error estimate will be larger than the “naive” standard error estimate that assumes the MCMC sample values are independent.</p>
</section>
</section>
<section id="using-jags" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="using-jags"><span class="header-section-number">3.7</span> Using JAGS</h2>
<p></p>
<p>Sections 9.3 and 9.5 have illustrated general strategies for simulating from a posterior distribution of one or more parameters. Over the years, there has been an effort to develop general-purpose Bayesian computing software that would take a Bayesian model (i.e.&nbsp;the specification of a prior and sampling density as input), and use an MCMC algorithm to output a matrix of simulated draws from the posterior. One of the earliest Bayesian simulation-based computing software was BUGS (for Bayesian inference Using Gibbs Sampling) and we illustrate in this text applications of a similar package JAGS (for Just Another Gibbs Sampler).</p>
<p>The use of JAGS has several attractive features. One defines a Bayesian model for a particular problem by writing a short script. One then inputs this script together with data and prior parameter values in a single R function from the <code>runjags</code> package that decides on the appropriate MCMC sampling algorithm for the particular Bayesian model. In addition, this function simulates from the MCMC algorithm for a specified number of samples and collects simulated draws of the parameters of interest.</p>
<section id="normal-sampling-model" class="level3" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="normal-sampling-model"><span class="header-section-number">3.7.1</span> Normal sampling model</h3>
<p>To illustrate the use of JAGS, consider the problem of estimating the mean Buffalo snowfall assuming a Normal sampling model with both the mean and standard deviation unknown, and independent priors placed on both parameters. As in Section 9.5.3 one expresses the parameters of the Normal distribution as <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span>, where the precision <span class="math inline">\(\phi\)</span> is the reciprocal of the variance <span class="math inline">\(\phi = 1 / \sigma^2\)</span>. One then writes this Bayesian model as</p>
<ul>
<li><p>Sampling, for <span class="math inline">\(i = 1, \cdots, n\)</span>: <span class="math display">\[\begin{equation}
Y_i \overset{i.i.d.}{\sim} \textrm{Normal}(\mu, \sqrt{1/\phi}).
\end{equation}\]</span></p></li>
<li><p>Independent priors for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span>: <span class="math display">\[\begin{equation}
\mu \sim \textrm{Normal}(\mu_0, \sqrt{1/\phi_0}), (\#eq:muphiprior2a)
\end{equation}\]</span> <span class="math display">\[\begin{equation}
\phi \sim \textrm{Gamma}(a, b).
\end{equation}\]</span></p></li>
</ul>
<p>The JAGS program parametrizes a Normal density in terms of the precision, so the prior precision is equal to <span class="math inline">\(\phi_0 = 1 / \sigma_0^2\)</span>. As in Section 9.5.3, the parameters of the Normal and Gamma priors are set at <span class="math inline">\(\mu_0 = 10, \phi_0 = 1 / 3 ^ 2, a = 1, b = 1.\)</span></p>
<p><strong>Describe the model by a script</strong></p>
<p>To begin, one writes the following script defining this model. The model is saved in the character string ```modelString}.</p>
<pre><code>modelString = "
model{
## sampling
for (i in 1:N) {
   y[i] ~ dnorm(mu, phi)
}
## priors
mu ~ dnorm(mu0, phi0)
phi ~ dgamma(a, b)
sigma &lt;- sqrt(pow(phi, -1))
}</code></pre>
<p>Note that this script closely resembles the statement of the model. In the sampling part of the script, the loop structure starting with <code>for (i in 1:N)</code> is used to assign the distribution of each value in the data vector <code>y</code> the same Normal distribution, represented by <code>dnorm</code>. The <code>~</code> operator is read as “is distributed as”.</p>
<p>In the priors part of the script, in addition to setting the Normal prior and Gamma prior for <code>mu</code> and <code>phi</code> respectively, <code>sigma &lt;- sqrt(pow(phi, -1))</code> is added to help track <code>sigma</code> directly.</p>
<p><strong>Define the data and prior parameters</strong></p>
<p>The next step is to define the data and provide values for parameters of the prior. In the script below, a list <code>the_data</code> is used to collect the vector of observations <code>y</code>, the number of observations <code>N</code>, and values of the Normal prior parameters <code>mu0</code>, <code>phi0</code>, and of the Gamma prior parameters <code>a</code> and <code>b</code>.</p>
<pre><code>buffalo &lt;- read.csv("../data/buffalo_snowfall.csv")
data &lt;- buffalo[59:78, c("SEASON", "JAN")]
y &lt;- data$JAN
N &lt;- length(y)
the_data &lt;- list("y" = y, "N" = N, 
                 "mu0"=10, "phi0"=1/3^2, 
                 "a"=1,"b"=1)</code></pre>
<p><strong>Define initial values</strong></p>
<p>One needs to supply initial values in the MCMC simulation for all of the parameters in the model. To obtain reproducible results, one can use the <code>initsfunction()</code> function shown below to set the seed for the sequence of simulated parameter values in the MCMC.</p>
<pre><code>initsfunction &lt;- function(chain){
  .RNG.seed &lt;- c(1,2)[chain]
  .RNG.name &lt;- c("base::Super-Duper",
                 "base::Wichmann-Hill")[chain]
  return(list(.RNG.seed=.RNG.seed,
              .RNG.name=.RNG.name))</code></pre>
<p>Alternatively, one can specify the initial values by means of a function – this will be implemented when multiple chains are discussed. If no initial values are specified, then JAGS will select initial values – these are usually a ``typical” value such as a mean or median from the prior distribution.</p>
<p><strong>Generate samples from the posterior distribution</strong></p>
<p>Now that the model definition and data have been defined, one is ready to draw samples from the posterior distribution. The <code>runjags</code> provides the R interface to the use of the JAGS software. The <code>run.jags()</code> function sets up the Bayesian model defined in <code>modelString</code>. The input <code>n.chains = 1</code> indicates that one stream of simulated values will be generated. <code>adapt = 1000</code> says that 1000 simulated iterations are used in “adapt period” to prepare for MCMC, <code>burnin = 1000</code> indicates 5000 simulated iterations are used in a “burn-in” period where the iterations are approaching the main probability region of the posterior distribution. The <code>sample = 5000</code> arguments indicates that 5000 additional iterations of the MCMC algorithm will be collected. The <code>monitor</code> arguments says that we are collecting simulated values of the mean <code>mu</code> and the standard deviation <code>sigma</code>. The output variable <code>posterior</code> includes a matrix of the simulated draws. The <code>inits = initsfunction</code> argument indicates that initial parameter values are chosen by the <code>initsfunction()</code> function.</p>
<pre><code>posterior &lt;- run.jags(modelString,
                      n.chains = 1,
                      data = the_data,
                      monitor = c("mu", "sigma"),
                      adapt = 1000,
                      burnin = 5000,
                      sample = 5000,
                      inits = initsfunction)</code></pre>
<p><strong>MCMC diagnostics and summarization</strong></p>
<p>Before summarizing the simulated sample, some graphical diagnostics methods should be implemented to judge if the sample appears to “mix” or move well across the space of likely values of the parameters. The <code>plot()</code> function in the <code>runjags</code> package constructs a collection of four graphs for a parameter of interest. By running <code>plot()</code> for <code>mu</code> and <code>sigma</code>, we obtain the graphs displayed in Figures 9.14 and 9.15.</p>
<pre><code>plot(posterior, vars = "mu")
plot(posterior, vars = "sigma")</code></pre>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/jags1a.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Diagnostic plots of simulated draws of mean using the JAGS software with the runjags package.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/jags1b.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Diagnostic plots of simulated draws of standard deviation using the JAGS software with the runjags package.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The trace and autocorrelation plots in the top left and bottom right sections of the display are helpful for seeing how the sampler moves across the posterior distribution. In Figures 9.14 and 9.15, the trace plots show little autocorrelation in the streams of simulated draws and both simulated samples of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> appear to mix well. In the autocorrelation plots, the value of the autocorrelation drops sharply to zero as a function of the lag which confirms that we have modest autocorrelation in these samples. In each display, the bottom left graph is a histogram of the simulated draws and the top right graph is an estimate at the cumulative distribution function of the variable.</p>
<p>Since we are encouraged by these diagnostic graphs, we go ahead and obtain summaries of the simulated samples of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> by the <code>print()</code> function on our MCMC object. The posterior mean of <span class="math inline">\(\mu\)</span> is 16.5. The standard error of this simulation estimate is the ``MCerr” value of 0.0486 – this standard error takes in account the correlated nature of these simulated draws. A 90% probability interval for the mean <span class="math inline">\(\mu\)</span> is found from the output to be (10.8, 21.4). For <span class="math inline">\(\sigma\)</span>, it has a posterior mean of 17.4, and a 90% probability interval (11.8, 24).</p>
<pre><code>print(posterior, digits = 3)
      Lower95 Median Upper95 Mean   SD Mode  MCerr 
mu       10.8   16.5    21.4 16.5 2.68   -- 0.0486     
sigma    11.8   17.1      24 17.4 3.18   -- 0.0576    </code></pre>
</section>
<section id="multiple-chains" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="multiple-chains"><span class="header-section-number">3.7.2</span> Multiple chains</h3>
<p>In Section 9.6.1, we explained the benefit of trying different starting values and running several MCMC chains. This is facilitated by arguments in the <code>run.jags()</code> function. Suppose one considers the very different pairs of starting values, <span class="math inline">\((\mu, \phi) = (2, 1 / 4)\)</span> and <span class="math inline">\((\mu, \phi) = (30, 1/ 900)\)</span>. Note that both pair of parameter values are far outside of the region where the posterior density is concentrated. One defines a value <code>InitialValues</code> that is a list containing two lists, each list containing a starting value.</p>
<pre><code>InitialValues &lt;- list(
  list(mu = 2, phi = 1 / 4),
  list(mu = 30, phi = 1 / 900)
)</code></pre>
<p>The <code>run.jags()</code> function is run with two modifications – one chooses <code>n.chains = 2</code> and the initial values are input through the <code>inits = InitialValues</code> option.</p>
<pre><code>posterior &lt;- run.jags(modelString,
                      n.chains = 2,
                      data = the_data,
                      monitor = c("mu", "sigma"),
                      adapt = 1000,
                      burnin = 5000,
                      sample = 5000,
                      inits = InitialValues)</code></pre>
<p>The output variable <code>posterior</code> contains a component <code>mcmc} which is a list of two components where</code>posterior$mcmc[[1]]<code>contains the simulated draws from the first chain and</code>posterior$mcmc[[2]]``` contains the simulated draws from the second chain. To see if the MCMC run is sensitive to the choice of starting value, one compares posterior summaries from the two chains. Below, we display posterior quantiles for the parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> for each chain. Note that these quantiles are very close in value indicating that the MCMC run is insensitive to the choice of starting value.</p>
<pre><code>summary(posterior$mcmc[[1]], digits = 3)
2. Quantiles for each variable:

       2.5%   25%   50%   75% 97.5%
mu    10.99 14.64 16.49 18.35 21.62
sigma 12.26 15.15 17.03 19.31 25.07

summary(posterior$mcmc[[2]], digits = 3)
2. Quantiles for each variable:

       2.5%   25%   50%   75% 97.5%
mu    10.97 14.59 16.55 18.33 21.54
sigma 12.21 15.08 16.96 19.18 24.99</code></pre>
</section>
<section id="posterior-predictive-checking" class="level3" data-number="3.7.3">
<h3 data-number="3.7.3" class="anchored" data-anchor-id="posterior-predictive-checking"><span class="header-section-number">3.7.3</span> Posterior predictive checking</h3>
<p></p>
<p>In Chapter 8 Section 8.7, we illustrated the usefulness of the posterior predictive checking in model checking. The basic idea is to simulate a number of replicated datasets from the posterior predictive distribution and see how the observed sample compares to the replications. If the observed data does resemble the replications, one says that the observed data is consistent with predicted data from the Bayesian model.</p>
<p>For our Buffalo snowfall example, suppose one wishes to simulate a replicated sample from the posterior predictive distribution. Since our original sample size was <span class="math inline">\(n = 20\)</span>, the intent is to simulate a sample of values <span class="math inline">\(\tilde y_1, ..., \tilde y_{20}\)</span> from the posterior predictive distribution. A single replicated sample is simulated in the following two steps.</p>
<ol type="1">
<li>We draw a set of parameter values, say <span class="math inline">\(\mu^*, \sigma^*\)</span> from the posterior distribution of <span class="math inline">\((\mu, \sigma)\)</span>.<br>
</li>
<li>Given these parameter values, we simulate <span class="math inline">\(\tilde y_1, ..., \tilde y_{20}\)</span> from the Normal sampling density with mean <span class="math inline">\(\mu^*\)</span> and standard deviation <span class="math inline">\(\sigma^*\)</span>.</li>
</ol>
<p>Recall that the simulated posterior values are stored in the matrix <code>post</code>. We write a function <code>postpred_sim()</code> to simulate one sample from the predictive distribution.</p>
<pre><code>post &lt;- data.frame(posterior$mcmc[[1]])
postpred_sim &lt;- function(j){
  rnorm(20, mean = post[j, "mu"],
        sd = post[j, "sigma"])
}
print(postpred_sim(1), digits = 3)
 [1]   5.37  10.91  40.87  15.94  16.93  43.49  22.48
 [8]  -6.43   3.26   7.30  35.27  20.79  21.47  16.62
[15]   5.45  44.69  23.10 -18.18  26.51   6.84</code></pre>
<p>If this process is repeated for each of the 5000 draws from the posterior distribution, then one obtains 5000 samples of size 20 drawn from the predictive distribution. In R, the function <code>sapply()</code> is used together with <code>postpred_sim()</code> to simulate 5000 samples that are stored in the matrix <code>ypred</code>.</p>
<pre><code>ypred &lt;- t(sapply(1:5000, postpred_sim))</code></pre>
<p>Figure 9.16 displays histograms of the predicted snowfalls from eight of these simulated samples and the observed snowfall measurements are displayed in the lower right panel. Generally, the center and spread of the observed snowfalls appear to be similar in appearance to the eight predicted snowfall samples from the fitted model. Can we detect any differences between the distribution of observed snowfalls and the distributions of predicted snowfalls? One concern is that some of the predictive samples contain negative snowfall values. Another concern from this inspection is that we observed a snowfall of 65.1 inches in our sample and none of our eight samples had a snowfall this large. Perhaps there is an outlier in our sample that is not consistent with predictions from our model.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/ppcheck1.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Histograms of eight simulated predictive samples and the observed sample for the snowfall example.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>When one notices a possible discrepancy between the observed sample and simulated prediction samples, one thinks of a checking function <span class="math inline">\(T()\)</span> that will distinguish the two types of samples. In this situation since we noticed the extreme snowfall of 65.1 inches, that suggests that we use <span class="math inline">\(T(y) = \max y\)</span> as a checking function.</p>
<p>Once one decides on a checking function <span class="math inline">\(T()\)</span>, then one simulates the posterior predictive distribution of <span class="math inline">\(T(\tilde y)\)</span>. This is conveniently done by evaluating the function <span class="math inline">\(T()\)</span> on each simulated sample from the predictive distribution. In R, this is conveniently done using the <code>apply()</code> function and the values of <span class="math inline">\(T(\tilde y)\)</span> are stored in the vector <code>postpred_max</code>.</p>
<pre><code>postpred_max &lt;- apply(ypred, 1, max)</code></pre>
<p>If the checking function evaluated at the observed sample <span class="math inline">\(T(y)\)</span> is not consistent with the distribution of <span class="math inline">\(T(\tilde y)\)</span>, then predictions from the model are not similar to the observed data and there is some issue with the model assumptions. Figure 9.17 displays a histogram of the predictive distribution of <span class="math inline">\(T(y)\)</span> in our example where <span class="math inline">\(T()\)</span> is the maximum function, and the observed maximum snowfall is shown by a vertical line. Here the observed maximum is in the right tail of the posterior predictive distribution – the interpretation is that this largest snowfall of 65.1 inches is not predicted from the model. In this case, one might want to think about revising the sampling model, say, by assuming that the data follow a distribution with flatter tails than the Normal.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/ppcheck2.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Histogram of the posterior predictive distribution of T(y) where T() is the maximum function. The vertical line shows the location of the observed value T(y).</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="comparing-two-proportions" class="level3" data-number="3.7.4">
<h3 data-number="3.7.4" class="anchored" data-anchor-id="comparing-two-proportions"><span class="header-section-number">3.7.4</span> Comparing two proportions</h3>
<p></p>
<p>To illustrate the usefulness of the JAGS software, we consider a problem comparing two proportions from independent samples. The model is defined in a JAGS script, the data and values of prior parameters are entered through a list, and the <code>run.jags()</code> function is used to simulate from the posterior of the parameters by an MCMC algorithm.</p>
<p>To better understand the behavior of Facebook users, a survey was administered in 2011 to 244 students. Each student was asked their gender and the average number of times they visited Facebook in a day. We say that the number of daily visits is “high” if the number of visits is 5 or more; otherwise it is “low”. If we classify the sample by gender and daily visits, one obtains the two by two table of counts as shown in Table 9.1.</p>
<p>Table 9.1. Two-way table of counts of students by gender and Facebook visits.</p>
<table class="table">
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Low</td>
</tr>
<tr class="even">
<td style="text-align: center;">Male</td>
<td style="text-align: center;">(y_M)</td>
<td style="text-align: center;">(n_M - y_M)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Female</td>
<td style="text-align: center;">(y_F)</td>
<td style="text-align: center;">(n_F - y_F)</td>
</tr>
</tbody>
</table>
<p>In Table 9.1, the random variable <span class="math inline">\(Y_M\)</span> represents the number of males who have a high number of Facebook visits in a sample of <span class="math inline">\(n_M\)</span>, and <span class="math inline">\(Y_F\)</span> and <span class="math inline">\(n_M\)</span> are the analogous count and sample size for women. Assuming that the sample survey represents a random sample from all students using Facebook, then it is reasonable to assume that <span class="math inline">\(Y_M\)</span> and <span class="math inline">\(Y_F\)</span> are independent with <span class="math inline">\(Y_M\)</span> distributed Binomial with parameters <span class="math inline">\(n_M\)</span> and <span class="math inline">\(p_M\)</span>, and <span class="math inline">\(Y_F\)</span> is Binomial with parameters <span class="math inline">\(n_F\)</span> and <span class="math inline">\(p_F\)</span>.</p>
<p>Table 9.2. Probability structure in two-way table.</p>
<table class="table">
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Low</td>
</tr>
<tr class="even">
<td style="text-align: center;">Male</td>
<td style="text-align: center;">(p_M)</td>
<td style="text-align: center;">(1 - p_M)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Female</td>
<td style="text-align: center;">(p_F)</td>
<td style="text-align: center;">(1 - p_F)</td>
</tr>
</tbody>
</table>
<p>The probabilities <span class="math inline">\(p_M\)</span> and <span class="math inline">\(p_F\)</span> are displayed in Table 9.2. In this type of data structure, one is interested in the association between gender and Facebook visits. Define the odds as the ratio of the probability of “high” to the probability of “low”. The odds of “high” for the men and odds of ’high” for the women are defined by <span class="math display">\[\begin{equation}
\frac{p_M}{1 - p_M},
\end{equation}\]</span> and <span class="math display">\[\begin{equation}
\frac{p_F}{1-p_F},
\end{equation}\]</span> respectively. The odds ratio <span class="math display">\[\begin{equation}
\alpha = \frac{p_M / (1 - p_M)}{p_F / (1 - p_F)},
\end{equation}\]</span> is a measure of association in this two-way table. If <span class="math inline">\(\alpha = 1\)</span>, this means that <span class="math inline">\(p_M = p_L\)</span> – this says that tendency to have high visits to Facebook does not depend on gender. If <span class="math inline">\(\alpha &gt; 1\)</span>, this indicates that men are more likely to have high visits to Facebook, and a value <span class="math inline">\(\alpha &lt; 1\)</span> indicates that women are more likely to have high visits. Sometimes association is expressed on a log scale – the log odds ratio <span class="math inline">\(\lambda\)</span> is written as <span class="math display">\[\begin{equation}
\lambda = \log \alpha = \log\left(\frac{p_M} {1 - p_M}\right) - \log\left(\frac{p_F} {1 - p_F}\right).
\end{equation}\]</span> That is, the log odds ratio is expressed as the difference in the logits of the men and women probabilities, where the logit of a probability <span class="math inline">\(p\)</span> is equal to <span class="math inline">\({\rm logit}(p) = \log(p) - \log(1 - p)\)</span>. If gender is independent of Facebook visits, then <span class="math inline">\(\lambda = 0\)</span>.</p>
<p>One’s prior beliefs about association in the two-way table is expressed in terms of logits and the log odds ratio. If one believes that gender and Facebook visits are independent, then the log odds ratio is assigned a Normal prior with mean 0 and standard deviation <span class="math inline">\(\sigma\)</span>. The mean of 0 reflects the prior guess of independence and <span class="math inline">\(\sigma\)</span> indicates the strength of the belief in independence. If one believed strongly in independence, then one would assign <span class="math inline">\(\sigma\)</span> a small value.</p>
<p>In addition, let <span class="math display">\[\begin{equation}
\theta = \frac{{\rm logit}(p_M) + \rm{logit}(p_F)}{2}
\end{equation}\]</span> be the mean of the logits, and assume that <span class="math inline">\(\theta\)</span> has a Normal prior with mean <span class="math inline">\(\theta_0\)</span> and standard deviation <span class="math inline">\(\sigma_0\)</span> (precision <span class="math inline">\(\phi_0\)</span>). The prior on <span class="math inline">\(\theta\)</span> reflects beliefs about the general size of the proportions on the logit scale.</p>
<p>To fit this model using JAGS, the following script, saved in <code>modelString</code>, is written defining the model.</p>
<pre><code>modelString = "
model{
## sampling
yF ~ dbin(pF, nF)
yM ~ dbin(pM, nM)
logit(pF) &lt;- theta - lambda / 2
logit(pM) &lt;- theta + lambda / 2
## priors
theta ~ dnorm(mu0, phi0)
lambda ~ dnorm(0, phi)
}
"</code></pre>
<p>In the sampling part of the script, the two first lines define the Binomial sampling models, and the logits of the probabilities are defined in terms of the log odds ratio <code>lambda</code> and the mean of the logits <code>theta</code>. In the priors part of the script, note that <code>theta</code> is assigned a Normal prior with mean <code>mu0</code> and precision <code>phi0</code>, and <code>lambda</code> is assigned a Normal prior with mean 0 and precision <code>phi</code>.</p>
<p>When the sample survey is conducted, one observes that 75 of the 151 female students say that they are high visitors of Facebook, and 39 of the 93 male students are high visitors. This data and the values of the prior parameters are entered into R by use of a list. Note that <code>phi = 2</code> indicating some belief that gender is independent of Facebook visits, and <code>mu0 = 0</code> and <code>phi0 = 0.001</code> reflecting little knowledge about the location of the logit proportions. Using the <code>run.jags()</code> function, we take an adapt period of 1000, burn-in period of 5000 iterations and collect 5000 iterations, storing values of <code>pF</code>, <code>pM</code> and the log odds ratio <code>lambda</code>.</p>
<pre><code>the_data &lt;- list("yF" = 75, "nF" = 151, 
                 "yM" = 39, "nM" = 93,
                 "mu0" = 0, "phi0" = 0.001, "phi" = 2)

posterior &lt;- run.jags(modelString,
                 data = the_data,
                 n.chains = 1,
                 monitor = c("pF", "pM", "lambda"),
                 adapt = 1000,
                 burnin = 5000,
                 sample = 5000)</code></pre>
<p>Since the main goal is to learn about the association structure in the table, Figure 9.18 displays a density estimate of the posterior draws of the log odds ratio <span class="math inline">\(\lambda\)</span>. A reference line at <span class="math inline">\(\lambda = 0\)</span> is drawn on the graph which corresponds to the case where <span class="math inline">\(p_M = p_L\)</span>. What is the probability that women are more likely than men to have high visits in Facebook? This is directly answered by computing the posterior probability <span class="math inline">\(Prob(\lambda &lt; 0 \mid data)\)</span> that is computed to be 0.874. Based on this computation, one concludes that it is very probable that women have a higher tendency than men to have high visits on Facebook.</p>
<pre><code>post &lt;- data.frame(posterior$mcmc[[1]])
post %&gt;% 
  summarize(Prob = mean(lambda &lt; 0))
      Prob
1 0.874</code></pre>
<p>In the end-of-chapter exercises, the reader will be asked to perform further explorations with this two proportion model.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/chapter9/jags4.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Posterior density estimate of simulated draws of log odds ratio for visits to Facebook example. A vertical line is drawn at the value 0 corresponding to no association between gender and visits to Facebook.</figcaption><p></p>
</figure>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./mean.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Modeling Measurement and Count Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./hierarchical.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayesian Hierarchical Modeling</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>