<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Simulation by Markov Chain Monte Carlo | Probability and Bayesian Modeling</title>
  <meta name="description" content="This is an introduction to probability and Bayesian modeling at the undergraduate level. It assumes the student has some background with calculus." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Simulation by Markov Chain Monte Carlo | Probability and Bayesian Modeling" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an introduction to probability and Bayesian modeling at the undergraduate level. It assumes the student has some background with calculus." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Simulation by Markov Chain Monte Carlo | Probability and Bayesian Modeling" />
  
  <meta name="twitter:description" content="This is an introduction to probability and Bayesian modeling at the undergraduate level. It assumes the student has some background with calculus." />
  

<meta name="author" content="Jim Albert and Jingchen Hu" />


<meta name="date" content="2020-07-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mean.html"/>
<link rel="next" href="bayesian-hierarchical-modeling.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Probability and Bayesian Modeling</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html"><i class="fa fa-check"></i><b>1</b> Probability: A Measurement of Uncertainty</a><ul>
<li class="chapter" data-level="1.1" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-classical-view-of-a-probability"><i class="fa fa-check"></i><b>1.2</b> The Classical View of a Probability</a></li>
<li class="chapter" data-level="1.3" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-frequency-view-of-a-probability"><i class="fa fa-check"></i><b>1.3</b> The Frequency View of a Probability</a></li>
<li class="chapter" data-level="1.4" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-subjective-view-of-a-probability"><i class="fa fa-check"></i><b>1.4</b> The Subjective View of a Probability</a></li>
<li class="chapter" data-level="1.5" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-sample-space"><i class="fa fa-check"></i><b>1.5</b> The Sample Space</a></li>
<li class="chapter" data-level="1.6" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#assigning-probabilities"><i class="fa fa-check"></i><b>1.6</b> Assigning Probabilities</a></li>
<li class="chapter" data-level="1.7" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#events-and-event-operations"><i class="fa fa-check"></i><b>1.7</b> Events and Event Operations</a></li>
<li class="chapter" data-level="1.8" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-three-probability-axioms"><i class="fa fa-check"></i><b>1.8</b> The Three Probability Axioms</a></li>
<li class="chapter" data-level="1.9" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-complement-and-addition-properties"><i class="fa fa-check"></i><b>1.9</b> The Complement and Addition Properties</a></li>
<li class="chapter" data-level="1.10" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#exercises"><i class="fa fa-check"></i><b>1.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="counting-methods.html"><a href="counting-methods.html"><i class="fa fa-check"></i><b>2</b> Counting Methods</a><ul>
<li class="chapter" data-level="2.1" data-path="counting-methods.html"><a href="counting-methods.html#introduction-rolling-dice-yahtzee-and-roulette"><i class="fa fa-check"></i><b>2.1</b> Introduction: Rolling Dice, Yahtzee, and Roulette</a></li>
<li class="chapter" data-level="2.2" data-path="counting-methods.html"><a href="counting-methods.html#equally-likely-outcomes"><i class="fa fa-check"></i><b>2.2</b> Equally Likely Outcomes</a></li>
<li class="chapter" data-level="2.3" data-path="counting-methods.html"><a href="counting-methods.html#the-multiplication-counting-rule"><i class="fa fa-check"></i><b>2.3</b> The Multiplication Counting Rule</a></li>
<li class="chapter" data-level="2.4" data-path="counting-methods.html"><a href="counting-methods.html#permutations"><i class="fa fa-check"></i><b>2.4</b> Permutations</a></li>
<li class="chapter" data-level="2.5" data-path="counting-methods.html"><a href="counting-methods.html#combinations"><i class="fa fa-check"></i><b>2.5</b> Combinations</a><ul>
<li class="chapter" data-level="2.5.1" data-path="counting-methods.html"><a href="counting-methods.html#number-of-subsets"><i class="fa fa-check"></i><b>2.5.1</b> Number of subsets</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="counting-methods.html"><a href="counting-methods.html#arrangements-of-non-distinct-objects"><i class="fa fa-check"></i><b>2.6</b> Arrangements of Non-Distinct Objects</a></li>
<li class="chapter" data-level="2.7" data-path="counting-methods.html"><a href="counting-methods.html#playing-yahtzee"><i class="fa fa-check"></i><b>2.7</b> Playing Yahtzee</a></li>
<li class="chapter" data-level="2.8" data-path="counting-methods.html"><a href="counting-methods.html#exercises"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>3</b> Conditional Probability</a><ul>
<li class="chapter" data-level="3.1" data-path="conditional-probability.html"><a href="conditional-probability.html#introduction-the-three-card-problem"><i class="fa fa-check"></i><b>3.1</b> Introduction: The Three Card Problem</a></li>
<li class="chapter" data-level="3.2" data-path="conditional-probability.html"><a href="conditional-probability.html#in-everyday-life"><i class="fa fa-check"></i><b>3.2</b> In Everyday Life</a></li>
<li class="chapter" data-level="3.3" data-path="conditional-probability.html"><a href="conditional-probability.html#in-a-two-way-table"><i class="fa fa-check"></i><b>3.3</b> In a Two-Way Table</a></li>
<li class="chapter" data-level="3.4" data-path="conditional-probability.html"><a href="conditional-probability.html#definition-and-the-multiplication-rule"><i class="fa fa-check"></i><b>3.4</b> Definition and the Multiplication Rule</a></li>
<li class="chapter" data-level="3.5" data-path="conditional-probability.html"><a href="conditional-probability.html#the-multiplication-rule-under-independence"><i class="fa fa-check"></i><b>3.5</b> The Multiplication Rule Under Independence</a></li>
<li class="chapter" data-level="3.6" data-path="conditional-probability.html"><a href="conditional-probability.html#learning-using-bayes-rule"><i class="fa fa-check"></i><b>3.6</b> Learning Using Bayes’ Rule</a></li>
<li class="chapter" data-level="3.7" data-path="conditional-probability.html"><a href="conditional-probability.html#r-example-learning-about-a-spinner"><i class="fa fa-check"></i><b>3.7</b> R Example: Learning About a Spinner</a></li>
<li class="chapter" data-level="3.8" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discrete-distributions.html"><a href="discrete-distributions.html"><i class="fa fa-check"></i><b>4</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="4.1" data-path="discrete-distributions.html"><a href="discrete-distributions.html#introduction-the-hat-check-problem"><i class="fa fa-check"></i><b>4.1</b> Introduction: The Hat Check Problem</a></li>
<li class="chapter" data-level="4.2" data-path="discrete-distributions.html"><a href="discrete-distributions.html#random-variable-and-probability-distribution"><i class="fa fa-check"></i><b>4.2</b> Random Variable and Probability Distribution</a></li>
<li class="chapter" data-level="4.3" data-path="discrete-distributions.html"><a href="discrete-distributions.html#summarizing-a-probability-distribution"><i class="fa fa-check"></i><b>4.3</b> Summarizing a Probability Distribution</a></li>
<li class="chapter" data-level="4.4" data-path="discrete-distributions.html"><a href="discrete-distributions.html#standard-deviation-of-a-probability-distribution"><i class="fa fa-check"></i><b>4.4</b> Standard Deviation of a Probability Distribution</a></li>
<li class="chapter" data-level="4.5" data-path="discrete-distributions.html"><a href="discrete-distributions.html#coin-tossing-distributions"><i class="fa fa-check"></i><b>4.5</b> Coin-Tossing Distributions</a><ul>
<li class="chapter" data-level="4.5.1" data-path="discrete-distributions.html"><a href="discrete-distributions.html#binomial-probabilities"><i class="fa fa-check"></i><b>4.5.1</b> Binomial probabilities</a></li>
<li class="chapter" data-level="4.5.2" data-path="discrete-distributions.html"><a href="discrete-distributions.html#binomial-computations"><i class="fa fa-check"></i><b>4.5.2</b> Binomial computations</a></li>
<li class="chapter" data-level="4.5.3" data-path="discrete-distributions.html"><a href="discrete-distributions.html#mean-and-standard-deviation-of-a-binomial"><i class="fa fa-check"></i><b>4.5.3</b> Mean and standard deviation of a Binomial</a></li>
<li class="chapter" data-level="4.5.4" data-path="discrete-distributions.html"><a href="discrete-distributions.html#negative-binomial-experiments"><i class="fa fa-check"></i><b>4.5.4</b> Negative Binomial Experiments</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="discrete-distributions.html"><a href="discrete-distributions.html#exercises"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-distributions.html"><a href="continuous-distributions.html"><i class="fa fa-check"></i><b>5</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="5.1" data-path="continuous-distributions.html"><a href="continuous-distributions.html#introduction-a-baseball-spinner-game"><i class="fa fa-check"></i><b>5.1</b> Introduction: A Baseball Spinner Game</a></li>
<li class="chapter" data-level="5.2" data-path="continuous-distributions.html"><a href="continuous-distributions.html#the-uniform-distribution"><i class="fa fa-check"></i><b>5.2</b> The Uniform Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="continuous-distributions.html"><a href="continuous-distributions.html#binomial-probabilities-and-the-normal-curve"><i class="fa fa-check"></i><b>5.3</b> Binomial Probabilities and the Normal Curve</a></li>
<li class="chapter" data-level="5.4" data-path="continuous-distributions.html"><a href="continuous-distributions.html#sampling-distribution-of-the-mean"><i class="fa fa-check"></i><b>5.4</b> Sampling Distribution of the Mean</a></li>
<li class="chapter" data-level="5.5" data-path="continuous-distributions.html"><a href="continuous-distributions.html#exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html"><i class="fa fa-check"></i><b>6</b> Joint Probability Distributions</a><ul>
<li class="chapter" data-level="6.1" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#joint-probability-mass-function-sampling-from-a-box"><i class="fa fa-check"></i><b>6.2</b> Joint Probability Mass Function: Sampling From a Box</a></li>
<li class="chapter" data-level="6.3" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#multinomial-experiments"><i class="fa fa-check"></i><b>6.3</b> Multinomial Experiments</a></li>
<li class="chapter" data-level="6.4" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#joint-density-functions"><i class="fa fa-check"></i><b>6.4</b> Joint Density Functions</a></li>
<li class="chapter" data-level="6.5" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#independence-and-measuring-association"><i class="fa fa-check"></i><b>6.5</b> Independence and Measuring Association</a></li>
<li class="chapter" data-level="6.6" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#flipping-a-random-coin-the-beta-binomial-distribution"><i class="fa fa-check"></i><b>6.6</b> Flipping a Random Coin: The Beta-Binomial Distribution</a></li>
<li class="chapter" data-level="6.7" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#bivariate-normal-distribution"><i class="fa fa-check"></i><b>6.7</b> Bivariate Normal Distribution</a></li>
<li class="chapter" data-level="6.8" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#exercises"><i class="fa fa-check"></i><b>6.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="proportion.html"><a href="proportion.html"><i class="fa fa-check"></i><b>7</b> Learning About a Binomial Probability</a><ul>
<li class="chapter" data-level="7.1" data-path="proportion.html"><a href="proportion.html#introduction-thinking-about-a-proportion-subjectively"><i class="fa fa-check"></i><b>7.1</b> Introduction: Thinking About a Proportion Subjectively</a></li>
<li class="chapter" data-level="7.2" data-path="proportion.html"><a href="proportion.html#bayesian-inference-with-discrete-priors"><i class="fa fa-check"></i><b>7.2</b> Bayesian Inference with Discrete Priors</a><ul>
<li class="chapter" data-level="7.2.1" data-path="proportion.html"><a href="proportion.html#example-students-dining-preference"><i class="fa fa-check"></i><b>7.2.1</b> Example: students’ dining preference</a></li>
<li class="chapter" data-level="7.2.2" data-path="proportion.html"><a href="proportion.html#discrete-prior-distributions-for-proportion-p"><i class="fa fa-check"></i><b>7.2.2</b> Discrete prior distributions for proportion <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="7.2.3" data-path="proportion.html"><a href="proportion.html#likelihood"><i class="fa fa-check"></i><b>7.2.3</b> Likelihood</a></li>
<li class="chapter" data-level="7.2.4" data-path="proportion.html"><a href="proportion.html#posterior-distribution-for-proportion-p"><i class="fa fa-check"></i><b>7.2.4</b> Posterior distribution for proportion <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="7.2.5" data-path="proportion.html"><a href="proportion.html#inference-students-dining-preference"><i class="fa fa-check"></i><b>7.2.5</b> Inference: students’ dining preference</a></li>
<li class="chapter" data-level="7.2.6" data-path="proportion.html"><a href="proportion.html#discussion-using-a-discrete-prior"><i class="fa fa-check"></i><b>7.2.6</b> Discussion: using a discrete prior</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="proportion.html"><a href="proportion.html#continuous-priors"><i class="fa fa-check"></i><b>7.3</b> Continuous Priors</a><ul>
<li class="chapter" data-level="7.3.1" data-path="proportion.html"><a href="proportion.html#the-beta-distribution-and-probabilities"><i class="fa fa-check"></i><b>7.3.1</b> The Beta distribution and probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="proportion.html"><a href="proportion.html#updating-the-beta-prior"><i class="fa fa-check"></i><b>7.4</b> Updating the Beta Prior</a><ul>
<li class="chapter" data-level="7.4.1" data-path="proportion.html"><a href="proportion.html#bayes-rule-calculation"><i class="fa fa-check"></i><b>7.4.1</b> Bayes’ rule calculation</a></li>
<li class="chapter" data-level="7.4.2" data-path="proportion.html"><a href="proportion.html#from-beta-prior-to-beta-posterior"><i class="fa fa-check"></i><b>7.4.2</b> From Beta prior to Beta posterior</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="proportion.html"><a href="proportion.html#bayesian-inferences-with-continuous-priors"><i class="fa fa-check"></i><b>7.5</b> Bayesian Inferences with Continuous Priors</a><ul>
<li class="chapter" data-level="7.5.1" data-path="proportion.html"><a href="proportion.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>7.5.1</b> Bayesian hypothesis testing</a></li>
<li class="chapter" data-level="7.5.2" data-path="proportion.html"><a href="proportion.html#bayesian-credible-intervals"><i class="fa fa-check"></i><b>7.5.2</b> Bayesian credible intervals</a></li>
<li class="chapter" data-level="7.5.3" data-path="proportion.html"><a href="proportion.html#bayesian-prediction"><i class="fa fa-check"></i><b>7.5.3</b> Bayesian prediction</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="proportion.html"><a href="proportion.html#predictive-checking"><i class="fa fa-check"></i><b>7.6</b> Predictive Checking</a><ul>
<li class="chapter" data-level="7.6.1" data-path="proportion.html"><a href="proportion.html#comparing-bayesian-models"><i class="fa fa-check"></i><b>7.6.1</b> Comparing Bayesian models</a></li>
<li class="chapter" data-level="7.6.2" data-path="proportion.html"><a href="proportion.html#posterior-predictive-checking"><i class="fa fa-check"></i><b>7.6.2</b> Posterior predictive checking</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="proportion.html"><a href="proportion.html#exercises"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mean.html"><a href="mean.html"><i class="fa fa-check"></i><b>8</b> Modeling Measurement and Count Data</a><ul>
<li class="chapter" data-level="8.1" data-path="mean.html"><a href="mean.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="mean.html"><a href="mean.html#modeling-measurements"><i class="fa fa-check"></i><b>8.2</b> Modeling Measurements</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mean.html"><a href="mean.html#examples"><i class="fa fa-check"></i><b>8.2.1</b> Examples</a></li>
<li class="chapter" data-level="8.2.2" data-path="mean.html"><a href="mean.html#the-general-approach"><i class="fa fa-check"></i><b>8.2.2</b> The general approach</a></li>
<li class="chapter" data-level="8.2.3" data-path="mean.html"><a href="mean.html#outline-of-chapter"><i class="fa fa-check"></i><b>8.2.3</b> Outline of chapter</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mean.html"><a href="mean.html#Normal:Discrete"><i class="fa fa-check"></i><b>8.3</b> Bayesian Inference with Discrete Priors</a><ul>
<li class="chapter" data-level="8.3.1" data-path="mean.html"><a href="mean.html#Normal:Discrete:Roger"><i class="fa fa-check"></i><b>8.3.1</b> Example: Roger Federer’s time-to-serve</a></li>
<li class="chapter" data-level="8.3.2" data-path="mean.html"><a href="mean.html#Normal:SamplingModel:derivation"><i class="fa fa-check"></i><b>8.3.2</b> Simplification of the likelihood</a></li>
<li class="chapter" data-level="8.3.3" data-path="mean.html"><a href="mean.html#Normal:SamplingModel:inference"><i class="fa fa-check"></i><b>8.3.3</b> Inference: Federer’s time-to-serve</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="mean.html"><a href="mean.html#Normal:Continuous"><i class="fa fa-check"></i><b>8.4</b> Continuous Priors</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mean.html"><a href="mean.html#Normal:Continuous:prior"><i class="fa fa-check"></i><b>8.4.1</b> The Normal prior for mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="8.4.2" data-path="mean.html"><a href="mean.html#Normal:Continuous:choosing"><i class="fa fa-check"></i><b>8.4.2</b> Choosing a Normal prior</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mean.html"><a href="mean.html#Normal:ContinuousUpdate"><i class="fa fa-check"></i><b>8.5</b> Updating the Normal Prior</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mean.html"><a href="mean.html#introduction-1"><i class="fa fa-check"></i><b>8.5.1</b> Introduction</a></li>
<li class="chapter" data-level="8.5.2" data-path="mean.html"><a href="mean.html#Normal:ContinuousUpdate:Overview"><i class="fa fa-check"></i><b>8.5.2</b> A quick peak at the update procedure</a></li>
<li class="chapter" data-level="8.5.3" data-path="mean.html"><a href="mean.html#Normal:ContinuousUpdate:BayesRule"><i class="fa fa-check"></i><b>8.5.3</b> Bayes’ rule calculation</a></li>
<li class="chapter" data-level="8.5.4" data-path="mean.html"><a href="mean.html#Normal:ContinuousUpdate:Conjugate"><i class="fa fa-check"></i><b>8.5.4</b> Conjugate Normal prior</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mean.html"><a href="mean.html#Normal:ContinuousInference"><i class="fa fa-check"></i><b>8.6</b> Bayesian Inferences for Continuous Normal Mean</a><ul>
<li class="chapter" data-level="8.6.1" data-path="mean.html"><a href="mean.html#Normal:ContinuousInference:HTandCI"><i class="fa fa-check"></i><b>8.6.1</b> Bayesian hypothesis testing and credible interval</a></li>
<li class="chapter" data-level="8.6.2" data-path="mean.html"><a href="mean.html#Normal:ContinuousInference:Prediction"><i class="fa fa-check"></i><b>8.6.2</b> Bayesian prediction</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="mean.html"><a href="mean.html#Normal:PPC"><i class="fa fa-check"></i><b>8.7</b> Posterior Predictive Checking</a></li>
<li class="chapter" data-level="8.8" data-path="mean.html"><a href="mean.html#modeling-count-data"><i class="fa fa-check"></i><b>8.8</b> Modeling Count Data</a><ul>
<li class="chapter" data-level="8.8.1" data-path="mean.html"><a href="mean.html#examples-1"><i class="fa fa-check"></i><b>8.8.1</b> Examples</a></li>
<li class="chapter" data-level="8.8.2" data-path="mean.html"><a href="mean.html#the-poisson-distribution"><i class="fa fa-check"></i><b>8.8.2</b> The Poisson distribution</a></li>
<li class="chapter" data-level="8.8.3" data-path="mean.html"><a href="mean.html#bayesian-inferences"><i class="fa fa-check"></i><b>8.8.3</b> Bayesian inferences</a></li>
<li class="chapter" data-level="8.8.4" data-path="mean.html"><a href="mean.html#case-study-learning-about-website-counts"><i class="fa fa-check"></i><b>8.8.4</b> Case study: Learning about website counts</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="mean.html"><a href="mean.html#exercises"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>9</b> Simulation by Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="9.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#introduction"><i class="fa fa-check"></i><b>9.1</b> Introduction</a><ul>
<li class="chapter" data-level="9.1.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#the-bayesian-computation-problem"><i class="fa fa-check"></i><b>9.1.1</b> The Bayesian computation problem</a></li>
<li class="chapter" data-level="9.1.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#choosing-a-prior"><i class="fa fa-check"></i><b>9.1.2</b> Choosing a prior</a></li>
<li class="chapter" data-level="9.1.3" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#the-two-parameter-normal-problem"><i class="fa fa-check"></i><b>9.1.3</b> The two-parameter Normal problem</a></li>
<li class="chapter" data-level="9.1.4" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#overview-of-the-chapter"><i class="fa fa-check"></i><b>9.1.4</b> Overview of the chapter</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#markov-chains"><i class="fa fa-check"></i><b>9.2</b> Markov Chains</a><ul>
<li class="chapter" data-level="9.2.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#definition"><i class="fa fa-check"></i><b>9.2.1</b> Definition</a></li>
<li class="chapter" data-level="9.2.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#some-properties"><i class="fa fa-check"></i><b>9.2.2</b> Some properties</a></li>
<li class="chapter" data-level="9.2.3" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#simulating-a-markov-chain"><i class="fa fa-check"></i><b>9.2.3</b> Simulating a Markov chain</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#the-metropolis-algorithm"><i class="fa fa-check"></i><b>9.3</b> The Metropolis Algorithm</a><ul>
<li class="chapter" data-level="9.3.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#example-walking-on-a-number-line"><i class="fa fa-check"></i><b>9.3.1</b> Example: Walking on a number line</a></li>
<li class="chapter" data-level="9.3.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#the-general-algorithm"><i class="fa fa-check"></i><b>9.3.2</b> The general algorithm</a></li>
<li class="chapter" data-level="9.3.3" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#a-general-function-for-the-metropolis-algorithm"><i class="fa fa-check"></i><b>9.3.3</b> A general function for the Metropolis algorithm</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#example-cauchy-normal-problem"><i class="fa fa-check"></i><b>9.4</b> Example: Cauchy-Normal problem</a><ul>
<li class="chapter" data-level="9.4.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#choice-of-starting-value-and-proposal-region"><i class="fa fa-check"></i><b>9.4.1</b> Choice of starting value and proposal region</a></li>
<li class="chapter" data-level="9.4.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#collecting-the-simulated-draws"><i class="fa fa-check"></i><b>9.4.2</b> Collecting the simulated draws</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#gibbs-sampling"><i class="fa fa-check"></i><b>9.5</b> Gibbs Sampling</a><ul>
<li class="chapter" data-level="9.5.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#bivariate-discrete-distribution"><i class="fa fa-check"></i><b>9.5.1</b> Bivariate discrete distribution}</a></li>
<li class="chapter" data-level="9.5.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#beta-binomial-sampling"><i class="fa fa-check"></i><b>9.5.2</b> Beta-binomial sampling</a></li>
<li class="chapter" data-level="9.5.3" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#normal-sampling-both-parameters-unknown"><i class="fa fa-check"></i><b>9.5.3</b> Normal sampling – both parameters unknown</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#mcmc-inputs-and-diagnostics"><i class="fa fa-check"></i><b>9.6</b> MCMC Inputs and Diagnostics</a><ul>
<li class="chapter" data-level="9.6.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#burn-in-starting-values-and-multiple-chains"><i class="fa fa-check"></i><b>9.6.1</b> Burn-in, starting values, and multiple chains</a></li>
<li class="chapter" data-level="9.6.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#diagnostics"><i class="fa fa-check"></i><b>9.6.2</b> Diagnostics</a></li>
<li class="chapter" data-level="9.6.3" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#graphs-and-summaries"><i class="fa fa-check"></i><b>9.6.3</b> Graphs and summaries</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#using-jags"><i class="fa fa-check"></i><b>9.7</b> Using JAGS</a><ul>
<li class="chapter" data-level="9.7.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#normal-sampling-model"><i class="fa fa-check"></i><b>9.7.1</b> Normal sampling model</a></li>
<li class="chapter" data-level="9.7.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#multiple-chains"><i class="fa fa-check"></i><b>9.7.2</b> Multiple chains</a></li>
<li class="chapter" data-level="9.7.3" data-path="proportion.html"><a href="proportion.html#posterior-predictive-checking"><i class="fa fa-check"></i><b>9.7.3</b> Posterior predictive checking</a></li>
<li class="chapter" data-level="9.7.4" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#comparing-two-proportions"><i class="fa fa-check"></i><b>9.7.4</b> Comparing two proportions</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#exercises"><i class="fa fa-check"></i><b>9.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html"><i class="fa fa-check"></i><b>10</b> Bayesian Hierarchical Modeling</a><ul>
<li class="chapter" data-level="10.1" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html#introduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html#hierarchical-normal-modeling"><i class="fa fa-check"></i><b>10.2</b> Hierarchical Normal Modeling</a></li>
<li class="chapter" data-level="10.3" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html#hierarchical-beta-binomial-modeling"><i class="fa fa-check"></i><b>10.3</b> Hierarchical Beta-Binomial Modeling</a></li>
<li class="chapter" data-level="10.4" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html#exercises"><i class="fa fa-check"></i><b>10.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#example-prices-and-areas-of-house-sales"><i class="fa fa-check"></i><b>11.2</b> Example: Prices and Areas of House Sales</a></li>
<li class="chapter" data-level="11.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#a-simple-linear-regression-model"><i class="fa fa-check"></i><b>11.3</b> A Simple Linear Regression Model</a></li>
<li class="chapter" data-level="11.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#a-weakly-informative-prior"><i class="fa fa-check"></i><b>11.4</b> A Weakly Informative Prior</a></li>
<li class="chapter" data-level="11.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#posterior-analysis"><i class="fa fa-check"></i><b>11.5</b> Posterior Analysis</a></li>
<li class="chapter" data-level="11.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-through-mcmc"><i class="fa fa-check"></i><b>11.6</b> Inference through MCMC</a></li>
<li class="chapter" data-level="11.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#bayesian-inferences-with-simple-linear-regression"><i class="fa fa-check"></i><b>11.7</b> Bayesian Inferences with Simple Linear Regression</a></li>
<li class="chapter" data-level="11.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#informative-prior"><i class="fa fa-check"></i><b>11.8</b> Informative Prior</a></li>
<li class="chapter" data-level="11.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#a-conditional-means-prior"><i class="fa fa-check"></i><b>11.9</b> A Conditional Means Prior</a></li>
<li class="chapter" data-level="11.10" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercises"><i class="fa fa-check"></i><b>11.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html"><i class="fa fa-check"></i><b>12</b> Bayesian Multiple Regression and Logistic Models</a><ul>
<li class="chapter" data-level="12.1" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#introduction"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#bayesian-multiple-linear-regression"><i class="fa fa-check"></i><b>12.2</b> Bayesian Multiple Linear Regression</a></li>
<li class="chapter" data-level="12.3" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#comparing-regression-models"><i class="fa fa-check"></i><b>12.3</b> Comparing Regression Models</a></li>
<li class="chapter" data-level="12.4" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#bayesian-logistic-regression"><i class="fa fa-check"></i><b>12.4</b> Bayesian Logistic Regression </a></li>
<li class="chapter" data-level="12.5" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#exercises"><i class="fa fa-check"></i><b>12.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="case-studies.html"><a href="case-studies.html"><i class="fa fa-check"></i><b>13</b> Case Studies</a><ul>
<li class="chapter" data-level="13.1" data-path="case-studies.html"><a href="case-studies.html#introduction"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="case-studies.html"><a href="case-studies.html#federalist-papers-study"><i class="fa fa-check"></i><b>13.2</b> Federalist Papers Study</a><ul>
<li class="chapter" data-level="13.2.1" data-path="case-studies.html"><a href="case-studies.html#introduction"><i class="fa fa-check"></i><b>13.2.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2.2" data-path="case-studies.html"><a href="case-studies.html#data-on-word-use"><i class="fa fa-check"></i><b>13.2.2</b> Data on word use</a></li>
<li class="chapter" data-level="13.2.3" data-path="case-studies.html"><a href="case-studies.html#poisson-density-sampling"><i class="fa fa-check"></i><b>13.2.3</b> Poisson density sampling</a></li>
<li class="chapter" data-level="13.2.4" data-path="case-studies.html"><a href="case-studies.html#negative-binomial-sampling"><i class="fa fa-check"></i><b>13.2.4</b> Negative Binomial sampling</a></li>
<li class="chapter" data-level="13.2.5" data-path="case-studies.html"><a href="case-studies.html#comparison-of-rates-for-two-authors"><i class="fa fa-check"></i><b>13.2.5</b> Comparison of rates for two authors</a></li>
<li class="chapter" data-level="13.2.6" data-path="case-studies.html"><a href="case-studies.html#which-words-distinguish-the-two-authors"><i class="fa fa-check"></i><b>13.2.6</b> Which words distinguish the two authors?</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="case-studies.html"><a href="case-studies.html#career-trajectories"><i class="fa fa-check"></i><b>13.3</b> Career Trajectories</a><ul>
<li class="chapter" data-level="13.3.1" data-path="case-studies.html"><a href="case-studies.html#introduction-2"><i class="fa fa-check"></i><b>13.3.1</b> Introduction</a></li>
<li class="chapter" data-level="13.3.2" data-path="case-studies.html"><a href="case-studies.html#measuring-hitting-performance-in-baseball"><i class="fa fa-check"></i><b>13.3.2</b> Measuring hitting performance in baseball</a></li>
<li class="chapter" data-level="13.3.3" data-path="case-studies.html"><a href="case-studies.html#a-hitters-career-trajectory"><i class="fa fa-check"></i><b>13.3.3</b> A hitter’s career trajectory</a></li>
<li class="chapter" data-level="13.3.4" data-path="case-studies.html"><a href="case-studies.html#estimating-a-single-trajectory"><i class="fa fa-check"></i><b>13.3.4</b> Estimating a single trajectory</a></li>
<li class="chapter" data-level="13.3.5" data-path="case-studies.html"><a href="case-studies.html#estimating-many-trajectories-by-a-hierarchical-model"><i class="fa fa-check"></i><b>13.3.5</b> Estimating many trajectories by a hierarchical model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="case-studies.html"><a href="case-studies.html#latent-class-modeling"><i class="fa fa-check"></i><b>13.4</b> Latent Class Modeling</a><ul>
<li class="chapter" data-level="13.4.1" data-path="case-studies.html"><a href="case-studies.html#two-classes-of-test-takers"><i class="fa fa-check"></i><b>13.4.1</b> Two classes of test takers</a></li>
<li class="chapter" data-level="13.4.2" data-path="case-studies.html"><a href="case-studies.html#a-latent-class-model-with-two-classes"><i class="fa fa-check"></i><b>13.4.2</b> A latent class model with two classes</a></li>
<li class="chapter" data-level="13.4.3" data-path="case-studies.html"><a href="case-studies.html#disputed-authorship-of-the-federalist-papers"><i class="fa fa-check"></i><b>13.4.3</b> Disputed authorship of the Federalist Papers</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="case-studies.html"><a href="case-studies.html#exercises"><i class="fa fa-check"></i><b>13.5</b> Exercises</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probability and Bayesian Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simulation-by-markov-chain-monte-carlo" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Simulation by Markov Chain Monte Carlo</h1>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">9.1</span> Introduction</h2>
<p></p>
<div id="the-bayesian-computation-problem" class="section level3">
<h3><span class="header-section-number">9.1.1</span> The Bayesian computation problem</h3>
<p></p>
<p>The Bayesian models in Chapters 7 and 8 describe the application of conjugate priors where the prior and posterior belong to the same family of distributions. In these cases, the posterior distribution has a convenient functional form such as a Beta density or Normal density, and the posterior distributions are easy to summarize. For example, if the posterior density has a Normal form, one uses the R functions <code>pnorm()</code> and <code>qnorm()</code> to compute posterior probabilities and quantiles.</p>
<p>In a general Bayesian problem, the data <span class="math inline">\(Y\)</span> comes from a sampling density <span class="math inline">\(f(y \mid \theta)\)</span> and the parameter <span class="math inline">\(\theta\)</span> is assigned a prior density <span class="math inline">\(\pi(\theta)\)</span>.
After <span class="math inline">\(Y = y\)</span> has been observed, the likelihood function is equal to <span class="math inline">\(L(\theta) = f(y \mid \theta)\)</span> and the posterior density is written as
<span class="math display" id="eq:posterior">\[\begin{equation}
\pi(\theta \mid y) = \frac{\pi(\theta) L(\theta)}
{\int \pi(\theta) L(\theta) d\theta}.
\tag{9.1}
\end{equation}\]</span>
If the prior and likelihood function do not combine in a helpful way, the normalizing constant <span class="math inline">\(\int \pi(\theta) L(\theta) d\theta\)</span> can not be evaluated analytically. In addition, summaries of the posterior distribution are expressed as ratios of integrals. For example, the posterior mean of <span class="math inline">\(\theta\)</span> is given by
<span class="math display" id="eq:postmean">\[\begin{equation}
E(\theta \mid y) = \frac{\int \theta \pi(\theta) L(\theta) d\theta}
{\int \pi(\theta) L(\theta) d\theta}.
\tag{9.2}
\end{equation}\]</span>
Computation of the posterior mean requires the evaluation of two integrals, each not expressible in closed-form.</p>
<p>The following sections illustrate this general problem where integrals of the product of the likelihood and prior can not be evaluated analytically and so there are challenges in summarizing the posterior distribution.</p>
</div>
<div id="choosing-a-prior" class="section level3">
<h3><span class="header-section-number">9.1.2</span> Choosing a prior</h3>
<p></p>
<p>Suppose you are planning to move to Buffalo, New York. You currently live on the west coast of the United States where the weather is warm and you are wondering about the snowfall you will encounter in Buffalo in the following winter season.</p>
<p>Suppose you focus on the quantity <span class="math inline">\(\mu\)</span>, the average snowfall during the month of January. After some reflection, you are 50 percent confident that <span class="math inline">\(\mu\)</span> falls between 8 and 12 inches. That is, the 25th percentile of your prior for <span class="math inline">\(\mu\)</span> is 8 inches and the 75th percentile is 12 inches.</p>
<p><strong>A Normal prior</strong></p>
<p>Once you have figured out your prior information, you construct a prior density for <span class="math inline">\(\mu\)</span> that matches this information. In one of the end-of-chapter exercises, you can confirm that one possible density matching this information is a Normal density with mean 10 and standard deviation 3.</p>
<p>We collect data for the last 20 seasons in January. Assume that these observations of January snowfall are Normally distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. For simplicity we assume that the sampling standard deviation <span class="math inline">\(\sigma\)</span> is equal to the observed standard deviation <span class="math inline">\(s\)</span>. The observed sample mean <span class="math inline">\(\bar y\)</span> and corresponding standard error are given by <span class="math inline">\(\bar y = 26.785\)</span>
and <span class="math inline">\(se = s / \sqrt{n} = 3.236\)</span>.</p>

<p>With this Normal prior and Normal sampling, results from Chapter 8 are applied to find the posterior distribution of <span class="math inline">\(\mu\)</span>.<br />
The <code>normal_update()</code> function is used to find the mean and standard deviation of the Normal posterior distribution.</p>
<pre><code>(post1 &lt;- normal_update(c(10, 3), c(ybar, se)))
[1] 17.75676  2.20020</code></pre>
<p>In Figure 9.1 the prior, likelihood, and posterior are displayed on the same graph. Initially you believed that <span class="math inline">\(\mu\)</span> was close to 10 inches, the data says that the mean is in the neighborhood of 26.75 inches, and the posterior is a compromise, where <span class="math inline">\(\mu\)</span> is in an interval about 17.75 inches.</p>

<div class="figure"><span id="fig:unnamed-chunk-1"></span>
<img src="../LATEX/figures/chapter9/triplot.png" alt="Prior, likelihood, and posterior of a Normal mean with a Normal prior." width="500" />
<p class="caption">
Figure 9.1: Prior, likelihood, and posterior of a Normal mean with a Normal prior.
</p>
</div>
<p><strong>An alternative prior</strong></p>
<p>Looking at Figure 9.1, there is some concern about this particular Bayesian analysis. Since the main probability contents of the prior and likelihood functions have little overlap, there is serious conflict between the information in your prior and the information from the data.</p>
<p>Since we have a prior-data conflict, it would make sense to revisit our choice for a prior density on <span class="math inline">\(\mu\)</span>. Remember you specified the quartiles for <span class="math inline">\(\mu\)</span> to be 8 and 12 inches. Another symmetric density that matches this information is a Cauchy density with location 10 inches and scale parameter 2 inches. The reader can confirm that the quantiles of a Cauchy(10, 2) do match your prior information. [Hint: use the <code>qcauchy()</code> R command.]</p>
<p>In Figure 9.2 we compare the Normal and Cauchy priors graphically. Remember these two densities have the same quartiles at 8 and 12 inches. But the two priors have different shapes – the Cauchy prior is more peaked near the median value 10 and has tails that decrease to zero at a slower rate than the Normal. In other words, the Cauchy curve has flatter tails than the Normal curve.</p>

<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="../LATEX/figures/chapter9/twopriors.png" alt="Two priors for representing prior opinion about a Normal mean." width="500" />
<p class="caption">
Figure 9.2: Two priors for representing prior opinion about a Normal mean.
</p>
</div>
<p>With the use of a <span class="math inline">\(\textrm{Cauchy}(10, 2)\)</span> prior and the same Normal likelihood, the posterior density of <span class="math inline">\(\mu\)</span> is</p>
<p><span class="math display" id="eq:cauchynormal">\[\begin{equation}
\pi(\mu \mid y) \propto  \pi(\mu)L(\mu) \propto  
\frac{1}{1 + \left(\frac{\mu - 10}{2}\right)^2} \times \exp\left\{-\frac{n}{2 \sigma^2}(\bar y - \mu)^2\right\}.
\tag{9.3}
\end{equation}\]</span></p>
<p>In contrast with a Normal prior, one can not algebraically simplify this likelihood times prior product to obtain a “nice” functional expression for the posterior density in terms of the mean <span class="math inline">\(\mu\)</span>. That raises the question – how does one implement a Bayesian analysis when one can not easily express the posterior density in a convenient functional form?</p>
</div>
<div id="the-two-parameter-normal-problem" class="section level3">
<h3><span class="header-section-number">9.1.3</span> The two-parameter Normal problem</h3>
<p></p>
<p>In the problem in learning about a Normal mean <span class="math inline">\(\mu\)</span> in Chapter 8, it was assumed that the sampling standard deviation <span class="math inline">\(\sigma\)</span> was known. This is unrealistic – in most settings, if one is uncertain about the mean of the population, then likely the population standard deviation will also be unknown.
From a Bayesian perspective, since we have two unknown parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, this situation presents new challenges. One needs to construct a joint prior <span class="math inline">\(\pi(\mu, \sigma)\)</span> for the two parameters – up to this point, we have only discussed constructing a prior distribution for a single parameter. Also, although one can compute the posterior density by the usual "prior times likelihood" recipe, it may be difficult to get nice analytic answers with this posterior to obtain particular inferences of interest.</p>
</div>
<div id="overview-of-the-chapter" class="section level3">
<h3><span class="header-section-number">9.1.4</span> Overview of the chapter</h3>
<p></p>
<p>In Chapters 7 and 8, we illustrated the use of simulation to summarize posterior distributions of a specific functional form such as the Beta and Normal. In this chapter, we introduce a general class of algorithms, collectively called Markov chain Monte Carlo (MCMC), that can be used to simulate the posterior from general Bayesian models. These algorithms are based on a general probability model called a Markov chain and Section 9.2 describes this probability model for situations where the possible models are finite. Section 9.3 introduces the Metropolis sampler, a general algorithm for simulating from an arbitrary posterior distribution. Section 9.4 describes the implementation of this simulation algorithm for the Normal sampling problem with a Cauchy prior. Section 9.5 introduces another MCMC simulation algorithm, Gibbs sampling, that is well-suited for simulation from posterior distributions of many parameters. One issue in the implementation of these MCMC algorithms is that the simulation draws represent an approximate sample from the posterior distribution. Section 9.6 describes some common diagnostic methods for seeing if the simulated sample is a suitable exploration of the posterior distribution. Finally in Section 9.7, we describe the use of a general-purpose software program Just Another Gibbs Sampler (JAGS) and R interface for implementing these MCMC algorithms.</p>
</div>
</div>
<div id="markov-chains" class="section level2">
<h2><span class="header-section-number">9.2</span> Markov Chains</h2>
<p></p>
<div id="definition" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Definition</h3>
<p></p>
<p>Since our simulation algorithms are based on Markov chains, we begin by defining this class of probability models in the situation where the possible outcomes are finite.
Suppose a person takes a random walk on a number line on the values 1, 2, 3,
4, 5, 6. If the person is currently at an interior value (2, 3, 4, or 5), in the next
second she is equally likely to remain at that number or move to an adjacent
number. If she does move, she is equally likely to move left or right. If the
person is currently at one of the end values (1 or 6), in the next second she is
equally likely to stay still or move to the adjacent location.</p>
<p>This is a simple example of a discrete Markov chain. A Markov chain describes
probabilistic movement between a number of states. Here there are
six possible states, 1 through 6, corresponding to the possible locations of the
walker. Given that the person is at a current location, she moves to other locations
with specified probabilities. The probability that she moves to another
location depends only on her current location and not on previous locations
visited. We describe movement between states in terms of transition probabilities
– they describe the likelihoods of moving between all possible states
in a single step in a Markov chain. We summarize the transition probabilities
by means of a transition matrix <span class="math inline">\(P\)</span>:
<span class="math display">\[
P = \begin{bmatrix} 
.50 &amp;.50&amp; 0&amp; 0&amp; 0&amp; 0 \\
.25 &amp;.50&amp; .25&amp; 0&amp; 0&amp; 0\\
0 &amp;.25&amp; .50&amp; .25&amp; 0&amp; 0\\
0 &amp;0&amp; .25&amp; .50&amp; .25&amp; 0\\
0 &amp;0&amp; 0&amp; .25&amp; .50&amp; .25\\
0 &amp;0&amp; 0&amp; 0&amp; .50&amp; .50\\
\end{bmatrix}
\]</span>
The first row in <span class="math inline">\(P\)</span> gives the probabilities of moving to all states 1 through 6 in
a single step from location 1, the second row gives the transition probabilities
in a single step from location 2, and so on.</p>
<p>There are several important properties of this particular Markov chain.
It is possible to go from every state to every state in one or more steps –
a Markov chain with this property is said to be <strong>irreducible</strong>. Given that the
person is in a particular state, if the person can only return to this state at
regular intervals, then the Markov chain is said to be <strong>periodic</strong>. This example is aperiodic since the walker cannot return to the current state at regular intervals.</p>
</div>
<div id="some-properties" class="section level3">
<h3><span class="header-section-number">9.2.2</span> Some properties</h3>
<p></p>
<p>We represent one’s current location as a probability row vector of the
form
<span class="math display">\[\begin{equation*}
p = (p_1, p_2, p_3, p_4, p_5, p_6),
\end{equation*}\]</span>
where <span class="math inline">\(p_i\)</span> represents the probability that the person is currently in state <span class="math inline">\(i\)</span>. If
<span class="math inline">\(p^{(j)}\)</span> represents the location of the traveler at step <span class="math inline">\(j\)</span>, then the location of the
traveler at the <span class="math inline">\(j + 1\)</span> step is given by the matrix product
<span class="math display">\[\begin{equation*}
p^{(j+1)} = p^{(j)} P.
\end{equation*}\]</span>
Moreover, if <span class="math inline">\(p^{(j)}\)</span> represents the location at step <span class="math inline">\(j\)</span>, then the location of the traveler after <span class="math inline">\(m\)</span> additional steps, <span class="math inline">\(p^{(j+m)}\)</span>, is given by the matrix product
<span class="math display">\[\begin{equation*}
p^{(j+m)} = p^{(j)} P^m,
\end{equation*}\]</span>
where <span class="math inline">\(P^m\)</span> indicates the matrix multiplication <span class="math inline">\(P \times P \times ... \times P\)</span> (the matrix <span class="math inline">\(P\)</span> multiplied by itself <span class="math inline">\(m\)</span> times).</p>

<p>To illustrate for our example using R, suppose that the person begins at state 3 that is represented in R by the vector <code>p</code> with a 1 in the third entry:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="simulation-by-markov-chain-monte-carlo.html#cb2-1"></a>p &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span></code></pre></div>
<p>We also define the transition matrix by use of the <code>matrix()</code> function.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="simulation-by-markov-chain-monte-carlo.html#cb3-1"></a>P &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(.<span class="dv">5</span>, <span class="fl">.5</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb3-2"><a href="simulation-by-markov-chain-monte-carlo.html#cb3-2"></a>              <span class="fl">.25</span>, <span class="fl">.5</span>, <span class="fl">.25</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb3-3"><a href="simulation-by-markov-chain-monte-carlo.html#cb3-3"></a>              <span class="dv">0</span>, <span class="fl">.25</span>, <span class="fl">.5</span>, <span class="fl">.25</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb3-4"><a href="simulation-by-markov-chain-monte-carlo.html#cb3-4"></a>              <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">.25</span>, <span class="fl">.5</span>, <span class="fl">.25</span>, <span class="dv">0</span>,</span>
<span id="cb3-5"><a href="simulation-by-markov-chain-monte-carlo.html#cb3-5"></a>              <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">.25</span>, <span class="fl">.5</span>, <span class="fl">.25</span>,</span>
<span id="cb3-6"><a href="simulation-by-markov-chain-monte-carlo.html#cb3-6"></a>              <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">.5</span>, <span class="fl">.5</span>),</span>
<span id="cb3-7"><a href="simulation-by-markov-chain-monte-carlo.html#cb3-7"></a>              <span class="dt">nrow=</span><span class="dv">6</span>, <span class="dt">ncol=</span><span class="dv">6</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p>If one multiplies this vector by the matrix <code>P</code>, one obtains the probabilities of being in all six states after one move.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="simulation-by-markov-chain-monte-carlo.html#cb4-1"></a><span class="kw">print</span>(p <span class="op">%*%</span><span class="st"> </span>P, <span class="dt">digits =</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6]
## [1,]    0 0.25  0.5 0.25    0    0</code></pre>
<p>After one move (starting at state 3), our walker will be at states 2, 3, and 4 with respective probabilities 0.25, 0.5, and 0.25.
If one multiplies <code>p</code> by the matrix <code>P</code> four times, one obtains the probabilities of being in the different states after four moves.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="simulation-by-markov-chain-monte-carlo.html#cb6-1"></a><span class="kw">print</span>(p <span class="op">%*%</span><span class="st"> </span>P <span class="op">%*%</span><span class="st"> </span>P <span class="op">%*%</span><span class="st"> </span>P <span class="op">%*%</span><span class="st"> </span>P, <span class="dt">digits =</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##         [,1] [,2]    [,3]    [,4]    [,5]    [,6]
## [1,] 0.10938 0.25 0.27734 0.21875 0.11328 0.03125</code></pre>
<p>Starting from state 3, this particular person is most likely will be in states 2, 3, and 4 after four moves.</p>
<p>For an irreducible, aperiodic Markov chain, there is a limiting behavior of the matrix power <span class="math inline">\(P^m\)</span> as <span class="math inline">\(m\)</span> approaches infinity. Specifically, this limit is equal to
<span class="math display" id="eq:mcchain">\[\begin{equation}
W = \lim_{m \rightarrow \infty} P^m,
\tag{9.4}
\end{equation}\]</span>
where <span class="math inline">\(W\)</span> has common rows equal to <span class="math inline">\(w\)</span>. The implication of this result is that, as one takes an infinite number of moves, the probability of landing at a particular state does not depend on the initial starting state.</p>
<p>One can demonstrate this result empirically for our example. Using a loop, we take the transition matrix <span class="math inline">\(P\)</span> to the 100th power by repeatedly multiplying the transition matrix by itself. From this calculation below, note that the rows of the matrix Pm appear to be approaching a constant vector. Specifically, it appears the constant vector <span class="math inline">\(w\)</span> is equal to (0.1, 0.2, 0.2, 0.2, 0.2, 0.1).</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="simulation-by-markov-chain-monte-carlo.html#cb8-1"></a>Pm &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">6</span>))</span>
<span id="cb8-2"><a href="simulation-by-markov-chain-monte-carlo.html#cb8-2"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>){</span>
<span id="cb8-3"><a href="simulation-by-markov-chain-monte-carlo.html#cb8-3"></a>  Pm &lt;-<span class="st"> </span>Pm <span class="op">%*%</span><span class="st"> </span>P</span>
<span id="cb8-4"><a href="simulation-by-markov-chain-monte-carlo.html#cb8-4"></a>}</span>
<span id="cb8-5"><a href="simulation-by-markov-chain-monte-carlo.html#cb8-5"></a><span class="kw">print</span>(Pm, <span class="dt">digits =</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##          [,1]    [,2]    [,3]    [,4]    [,5]     [,6]
## [1,] 0.100009 0.20001 0.20001 0.19999 0.19999 0.099991
## [2,] 0.100007 0.20001 0.20000 0.20000 0.19999 0.099993
## [3,] 0.100003 0.20000 0.20000 0.20000 0.20000 0.099997
## [4,] 0.099997 0.20000 0.20000 0.20000 0.20000 0.100003
## [5,] 0.099993 0.19999 0.20000 0.20000 0.20001 0.100007
## [6,] 0.099991 0.19999 0.19999 0.20001 0.20001 0.100009</code></pre>
<p>From this result about the limiting behavior of the matrix power <span class="math inline">\(P^m\)</span>, one can derive a rule for determining this constant vector.
Suppose we can find a probability vector <span class="math inline">\(w\)</span> such that <span class="math inline">\(wP = w\)</span>. This vector <span class="math inline">\(w\)</span> is
said to be the <strong>stationary distribution</strong>. If a Markov chain is irreducible and
aperiodic, then it has a unique stationary distribution. Moreover, as illustrated above, the limiting
distribution of this Markov chain, as the number of steps approaches infinity,
will be equal to this stationary distribution.</p>
</div>
<div id="simulating-a-markov-chain" class="section level3">
<h3><span class="header-section-number">9.2.3</span> Simulating a Markov chain</h3>
<p></p>
<p>Another method for demonstrating the existence of the stationary distribution
of our Markov chain by running a simulation experiment. We start our
random walk at a particular state, say location 3, and then simulate many
steps of the Markov chain using the transition matrix <span class="math inline">\(P\)</span>. The relative frequencies
of our traveler in the six locations after many steps will eventually
approach the stationary distribution <span class="math inline">\(w\)</span>.</p>

<p>In R we have already defined the transition matrix <code>P</code>. To begin the simulation exercise, we set up a storage vector <code>s</code> for the locations of our traveler in the random
walk. We indicate that the starting location for our traveler is state 3 and perform
a loop to simulate 10,000 draws from the Markov chain. We use the <code>sample()</code>
function to simulate one step – the arguments to this function indicate that
we are sampling a single value from the set {1, 2, 3, 4, 5, 6} with probabilities
given by the <span class="math inline">\(s_j^1\)</span> row of the transition matrix <span class="math inline">\(P\)</span>, where <span class="math inline">\(s_j^1\)</span> is the current
location of our traveler.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="simulation-by-markov-chain-monte-carlo.html#cb10-1"></a>s &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dv">10000</span>)</span>
<span id="cb10-2"><a href="simulation-by-markov-chain-monte-carlo.html#cb10-2"></a>s[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">3</span></span>
<span id="cb10-3"><a href="simulation-by-markov-chain-monte-carlo.html#cb10-3"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span><span class="dv">10000</span>)</span>
<span id="cb10-4"><a href="simulation-by-markov-chain-monte-carlo.html#cb10-4"></a>s[j] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>P[s[j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>], ])</span></code></pre></div>
<p>Suppose that we record the relative frequencies of each of the outcomes 1, 2, …, 6 after each iteration of the simulation. Figure 9.3 graphs the relative frequencies of each of the outcomes as a function of the iteration number.</p>

<div class="figure"><span id="fig:unnamed-chunk-9"></span>
<img src="../LATEX/figures/chapter9/markovchainrun.png" alt="Relative frequencies of the states 1 through 6 as a function of the number of iterations for Markov chain simulation.  As the number of iterations increases, the relative frequencies appear to approach the probabilities in the stationary distribution $w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1)$." width="500" />
<p class="caption">
Figure 9.3: Relative frequencies of the states 1 through 6 as a function of the number of iterations for Markov chain simulation. As the number of iterations increases, the relative frequencies appear to approach the probabilities in the stationary distribution <span class="math inline">\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1)\)</span>.
</p>
</div>
<p>It appears from Figure 9.3 that the relative frequencies of the states are converging
to the stationary distribution <span class="math inline">\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1).\)</span> One
confirms that this specific vector <span class="math inline">\(w\)</span> is indeed the stationary distribution of this chain by multiplying
<span class="math inline">\(w\)</span> by the transition matrix <span class="math inline">\(P\)</span> and noticing that the product is equal to <span class="math inline">\(w\)</span>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="simulation-by-markov-chain-monte-carlo.html#cb11-1"></a>w &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(.<span class="dv">1</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">1</span>), <span class="dt">nrow=</span><span class="dv">1</span>, <span class="dt">ncol=</span><span class="dv">6</span>)</span>
<span id="cb11-2"><a href="simulation-by-markov-chain-monte-carlo.html#cb11-2"></a> w <span class="op">%*%</span><span class="st"> </span>P</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6]
## [1,]  0.1  0.2  0.2  0.2  0.2  0.1</code></pre>
</div>
</div>
<div id="the-metropolis-algorithm" class="section level2">
<h2><span class="header-section-number">9.3</span> The Metropolis Algorithm</h2>
<p></p>
<div id="example-walking-on-a-number-line" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Example: Walking on a number line</h3>
<p></p>
<p>Markov chains can be used to sample from an arbitrary probability distribution. To introduce a general Markov chain sampling algorithm, we illustrate sampling from a discrete distribution.
Suppose one defines a discrete probability distribution on the integers 1, …, <span class="math inline">\(K\)</span>.</p>

<p>As an example, we write a short function <code>pd()</code> in R taking on the values 1, …, 8 with probabilities proportional to the values 5, 10, 4, 4, 20, 20, 12, and 5. Note that these probabilities don’t sum to one, but we will shortly see that only the relative sizes of these values are relevant in this algorithm. A line graph of this probability distribution is displayed in Figure 9.4.</p>
<pre><code>pd &lt;- function(x){
  values &lt;- c(5, 10, 4, 4, 20, 20, 12, 5)
  ifelse(x %in% 1:length(values), values[x], 0)
}
prob_dist &lt;- data.frame(x = 1:8, 
                        prob = pd(1:8))</code></pre>

<div class="figure"><span id="fig:unnamed-chunk-11"></span>
<img src="../LATEX/figures/chapter9/mcmc1.png" alt="A discrete probability distribution on the values 1, ..., 8." width="500" />
<p class="caption">
Figure 9.4: A discrete probability distribution on the values 1, …, 8.
</p>
</div>
<p>To simulate from this probability distribution, we will take a simple random walk described as follows.</p>
<ol style="list-style-type: decimal">
<li><p>We start at any possible location of our random variable from 1 to <span class="math inline">\(K = 8\)</span>.</p></li>
<li><p>To decide where to visit next, a fair coin is flipped. If the coin lands heads, we think about visiting the location one value to the left, and if coin lands tails, we consider visiting the location one value to right. We call this location the “candidate” location.</p></li>
<li><p>We compute
<span class="math display" id="eq:mhratio">\[\begin{equation}
R = \frac{pd(candidate)}{pd(current)},
\tag{9.5}
\end{equation}\]</span>
the ratio of the probabilities at the candidate and current locations.</p></li>
<li><p>We spin a continuous spinner that lands anywhere from 0 to 1 – call the random spin <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> is smaller than <span class="math inline">\(R\)</span>, we move to the candidate location, and otherwise we remain at the current location.</p></li>
</ol>
<p>Steps 1 through 4 define an irreducible, aperiodic Markov chain on the state values {1, 2, …, 8} where Step 1 gives the starting location and the transition matrix <span class="math inline">\(P\)</span> is defined by Steps 2 through 4. One way of "discovering" the discrete probability distribution <span class="math inline">\(pd\)</span> is by starting at any location and walking through the distribution many times repeating Steps 2, 3, and 4 (propose a candidate location, compute the ratio, and decide whether to visit the candidate location). If this process is repeated for a large number of steps, the distribution of our actual visits should approximate the probability distribution <span class="math inline">\(pd\)</span>.</p>

<p>A R function <code>random_walk()</code> is written implementing this random walk algorithm. There are three inputs to this function, the probability distribution <code>pd</code>, the starting location <code>start</code> and the number of steps of the algorithm <code>s</code>.</p>
<pre><code>random_walk &lt;- function(pd, start, num_steps){
  y &lt;- rep(0, num_steps)
  current &lt;- start
  for (j in 1:num_steps){
    candidate &lt;- current + sample(c(-1, 1), 1)
    prob &lt;- pd(candidate) / pd(current)
    if (runif(1) &lt; prob) current &lt;- candidate
    y[j] &lt;- current
  }
  return(y)
}</code></pre>
<p>We have already defined the probability distribution by use of the function <code>pd()</code>. Below, we implement the random walk algorithm by inputting this probability function, starting at the value <span class="math inline">\(X = 4\)</span> and running the algorithm for <span class="math inline">\(s\)</span> = 10,000 iterations.</p>
<pre><code>out &lt;- random_walk(pd, 4, 10000)
data.frame(out) %&gt;% group_by(out) %&gt;% 
  summarize(N = n(), Prob = N / 10000) -&gt; S</code></pre>
<p>In Figure 9.5 a histogram of the simulated values from the random walk is compared with the actual probability distribution. Note that the collection of simulated draws appears to be a close match to the true probabilities.</p>

<div class="figure"><span id="fig:unnamed-chunk-12"></span>
<img src="../LATEX/figures/chapter9/mcmc2.png" alt="Histogram of simulated draws from the random walk compared with the actual probabilities of the distribution." width="500" />
<p class="caption">
Figure 9.5: Histogram of simulated draws from the random walk compared with the actual probabilities of the distribution.
</p>
</div>
</div>
<div id="the-general-algorithm" class="section level3">
<h3><span class="header-section-number">9.3.2</span> The general algorithm</h3>
<p></p>
<p>A popular way of simulating from a general continuous posterior distribution is by using a
generalization of the discrete Markov chain setup described in the random walk example in the previous
section. The Markov chain Monte Carlo sampling strategy sets up an irreducible, aperiodic
Markov chain for which the stationary distribution equals the posterior distribution
of interest. This method, called the Metropolis algorithm, is applicable to a wide range of Bayesian inference problems.</p>
<p>Here the Metropolis algorithm is presented and illustrated. This algorithm is a special case of the Metropolis-Hastings algorithm, where the proposal distribution is symmetric (e.g. Uniform or Normal).</p>
<p>Suppose the posterior density is written as
<span class="math display">\[\begin{equation*}
\pi_n(\theta) \propto  \pi(\theta) L(\theta),
\end{equation*}\]</span>
where <span class="math inline">\(\pi(\theta)\)</span> is the prior and <span class="math inline">\(L(\theta)\)</span> is the likelihood function. In this algorithm, it is not necessary to compute the normalizing constant – only the product of likelihood and prior is needed.</p>
<ol style="list-style-type: decimal">
<li><p>(START) As in the random walk algorithm, we begin by selecting any <span class="math inline">\(\theta\)</span> value where the posterior density is positive – the value we select <span class="math inline">\(\theta^{(0)}\)</span> is the starting value.</p></li>
<li><p>(PROPOSE) Given the current simulated value <span class="math inline">\(\theta^{(j)}\)</span> we propose a new value <span class="math inline">\(\theta^P\)</span> which is selected at random in the interval (<span class="math inline">\(\theta^{(j)} - C, \theta^{(j)} + C)\)</span> where <span class="math inline">\(C\)</span> is a preselected constant.</p></li>
<li><p>(ACCEPTANCE PROBABILITY) One computes the ratio <span class="math inline">\(R\)</span> of the posterior density at the proposed value and the current value:
<span class="math display" id="eq:mhratio2">\[\begin{equation}
R = \frac{\pi_n(\theta^{P})}{\pi_n(\theta^{(j)})}.
\tag{9.6}
\end{equation}\]</span>
The acceptance probability is the minimum of <span class="math inline">\(R\)</span> and 1:
<span class="math display" id="eq:mhprob">\[\begin{equation}
PROB = \min\{R, 1\}.
\tag{9.7}
\end{equation}\]</span></p></li>
<li><p>(MOVE OR STAY?) One simulates a Uniform random variable <span class="math inline">\(U\)</span>. If <span class="math inline">\(U\)</span> is smaller than the acceptance probability <span class="math inline">\(PROB\)</span>, one moves to the proposed value <span class="math inline">\(\theta^P\)</span>; otherwise one stays at the current value <span class="math inline">\(\theta^{(j)}\)</span>. In other words, the next simulated draw <span class="math inline">\(\theta^{(j+1)}\)</span>
<span class="math display" id="eq:mhmove">\[\begin{equation}
\theta^{(j+1)} = 
\begin{cases}
  \theta^{p} &amp; \mbox{if} \, \, U &lt; PROB, \\
  \theta^{(j)} &amp; \mbox{elsewhere}.
\end{cases}
\tag{9.8}
\end{equation}\]</span></p></li>
<li><p>(CONTINUE) One continues by returning to Step 2 – propose a new simulated value, compute an acceptance probability, decide to move to the proposed value or stay, and so on.</p></li>
</ol>
<p>Figure 9.6 illustrates how the Metropolis algorithm works. The bell-shaped curve is the posterior density of interest. In the top-left panel, the solid dot represents the current simulated draw and the black bar represents the proposal region. One simulates the proposed value represented by the “P” symbol. One computes the probability of accepting this proposed value – in this case, this probability is 0.02. By simulating a Uniform draw, one decides not to accept this proposal and the new simulated draw is the current value shown in the top-right panel. A different scenario is shown in the bottom panels. One proposes a value corresponding to a higher posterior density value. The probability of accepting this proposal is 1 and the bottom left graph shows that the new simulated draw is the proposed value.</p>

<div class="figure"><span id="fig:unnamed-chunk-13"></span>
<img src="../LATEX/figures/chapter9/showmetrop.png" alt="Illustration of the Metropolis algorithm.  The left graphs show the proposal region and two possible proposal values and the right graphs show the result of either accepting or rejecting the proposal." width="500" />
<p class="caption">
Figure 9.6: Illustration of the Metropolis algorithm. The left graphs show the proposal region and two possible proposal values and the right graphs show the result of either accepting or rejecting the proposal.
</p>
</div>
</div>
<div id="a-general-function-for-the-metropolis-algorithm" class="section level3">
<h3><span class="header-section-number">9.3.3</span> A general function for the Metropolis algorithm</h3>
<p></p>
<p>Since the Metropolis is a relatively simple algorithm, one writes a short function in R to implement this sampling for an arbitrary probability distribution.</p>

<p>The function <code>metropolis()</code> has five inputs: <code>logpost</code> is a function defining the logarithm of the density, <code>current</code> is the starting value, <code>C</code> defines the neighborhood where one looks for a proposal value, <code>iter</code> is the number of iterations of the algorithm, and <code>...</code> denotes any data or parameters needed in the function <code>logpost()</code>.</p>
<pre><code>metropolis &lt;- function(logpost, current, C, iter, ...){
  S &lt;- rep(0, iter) 
  n_accept &lt;- 0
  for(j in 1:iter){
  candidate &lt;- runif(1, min=current - C, 
                       max=current + C)
  prob &lt;- exp(logpost(candidate, ...) - 
             logpost(current, ...))
  accept &lt;- ifelse(runif(1) &lt; prob, &quot;yes&quot;, &quot;no&quot;)
  current &lt;- ifelse(accept == &quot;yes&quot;, 
                    candidate, current)
  S[j] &lt;- current
  n_accept &lt;- n_accept + (accept == &quot;yes&quot;)
  }
  list(S=S, accept_rate=n_accept / iter)
}</code></pre>
</div>
</div>
<div id="example-cauchy-normal-problem" class="section level2">
<h2><span class="header-section-number">9.4</span> Example: Cauchy-Normal problem</h2>
<p></p>
<p>To illustrate using the <code>metropolis()</code> function, suppose we wish to simulate 1000 values from the posterior distribution in our Buffalo snowfall problem where one uses a Cauchy prior to model one’s prior opinion about the mean snowfall amount. Recall that the posterior density of <span class="math inline">\(\mu\)</span> is proportional to
<span class="math display" id="eq:normalcauchy2">\[\begin{equation}
\pi(\mu \mid y) \propto \frac{1}{1 + \left(\frac{\mu - 10}{2}\right)^2} \times \exp\left\{-\frac{n}{2 \sigma^2}(\bar y - \mu)^2\right\}.
\tag{9.9}
\end{equation}\]</span>
There are four inputs to this posterior – the mean <span class="math inline">\(\bar y\)</span> and corresponding standard error <span class="math inline">\(\sigma / \sqrt{n}\)</span>, and the location parameter 10 and the scale parameter 2 for the Cauchy prior. Recall that for the Buffalo snowfall, we observed <span class="math inline">\(\bar y = 26.785\)</span> and <span class="math inline">\(\sigma / \sqrt{n} = 3.236\)</span>.</p>

<p>First we need to define a short function defining the logarithm of the posterior density function. Ignoring constants, the logarithm of this density is given by
<span class="math display" id="eq:lognormcauchy">\[\begin{equation}
 \log \pi(\mu \mid y) =  - 
 \log\left\{1 + \left(\frac{\mu - 10}{2}\right)^2\right\} -\frac{n}{2 \sigma^2}(\bar y - \mu)^2.
 \tag{9.10}
 \end{equation}\]</span></p>
<p>The function <code>lpost()</code> returns the value of the logarithm of the posterior where <code>s</code> is a list containing the four inputs <code>ybar</code>, <code>se</code>, <code>loc</code>, and <code>scale</code>.</p>
<pre><code>lpost &lt;- function(theta, s){
    dcauchy(theta, s$loc, s$scale, log = TRUE) +
    dnorm(s$ybar, theta, s$se, log = TRUE)
}</code></pre>
<p>A list named <code>s</code> is defined that contains these inputs for this particular problem.</p>
<pre><code>s &lt;- list(loc = 10, scale = 2,
          ybar = mean(data$JAN),
          se = sd(data$JAN) / sqrt(20))</code></pre>
<p>Now we are ready to apply the Metropolis algorithm as coded in the function <code>metropolis()</code>. The inputs to this function are the log posterior function <code>lpost</code>, the starting value <span class="math inline">\(\mu = 5\)</span>, the width of the proposal density <span class="math inline">\(C = 20\)</span>, the number of iterations 10,000, and the list <code>s</code> that contains the inputs to the log posterior function.</p>
<pre><code>out &lt;- metropolis(lpost, 5, 20, 10000, s)</code></pre>
<p>The output variable <code>out</code> has two components – <code>S</code> is a vector of the simulated draws and <code>accept_rate</code> gives the acceptance rate of the algorithm.</p>
<div id="choice-of-starting-value-and-proposal-region" class="section level3">
<h3><span class="header-section-number">9.4.1</span> Choice of starting value and proposal region</h3>
<p></p>
<p>In implementing this Metropolis algorithm, the user has to make two choices. One needs to select a starting value for the algorithm and select a value of <span class="math inline">\(C\)</span> which determines the width of the proposal region.</p>
<p>Assuming that the starting value is a place where the density is positive, then this particular choice in usual practice is not critical. In the event where the probability density at the starting value is small, the algorithm will move towards the region where the density is more probable.</p>
<p>The choice of the constant <span class="math inline">\(C\)</span> is more critical. If one chooses a very small value of <span class="math inline">\(C\)</span>, then the simulated values from the algorithm tend to be strongly correlated and it takes a relatively long time to explore the entire probability distribution. In contrast, if <span class="math inline">\(C\)</span> is chosen too large, then it is more likely that proposal values will not be accepted and the simulated values tend to get stuck at the current values. One monitors the choice of <span class="math inline">\(C\)</span> by computing the acceptance rate, the proportion of proposal values that are accepted. If the acceptance rate is large, that indicates that the simulated values are highly correlated and the algorithm is not efficiently exploring the distribution. If the acceptance rate is low, then few candidate values are accepted and the algorithm tends to be "sticky" or stuck at current draws.</p>
<p>We illustrate different choices of <span class="math inline">\(C\)</span> for the mean amount of Buffalo snowfall problem. In each case, we start with the value <span class="math inline">\(\mu = 20\)</span> and try the <span class="math inline">\(C\)</span> values 0.3, 3, 30, and 200. In each case, we simulate 5000 values of the MCMC chain. Figure 9.7 shows in each case a line graph of the simulated draws against the iteration number and the acceptance rate of the algorithm is displayed.</p>

<div class="figure"><span id="fig:unnamed-chunk-14"></span>
<img src="../LATEX/figures/chapter9/mcmc4.png" alt="Trace plots of simulated draws using different choices of the constant $C$." width="500" />
<p class="caption">
Figure 9.7: Trace plots of simulated draws using different choices of the constant <span class="math inline">\(C\)</span>.
</p>
</div>
<p>When one chooses a small value <span class="math inline">\(C = 0.3\)</span> (top-left panel in Figure 9.7), note that the graph of simulated draws has a snake-like appearance. Due to the strong autocorrelation of the simulated draws, the sampler does a relatively poor job of exploring the posterior distribution. One measure that this sampler is not working well is the large acceptance rate of 0.9702. On the other hand, if one uses a large value <span class="math inline">\(C = 200\)</span> (bottom-right panel in Figure 9.7), the flat-portions in the graph indicates there are many occurrences where the chain will not move from the current value. The low acceptance rate of 0.0272 indicates this problem. The more moderate values of <span class="math inline">\(C = 3\)</span> and <span class="math inline">\(C = 30\)</span> (top-right and bottom-left panels in Figure 9.7) produce more acceptable streams of simulated values, although the respectively acceptance rates (0.8158 and 0.179) are very different.</p>
<p>In practice, it is recommended that the Metropolis algorithm has an acceptance rate between 20% and 40%. For this example, this would suggest trying an alternative choice of <span class="math inline">\(C\)</span> between 2 and 20.</p>
</div>
<div id="collecting-the-simulated-draws" class="section level3">
<h3><span class="header-section-number">9.4.2</span> Collecting the simulated draws</h3>
<p>Using MCMC diagnostic methods that will be described in Section 9.6, one sees that the simulated draws are a reasonable approximation to the posterior density of <span class="math inline">\(\mu\)</span>. One displays the posterior density by computing a density estimate of the simulated sample.
In Figure 9.8, we plot the prior, likelihood, and posterior density for the mean amount of Buffalo snowfall <span class="math inline">\(\mu\)</span> using the Cauchy prior. Recall that we have prior-data conflict, the prior says that the mean snowfall is about 10 inches and the likelihood indicates that the mean snowfall was around 27 inches. When a Normal prior was applied, we found that the posterior mean was 17.75 inches – actually the posterior density has little overlap with the prior or the likelihood in Figure 9.1. In contrast, it is seen from Figure 9.8 that the posterior density using the Cauchy density resembles the likelihood. Essentially this posterior analysis says that our prior information was off the mark and the posterior is most influenced by the data.</p>

<div class="figure"><span id="fig:unnamed-chunk-15"></span>
<img src="../LATEX/figures/chapter9/cauchypost.png" alt="Prior, likelihood, and posterior of a Normal mean with a Cauchy prior." width="500" />
<p class="caption">
Figure 9.8: Prior, likelihood, and posterior of a Normal mean with a Cauchy prior.
</p>
</div>
</div>
</div>
<div id="gibbs-sampling" class="section level2">
<h2><span class="header-section-number">9.5</span> Gibbs Sampling</h2>
<p></p>
<p>In our examples, we have focused on the use of the Metropolis sampler in simulating from a probability distribution of a single variable. Here we introduce an MCMC algorithm for simulating from a probability distribution of several variables based on conditional distributions: the Gibbs sampling algorithm. As we will see, it facilitates parameter estimation in Bayesian models with more than one parameter, providing data analysts much flexibility in specifying Bayesian models.</p>
<div id="bivariate-discrete-distribution" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Bivariate discrete distribution}</h3>
<p></p>
<p>To introduce the Gibbs sampling method, suppose that the random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> each take on the values 1, 2, 3, 4, and the joint probability distribution is given in the following table.</p>
<table>
<tbody>
<tr class="odd">
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(Y\)</span></td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.100</td>
<td align="right">0.075</td>
<td align="right">0.050</td>
<td align="right">0.025</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.075</td>
<td align="right">0.100</td>
<td align="right">0.075</td>
<td align="right">0.050</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.050</td>
<td align="right">0.075</td>
<td align="right">0.100</td>
<td align="right">0.075</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.025</td>
<td align="right">0.050</td>
<td align="right">0.075</td>
<td align="right">0.100</td>
</tr>
</tbody>
</table>
<p>Suppose it is of interest to simulate from this joint distribution of <span class="math inline">\((X, Y)\)</span>. We set up a Markov chain by taking simulated draws from the conditional distributions <span class="math inline">\(f(x \mid y)\)</span> and <span class="math inline">\(f(y \mid x)\)</span>. Let’s describe this Markov chain by example. Suppose the algorithm starts at the value <span class="math inline">\(X = 1\)</span>.</p>
<ol style="list-style-type: decimal">
<li>[Step 1] One simulates <span class="math inline">\(Y\)</span> from the conditional distribution <span class="math inline">\(f(y \mid X = 1)\)</span>. This conditional distribution is represented by the probabilities in the first column of the probability matrix.</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(Y\)</span></th>
<th align="right">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.100</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.075</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.050</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.025</td>
</tr>
</tbody>
</table>
<p>(Actually these values are proportional to the distribution <span class="math inline">\(f(y \mid X = 1)\)</span>.) Suppose we perform this simulation and obtain <span class="math inline">\(Y = 2\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li>[Step 2] Next one simulates <span class="math inline">\(X\)</span> from the conditional distribution of <span class="math inline">\(f(x \mid Y = 2).\)</span> This distribution is found by looking at the probabilities in the second row of the probability matrix.</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(X\)</span></th>
<th align="right">1</th>
<th align="right">2</th>
<th align="right">3</th>
<th align="right">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Probability</td>
<td align="right">0.075</td>
<td align="right">0.100</td>
<td align="right">0.075</td>
<td align="right">0.050</td>
</tr>
</tbody>
</table>
<p>Suppose the simulated draw from this distribution is <span class="math inline">\(X = 3\)</span>.</p>
<p>By implementing Steps 1 and 2, we have one iteration of Gibbs sampling, obtaining the simulated pair <span class="math inline">\((X, Y) = (3, 2)\)</span>. To continue this algorithm, we repeat Steps 1 and 2 many times where we condition in each case on the most recently simulated values of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span>.</p>
<p>By simulating successively from the distributions <span class="math inline">\(f(y \mid x)\)</span> and <span class="math inline">\(f(x \mid y)\)</span>, one defines a Markov chain that moves from one simulated pair <span class="math inline">\((X^{(j)}, Y^{(j)})\)</span> to the next simulated pair <span class="math inline">\((X^{(j+1)}, Y^{(j+1)})\)</span>. In theory, after simulating from these two conditional distributions a large number of times, the distribution will converge to the joint probability distribution of <span class="math inline">\((X, Y)\)</span>.</p>

<p>We write a short R function <code>gibbs_discrete()</code> to implement Gibbs sampling for a two-parameter discrete distribution where the probabilities are represented in a matrix. One inputs the matrix <code>p</code> and the output is a matrix of simulated draws of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> where each row corresponds to a simulated pair. By default, the sampler starts at the value <span class="math inline">\(X = 1\)</span> and 1000 iterations of the algorithm will be taken.</p>
<pre><code>gibbs_discrete &lt;- function(p, i = 1, iter = 1000){
  x &lt;- matrix(0, iter, 2)
  nX &lt;- dim(p)[1]
  nY &lt;- dim(p)[2]
  for(k in 1:iter){
    j &lt;- sample(1:nY, 1, prob = p[i, ])
    i &lt;- sample(1:nX, 1, prob = p[, j])
    x[k, ] &lt;- c(i, j)
  }
  x
}</code></pre>
<p>The function <code>gibbs_discrete()</code> is run using the probability matrix for our example. The output is converted to a data frame and we tally the counts for each possible pair of values of <span class="math inline">\((X, Y)\)</span>, and then divide the counts by the simulation sample size of 1000. One can check that the relative frequencies of these pairs are good approximations to the joint probabilities.</p>
<pre><code>sp &lt;- data.frame(gibbs_discrete(p))
names(sp) &lt;- c(&quot;X&quot;, &quot;Y&quot;)
table(sp) / 1000
    Y
X       1     2     3     4
  1 0.086 0.058 0.050 0.020
  2 0.061 0.081 0.079 0.048
  3 0.046 0.070 0.090 0.079
  4 0.017 0.036 0.068 0.111</code></pre>
</div>
<div id="beta-binomial-sampling" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Beta-binomial sampling</h3>
<p></p>
<p>The previous example demonstrated Gibbs sampling for a two-parameter discrete distribution. In fact, the Gibbs sampling algorithm works for any two-parameter distribution. To illustrate, consider a familiar Bayesian model discussed in Chapter 7. Suppose we flip a coin <span class="math inline">\(n\)</span> times and observe <span class="math inline">\(y\)</span> heads where the probability of heads is <span class="math inline">\(p\)</span>, and our prior for the heads probability is described by a Beta curve with shape parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. It is convenient to write <span class="math inline">\(X \mid Y = y\)</span> as the conditional distribution of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span>. Using this notation we have</p>
<p><span class="math display" id="eq:betabinomiala">\[\begin{equation}
Y \mid p \sim  \textrm{Binomial}(n, p),
\tag{9.11}
\end{equation}\]</span>
<span class="math display" id="eq:betabinomialb">\[\begin{equation}
 p \sim \textrm{Beta}(a, b).
 \tag{9.12}
\end{equation}\]</span></p>
<p>To implement Gibbs sampling for this situation, one needs to identify the two conditional distributions <span class="math inline">\(Y \mid p\)</span> and <span class="math inline">\(p \mid Y\)</span>. First write down the joint density of <span class="math inline">\((Y, p)\)</span> which is found by multiplying the marginal density <span class="math inline">\(\pi(p)\)</span> with the conditional density <span class="math inline">\(f(y \mid p)\)</span>.</p>
<p><span class="math display" id="eq:bbdist">\[\begin{eqnarray}
f(Y = y, p) &amp;=&amp; \pi(p)f(Y = y \mid p) \nonumber \\ 
&amp;=&amp;  \left[\frac{1}{B(a, b)} p^{a - 1} (1-p)^{b-1}\right] \left[{n \choose y} p^y (1 - p)^{n-y}\right]. \nonumber \\
\tag{9.13}
\end{eqnarray}\]</span></p>
<ol style="list-style-type: decimal">
<li><p>The conditional density <span class="math inline">\(f(Y = y \mid p)\)</span> is found by fixing a value of the proportion <span class="math inline">\(p\)</span> and then the only random variable is <span class="math inline">\(Y\)</span>. This distribution is <span class="math inline">\(\textrm{Binomial}(n, p)\)</span> which actually was given in the statement of the problem.</p></li>
<li><p>Turning things around, the conditional density <span class="math inline">\(\pi(p \mid y)\)</span> takes the number of successes <span class="math inline">\(y\)</span> and views the joint density as a function only of the random variable <span class="math inline">\(p\)</span>. Ignoring constants, we see this conditional density is proportional to
<span class="math display" id="eq:bbcond1">\[\begin{equation}
p^{y + a - 1} (1 - p)^{n - y + b - 1},
\tag{9.14}
\end{equation}\]</span>
which we recognize as a Beta distribution with shape parameters <span class="math inline">\(y + a\)</span> and <span class="math inline">\(n - y + b\)</span>. Using our notation, we have <span class="math inline">\(p \mid y \sim \textrm{Beta}(y + a, n - y + b)\)</span>.</p></li>
</ol>

<p>Once these conditional distributions are identified, it is straightforward to write an algorithm to implement Gibbs sampling. For example, suppose <span class="math inline">\(n = 20\)</span> and the prior density for <span class="math inline">\(p\)</span> is <span class="math inline">\(\textrm{Beta}(5, 5)\)</span>. Suppose that the current simulated value of <span class="math inline">\(p\)</span> is <span class="math inline">\(p^{(j)}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Simulate <span class="math inline">\(Y^{(j)}\)</span> from a <span class="math inline">\(\textrm{Binomial}(20, p^{(j)})\)</span> distribution.</li>
</ol>
<pre><code>y &lt;- rbinom(1, size = 20, prob = p)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Given the current simulated value <span class="math inline">\(y^{(j)}\)</span>, simulate <span class="math inline">\(p^{(j+1)}\)</span> from a Beta distribution with shape parameters <span class="math inline">\(y^{(j)} + 5\)</span> and <span class="math inline">\(20 - y^{(j)} + 5\)</span>.</li>
</ol>
<pre><code>p &lt;- rbeta(1, y + a, n - y + b)</code></pre>
<p>The R function <code>gibbs_betabin()</code> will implement Gibbs sampling for this problem. One inputs the sample size <span class="math inline">\(n\)</span> and the shape parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. By default, one starts the algorithm at the proportion value <span class="math inline">\(p = 0.5\)</span> and one takes 1000 iterations of the algorithm.</p>
<pre><code>gibbs_betabin &lt;- function(n, a, b, p = 0.5, iter = 1000){
  x &lt;- matrix(0, iter, 2)
  for(k in 1:iter){
    y &lt;- rbinom(1, size = n, prob = p)
    p &lt;- rbeta(1, y + a, n - y + b )
    x[k, ] &lt;- c(y, p)
  }
  x
}</code></pre>
<p>Below we run Gibbs sampling for this Beta-Binomial model with <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(a = 5\)</span>, and <span class="math inline">\(b = 5\)</span>. After performing 1000 iterations, one regards the matrix <code>sp</code> as an approximate simulated sample from the joint distribution of <span class="math inline">\(Y\)</span> and <span class="math inline">\(p\)</span>. A histogram is constructed of the simulated draws of <span class="math inline">\(Y\)</span> in Figure 9.9. This graph represents an approximate sample from the marginal distribution <span class="math inline">\(f(y)\)</span> of <span class="math inline">\(Y\)</span>.</p>
<pre><code>sp &lt;- data.frame(gibbs_betabin(20, 5, 5))</code></pre>

<div class="figure"><span id="fig:unnamed-chunk-16"></span>
<img src="../LATEX/figures/chapter9/mcmc5.png" alt="Histogram of simulated draws of $Y$ from Gibbs sampling for the Beta-Binomial model with $n = 20$, $a = 5$, and $b = 5$." width="500" />
<p class="caption">
Figure 9.9: Histogram of simulated draws of <span class="math inline">\(Y\)</span> from Gibbs sampling for the Beta-Binomial model with <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(a = 5\)</span>, and <span class="math inline">\(b = 5\)</span>.
</p>
</div>
</div>
<div id="normal-sampling-both-parameters-unknown" class="section level3">
<h3><span class="header-section-number">9.5.3</span> Normal sampling – both parameters unknown</h3>
<p></p>
<p>In Chapter 8, we considered the situation of sampling from a Normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. To simplify this to a one-parameter model, we assumed that the value of <span class="math inline">\(\sigma\)</span> was known and focused on the problem of learning about the mean <span class="math inline">\(\mu\)</span>. Since Gibbs sampling provides us to simulate from posterior distributions of more than one parameter, we can generalize to the more realistic situation where both the mean and the standard deviation are unknown.</p>
<p>Suppose we take a sample of <span class="math inline">\(n\)</span> observations <span class="math inline">\(Y_1, .., Y_n\)</span> from a Normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Recall the sampling density of <span class="math inline">\(Y_i\)</span> has the form
<span class="math display" id="eq:normsampling">\[\begin{equation}
f(y_i \mid \mu, \sigma) = \frac{1}{\sqrt{2 \pi} \sigma} \exp\left\{- \frac{1}{2 \sigma^2}(y_i - \mu)^2\right\}.
\tag{9.15}
\end{equation}\]</span>
It will be convenient to reexpress the variance <span class="math inline">\(\sigma\)</span> by the <em>precision</em> <span class="math inline">\(\phi\)</span> where
<span class="math display" id="eq:precision">\[\begin{equation}
\phi = \frac{1}{\sigma^2}.
\tag{9.16}
\end{equation}\]</span>
The precision <span class="math inline">\(\phi\)</span> reflects the strength in knowledge about the location of the observation <span class="math inline">\(Y_i\)</span>. If <span class="math inline">\(Y_i\)</span> is likely to be close to the mean <span class="math inline">\(\mu\)</span>, then the variance <span class="math inline">\(\sigma^2\)</span> would be small and so the precision <span class="math inline">\(\phi\)</span> would be large.
So we restate the sampling model as follows. The observations <span class="math inline">\(Y_1, .., Y_n\)</span> are a random sample from a Normal density with mean <span class="math inline">\(\mu\)</span> and precision <span class="math inline">\(\phi\)</span>, where the sampling density of <span class="math inline">\(Y_i\)</span> is given by
<span class="math display" id="eq:normsampling2">\[\begin{equation}
f(y_i \mid \mu, \phi) = \frac{\sqrt{\phi}}{\sqrt{2 \pi}} \exp\left\{- \frac{\phi}{2}(y_i - \mu)^2\right\}.
\tag{9.17}
\end{equation}\]</span></p>
<p>The next step is to construct a prior density on the parameter vector <span class="math inline">\((\mu, \phi)\)</span>. A convenient choice for this prior is to assume that one’s opinion about the location of the mean <span class="math inline">\(\mu\)</span> is independent of one’s belief about the location of the precision <span class="math inline">\(\phi\)</span>. So we assume that <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span> are independent, so one writes the joint prior density as
<span class="math display" id="eq:muphiprior">\[\begin{equation}
\pi(\mu, \phi) = \pi_{\mu}(\mu) \pi_{\phi}(\phi),
\tag{9.18}
\end{equation}\]</span>
where <span class="math inline">\(\pi_{\mu}()\)</span> and <span class="math inline">\(\pi_{\phi}()\)</span> are marginal densities. For convenience, each of these marginal priors are assigned conjugate forms: we assume that <span class="math inline">\(\mu\)</span> is Normal with mean <span class="math inline">\(\mu_0\)</span> and precision <span class="math inline">\(\phi_0\)</span>:
<span class="math display" id="eq:muprior">\[\begin{equation}
\pi_{\mu}(\mu) = \frac{\sqrt{\phi_0}}{\sqrt{2 \pi}} \exp\left\{-\frac{\phi_0}{2}(\mu - \mu_0)^2\right\}.
\tag{9.19}
\end{equation}\]</span>
The prior for the precision parameter <span class="math inline">\(\phi\)</span> is assumed Gamma with parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>:
<span class="math display" id="eq:phiprior">\[\begin{equation}
\pi_{\phi}(\phi) = \frac{b^a}{\Gamma(a)} \phi^{a-1} \exp(-b \phi), \, \, \phi  &gt; 0.
\tag{9.20}
\end{equation}\]</span></p>
<p>Once values of <span class="math inline">\(y_1, ..., y_n\)</span> are observed, the likelihood is the density of these Normal observations viewed as a function of the mean <span class="math inline">\(\mu\)</span> and the precision parameter <span class="math inline">\(\phi\)</span>. Simplifying the expression and removing constants, one obtains:
<span class="math display" id="eq:normlike">\[\begin{align}
        L(\mu, \phi) &amp;=\prod_{i=1}^n \frac{\sqrt{\phi}}{\sqrt{2 \pi}} \exp\left\{-\frac{\phi}{2}(y_i - \mu)^2\right\} \nonumber \\
        &amp; \propto \phi^{n/2} \exp\left\{-\frac{\phi}{2}\sum_{i=1}^n (y_i - \mu)^2\right\}.
\tag{9.21}
\end{align}\]</span></p>
<p>To implement Gibbs sampling, one first writes down the expression for the posterior density as the product of the likelihood and prior where any constants not involving the parameters are removed.</p>
<p><span class="math display" id="eq:postmuphi">\[\begin{eqnarray}
\pi(\mu, \phi \mid y_1, \cdots, y_n ) &amp;\propto &amp; \phi^{n/2} \exp\left\{-\frac{\phi}{2}\sum_{i=1}^n (y_i - \mu)^2\right\} \nonumber \\
 &amp; \times &amp; \exp\left\{-\frac{\phi_0}{2}(\mu - \mu_0)^2\right\}  \phi^{a-1} \exp(-b \phi).
 \tag{9.22}
\end{eqnarray}\]</span></p>
<p>Next, the two conditional posterior distributions <span class="math inline">\(\pi(\mu \mid \phi, y_1, \cdots, y_n)\)</span> and <span class="math inline">\(\pi(\phi \mid \mu, y_1, \cdots, y_n)\)</span> are identified.</p>
<ol style="list-style-type: decimal">
<li>The first conditional density <span class="math inline">\(\pi(\mu \mid \phi, y_1, \cdots, y_n)\)</span> follows from the work in Chapter 8 on Bayesian inference about a mean with a conjugate prior when the sampling standard deviation was assumed known. One obtains that this conditional distribution <span class="math inline">\(\pi(\mu \mid \phi, y_1, \cdots, y_n)\)</span> is Normal with mean
<span class="math display" id="eq:mumean">\[\begin{equation}
\mu_n = \frac{\phi_0 \mu_0  + n \phi \bar y }{\phi_0  + n \phi}.
\tag{9.23}
\end{equation}\]</span>
and standard deviation
<span class="math display" id="eq:musd">\[\begin{equation}
\sigma_n = \sqrt{\frac{1}{\phi_0  + n \phi}}.
\tag{9.24}
\end{equation}\]</span></li>
<li>Collecting terms, the second conditional density <span class="math inline">\(\pi(\phi \mid \mu, y_1, \cdots, y_n)\)</span> is proportional to
<span class="math display" id="eq:phipost">\[\begin{equation}
\pi(\phi \mid \mu, y_1, \cdots y_n) \propto \phi^{n/2 + a - 1} \exp\left\{-\phi\left[\frac{1}{2}\sum_{i=1}^n (y_i- \mu)^2 + b\right]\right\}. \\
\tag{9.25}
\end{equation}\]</span>
The second conditional distribution <span class="math inline">\(\pi(\phi \mid \mu, y_1, \cdots, y_n)\)</span> is seen to be a Gamma density with parameters
<span class="math display" id="eq:gamparametersA">\[\begin{equation}
a_n = \frac{n}{2} + a, 
\tag{9.26}
\end{equation}\]</span>
<span class="math display" id="eq:gamparametersB">\[\begin{equation}
b_n = \frac{1}{2}\sum_{i=1}^n (y_i - \mu)^2 + b.
\tag{9.27}
\end{equation}\]</span></li>
</ol>

    <p>An R function <code>gibbs_normal()</code> is written to implement this Gibbs sampling simulation. The inputs to this function are a list <code>s</code> containing the vector of observations <code>y</code> and the prior parameters <code>mu0</code>, <code>phi0</code>, <code>a</code>, and <code>b</code>, the starting value of the precision parameter <span class="math inline">\(\phi\)</span>, <code>phi</code>, and the number of Gibbs sampling iterations <code>S</code>. This function is similar in structure to the <code>gibbs_betabin()</code> function – the two simulations in the Gibbs sampling are accomplished by use of the <code>rnorm()</code> and <code>rgamma()</code> functions.</p>
<pre><code>gibbs_normal &lt;- function(s, phi = 0.002, iter = 1000){
  ybar &lt;- mean(s$y)
  n &lt;- length(s$y)
  mu0 &lt;- s$mu0
  phi0 &lt;- s$phi0
  a &lt;- s$a
  b &lt;- s$b
  x &lt;- matrix(0, iter, 2)
  for(k in 1:iter){
   mun &lt;- (phi0 * mu0 + n * phi * ybar) /
      (phi0 + n * phi)
    sigman &lt;- sqrt(1 / (phi0 + n * phi))
    mu &lt;- rnorm(1, mean = mun, sd = sigman)
    an &lt;- n / 2 + a
    bn &lt;- sum((s$y - mu) ^ 2) / 2 + b
    phi &lt;- rgamma(1, shape = an, rate = bn)
    x[k, ] &lt;- c(mu, phi)
  }
  x
}</code></pre>
<p>We run this function for our Buffalo snowfall example where now the sampling model is Normal with both the mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> unknown. The prior distribution assumes that <span class="math inline">\(\mu\)</span> and the precision <span class="math inline">\(\phi\)</span> are independent, where <span class="math inline">\(\mu\)</span> is Normal with mean 10 and standard deviation 3 (i.e. precision <span class="math inline">\(1/3^2\)</span>), and <span class="math inline">\(\phi\)</span> is Gamma with <span class="math inline">\(a = b = 1\)</span>. The output of this function is a matrix <code>out</code>  where the two columns of the matrix correspond to random draws of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span> from the posterior distribution.</p>
<pre><code>s &lt;- list(y = data$JAN, mu0 = 10, phi0 = 1/3^2, a = 1, b = 1)
out &lt;- gibbs_normal(s, iter=10000)</code></pre>
<p>By performing the transformation <span class="math inline">\(\sigma = \sqrt{1 / \phi}\)</span>, one obtains a sample of the simulated draws of the standard deviation <span class="math inline">\(\sigma\)</span>. Figure 9.10  displays a scatterplot of the posterior draws of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p>

<div class="figure"><span id="fig:unnamed-chunk-17"></span>
<img src="../LATEX/figures/chapter9/mcmc9.png" alt="Scatterplot of simulated draws of the posterior distribution of mean and standard deviation from Gibbs sampling for the Normal sampling model with independent priors on the  mean and the precision." width="500" />
<p class="caption">
Figure 9.10: Scatterplot of simulated draws of the posterior distribution of mean and standard deviation from Gibbs sampling for the Normal sampling model with independent priors on the mean and the precision.
</p>
</div>
</div>
</div>
<div id="mcmc-inputs-and-diagnostics" class="section level2">
<h2><span class="header-section-number">9.6</span> MCMC Inputs and Diagnostics</h2>
<p></p>
<div id="burn-in-starting-values-and-multiple-chains" class="section level3">
<h3><span class="header-section-number">9.6.1</span> Burn-in, starting values, and multiple chains</h3>
<p></p>
<p>In theory, the Metropolis and Gibbs sampling algorithms will produce simulated draws that converge to the posterior distribution of interest. But in typical practice, it may take a number of iterations before the simulation values are close to the posterior distribution. So in general it is recommended that one run the algorithm for a number of “burn-in” iterations before one collects iterations for inference. The JAGS software that is introduced in Section 9.7 will allow the user to specify the number of burn-in iterations.</p>
<p>In the examples, we have illustrated running a single “chain” where one has a single starting value and one collects simulated draws from many iterations. It is possible that the MCMC sample will depend on the choice of starting value. So a general recommendation is to run the MCMC algorithm several times using different starting values. In this case, one will have multiple MCMC chains. By comparing the inferential summaries from the different chains one explores the sensitivity of the inference to the choice of starting value. Although we will focus on the use of a single chain, we will explore the use of different starting values and multiple chains in an example in this chapter. The JAGS software and other programs to implement MCMC will allow for different starting values and several chains.</p>
</div>
<div id="diagnostics" class="section level3">
<h3><span class="header-section-number">9.6.2</span> Diagnostics</h3>
<p>The output of a single chain from the Metropolis and Gibbs algorithms is a vector or matrix of simulated draws. Before one believes that a collection of simulated draws is a close approximation to the posterior distribution, some special diagnostic methods should be initially performed.</p>
<p><strong>Trace plot</strong></p>
<p>It is helpful to construct a trace plot which is a line plot of the simulated draws of the parameter of interest graphed against the iteration number. Figure 9.11 displays a trace plot of the simulated draws of <span class="math inline">\(\mu\)</span> from the Metropolis algorithm for our Buffalo snowfall example for Normal sampling (known standard deviation) with a Cauchy prior. Section 9.4.1 shows some sample trace plots for Metropolis sampler. As discussed in that section, it is undesirable to have a snack-like appearance in the trace plot indicating a high acceptance rate. Also, Section 9.4.1 displays a trace plot with many flat portions that indicates a sampler with a low acceptance rate. From the authors’ experience, the trace plot in Figure 9.11 indicates that the sampler is using a good value of the constant <span class="math inline">\(C\)</span> and efficiently sampling from the posterior distribution.</p>

<div class="figure"><span id="fig:unnamed-chunk-18"></span>
<img src="../LATEX/figures/chapter9/mcmc6.png" alt="Trace plot of simulated draws of normal mean using the Metropolis algorithm with $C = 20$." width="500" />
<p class="caption">
Figure 9.11: Trace plot of simulated draws of normal mean using the Metropolis algorithm with <span class="math inline">\(C = 20\)</span>.
</p>
</div>
<p><strong>Autocorrelation plot</strong></p>
<p>Since one is simulating a dependent sequence of values of the parameter, one is concerned about the possible strong correlation between successive draws of the sampler. One visualizes this dependence by computing the correlation of the pairs {<span class="math inline">\(\theta^{(j)}, \theta^{(j + l)}\)</span>} and plotting this "lag-correlation" as a function of the lag value <span class="math inline">\(l\)</span>. This autocorrelation plot of the simulated draws from our example is displayed in Figure 9.12. If there is a strong degree of autocorrelation in the sequence, then there will be a large correlation of these pairs even for large values of the lag value. Figure 9.12 is an example of a suitable autocorrelation graph where the lag correlation values quickly drop to zero as a function of the lag value. This autocorrelation graph is another indication that the Metropolis algorithm is providing an efficient sampler of the posterior.</p>

<div class="figure"><span id="fig:unnamed-chunk-19"></span>
<img src="../LATEX/figures/chapter9/mcmc7.png" alt="Autocorrelation plot of simulated draws of normal mean using the Metropolis algorithm with $C = 20$." width="500" />
<p class="caption">
Figure 9.12: Autocorrelation plot of simulated draws of normal mean using the Metropolis algorithm with <span class="math inline">\(C = 20\)</span>.
</p>
</div>

</div>
<div id="graphs-and-summaries" class="section level3">
<h3><span class="header-section-number">9.6.3</span> Graphs and summaries</h3>
<p>If the trace plot or autocorrelation plot indicate issues with the Metropolis sampler, then the width of the proposal <span class="math inline">\(C\)</span> should be adjusted and the algorithm run again. Since we believe that the Metropolis simulation stream is reasonable with the use of the value <span class="math inline">\(C = 20\)</span> , then one uses a histogram of simulated draws, as displayed in Figure 9.13 to represent the posterior distribution. Alternatively, a density estimate of the simulated draws can be used to show a smoothed representation of the posterior density. Figure  places a density estimate on top of the histogram of the simulated values of the parameter <span class="math inline">\(\mu\)</span>.</p>
<div class="figure"><span id="fig:unnamed-chunk-20"></span>
<img src="../LATEX/figures/chapter9/mcmc8.png" alt="Histogram of simulated draws of the normal mean using the Metropolis algorithm with $C = 20$. The solid curve is a density estimate of the simulated values." width="500" />
<p class="caption">
Figure 9.13: Histogram of simulated draws of the normal mean using the Metropolis algorithm with <span class="math inline">\(C = 20\)</span>. The solid curve is a density estimate of the simulated values.
</p>
</div>
<p>One estimates different summaries of the posterior distribution by computing different summaries of the simulated sample. In our Cauchy-Normal model, one estimates, for example, the posterior mean of <span class="math inline">\(\mu\)</span> by computing the mean of the simulated posterior draws:
<span class="math display" id="eq:simmean">\[\begin{equation}
E(\mu \mid y) \approx \frac{\sum_{j = 1}^S \mu^{(j)}}{S}.
\tag{9.28}
\end{equation}\]</span>
One typically wants to estimate the simulation standard error of this MCMC estimate. If the draws from the posterior were independent, then the Monte Carlo standard error of this posterior mean estimate would be given by the standard deviation of the draws divided by the square root of the simulation sample size:
<span class="math display" id="eq:simse">\[\begin{equation}
se = \frac{sd(\{\mu^{(j)}\})}{\sqrt{S}}.
\tag{9.29}
\end{equation}\]</span>
However, this estimate of the standard error is not correct since the MCMC sample is not independent (the simulated value <span class="math inline">\(\mu^{(j)}\)</span> depends on the value of the previous simulated value <span class="math inline">\(\mu^{(j-1)}\)</span>). One obtains a more accurate estimate of Monte Carlo standard error by using time-series methods. As we will see in the examples of Section 9.7, this standard error estimate will be larger than the “naive” standard error estimate that assumes the MCMC sample values are independent.</p>
</div>
</div>
<div id="using-jags" class="section level2">
<h2><span class="header-section-number">9.7</span> Using JAGS</h2>
<p></p>
<p>Sections 9.3 and 9.5 have illustrated general strategies for simulating from a posterior distribution of one or more parameters. Over the years, there has been an effort to develop general-purpose Bayesian computing software that would take a Bayesian model (i.e. the specification of a prior and sampling density as input), and use an MCMC algorithm to output a matrix of simulated draws from the posterior. One of the earliest Bayesian simulation-based computing software was BUGS (for Bayesian inference Using Gibbs Sampling) and we illustrate in this text applications of a similar package JAGS (for Just Another Gibbs Sampler).</p>
<p>The use of JAGS has several attractive features. One defines a Bayesian model for a particular problem by writing a short script. One then inputs this script together with data and prior parameter values in a single R function from the <code>runjags</code> package that decides on the appropriate MCMC sampling algorithm for the particular Bayesian model. In addition, this function simulates from the MCMC algorithm for a specified number of samples and collects simulated draws of the parameters of interest.</p>
<div id="normal-sampling-model" class="section level3">
<h3><span class="header-section-number">9.7.1</span> Normal sampling model</h3>
<p>To illustrate the use of JAGS, consider the problem of estimating the mean Buffalo snowfall assuming a Normal sampling model with both the mean and standard deviation unknown, and independent priors placed on both parameters. As in Section 9.5.3 one expresses the parameters of the Normal distribution as <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span>, where the precision <span class="math inline">\(\phi\)</span> is the reciprocal of the variance <span class="math inline">\(\phi = 1 / \sigma^2\)</span>. One then writes this Bayesian model as</p>
<ul>
<li><p>Sampling, for <span class="math inline">\(i = 1, \cdots, n\)</span>:
<span class="math display" id="eq:sampnormal2">\[\begin{equation}
Y_i \overset{i.i.d.}{\sim} \textrm{Normal}(\mu, \sqrt{1/\phi}).
\tag{9.30}
\end{equation}\]</span></p></li>
<li><p>Independent priors for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span>:
<span class="math display" id="eq:muphiprior2a">\[\begin{equation}
\mu \sim \textrm{Normal}(\mu_0, \sqrt{1/\phi_0}), \tag{9.31}
\end{equation}\]</span>
<span class="math display" id="eq:muphiprior2b">\[\begin{equation}
\phi \sim \textrm{Gamma}(a, b).
\tag{9.32}
\end{equation}\]</span></p></li>
</ul>
<p>The JAGS program parametrizes a Normal density in terms of the precision, so the prior precision is equal to <span class="math inline">\(\phi_0 = 1 / \sigma_0^2\)</span>. As in Section 9.5.3, the parameters of the Normal and Gamma priors are set at <span class="math inline">\(\mu_0 = 10, \phi_0 = 1 / 3 ^ 2, a = 1, b = 1.\)</span></p>
<p><strong>Describe the model by a script</strong></p>

<p>To begin, one writes the following script defining this model. The model is saved in the character string <code>modelString</code>.</p>
<pre><code>modelString = &quot;
model{
## sampling
for (i in 1:N) {
   y[i] ~ dnorm(mu, phi)
}
## priors
mu ~ dnorm(mu0, phi0)
phi ~ dgamma(a, b)
sigma &lt;- sqrt(pow(phi, -1))
}</code></pre>
<p>Note that this script closely resembles the statement of the model. In the sampling part of the script, the loop structure starting with <code>for (i in 1:N)</code> is used to assign the distribution of each value in the data vector <code>y</code> the same Normal distribution, represented by <code>dnorm</code>. The <code>~</code> operator is read as “is distributed as”.</p>
<p>In the priors part of the script, in addition to setting the Normal prior and Gamma prior for <code>mu</code> and <code>phi</code> respectively, <code>sigma &lt;- sqrt(pow(phi, -1))</code> is added to help track <code>sigma</code> directly.</p>
<p><strong>Define the data and prior parameters</strong></p>
<p>The next step is to define the data and provide values for parameters of the prior. In the script below, a list <code>the_data</code> is used to collect the vector of observations <code>y</code>, the number of observations <code>N</code>, and values of the Normal prior parameters <code>mu0</code>, <code>phi0</code>, and of the Gamma prior parameters <code>a</code> and <code>b</code>.</p>
<pre><code>buffalo &lt;- read.csv(&quot;../data/buffalo_snowfall.csv&quot;)
data &lt;- buffalo[59:78, c(&quot;SEASON&quot;, &quot;JAN&quot;)]
y &lt;- data$JAN
N &lt;- length(y)
the_data &lt;- list(&quot;y&quot; = y, &quot;N&quot; = N, 
                 &quot;mu0&quot;=10, &quot;phi0&quot;=1/3^2, 
                 &quot;a&quot;=1,&quot;b&quot;=1)</code></pre>
<p><strong>Define initial values</strong></p>
<p>One needs to supply initial values in the MCMC simulation for all of the parameters in the model.
To obtain reproducible results, one can use the <code>initsfunction()</code> function shown below to set the seed for the sequence of simulated parameter values in the MCMC.</p>
<pre><code>initsfunction &lt;- function(chain){
  .RNG.seed &lt;- c(1,2)[chain]
  .RNG.name &lt;- c(&quot;base::Super-Duper&quot;,
                 &quot;base::Wichmann-Hill&quot;)[chain]
  return(list(.RNG.seed=.RNG.seed,
              .RNG.name=.RNG.name))</code></pre>
<p>Alternatively, one can specify the initial values by means of a function – this will be implemented when multiple chains are discussed. If no initial values are specified, then JAGS will select initial values – these are usually a "typical" value such as a mean or median from the prior distribution.</p>
<p><strong>Generate samples from the posterior distribution</strong></p>
<p>Now that the model definition and data have been defined, one is ready to draw samples from the posterior distribution. The <code>runjags</code> provides the R interface to the use of the JAGS software. The <code>run.jags()</code> function sets up the Bayesian model defined in <code>modelString</code>. The input <code>n.chains = 1</code> indicates that one stream of simulated values will be generated. <code>adapt = 1000</code> says that 1000 simulated iterations are used in “adapt period” to prepare for MCMC, <code>burnin = 1000</code> indicates 5000 simulated iterations are used in a “burn-in” period where the iterations are approaching the main probability region of the posterior distribution. The <code>sample = 5000</code> arguments indicates that 5000 additional iterations of the MCMC algorithm will be collected. The <code>monitor</code> arguments says that we are collecting simulated values of the mean <code>mu</code> and the standard deviation <code>sigma</code>. The output variable <code>posterior</code> includes a matrix of the simulated draws. The <code>inits = initsfunction</code> argument indicates that initial parameter values are chosen by the <code>initsfunction()</code> function.</p>
<pre><code>posterior &lt;- run.jags(modelString,
                      n.chains = 1,
                      data = the_data,
                      monitor = c(&quot;mu&quot;, &quot;sigma&quot;),
                      adapt = 1000,
                      burnin = 5000,
                      sample = 5000,
                      inits = initsfunction)</code></pre>
<p><strong>MCMC diagnostics and summarization</strong></p>
<p>Before summarizing the simulated sample, some graphical diagnostics methods should be implemented to judge if the sample appears to “mix” or move well across the space of likely values of the parameters. The <code>plot()</code> function in the <code>runjags</code> package constructs a collection of four graphs for a parameter of interest. By running <code>plot()</code> for <code>mu</code> and <code>sigma</code>, we obtain the graphs displayed in Figures 9.14 and 9.15.</p>
<pre><code>plot(posterior, vars = &quot;mu&quot;)
plot(posterior, vars = &quot;sigma&quot;)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-21"></span>
<img src="../LATEX/figures/chapter9/jags1a.png" alt="Diagnostic plots of simulated draws of mean using the JAGS software with the runjags package." width="500" />
<p class="caption">
Figure 9.14: Diagnostic plots of simulated draws of mean using the JAGS software with the runjags package.
</p>
</div>
<div class="figure"><span id="fig:unnamed-chunk-22"></span>
<img src="../LATEX/figures/chapter9/jags1b.png" alt="Diagnostic plots of simulated draws of standard deviation using the JAGS software with the runjags package." width="500" />
<p class="caption">
Figure 9.15: Diagnostic plots of simulated draws of standard deviation using the JAGS software with the runjags package.
</p>
</div>
<p>The trace and autocorrelation plots in the top left and bottom right sections of the display are helpful for seeing how the sampler moves across the posterior distribution.
In Figures 9.14 and 9.15, the trace plots show little autocorrelation in the streams of simulated draws and both simulated samples of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> appear to mix well. In the autocorrelation plots, the value of the autocorrelation drops sharply to zero as a function of the lag which confirms that we have modest autocorrelation in these samples. In each display, the bottom left graph is a histogram of the simulated draws and the top right graph is an estimate at the cumulative distribution function of the variable.</p>
<p>Since we are encouraged by these diagnostic graphs, we go ahead and obtain summaries of the simulated samples of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> by the <code>print()</code> function on our MCMC object. The posterior mean of <span class="math inline">\(\mu\)</span> is 16.5. The standard error of this simulation estimate is the "MCerr" value of 0.0486 – this standard error takes in account the correlated nature of these simulated draws. A 90% probability interval for the mean <span class="math inline">\(\mu\)</span> is found from the output to be (10.8, 21.4). For <span class="math inline">\(\sigma\)</span>, it has a posterior mean of 17.4, and a 90% probability interval (11.8, 24).</p>
<pre><code>print(posterior, digits = 3)
      Lower95 Median Upper95 Mean   SD Mode  MCerr 
mu       10.8   16.5    21.4 16.5 2.68   -- 0.0486     
sigma    11.8   17.1      24 17.4 3.18   -- 0.0576    </code></pre>
</div>
<div id="multiple-chains" class="section level3">
<h3><span class="header-section-number">9.7.2</span> Multiple chains</h3>
<p>In Section 9.6.1, we explained the benefit of trying different starting values and running several MCMC chains. This is facilitated by arguments in the <code>run.jags()</code> function. Suppose one considers the very different pairs of starting values, <span class="math inline">\((\mu, \phi) = (2, 1 / 4)\)</span> and <span class="math inline">\((\mu, \phi) = (30, 1/ 900)\)</span>. Note that both pair of parameter values are far outside of the region where the posterior density is concentrated. One defines a value <code>InitialValues</code> that is a list containing two lists, each list containing a starting value.</p>
<pre><code>InitialValues &lt;- list(
  list(mu = 2, phi = 1 / 4),
  list(mu = 30, phi = 1 / 900)
)</code></pre>
<p>The <code>run.jags()</code> function is run with two modifications – one chooses <code>n.chains = 2</code> and the initial values are input through the <code>inits = InitialValues</code> option.</p>
<pre><code>posterior &lt;- run.jags(modelString,
                      n.chains = 2,
                      data = the_data,
                      monitor = c(&quot;mu&quot;, &quot;sigma&quot;),
                      adapt = 1000,
                      burnin = 5000,
                      sample = 5000,
                      inits = InitialValues)</code></pre>
    <p>The output variable <code>posterior</code> contains a component <code>mcmc</code> which is a list of two components where<code>posterior$mcmc[[1]]</code>contains the simulated draws from the first chain and<code>posterior$mcmc[[2]]</code> contains the simulated draws from the second chain. To see if the MCMC run is sensitive to the choice of starting value, one compares posterior summaries from the two chains. Below, we display posterior quantiles for the parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> for each chain. Note that these quantiles are very close in value indicating that the MCMC run is insensitive to the choice of starting value.</p>
<pre><code>summary(posterior$mcmc[[1]], digits = 3)
2. Quantiles for each variable:

       2.5%   25%   50%   75% 97.5%
mu    10.99 14.64 16.49 18.35 21.62
sigma 12.26 15.15 17.03 19.31 25.07

summary(posterior$mcmc[[2]], digits = 3)
2. Quantiles for each variable:

       2.5%   25%   50%   75% 97.5%
mu    10.97 14.59 16.55 18.33 21.54
sigma 12.21 15.08 16.96 19.18 24.99</code></pre>
</div>
<div id="posterior-predictive-checking" class="section level3">
<h3><span class="header-section-number">9.7.3</span> Posterior predictive checking</h3>
<p></p>
<p>In Chapter 8 Section 8.7, we illustrated the usefulness of the posterior predictive checking in model checking. The basic idea is to simulate a number of replicated datasets from the posterior predictive distribution and see how the observed sample compares to the replications. If the observed data does resemble the replications, one says that the observed data is consistent with predicted data from the Bayesian model.</p>
<p>For our Buffalo snowfall example, suppose one wishes to simulate a replicated sample from the posterior predictive distribution. Since our original sample size was <span class="math inline">\(n = 20\)</span>, the intent is to simulate a sample of values <span class="math inline">\(\tilde y_1, ..., \tilde y_{20}\)</span> from the posterior predictive distribution. A single replicated sample is simulated in the following two steps.</p>
<ol style="list-style-type: decimal">
<li>We draw a set of parameter values, say <span class="math inline">\(\mu^*, \sigma^*\)</span> from the posterior distribution of <span class="math inline">\((\mu, \sigma)\)</span>.<br />
</li>
<li>Given these parameter values, we simulate <span class="math inline">\(\tilde y_1, ..., \tilde y_{20}\)</span> from the Normal sampling density with mean <span class="math inline">\(\mu^*\)</span> and standard deviation <span class="math inline">\(\sigma^*\)</span>.</li>
</ol>

<p>Recall that the simulated posterior values are stored in the matrix <code>post</code>. We write a function <code>postpred_sim()</code> to simulate one sample from the predictive distribution.</p>
<pre><code>post &lt;- data.frame(posterior$mcmc[[1]])
postpred_sim &lt;- function(j){
  rnorm(20, mean = post[j, &quot;mu&quot;],
        sd = post[j, &quot;sigma&quot;])
}
print(postpred_sim(1), digits = 3)
 [1]   5.37  10.91  40.87  15.94  16.93  43.49  22.48
 [8]  -6.43   3.26   7.30  35.27  20.79  21.47  16.62
[15]   5.45  44.69  23.10 -18.18  26.51   6.84</code></pre>
<p>If this process is repeated for each of the 5000 draws from the posterior distribution, then one obtains 5000 samples of size 20 drawn from the predictive distribution.
In R, the function <code>sapply()</code> is used together with <code>postpred_sim()</code> to simulate 5000 samples that are stored in the matrix <code>ypred</code>.</p>
<pre><code>ypred &lt;- t(sapply(1:5000, postpred_sim))</code></pre>
<p>Figure 9.16 displays histograms of the predicted snowfalls from eight of these simulated samples and the observed snowfall measurements are displayed in the lower right panel. Generally, the center and spread of the observed snowfalls appear to be similar in appearance to the eight predicted snowfall samples from the fitted model.
Can we detect any differences between the distribution of observed snowfalls and the distributions of predicted snowfalls? One concern is that some of the predictive samples contain negative snowfall values. Another concern from this inspection is that we observed a snowfall of 65.1 inches in our sample and none of our eight samples had a snowfall this large. Perhaps there is an outlier in our sample that is not consistent with predictions from our model.</p>

<div class="figure"><span id="fig:unnamed-chunk-23"></span>
<img src="../LATEX/figures/chapter9/ppcheck1.png" alt="Histograms of eight simulated predictive samples and the observed sample for the snowfall example." width="500" />
<p class="caption">
Figure 9.16: Histograms of eight simulated predictive samples and the observed sample for the snowfall example.
</p>
</div>
<p>When one notices a possible discrepancy between the observed sample and simulated prediction samples, one thinks of a checking function <span class="math inline">\(T()\)</span> that will distinguish the two types of samples. In this situation since we noticed the extreme snowfall of 65.1 inches, that suggests that we use <span class="math inline">\(T(y) = \max y\)</span> as a checking function.</p>
<p>Once one decides on a checking function <span class="math inline">\(T()\)</span>, then one simulates the posterior predictive distribution of <span class="math inline">\(T(\tilde y)\)</span>. This is conveniently done by evaluating the function <span class="math inline">\(T()\)</span> on each simulated sample from the predictive distribution. In R, this is conveniently done using the <code>apply()</code> function and the values of <span class="math inline">\(T(\tilde y)\)</span> are stored in the vector <code>postpred_max</code>.</p>
<pre><code>postpred_max &lt;- apply(ypred, 1, max)</code></pre>
<p>If the checking function evaluated at the observed sample <span class="math inline">\(T(y)\)</span> is not consistent with the distribution of <span class="math inline">\(T(\tilde y)\)</span>, then predictions from the model are not similar to the observed data and there is some issue with the model assumptions. Figure 9.17 displays a histogram of the predictive distribution of <span class="math inline">\(T(y)\)</span> in our example where <span class="math inline">\(T()\)</span> is the maximum function, and the observed maximum snowfall is shown by a vertical line. Here the observed maximum is in the right tail of the posterior predictive distribution – the interpretation is that this largest snowfall of 65.1 inches is not predicted from the model. In this case, one might want to think about revising the sampling model, say, by assuming that the data follow a distribution with flatter tails than the Normal.</p>

<div class="figure"><span id="fig:unnamed-chunk-24"></span>
<img src="../LATEX/figures/chapter9/ppcheck2.png" alt="Histogram of the posterior predictive distribution of T(y) where T() is the maximum function.  The vertical line shows the location of the observed value T(y)." width="500" />
<p class="caption">
Figure 9.17: Histogram of the posterior predictive distribution of T(y) where T() is the maximum function. The vertical line shows the location of the observed value T(y).
</p>
</div>
</div>
<div id="comparing-two-proportions" class="section level3">
<h3><span class="header-section-number">9.7.4</span> Comparing two proportions</h3>
<p></p>
<p>To illustrate the usefulness of the JAGS software, we consider a problem comparing two proportions from independent samples. The model is defined in a JAGS script, the data and values of prior parameters are entered through a list, and the <code>run.jags()</code> function is used to simulate from the posterior of the parameters by an MCMC algorithm.</p>
<p>To better understand the behavior of Facebook users, a survey was administered in 2011 to 244 students. Each student was asked their gender and the average number of times they visited Facebook in a day. We say that the number of daily visits is “high” if the number of visits is 5 or more; otherwise it is “low”. If we classify the sample by gender and daily visits, one obtains the two by two table of counts as shown in Table 9.1.</p>
<p>Table 9.1. Two-way table of counts of students by gender and Facebook visits.</p>
<table>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center">High</td>
<td align="center">Low</td>
</tr>
<tr class="even">
<td align="center">Male</td>
<td align="center"><span class="math inline">\(y_M\)</span></td>
<td align="center"><span class="math inline">\(n_M - y_M\)</span></td>
</tr>
<tr class="odd">
<td align="center">Female</td>
<td align="center"><span class="math inline">\(y_F\)</span></td>
<td align="center"><span class="math inline">\(n_F - y_F\)</span></td>
</tr>
</tbody>
</table>
<p>In Table 9.1, the random variable <span class="math inline">\(Y_M\)</span> represents the number of males who have a high number of Facebook visits in a sample of <span class="math inline">\(n_M\)</span>, and <span class="math inline">\(Y_F\)</span> and <span class="math inline">\(n_M\)</span> are the analogous count and sample size for women. Assuming that the sample survey represents a random sample from all students using Facebook, then it is reasonable to assume that <span class="math inline">\(Y_M\)</span> and <span class="math inline">\(Y_F\)</span> are independent with <span class="math inline">\(Y_M\)</span> distributed Binomial with parameters <span class="math inline">\(n_M\)</span> and <span class="math inline">\(p_M\)</span>, and <span class="math inline">\(Y_F\)</span> is Binomial with parameters <span class="math inline">\(n_F\)</span> and <span class="math inline">\(p_F\)</span>.</p>
<p>Table 9.2. Probability structure in two-way table.</p>
<table>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center">High</td>
<td align="center">Low</td>
</tr>
<tr class="even">
<td align="center">Male</td>
<td align="center"><span class="math inline">\(p_M\)</span></td>
<td align="center"><span class="math inline">\(1 - p_M\)</span></td>
</tr>
<tr class="odd">
<td align="center">Female</td>
<td align="center"><span class="math inline">\(p_F\)</span></td>
<td align="center"><span class="math inline">\(1 - p_F\)</span></td>
</tr>
</tbody>
</table>
<p>The probabilities <span class="math inline">\(p_M\)</span> and <span class="math inline">\(p_F\)</span> are displayed in Table 9.2. In this type of data structure, one is interested in the association between gender and Facebook visits. Define the odds as the ratio of the probability of “high” to the probability of “low”. The odds of “high” for the men and odds of ’high" for the women are defined by
<span class="math display" id="eq:oddsM">\[\begin{equation}
\frac{p_M}{1 - p_M},
\tag{9.33}
\end{equation}\]</span>
and
<span class="math display" id="eq:oddsF">\[\begin{equation}
\frac{p_F}{1-p_F},
\tag{9.34}
\end{equation}\]</span>
respectively. The odds ratio
<span class="math display" id="eq:oddsratio">\[\begin{equation}
\alpha = \frac{p_M / (1 - p_M)}{p_F / (1 - p_F)},
\tag{9.35}
\end{equation}\]</span>
is a measure of association in this two-way table. If <span class="math inline">\(\alpha = 1\)</span>, this means that <span class="math inline">\(p_M = p_L\)</span> – this says that tendency to have high visits to Facebook does not depend on gender. If <span class="math inline">\(\alpha &gt; 1\)</span>, this indicates that men are more likely to have high visits to Facebook, and a value <span class="math inline">\(\alpha &lt; 1\)</span> indicates that women are more likely to have high visits. Sometimes association is expressed on a log scale – the log odds ratio <span class="math inline">\(\lambda\)</span> is written as
<span class="math display" id="eq:logoddsratio">\[\begin{equation}
\lambda = \log \alpha = \log\left(\frac{p_M} {1 - p_M}\right) - \log\left(\frac{p_F} {1 - p_F}\right).
\tag{9.36}
\end{equation}\]</span>
That is, the log odds ratio is expressed as the difference in the logits of the men and women probabilities, where the logit of a probability <span class="math inline">\(p\)</span> is equal to <span class="math inline">\({\rm logit}(p) = \log(p) - \log(1 - p)\)</span>. If gender is independent of Facebook visits, then <span class="math inline">\(\lambda = 0\)</span>.</p>
<p>One’s prior beliefs about association in the two-way table is expressed in terms of logits and the log odds ratio. If one believes that gender and Facebook visits are independent, then the log odds ratio is assigned a Normal prior with mean 0 and standard deviation <span class="math inline">\(\sigma\)</span>. The mean of 0 reflects the prior guess of independence and <span class="math inline">\(\sigma\)</span> indicates the strength of the belief in independence. If one believed strongly in independence, then one would assign <span class="math inline">\(\sigma\)</span> a small value.</p>
<p>In addition, let
<span class="math display" id="eq:meanlogits">\[\begin{equation}
\theta = \frac{{\rm logit}(p_M) + \rm{logit}(p_F)}{2}
\tag{9.37}
\end{equation}\]</span>
be the mean of the logits, and assume that <span class="math inline">\(\theta\)</span> has a Normal prior with mean <span class="math inline">\(\theta_0\)</span> and standard deviation <span class="math inline">\(\sigma_0\)</span> (precision <span class="math inline">\(\phi_0\)</span>). The prior on <span class="math inline">\(\theta\)</span> reflects beliefs about the general size of the proportions on the logit scale.</p>

<p>To fit this model using JAGS, the following script, saved in <code>modelString</code>, is written defining the model.</p>
<pre><code>modelString = &quot;
model{
## sampling
yF ~ dbin(pF, nF)
yM ~ dbin(pM, nM)
logit(pF) &lt;- theta - lambda / 2
logit(pM) &lt;- theta + lambda / 2
## priors
theta ~ dnorm(mu0, phi0)
lambda ~ dnorm(0, phi)
}
&quot;</code></pre>
<p>In the sampling part of the script, the two first lines define the Binomial sampling models, and the logits of the probabilities are defined in terms of the log odds ratio <code>lambda</code> and the mean of the logits <code>theta</code>. In the priors part of the script, note that <code>theta</code> is assigned a Normal prior with mean <code>mu0</code> and precision <code>phi0</code>, and <code>lambda</code> is assigned a Normal prior with mean 0 and precision <code>phi</code>.</p>
<p>When the sample survey is conducted, one observes that 75 of the 151 female students say that they are high visitors of Facebook, and 39 of the 93 male students are high visitors. This data and the values of the prior parameters are entered into R by use of a list. Note that <code>phi = 2</code> indicating some belief that gender is independent of Facebook visits, and <code>mu0 = 0</code> and <code>phi0 = 0.001</code> reflecting little knowledge about the location of the logit proportions. Using the <code>run.jags()</code> function, we take an adapt period of 1000, burn-in period of 5000 iterations and collect 5000 iterations, storing values of <code>pF</code>, <code>pM</code> and the log odds ratio <code>lambda</code>.</p>
<pre><code>the_data &lt;- list(&quot;yF&quot; = 75, &quot;nF&quot; = 151, 
                 &quot;yM&quot; = 39, &quot;nM&quot; = 93,
                 &quot;mu0&quot; = 0, &quot;phi0&quot; = 0.001, &quot;phi&quot; = 2)

posterior &lt;- run.jags(modelString,
                 data = the_data,
                 n.chains = 1,
                 monitor = c(&quot;pF&quot;, &quot;pM&quot;, &quot;lambda&quot;),
                 adapt = 1000,
                 burnin = 5000,
                 sample = 5000)</code></pre>
<p>Since the main goal is to learn about the association structure in the table, Figure 9.18 displays a density estimate of the posterior draws of the log odds ratio <span class="math inline">\(\lambda\)</span>. A reference line at <span class="math inline">\(\lambda = 0\)</span> is drawn on the graph which corresponds to the case where <span class="math inline">\(p_M = p_L\)</span>. What is the probability that women are more likely than men to have high visits in Facebook? This is directly answered by computing the posterior probability <span class="math inline">\(Prob(\lambda &lt; 0 \mid data)\)</span> that is computed to be 0.874. Based on this computation, one concludes that it is very probable that women have a higher tendency than men to have high visits on Facebook.</p>
<pre><code>post &lt;- data.frame(posterior$mcmc[[1]])
post %&gt;% 
  summarize(Prob = mean(lambda &lt; 0))
      Prob
1 0.874</code></pre>

<p>In the end-of-chapter exercises, the reader will be asked to perform further explorations with this two proportion model.</p>
<div class="figure"><span id="fig:unnamed-chunk-25"></span>
<img src="../LATEX/figures/chapter9/jags4.png" alt="Posterior density estimate of simulated draws of log odds ratio  for visits to Facebook example.  A vertical line is drawn at the value 0 corresponding to no association between gender and visits to Facebook." width="500" />
<p class="caption">
Figure 9.18: Posterior density estimate of simulated draws of log odds ratio for visits to Facebook example. A vertical line is drawn at the value 0 corresponding to no association between gender and visits to Facebook.
</p>
</div>
</div>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">9.8</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><strong>Normal and Cauchy Priors</strong></li>
</ol>
<p>In the example in Section 9.1.2, it was assumed that the prior for the average snowfall <span class="math inline">\(\mu\)</span> was Normal with mean 10 inches and standard deviation 3 inches.</p>
<ol style="list-style-type: lower-alpha">
<li>Confirm that the 25th and 75th percentiles of this prior are equal to 8 and 12 inches, respectively.</li>
<li>Show that under this Normal prior, it is unlikely that the mean <span class="math inline">\(\mu\)</span> is at least as large as 26.75 inches.</li>
<li>Confirm that a Cauchy distribution with location 10 inches and scale parameter 2 inches also have 25th and 75th percentiles equal to 8 and 12 inches, respectively.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><strong>A Random Walk</strong>
</li>
</ol>
<p>The following matrix represents the transition matrix for a random walk
on the integers {1, 2, 3, 4, 5}.</p>
<p><span class="math display">\[
P = \begin{bmatrix} 
.2 &amp;.8&amp; 0&amp; 0&amp; 0 \\
.2 &amp;.2&amp; .6&amp; 0&amp; 0\\
0 &amp;.2&amp; .6&amp; .2&amp; 0\\
0 &amp;0&amp; .6&amp; .2&amp; .2\\
0 &amp;0&amp; 0&amp; .8&amp; .2\\
\end{bmatrix}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Suppose one starts walking at the state value 4. Find the probability of landing at each location after a single step.</li>
<li>Starting at value 4, find the probability of landing at each location after three steps.</li>
<li>Explain what is means for this Markov Chain to be irreducible and aperiodic.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li><strong>A Random Walk (continued)</strong></li>
</ol>
<p>Consider the random walk Markov chain described in Exercise 2.</p>
<ol style="list-style-type: lower-alpha">
<li>Suppose one starts at the location 1. Using an R script with the <code>sample()</code> function (see example script Section 9.2.3),
simulate 1000 steps of the Markov chain using the probabilities given
in the transition matrix. Store the locations of the walk in a vector.</li>
<li>Compute the relative frequencies of the walker in the five states from
the simulation output. From this computation, guess at the value of the stationary distribution
vector <span class="math inline">\(w\)</span>.</li>
<li>Confirm that your guess is indeed the stationary distribution by using
the matrix computation <span class="math inline">\(w\)</span> %*% <span class="math inline">\(P\)</span>.</li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li><strong>Weird Weather</strong></li>
</ol>
<p>Suppose a city in Alaska has interesting weather. The four possible weather states are “sunny” (<span class="math inline">\(SU\)</span>), “rainy” (<span class="math inline">\(R\)</span>), “cloudy” (<span class="math inline">\(C\)</span>), and “snow” (<span class="math inline">\(SN\)</span>). If it is sunny one day, it is equally likely to be rainy, cloudy, and snow on the next day. If is currently rainy, then the probabilities of sunny, rain, cloudy, and snow on the next day are respectively 1/2, 1/6, 1/6, and 1/6. The following matrix gives the transitions of weather from one day to the next day.</p>
<p><span class="math display">\[
\begin{bmatrix} 
 &amp; SU &amp; R &amp; C &amp;  SN \\
  SU &amp; 0 &amp; 1/3 &amp; 1/3 &amp; 1/3 \\
  R &amp; 1/2 &amp; 1/6 &amp; 1/6 &amp; 1/6  \\
  C &amp; 0 &amp; 1/4 &amp; 1/2 &amp; 1/4  \\
  SN &amp; 0 &amp; 1/4 &amp; 1/4 &amp; 1/2  \\
\end{bmatrix}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>If the weather is rainy today, find the probability that is rainy two days later.</li>
<li>Starting with a sunny day, write an R script to simulate 1000 days of weather using this Markov Chain.</li>
<li>Find the relative frequencies of the four states. Are these values approximately the stationary distribution of the Markov chain?</li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li><strong>Ehrenfest Urn Model</strong></li>
</ol>
<p>Grinstead and Snell (2006) describe a model used to explain diffusion of gases. One version of this model is described in the setting of two urns that, between them, contains four balls. A state is the number of balls in the first urn. There are five possible states 0, 1, 2, 3, and 4. At each step, one ball is chosen at random and moved from the urn it is located to the other urn. The transition matrix for this Markov chain is shown below:</p>
<p><span class="math display">\[
P = \begin{bmatrix} 
0 &amp;1 &amp; 0&amp; 0&amp; 0 \\
1/4 &amp; 0 &amp; 3/4 &amp; 0&amp; 0\\
0 &amp; 1/2&amp; 0&amp; 1/2&amp; 0\\
0 &amp;0&amp; 3/4 &amp; 0&amp; 1/4\\
0 &amp;0&amp; 0&amp; 1&amp; 0\\
\end{bmatrix}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Starting at state 1, find the probabilities of each state after two steps.</li>
<li>Starting at state 1, find the probabilities of each state after three steps.</li>
<li>Explain why this Markov Chain is not aperiodic.</li>
<li>Does a stationary distribution exist for this Markov Chain? Why or why not?</li>
</ol>
<ol start="6" style="list-style-type: decimal">
<li><strong>Metropolis Sampling in a Random Walk</strong></li>
</ol>
<p>Suppose the variable <span class="math inline">\(X\)</span> takes on values from 1 to 9 with respective probabilities that are proportional to the values 9, 7, 5, 3, 1, 3, 5, 7, 9. This probability distribution displayed in Figure 9.19 has a “bathtub” shape.</p>
<div class="figure"><span id="fig:unnamed-chunk-26"></span>
<img src="../LATEX/figures/chapter9/bathtub.png" alt="Bathtub shaped probability distribution." width="500" />
<p class="caption">
Figure 9.19: Bathtub shaped probability distribution.
</p>
</div>
<ol style="list-style-type: lower-alpha">
<li>Write an R function that computes this probability distribution for any value of <span class="math inline">\(X\)</span>.</li>
<li>Using the Metropolis algorithm described in Section 9.3.1 as programmed in the function <code>random_walk()</code>, simulate 10,000 draws from this probability distribution starting at the value <span class="math inline">\(X = 2\)</span>.</li>
<li>Collect the simulated draws and find the relative frequencies of the values 1 through 9. Compare these approximate probabilities with the exact probabilities.</li>
</ol>
<ol start="7" style="list-style-type: decimal">
<li><strong>Metropolis Sampling of a Binomial Distribution</strong></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Using the Metropolis algorithm described in Section 9.3 as programmed in the function <code>random_walk()</code>, simulate 1000 draws from a Binomial distribution with parameters <span class="math inline">\(n = 20\)</span> and <span class="math inline">\(p = 0.3\)</span>.</li>
<li>Collect the simulated draws and find the relative frequencies of the values 0 through 20. Compare these approximate probabilities with the exact probabilities.</li>
<li>Using the simulated values, estimate the mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> of the distribution and compare these estimates with the known values of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> of a binomial distribution.</li>
</ol>
<ol start="8" style="list-style-type: decimal">
<li><strong>Metropolis Sampling - Poisson-Gamma Model</strong></li>
</ol>
<p>Suppose we observe <span class="math inline">\(y_1, ..., y_n\)</span> from a Poisson distribution with mean <span class="math inline">\(\lambda\)</span>, and the parameter <span class="math inline">\(\lambda\)</span> has a Gamma(<span class="math inline">\(a, b\)</span>) distribution. The posterior density is proportional to
<span class="math display">\[\begin{equation*}
\pi(\lambda \mid y_1, \cdots, y_n) \propto \left[\prod_{i = 1}^n \exp(-\lambda) \lambda^{y_i} \right]
\left[ \lambda^{a-1} \exp(-b \lambda) \right].
\end{equation*}\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Write a function to compute the logarithm of the posterior density. Assume that one observes the sample 2, 5, 10, 5, 6, and the prior parameters are <span class="math inline">\(a = b = 1\)</span>.</p></li>
<li><p>Use the <code>metropolis()</code> function in Section 9.3.3 to collect 1000 draws from the posterior distribution. Use a starting value of <span class="math inline">\(\lambda = 5\)</span> and a neighborhood scale value of <span class="math inline">\(C = 2\)</span>.</p></li>
<li><p>Inspect MCMC diagnostic graphs to assess if the simulated sample approximates the posterior density of <span class="math inline">\(\lambda\)</span>.</p></li>
</ol>
<ol start="9" style="list-style-type: decimal">
<li><strong>Metropolis Sampling from a Bimodal Distribution</strong></li>
</ol>
Suppose we observe a random sample <span class="math inline">\(y_1, ..., y_n\)</span> from a Cauchy distribution with location <span class="math inline">\(\theta\)</span> and scale parameter 1 with density
<span class="math display" id="eq:cauchy">\[\begin{equation}
f(y_i \mid \theta) = \frac{1}{\pi  \left[1 + (y_i - \theta)^2\right]}.
\tag{9.38}
\end{equation}\]</span>
If a Uniform prior is placed on <span class="math inline">\(\theta\)</span>, then the posterior density of <span class="math inline">\(\theta\)</span> is proportional to
<span class="math display" id="eq:cauchypost">\[\begin{equation}
\pi(\theta \mid y_1, \cdots, y_n) \propto \prod_{i = 1}^n \frac{1}{\pi  \left[1 + (y_i - \theta)^2\right]}
\tag{9.39}
\end{equation}\]</span>
If we observe the values 3, 6, 7, 8, 15, 14, 16, 17, Figure 9.20 displays the bimodal shape of the posterior density.<br />


<div class="figure"><span id="fig:unnamed-chunk-27"></span>
<img src="../LATEX/figures/chapter9/bimodal.png" alt="Posterior density of location parameter with Cauchy sampling." width="500" />
<p class="caption">
Figure 9.20: Posterior density of location parameter with Cauchy sampling.
</p>
</div>
<ol style="list-style-type: lower-alpha">
<li>Write a function to compute the logarithm of the posterior density.</li>
<li>Using the <code>metropolis()</code> function in Section 9.3.3, collect a simulated sample of 1000 from the posterior distribution. Run the sampler twice, once using a starting value of <span class="math inline">\(\theta = 10\)</span> and a neighborhood scale value of <span class="math inline">\(C = 3\)</span>, and a second time with the same starting value and a scale value of <span class="math inline">\(C = 0.2\)</span>.</li>
<li>By inspecting MCMC diagnostic graphs, which value of <span class="math inline">\(C\)</span> appears to result in a simulated sample that is a better approximation to the posterior distribution? Explain.</li>
</ol>
<ol start="10" style="list-style-type: decimal">
<li><strong>Gibbs Sampling - Poisson-Gamma Model</strong></li>
</ol>
<p>Suppose a single observation <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\(\lambda\)</span> is Poisson with mean <span class="math inline">\(\lambda\)</span>, and <span class="math inline">\(\lambda\)</span> has a Gamma(<span class="math inline">\(a, b\)</span>) prior with density equal to
<span class="math display">\[\begin{equation*}
\pi(\lambda) = \frac{b^a}{\Gamma(a)} \lambda^{a-1} \exp(-b \lambda).
\end{equation*}\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Write down the joint density of <span class="math inline">\(Y\)</span> and <span class="math inline">\(\lambda\)</span>.</li>
<li>Identify the conditional distribution <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\(\lambda\)</span>, and the conditional distribution of <span class="math inline">\(\lambda\)</span> conditional on <span class="math inline">\(Y = y\)</span>.</li>
<li>Use the information from part (b) to construct a Gibbs sampling algorithm to sample from the joint distribution of <span class="math inline">\((Y, \lambda)\)</span>.</li>
<li>Write an R function to implement one cycle of Gibbs sampling, and run 1000 iterations of Gibbs sampling for the case where <span class="math inline">\(a = 3\)</span> and <span class="math inline">\(b = 3\)</span>.</li>
<li>By integration, find the marginal density of <span class="math inline">\(Y\)</span>. Compare the exact values of the marginal density with the simulated draws of <span class="math inline">\(Y\)</span> found using Gibbs sampling.</li>
</ol>
<ol start="11" style="list-style-type: decimal">
<li><strong>Gibbs Sampling - Coin Flips</strong></li>
</ol>
<p>Suppose one observes the outcomes of four fair coin flips <span class="math inline">\(W_1, ..., W_4\)</span> where <span class="math inline">\(W_i = 1\)</span> if the outcome is heads and <span class="math inline">\(W_i = 0\)</span> otherwise. Let <span class="math inline">\(X = W_1 + W_2 +W_3\)</span> denote the number of heads in the first three flips and <span class="math inline">\(Y = W_2 + W_3 + W_4\)</span> is the number of heads in the last three flips. The joint probability of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is given in Table 9.3.</p>
<p>Table 9.3. Table of number of heads <span class="math inline">\(X\)</span> in the first three flips and number of heads <span class="math inline">\(Y\)</span> in last three flips in four flips of a fair coin.</p>
<table>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center"></td>
<td align="center"><span><span class="math inline">\(Y\)</span></span></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">0</td>
<td align="center">1/16</td>
<td align="center">1/16</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X\)</span></td>
<td align="center">1</td>
<td align="center">1/16</td>
<td align="center">3/16</td>
<td align="center">2/16</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">2</td>
<td align="center">0</td>
<td align="center">2/16</td>
<td align="center">3/16</td>
<td align="center">1/16</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">3</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1/16</td>
<td align="center">1/16</td>
</tr>
</tbody>
</table>
<p>The joint probability mass function <span class="math inline">\(f(x, y)\)</span> of the number of heads
in the first three flips <span class="math inline">\(X\)</span> and the number of heads in the last three
flips <span class="math inline">\(Y\)</span> in four tosses of a fair coin.</p>
<ol style="list-style-type: lower-alpha">
<li>Find the conditional distribution <span class="math inline">\(f(x \mid Y = 1)\)</span>.</li>
<li>Find the conditional distribution <span class="math inline">\(f(y \mid X = 2)\)</span>.</li>
<li>Describe how Gibbs sampling can be used to simulate from the joint distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</li>
<li>Using the <code>gibbs_discrete()</code> function in Section 9.5.1, simulate 1000 iterations of Gibbs sampling using this probability distribution. By tabulating the <span class="math inline">\((X, Y)\)</span> output and computing relative frequencies, confirm that the relative frequencies are good approximations to the actual probabilities.</li>
</ol>
<ol start="12" style="list-style-type: decimal">
<li><strong>Normal Sampling with Both Parameters Unknown</strong>
</li>
</ol>
<p>The heights in inches of 20 college women were collected, observing the following measurements:</p>
<table>
<tbody>
<tr class="odd">
<td align="center">47</td>
<td align="center">64</td>
<td align="center">61</td>
<td align="center">61</td>
<td align="center">63</td>
<td align="center">61</td>
<td align="center">64</td>
<td align="center">66</td>
<td align="center">63</td>
<td align="center">67</td>
</tr>
<tr class="even">
<td align="center">63.5</td>
<td align="center">65</td>
<td align="center">62</td>
<td align="center">64</td>
<td align="center">61</td>
<td align="center">56</td>
<td align="center">63</td>
<td align="center">65</td>
<td align="center">64</td>
<td align="center">59</td>
</tr>
</tbody>
</table>
<p>Suppose one assumes that the Normal mean and precision parameters are independent with <span class="math inline">\(\mu\)</span> distributed <span class="math inline">\(\textrm{Normal}(62, 1)\)</span> and <span class="math inline">\(\phi\)</span> distributed Gamma with parameters <span class="math inline">\(a = 1\)</span> and <span class="math inline">\(b = 1\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Using the <code>gibbs_normal()</code> function in Section 9.5.3, collect a sample of 5000 from the joint posterior distribution of <span class="math inline">\((\mu, \phi)\)</span>.</li>
<li>Find a 90% interval estimate for the standard deviation <span class="math inline">\(\sigma = 1 / \sqrt{\phi}\)</span>.</li>
<li>Suppose one is interested in estimating the 90th percentile of the height distribution <span class="math inline">\(P_{90} = \mu + 1.645 \sigma\)</span>. Collect simulated draws from the posterior of <span class="math inline">\(P_{90}\)</span> and construct a density estimate.</li>
</ol>
<ol start="13" style="list-style-type: decimal">
<li><strong>Normal Sampling with Both Parameters Unknown (continued)</strong></li>
</ol>
<p>In Exercise 12, one learned about the mean and precision of the heights by use of a Gibbs sampling algorithm. Use JAGS and the <code>runjags</code> package to collect MCMC draws from this model. Write a JAGS script for this Normal sampling problem and use the <code>run.jags()</code> function. Answer questions from parts (c) and (d) from Exercise 12. (Note that the sample JAGS script in Section 9.7.1 returns samples of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.)</p>
<ol start="14" style="list-style-type: decimal">
<li><strong>Normal Sampling with Both Parameters Unknown (continued)</strong></li>
</ol>
<p>If one graphs the height data from Exercise 12, one notes that there is one unusually small height value, 47. One wonders if this minimum height is consistent with the fitted model.</p>
<ol style="list-style-type: lower-alpha">
<li>Write a function to simulate a sample of size 20 from the posterior predictive distribution. You can use either the <code>gibbs_normal()</code> function in Section 9.5.3 or the JAGS sample script in Section 9.7.1 to generate a sample from the posterior distribution of (<span class="math inline">\(\mu, \phi\)</span>) or (<span class="math inline">\(\mu, \sigma\)</span>). For each sample, compute the minimum value <span class="math inline">\(T(\tilde y)\)</span>.</li>
<li>Repeat the procedure 1000 times, collecting a sample of the predictive distribution of the minimum observation.</li>
<li>Graph the predictive distribution. From comparing the observed minimum height with this distribution, what can you conclude about the suitability of the model?</li>
</ol>
<ol start="15" style="list-style-type: decimal">
<li><strong>Comparing Proportions</strong></li>
</ol>
<p>In Section 9.7.4, the problem of comparing proportions of high visits to Facebook from male and female students was considered.</p>
<ol style="list-style-type: lower-alpha">
<li>Using the same prior, use JAGS to take a simulated sample of size 5000 from the posterior of <span class="math inline">\(p_F\)</span> and <span class="math inline">\(p_M\)</span>. Construct a 90% probability interval estimate for the difference is proportions <span class="math inline">\(\delta = p_W - p_M\)</span>.</li>
<li>Use the same simulated sample to perform inferences about the ratio of proportions <span class="math inline">\(R = p_W / p_M\)</span>. Construct a density estimate of <span class="math inline">\(R\)</span> and construct a 90% probability interval estimate.</li>
</ol>
<ol start="16" style="list-style-type: decimal">
<li><strong>Comparing Poisson Rates</strong></li>
</ol>
<p>Suppose the number of customers <span class="math inline">\(y_j\)</span> arriving at a bank during a half-hour period in the morning is Poisson with mean <span class="math inline">\(\lambda_M\)</span>, and the number of customers <span class="math inline">\(w_j\)</span> arriving in an afternoon half-hour period is Poisson with mean <span class="math inline">\(\lambda_A\)</span>. Suppose one observes the counts 3, 3, 6, 3, 2, 3, 7, 6 for the morning periods, and the counts 11, 3, 9, 10, 10, 5, 8, 7 for the afternoon periods. Assume that <span class="math inline">\(\lambda_M\)</span> and <span class="math inline">\(\lambda_A\)</span> have independent Gamma(1, 1) priors. Use JAGS to obtain a simulated sample from the joint posterior of <span class="math inline">\((\lambda_M, \lambda_A)\)</span> and use the output to obtain a 90% posterior interval estimate for the ratio of means <span class="math inline">\(R = \lambda_A / \lambda_M\)</span>.</p>
<ol start="17" style="list-style-type: decimal">
<li><strong>Normal Sampling with a Cauchy Prior</strong>
</li>
</ol>
<p>In Section 9.4, we considered the problem of estimating the mean snowfall amount in Buffalo with a Cauchy prior. The sample mean <span class="math inline">\(\bar y\)</span> is Normal with mean <span class="math inline">\(\mu\)</span> and standard error <span class="math inline">\(se\)</span> and <span class="math inline">\(\mu\)</span> is Cauchy with location 10 and scale 2. In our problem, <span class="math inline">\(\bar y= 26.785\)</span> and <span class="math inline">\(se = 3.236\)</span>.
Write a JAGS script for this Bayesian model. Use the <code>run.jags()</code> function to simulate 1000 draws of the posterior distribution for <span class="math inline">\(\mu\)</span>. Compute the posterior mean and posterior standard deviation for <span class="math inline">\(\mu\)</span>.</p>
<ol start="18" style="list-style-type: decimal">
<li><strong>Normal Sampling with a Cauchy Prior (continued)</strong></li>
</ol>
<p>In Exercise 17, one used JAGS to simulate values from the posterior of <span class="math inline">\(\mu\)</span> from a single MCMC chain. Instead use two chains with the different starting values of <span class="math inline">\(\mu = 0\)</span> and <span class="math inline">\(\mu = 50\)</span>. Run JAGS with two chains and estimate the posterior mean and posterior standard deviation using output from each of the two chains. Based on the output, comment on the sensitivity of the MCMC run with the choice of the starting value.</p>
<ol start="19" style="list-style-type: decimal">
<li><strong>Bivariate Normal</strong></li>
</ol>
<p>Section 6.7 introduced the Bivariate Normal distribution. Suppose we wish to use Gibbs sampling to simulate from this distribution. In the following assume <span class="math inline">\((X, Y)\)</span> is Bivariate Normal with parameters <span class="math inline">\((\mu_X, \mu_Y, \sigma_X, \sigma_Y, \rho)\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Using results from Section 6.7, identify the two conditional distributions <span class="math inline">\(f(x \mid y)\)</span> and <span class="math inline">\(f(y \mid x)\)</span> and write down a Gibbs sampling algorithm for simulating from the joint distribution of <span class="math inline">\((X, Y)\)</span>.</li>
<li>Write an R function to simulate a sample from the distribution using Gibbs sampling.</li>
<li>Assume <span class="math inline">\(\mu_X = 0, \mu_Y = 0, \sigma_X = 1, \sigma_Y = 1, \rho = 0.5\)</span> and run the simulation for 1000 iterations. Compare the means, standard deviations, and correlation computed from the simulation with the true values of the parameters.</li>
<li>Repeat part (c) using the correlation value <span class="math inline">\(\rho= 0.95\)</span> and again compare the simulation estimates with the true values. Explain why Gibbs sampling does not appear to work as well in this situation.</li>
</ol>
<ol start="20" style="list-style-type: decimal">
<li><strong>A Normal Mixture Model</strong></li>
</ol>
<p>Consider a three-component mixture distribution, where the density for <span class="math inline">\(x\)</span> has the form
<span class="math display" id="eq:normalmix">\[\begin{equation}
    f(x) =  0.45 \times \phi(x, -3, 1/3) + 0.1 \times \phi(x, 0, 1/3) + 0.45 \times \phi(x, 3, 1/3),  \\
\tag{9.40}
\end{equation}\]</span>
where <span class="math inline">\(\phi(x, \mu, \sigma)\)</span> is the Normal density with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. Consider the following two ways of simulating from this mixture density.</p>
<p><strong>Approach 1: Monte Carlo</strong>:
Introduce a “mixture component indicator”, <span class="math inline">\(\delta\)</span>, an unobserved latent variable. The variable <span class="math inline">\(z\)</span> is equal to 1, 2, and 3 with respective probabilities 0.45, 0.1, and 0.45. The density for <span class="math inline">\(x\)</span> conditional on <span class="math inline">\(z\)</span> is normal where <span class="math inline">\([x \mid z = 1] \sim \textrm{Normal}(-3, 1/3)\)</span>,
<span class="math inline">\([x \mid z = 2] \sim \textrm{Normal}(0, 1/3)\)</span>, and <span class="math inline">\([x \mid z = 3] \sim \textrm{Normal}(3, 1/3)\)</span>.</p>
<p>One simulates <span class="math inline">\(x\)</span> by first simulating a value of <span class="math inline">\(z\)</span> from its discrete distribution and then simulating a value of <span class="math inline">\(x\)</span> from the corresponding conditional distribution. By repeating this method, one obtains a Monte Carlo simulated sample from the exact mixture distribution.</p>
<p><strong>Approach 2: Gibbs Sampling</strong>: An alternative way of simulating from the mixture density is based on Gibbs sampling. Introduce the latent variable <span class="math inline">\(z\)</span> and consider the two conditional distributions <span class="math inline">\([x \mid z]\)</span> and <span class="math inline">\([z \mid x]\)</span>. The conditional distribution <span class="math inline">\([x \mid z]\)</span> will be a Normal density where the Normal parameters depend on the value of the latent variable. The conditional distribution <span class="math inline">\([z \mid x]\)</span> is discrete on the values 1, 2, 3 where the probabilities are proportional to <span class="math inline">\(0.45 \times \phi(x, -3, 1/3)\)</span>, <span class="math inline">\(0.1 \times \phi(x, 0, 1/3)\)</span>, <span class="math inline">\(0.45 \times \phi(x, 3, 1/3)\)</span> respectively.</p>
<p>Write R scripts to use both the Monte Carlo and Gibbs sampling methods to simulate 1000 draws from this mixture density.</p>
<ol start="21" style="list-style-type: decimal">
<li><strong>A Normal Mixture Model – MCMC Diagnostics</strong></li>
</ol>
<p>Figure 9.21 displays histograms of simulated draws from the mixture distribution using the Monte Carlo and Gibbs sampling algorithms, and the exact mixture density is overlaid on top. It is clear from the figure that the Gibbs sampling does not appear to perform as well as the Monte Carlo method in simulating from this distribution. Using MCMC diagnostic graphs, explore the Gibbs sampling output. Are there particular features in these diagnostic graphs that would indicate problems in the convergence of the Gibbs sampling algorithm?</p>

<div class="figure"><span id="fig:unnamed-chunk-28"></span>
<img src="../LATEX/figures/chapter9/normalmix.png" alt="Histogram of 1000 samples of mean from the Monte Carlo and Gibbs sampling algorithms." width="500" />
<p class="caption">
Figure 9.21: Histogram of 1000 samples of mean from the Monte Carlo and Gibbs sampling algorithms.
</p>
</div>
<ol start="22" style="list-style-type: decimal">
<li><strong>Change Point Analysis</strong></li>
</ol>
<p>The World Meteorological Association collects data on tropical storms, and scientists want to find out whether the distribution of storms changed over time, and if so, when. Data on the number of storms per year has been collected for <span class="math inline">\(n\)</span> years, and let <span class="math inline">\(y_i\)</span> be the number of storms in year <span class="math inline">\(i\)</span>, where <span class="math inline">\(i = 1, \cdots, n\)</span>. Let <span class="math inline">\(M\)</span> be the year in which the distribution of <span class="math inline">\(Y\)</span> changes, where <span class="math inline">\(M \in \{1, \cdots, n-1\}\)</span>.</p>
<p>A reasonable sampling model for <span class="math inline">\(Y\)</span> is:
<span class="math display">\[\begin{eqnarray*}
y_i \mid \lambda_1, M &amp;\sim&amp; \textrm{Poisson}(\lambda_1), \,\,\, i = 1, \cdots, M; \\
y_i \mid \lambda_2, M &amp;\sim&amp; \textrm{Poisson}(\lambda_2), \,\,\, i = M+1, \cdots, n.
\end{eqnarray*}\]</span></p>
<p>Suppose one gives a Uniform prior for <span class="math inline">\(M\)</span> over integers from <span class="math inline">\(1\)</span> to <span class="math inline">\(n-1\)</span> to represent complete uncertainty about change point:
<span class="math display">\[\begin{equation*}
M \mid \lambda_1, \lambda_2 \sim \textrm{Discrete}(\frac{1}{n-1}, \cdots, \frac{1}{n-1}), \,\,\, M \in \{1, \cdots, n-1\}.
\end{equation*}\]</span>
Equivalently, you can think of the Uniform prior as:
<span class="math display">\[\begin{equation*}
Prob(M = m) = \frac{1}{n-1}, \,\,\, M \in \{1, \cdots, n-1\}.
\end{equation*}\]</span></p>
<p>Recall that Gamma distributions are conjugate prior distributions for Poisson data model. Suppose one uses independent conjugate Gamma priors for <span class="math inline">\(\lambda_1\)</span> and <span class="math inline">\(\lambda_2\)</span>:
<span class="math display">\[\begin{eqnarray*}
\lambda_1 \mid a_1, b_1 &amp;\sim&amp; \textrm{Gamma}(a_1, b_1), \\
\lambda_2 \mid a_2, b_2 &amp;\sim&amp; \textrm{Gamma}(a_2, b_2). 
\end{eqnarray*}\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Write the joint posterior distribution, <span class="math inline">\(\pi(\lambda_1, \lambda_2, M \mid y_1, \cdots, y_n)\)</span>, up to a constant.</p></li>
<li><p>Find the full conditional posterior distribution for <span class="math inline">\(\lambda_1\)</span> and <span class="math inline">\(\lambda_2\)</span>. Write the name of the distributions and expressions for their parameter values.</p></li>
<li><p>Find the full conditional posterior distribution for <span class="math inline">\(M\)</span>, which should be a discrete distribution over <span class="math inline">\(m = 1, \cdots, n-1\)</span>.</p></li>
<li><p>Describe how you would design a Gibbs sampling to simulate posterior draws of the set of parameters, <span class="math inline">\((\lambda_1, \lambda_2, M)\)</span>.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mean.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayesian-hierarchical-modeling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/09-mcmc.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
