<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Probability and Bayesian Modeling</title>
  <meta name="description" content="This is an introduction to probability and Bayesian modeling at the undergraduate level. It assumes the student has some background with calculus." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Probability and Bayesian Modeling" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an introduction to probability and Bayesian modeling at the undergraduate level. It assumes the student has some background with calculus." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Probability and Bayesian Modeling" />
  
  <meta name="twitter:description" content="This is an introduction to probability and Bayesian modeling at the undergraduate level. It assumes the student has some background with calculus." />
  

<meta name="author" content="Jim Albert and Jingchen Hu" />


<meta name="date" content="2019-09-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="counting-methods.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Probability and Bayesian Modeling</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html"><i class="fa fa-check"></i><b>1</b> Probability: A Measurement of Uncertainty</a><ul>
<li class="chapter" data-level="1.1" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-classical-view-of-a-probability"><i class="fa fa-check"></i><b>1.2</b> The Classical View of a Probability</a></li>
<li class="chapter" data-level="1.3" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-frequency-view-of-a-probability"><i class="fa fa-check"></i><b>1.3</b> The Frequency View of a Probability</a></li>
<li class="chapter" data-level="1.4" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-subjective-view-of-a-probability"><i class="fa fa-check"></i><b>1.4</b> The Subjective View of a Probability</a><ul>
<li class="chapter" data-level="1.4.1" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#measuring-probabilities-subjectively"><i class="fa fa-check"></i><b>1.4.1</b> Measuring probabilities subjectively</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-sample-space"><i class="fa fa-check"></i><b>1.5</b> The Sample Space</a><ul>
<li class="chapter" data-level="1.5.1" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#roll-two-fair-indistinguishable-dice"><i class="fa fa-check"></i><b>1.5.1</b> Roll two fair, indistinguishable dice</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#assigning-probabilities"><i class="fa fa-check"></i><b>1.6</b> Assigning Probabilities</a><ul>
<li class="chapter" data-level="1.6.1" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#events-and-event-operations"><i class="fa fa-check"></i><b>1.6.1</b> Events and Event Operations</a></li>
<li class="chapter" data-level="1.6.2" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-three-probability-axioms"><i class="fa fa-check"></i><b>1.6.2</b> The Three Probability Axioms</a></li>
<li class="chapter" data-level="1.6.3" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#the-complement-and-addition-properties"><i class="fa fa-check"></i><b>1.6.3</b> The Complement and Addition Properties</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="probability-a-measurement-of-uncertainty.html"><a href="probability-a-measurement-of-uncertainty.html#exercises"><i class="fa fa-check"></i><b>1.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="counting-methods.html"><a href="counting-methods.html"><i class="fa fa-check"></i><b>2</b> Counting Methods</a><ul>
<li class="chapter" data-level="2.1" data-path="counting-methods.html"><a href="counting-methods.html#introduction-rolling-dice-yahtzee-and-roulette"><i class="fa fa-check"></i><b>2.1</b> Introduction: Rolling Dice, Yahtzee, and Roulette</a></li>
<li class="chapter" data-level="2.2" data-path="counting-methods.html"><a href="counting-methods.html#equally-likely-outcomes"><i class="fa fa-check"></i><b>2.2</b> Equally Likely Outcomes</a></li>
<li class="chapter" data-level="2.3" data-path="counting-methods.html"><a href="counting-methods.html#the-multiplication-counting-rule"><i class="fa fa-check"></i><b>2.3</b> The Multiplication Counting Rule</a></li>
<li class="chapter" data-level="2.4" data-path="counting-methods.html"><a href="counting-methods.html#permutations"><i class="fa fa-check"></i><b>2.4</b> Permutations</a></li>
<li class="chapter" data-level="2.5" data-path="counting-methods.html"><a href="counting-methods.html#combinations"><i class="fa fa-check"></i><b>2.5</b> Combinations</a><ul>
<li class="chapter" data-level="2.5.1" data-path="counting-methods.html"><a href="counting-methods.html#number-of-subsets"><i class="fa fa-check"></i><b>2.5.1</b> Number of subsets</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="counting-methods.html"><a href="counting-methods.html#arrangements-of-non-distinct-objects"><i class="fa fa-check"></i><b>2.6</b> Arrangements of Non-Distinct Objects</a></li>
<li class="chapter" data-level="2.7" data-path="counting-methods.html"><a href="counting-methods.html#playing-yahtzee"><i class="fa fa-check"></i><b>2.7</b> Playing Yahtzee</a></li>
<li class="chapter" data-level="2.8" data-path="counting-methods.html"><a href="counting-methods.html#exercises-1"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>3</b> Conditional Probability</a><ul>
<li class="chapter" data-level="3.1" data-path="conditional-probability.html"><a href="conditional-probability.html#introduction-the-three-card-problem"><i class="fa fa-check"></i><b>3.1</b> Introduction: The Three Card Problem</a></li>
<li class="chapter" data-level="3.2" data-path="conditional-probability.html"><a href="conditional-probability.html#independent-events"><i class="fa fa-check"></i><b>3.2</b> Independent Events</a></li>
<li class="chapter" data-level="3.3" data-path="conditional-probability.html"><a href="conditional-probability.html#in-everyday-life"><i class="fa fa-check"></i><b>3.3</b> In Everyday Life</a></li>
<li class="chapter" data-level="3.4" data-path="conditional-probability.html"><a href="conditional-probability.html#in-a-two-way-table"><i class="fa fa-check"></i><b>3.4</b> In a Two-Way Table</a></li>
<li class="chapter" data-level="3.5" data-path="conditional-probability.html"><a href="conditional-probability.html#definition-and-the-multiplication-rule"><i class="fa fa-check"></i><b>3.5</b> Definition and the Multiplication Rule</a></li>
<li class="chapter" data-level="3.6" data-path="conditional-probability.html"><a href="conditional-probability.html#the-multiplication-rule"><i class="fa fa-check"></i><b>3.6</b> The Multiplication Rule</a></li>
<li class="chapter" data-level="3.7" data-path="conditional-probability.html"><a href="conditional-probability.html#the-multiplication-rule-under-independence"><i class="fa fa-check"></i><b>3.7</b> The Multiplication Rule Under Independence</a></li>
<li class="chapter" data-level="3.8" data-path="conditional-probability.html"><a href="conditional-probability.html#learning-using-bayes-rule"><i class="fa fa-check"></i><b>3.8</b> Learning Using Bayes’ Rule</a></li>
<li class="chapter" data-level="3.9" data-path="conditional-probability.html"><a href="conditional-probability.html#r-example-learning-about-a-spinner"><i class="fa fa-check"></i><b>3.9</b> R Example: Learning About a Spinner</a></li>
<li class="chapter" data-level="3.10" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>3.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discrete-distributions.html"><a href="discrete-distributions.html"><i class="fa fa-check"></i><b>4</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="4.1" data-path="discrete-distributions.html"><a href="discrete-distributions.html#introduction-the-hat-check-problem"><i class="fa fa-check"></i><b>4.1</b> Introduction: The Hat Check Problem</a></li>
<li class="chapter" data-level="4.2" data-path="discrete-distributions.html"><a href="discrete-distributions.html#random-variable-and-probability-distribution"><i class="fa fa-check"></i><b>4.2</b> Random Variable and Probability Distribution</a></li>
<li class="chapter" data-level="4.3" data-path="discrete-distributions.html"><a href="discrete-distributions.html#probability-distribution"><i class="fa fa-check"></i><b>4.3</b> Probability distribution</a></li>
<li class="chapter" data-level="4.4" data-path="discrete-distributions.html"><a href="discrete-distributions.html#summarizing-a-probability-distribution"><i class="fa fa-check"></i><b>4.4</b> Summarizing a Probability Distribution</a></li>
<li class="chapter" data-level="4.5" data-path="discrete-distributions.html"><a href="discrete-distributions.html#standard-deviation-of-a-probability-distribution"><i class="fa fa-check"></i><b>4.5</b> Standard Deviation of a Probability Distribution</a></li>
<li class="chapter" data-level="4.6" data-path="discrete-distributions.html"><a href="discrete-distributions.html#coin-tossing-distributions"><i class="fa fa-check"></i><b>4.6</b> Coin-Tossing Distributions</a></li>
<li class="chapter" data-level="4.7" data-path="discrete-distributions.html"><a href="discrete-distributions.html#binomial-probabilities"><i class="fa fa-check"></i><b>4.7</b> Binomial probabilities</a></li>
<li class="chapter" data-level="4.8" data-path="discrete-distributions.html"><a href="discrete-distributions.html#binomial-experiments"><i class="fa fa-check"></i><b>4.8</b> Binomial experiments</a></li>
<li class="chapter" data-level="4.9" data-path="discrete-distributions.html"><a href="discrete-distributions.html#binomial-computations"><i class="fa fa-check"></i><b>4.9</b> Binomial computations</a></li>
<li class="chapter" data-level="4.10" data-path="discrete-distributions.html"><a href="discrete-distributions.html#mean-and-standard-deviation-of-a-binomial"><i class="fa fa-check"></i><b>4.10</b> Mean and standard deviation of a Binomial</a></li>
<li class="chapter" data-level="4.11" data-path="discrete-distributions.html"><a href="discrete-distributions.html#negative-binomial-experiments"><i class="fa fa-check"></i><b>4.11</b> Negative Binomial Experiments</a></li>
<li class="chapter" data-level="4.12" data-path="discrete-distributions.html"><a href="discrete-distributions.html#exercises-3"><i class="fa fa-check"></i><b>4.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-distributions.html"><a href="continuous-distributions.html"><i class="fa fa-check"></i><b>5</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="5.1" data-path="continuous-distributions.html"><a href="continuous-distributions.html#introduction-a-baseball-spinner-game"><i class="fa fa-check"></i><b>5.1</b> Introduction: A Baseball Spinner Game</a></li>
<li class="chapter" data-level="5.2" data-path="continuous-distributions.html"><a href="continuous-distributions.html#the-uniform-distribution"><i class="fa fa-check"></i><b>5.2</b> The Uniform Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="continuous-distributions.html"><a href="continuous-distributions.html#binomial-probabilities-and-the-normal-curve"><i class="fa fa-check"></i><b>5.3</b> Binomial Probabilities and the Normal Curve</a></li>
<li class="chapter" data-level="5.4" data-path="continuous-distributions.html"><a href="continuous-distributions.html#sampling-distribution-of-the-mean"><i class="fa fa-check"></i><b>5.4</b> Sampling Distribution of the Mean</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html"><i class="fa fa-check"></i><b>6</b> Joint Probability Distributions</a><ul>
<li class="chapter" data-level="6.1" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#joint-probability-mass-function-sampling-from-a-box"><i class="fa fa-check"></i><b>6.1</b> Joint Probability Mass Function: Sampling From a Box</a></li>
<li class="chapter" data-level="6.2" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#multinomial-experiments"><i class="fa fa-check"></i><b>6.2</b> Multinomial Experiments</a></li>
<li class="chapter" data-level="6.3" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#joint-density-functions"><i class="fa fa-check"></i><b>6.3</b> Joint Density Functions</a></li>
<li class="chapter" data-level="6.4" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#independence-and-measuring-association"><i class="fa fa-check"></i><b>6.4</b> Independence and Measuring Association</a></li>
<li class="chapter" data-level="6.5" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#flipping-a-random-coin-the-beta-binomial-distribution"><i class="fa fa-check"></i><b>6.5</b> Flipping a Random Coin: The Beta-Binomial Distribution</a></li>
<li class="chapter" data-level="6.6" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#bivariate-normal-distribution"><i class="fa fa-check"></i><b>6.6</b> Bivariate Normal Distribution</a></li>
<li class="chapter" data-level="6.7" data-path="joint-probability-distributions.html"><a href="joint-probability-distributions.html#exercises-4"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="proportion.html"><a href="proportion.html"><i class="fa fa-check"></i><b>7</b> Learning About a Binomial Probability</a><ul>
<li class="chapter" data-level="7.1" data-path="proportion.html"><a href="proportion.html#introduction-thinking-about-a-proportion-subjectively"><i class="fa fa-check"></i><b>7.1</b> Introduction: Thinking About a Proportion Subjectively</a></li>
<li class="chapter" data-level="7.2" data-path="proportion.html"><a href="proportion.html#bayesian-inference-with-discrete-priors"><i class="fa fa-check"></i><b>7.2</b> Bayesian Inference with Discrete Priors</a><ul>
<li class="chapter" data-level="7.2.1" data-path="proportion.html"><a href="proportion.html#example-students-dining-preference"><i class="fa fa-check"></i><b>7.2.1</b> Example: students’ dining preference</a></li>
<li class="chapter" data-level="7.2.2" data-path="proportion.html"><a href="proportion.html#discrete-prior-distributions-for-proportion-p"><i class="fa fa-check"></i><b>7.2.2</b> Discrete prior distributions for proportion <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="7.2.3" data-path="proportion.html"><a href="proportion.html#likelihood"><i class="fa fa-check"></i><b>7.2.3</b> Likelihood</a></li>
<li class="chapter" data-level="7.2.4" data-path="proportion.html"><a href="proportion.html#posterior-distribution-for-proportion-p"><i class="fa fa-check"></i><b>7.2.4</b> Posterior distribution for proportion <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="7.2.5" data-path="proportion.html"><a href="proportion.html#inference-students-dining-preference"><i class="fa fa-check"></i><b>7.2.5</b> Inference: students’ dining preference</a></li>
<li class="chapter" data-level="7.2.6" data-path="proportion.html"><a href="proportion.html#discussion-using-a-discrete-prior"><i class="fa fa-check"></i><b>7.2.6</b> Discussion: using a discrete prior</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="proportion.html"><a href="proportion.html#continuous-priors"><i class="fa fa-check"></i><b>7.3</b> Continuous Priors</a><ul>
<li class="chapter" data-level="7.3.1" data-path="proportion.html"><a href="proportion.html#the-beta-distribution-and-probabilities"><i class="fa fa-check"></i><b>7.3.1</b> The Beta distribution and probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="proportion.html"><a href="proportion.html#updating-the-beta-prior"><i class="fa fa-check"></i><b>7.4</b> Updating the Beta Prior</a><ul>
<li class="chapter" data-level="7.4.1" data-path="proportion.html"><a href="proportion.html#bayes-rule-calculation"><i class="fa fa-check"></i><b>7.4.1</b> Bayes’ rule calculation</a></li>
<li class="chapter" data-level="7.4.2" data-path="proportion.html"><a href="proportion.html#from-beta-prior-to-beta-posterior"><i class="fa fa-check"></i><b>7.4.2</b> From Beta prior to Beta posterior</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="proportion.html"><a href="proportion.html#bayesian-inferences-with-continuous-priors"><i class="fa fa-check"></i><b>7.5</b> Bayesian Inferences with Continuous Priors</a><ul>
<li class="chapter" data-level="7.5.1" data-path="proportion.html"><a href="proportion.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>7.5.1</b> Bayesian hypothesis testing</a></li>
<li class="chapter" data-level="7.5.2" data-path="proportion.html"><a href="proportion.html#bayesian-credible-intervals"><i class="fa fa-check"></i><b>7.5.2</b> Bayesian credible intervals</a></li>
<li class="chapter" data-level="7.5.3" data-path="proportion.html"><a href="proportion.html#bayesian-prediction"><i class="fa fa-check"></i><b>7.5.3</b> Bayesian prediction</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="proportion.html"><a href="proportion.html#predictive-checking"><i class="fa fa-check"></i><b>7.6</b> Predictive Checking</a><ul>
<li class="chapter" data-level="7.6.1" data-path="proportion.html"><a href="proportion.html#comparing-bayesian-models"><i class="fa fa-check"></i><b>7.6.1</b> Comparing Bayesian models</a></li>
<li class="chapter" data-level="7.6.2" data-path="proportion.html"><a href="proportion.html#posterior-predictive-checking"><i class="fa fa-check"></i><b>7.6.2</b> Posterior predictive checking</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="proportion.html"><a href="proportion.html#exercises-5"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mean.html"><a href="mean.html"><i class="fa fa-check"></i><b>8</b> Modeling Measurement and Count Data</a><ul>
<li class="chapter" data-level="8.1" data-path="mean.html"><a href="mean.html#introduction-1"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="mean.html"><a href="mean.html#modeling-measurements"><i class="fa fa-check"></i><b>8.2</b> Modeling Measurements</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mean.html"><a href="mean.html#examples"><i class="fa fa-check"></i><b>8.2.1</b> Examples</a></li>
<li class="chapter" data-level="8.2.2" data-path="mean.html"><a href="mean.html#the-general-approach"><i class="fa fa-check"></i><b>8.2.2</b> The general approach</a></li>
<li class="chapter" data-level="8.2.3" data-path="mean.html"><a href="mean.html#outline-of-chapter"><i class="fa fa-check"></i><b>8.2.3</b> Outline of chapter</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mean.html"><a href="mean.html#Normal:Discrete"><i class="fa fa-check"></i><b>8.3</b> Bayesian Inference with Discrete Priors</a><ul>
<li class="chapter" data-level="8.3.1" data-path="mean.html"><a href="mean.html#example-roger-federers-time-to-serve"><i class="fa fa-check"></i><b>8.3.1</b> Example: Roger Federer’s time-to-serve</a></li>
<li class="chapter" data-level="8.3.2" data-path="mean.html"><a href="mean.html#Normal:SamplingModel:derivation"><i class="fa fa-check"></i><b>8.3.2</b> Simplification of the likelihood</a></li>
<li class="chapter" data-level="8.3.3" data-path="mean.html"><a href="mean.html#Normal:SamplingModel:inference"><i class="fa fa-check"></i><b>8.3.3</b> Inference: Federer’s time-to-serve</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="mean.html"><a href="mean.html#Normal:Continuous"><i class="fa fa-check"></i><b>8.4</b> Continuous Priors</a><ul>
<li class="chapter" data-level="8.4.1" data-path="mean.html"><a href="mean.html#Normal:Continuous:prior"><i class="fa fa-check"></i><b>8.4.1</b> The Normal prior for mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="8.4.2" data-path="mean.html"><a href="mean.html#Normal:Continuous:choosing"><i class="fa fa-check"></i><b>8.4.2</b> Choosing a Normal prior</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mean.html"><a href="mean.html#Normal:ContinuousUpdate"><i class="fa fa-check"></i><b>8.5</b> Updating the Normal Prior</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mean.html"><a href="mean.html#introduction-2"><i class="fa fa-check"></i><b>8.5.1</b> Introduction</a></li>
<li class="chapter" data-level="8.5.2" data-path="mean.html"><a href="mean.html#Normal:ContinuousUpdate:Overview"><i class="fa fa-check"></i><b>8.5.2</b> A quick peak at the update procedure</a></li>
<li class="chapter" data-level="8.5.3" data-path="mean.html"><a href="mean.html#Normal:ContinuousUpdate:BayesRule"><i class="fa fa-check"></i><b>8.5.3</b> Bayes’ rule calculation</a></li>
<li class="chapter" data-level="8.5.4" data-path="mean.html"><a href="mean.html#Normal:ContinuousUpdate:Conjugate"><i class="fa fa-check"></i><b>8.5.4</b> Conjugate Normal prior</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mean.html"><a href="mean.html#Normal:ContinuousInference"><i class="fa fa-check"></i><b>8.6</b> Bayesian Inferences for Continuous Normal Mean</a><ul>
<li class="chapter" data-level="8.6.1" data-path="mean.html"><a href="mean.html#Normal:ContinuousInference:HTandCI"><i class="fa fa-check"></i><b>8.6.1</b> Bayesian hypothesis testing and credible interval</a></li>
<li class="chapter" data-level="8.6.2" data-path="mean.html"><a href="mean.html#Normal:ContinuousInference:Prediction"><i class="fa fa-check"></i><b>8.6.2</b> Bayesian prediction</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="mean.html"><a href="mean.html#Normal:PPC"><i class="fa fa-check"></i><b>8.7</b> Posterior Predictive Checking</a></li>
<li class="chapter" data-level="8.8" data-path="mean.html"><a href="mean.html#modeling-count-data"><i class="fa fa-check"></i><b>8.8</b> Modeling Count Data</a><ul>
<li class="chapter" data-level="8.8.1" data-path="mean.html"><a href="mean.html#examples-1"><i class="fa fa-check"></i><b>8.8.1</b> Examples</a></li>
<li class="chapter" data-level="8.8.2" data-path="mean.html"><a href="mean.html#the-poisson-distribution"><i class="fa fa-check"></i><b>8.8.2</b> The Poisson distribution</a></li>
<li class="chapter" data-level="8.8.3" data-path="mean.html"><a href="mean.html#bayesian-inferences"><i class="fa fa-check"></i><b>8.8.3</b> Bayesian inferences</a></li>
<li class="chapter" data-level="8.8.4" data-path="mean.html"><a href="mean.html#case-study-learning-about-website-counts"><i class="fa fa-check"></i><b>8.8.4</b> Case study: Learning about website counts</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="mean.html"><a href="mean.html#exercises-6"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>9</b> Simulation by Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="9.1" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#introduction-3"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#markov-chains"><i class="fa fa-check"></i><b>9.2</b> Markov Chains</a></li>
<li class="chapter" data-level="9.3" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#the-metropolis-algorithm"><i class="fa fa-check"></i><b>9.3</b> The Metropolis Algorithm</a></li>
<li class="chapter" data-level="9.4" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#example-cauchy-normal-problem"><i class="fa fa-check"></i><b>9.4</b> Example: Cauchy-Normal problem</a></li>
<li class="chapter" data-level="9.5" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#gibbs-sampling"><i class="fa fa-check"></i><b>9.5</b> Gibbs Sampling</a></li>
<li class="chapter" data-level="9.6" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#mcmc-inputs-and-diagnostics"><i class="fa fa-check"></i><b>9.6</b> MCMC Inputs and Diagnostics</a></li>
<li class="chapter" data-level="9.7" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#using-jags"><i class="fa fa-check"></i><b>9.7</b> Using JAGS</a></li>
<li class="chapter" data-level="9.8" data-path="simulation-by-markov-chain-monte-carlo.html"><a href="simulation-by-markov-chain-monte-carlo.html#exercises-7"><i class="fa fa-check"></i><b>9.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html"><i class="fa fa-check"></i><b>10</b> Bayesian Hierarchical Modeling</a><ul>
<li class="chapter" data-level="10.1" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html#introduction-4"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html#hierarchical-normal-modeling"><i class="fa fa-check"></i><b>10.2</b> Hierarchical Normal Modeling</a></li>
<li class="chapter" data-level="10.3" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html#hierarchical-beta-binomial-modeling"><i class="fa fa-check"></i><b>10.3</b> Hierarchical Beta-Binomial Modeling</a></li>
<li class="chapter" data-level="10.4" data-path="bayesian-hierarchical-modeling.html"><a href="bayesian-hierarchical-modeling.html#exercises-8"><i class="fa fa-check"></i><b>10.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction-5"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#example-prices-and-areas-of-house-sales"><i class="fa fa-check"></i><b>11.2</b> Example: Prices and Areas of House Sales</a></li>
<li class="chapter" data-level="11.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#a-simple-linear-regression-model"><i class="fa fa-check"></i><b>11.3</b> A Simple Linear Regression Model</a></li>
<li class="chapter" data-level="11.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#a-weakly-informative-prior"><i class="fa fa-check"></i><b>11.4</b> A Weakly Informative Prior</a></li>
<li class="chapter" data-level="11.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#posterior-analysis"><i class="fa fa-check"></i><b>11.5</b> Posterior Analysis</a></li>
<li class="chapter" data-level="11.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-through-mcmc"><i class="fa fa-check"></i><b>11.6</b> Inference through MCMC</a></li>
<li class="chapter" data-level="11.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#bayesian-inferences-with-simple-linear-regression"><i class="fa fa-check"></i><b>11.7</b> Bayesian Inferences with Simple Linear Regression</a></li>
<li class="chapter" data-level="11.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#informative-prior-1"><i class="fa fa-check"></i><b>11.8</b> Informative Prior</a></li>
<li class="chapter" data-level="11.9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#a-conditional-means-prior"><i class="fa fa-check"></i><b>11.9</b> A Conditional Means Prior</a></li>
<li class="chapter" data-level="11.10" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercises-9"><i class="fa fa-check"></i><b>11.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html"><i class="fa fa-check"></i><b>12</b> Bayesian Multiple Regression and Logistic Models</a><ul>
<li class="chapter" data-level="12.1" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#introduction-6"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#bayesian-multiple-linear-regression"><i class="fa fa-check"></i><b>12.2</b> Bayesian Multiple Linear Regression</a></li>
<li class="chapter" data-level="12.3" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#bayesian-logistic-regression"><i class="fa fa-check"></i><b>12.3</b> Bayesian Logistic Regression </a></li>
<li class="chapter" data-level="12.4" data-path="bayesian-multiple-regression-and-logistic-models.html"><a href="bayesian-multiple-regression-and-logistic-models.html#exercises-10"><i class="fa fa-check"></i><b>12.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="case-studies.html"><a href="case-studies.html"><i class="fa fa-check"></i><b>13</b> Case Studies</a><ul>
<li class="chapter" data-level="13.1" data-path="case-studies.html"><a href="case-studies.html#introduction-7"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="case-studies.html"><a href="case-studies.html#federalist-papers-study"><i class="fa fa-check"></i><b>13.2</b> Federalist Papers Study</a></li>
<li class="chapter" data-level="13.3" data-path="case-studies.html"><a href="case-studies.html#negative-binomial-sampling"><i class="fa fa-check"></i><b>13.3</b> Negative Binomial sampling</a></li>
<li class="chapter" data-level="13.4" data-path="case-studies.html"><a href="case-studies.html#comparison-of-rates-for-two-authors"><i class="fa fa-check"></i><b>13.4</b> Comparison of rates for two authors</a></li>
<li class="chapter" data-level="13.5" data-path="case-studies.html"><a href="case-studies.html#which-words-distinguish-the-two-authors"><i class="fa fa-check"></i><b>13.5</b> Which words distinguish the two authors?</a></li>
<li class="chapter" data-level="13.6" data-path="case-studies.html"><a href="case-studies.html#career-trajectories"><i class="fa fa-check"></i><b>13.6</b> Career Trajectories</a></li>
<li class="chapter" data-level="13.7" data-path="case-studies.html"><a href="case-studies.html#latent-class-modeling"><i class="fa fa-check"></i><b>13.7</b> Latent Class Modeling</a></li>
<li class="chapter" data-level="13.8" data-path="case-studies.html"><a href="case-studies.html#exercises-11"><i class="fa fa-check"></i><b>13.8</b> Exercises</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probability and Bayesian Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Probability and Bayesian Modeling</h1>
<p class="author"><em>Jim Albert and Jingchen Hu</em></p>
<p class="date"><em>2019-09-30</em></p>
</div>
<div id="probability-a-measurement-of-uncertainty" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Probability: A Measurement of Uncertainty</h1>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">1.1</span> Introduction</h2>
<p>The magazine <em>Discover</em> once had a special issue on “Life at Risk.” In an article, Jeffrey Kluger describes the risks of making it through one day:</p>

<p>“Imagine my relief when I made it out of bed alive last Monday morning. It was touch and go there for a while, but I managed to scrape through. Getting up was not the only death-defying act I performed that day. There was shaving, for example; that was no walk in the park. Then there was showering, followed by leaving the house and walking to work and spending eight hours at the office. By the time I finished my day – a day that also included eating lunch, exercising, going out to dinner, and going home – I
counted myself lucky to have survived in one piece.”</p>

<p>Is this writer unusually fearful? No. He has read mortality studies and concludes “there is not a single thing you can do in an ordinary day – sleeping included – that isn’t risky enough to be the last thing you ever do.” In <em>The Book of Risks</em> by Larry Laudan, we learn that</p>
<ul>
<li>1 out of 2 million people will die from falling out of bed.</li>
<li>1 out of 400 will be injured falling out of bed.</li>
<li>1 out of 77 adults over 35 will have a heart attack this year.</li>
<li>The average American faces a 1 in 13 risk of suffering some kind of injury in home that necessitates medical attention.</li>
<li>1 out of 7000 will experience a shaving injury requiring medical attention.</li>
<li>The average American faces a 1 out of 14 risk of having property stolen this year.</li>
<li>1 out of 32 risk of being the victim of some violent crime.</li>
<li>The annual odds of dying in any kind of motor vehicle accident is 1 in 5800.</li>
</ul>
<p>Where do these reported odds come from? They are simply probabilities calculated from the counts of reported accidents. Since all of these accidents are possible, that means that there is a risk to the average American that they will happen to him or her. But fortunately, you need not worry – many of these reported risks are too small to really take seriously or change your style of living.</p>

<p></p>

<p>Everywhere we are surrounded by uncertainty. If you think about it, there are a number of things that one are unsure about, like</p>
<ul>
<li>what is the high temperature next Monday?</li>
<li>how many inches of snow will our town get next January?</li>
<li>what’s your final grade in this class?</li>
<li>will you be living in the same state twenty years from now?</li>
<li>who will win the U.S. presidential election in 2024?</li>
<li>is there life on Mars?</li>
</ul>
<p>A probability is simply a number between 0 and 1 that measures the uncertainty of a particular event.
Although many events are uncertain, one possesses different degrees of belief about the truth of an uncertain event. For example, most of us are pretty certain of the statement “the sun will rise tomorrow”, and pretty sure that the statement “the moon is made of green cheese” is false.
One thinks of a probability scale from 0 to 1.</p>
<p>One typically would give the statement “the sun will rise tomorrow” a probability close to 1, and the statement “the moon is made of green cheese” a probability close to 0. It is harder to assign probabilities to uncertain events that have probabilities between 0 and 1. In this chapter, we first get some experience in assigning probabilities. Then three general ways of thinking about probabilities will be described.</p>
</div>
<div id="the-classical-view-of-a-probability" class="section level2">
<h2><span class="header-section-number">1.2</span> The Classical View of a Probability</h2>
<p>Suppose that one observes some phenomena (say, the rolls of two dice) where the outcome is random. Suppose one writes down the list of all possible outcomes, and one believes that each outcome in the list has the same probability. Then the probability of each outcome will be</p>
<p><span class="math display" id="eq:cprob">\[\begin{equation}
Prob({\rm Outcome}) = \frac{1}{{\rm Number} \, {\rm of} \, {\rm outcomes}}.
\tag{1.1}
\end{equation}\]</span></p>
<p>Let’s illustrate this classical view of probability by a simple example. Suppose one has a bowl with 4 white and 2 black balls</p>
<p><img src="../LATEX/figures/chapter1/ballsinbowl1.png" width="490" /></p>
<p>and two balls from the bowl are drawn at random. It is assumed that the balls are drawn without replacement which means that one doesn’t place a ball back into the bowl after it has been selected. What are possible outcomes? There are different ways of writing down the possible outcomes, depending if one decides to distinguish the balls of the same color.</p>

<p> If one doesn’t distinguish between balls of the same color, then there are three possible outcomes – essentially one chooses 0 black, 1 black, or 2 black balls.</p>
<p><img src="../LATEX/figures/chapter1/ballsinbowl2.png" width="337" /></p>
<p> If one does distinguish between the balls of the same color, label the balls in the bowl and then write down 15 distinct outcomes of the experiment of choosing two balls.</p>
<p><img src="../LATEX/figures/chapter1/ballsinbowl3.png" width="493" /></p>
<p><img src="../LATEX/figures/chapter1/ballsinbowl4.png" width="706" /></p>

<p></p>

<p>To apply the classical view of probability, one has to assume that the outcomes are all equally likely. In the first list of three outcomes, one can’t assume that they are equally likely. Since there are more white than black balls in the basket, it is more likely to choose two white balls than to choose two black balls. So it is incorrect to say that the probability of each one of the three possible outcomes is 1/3. That is, the probabilities of choosing 0 black, 1 black, and 2 blacks are not equal to 1/3, 1/3, and 1/3.</p>
<p>On the other hand, since one are choosing two balls at random from the basket, it makes sense that the 15 outcomes in the second listing (where we assumed the balls distinguishable) are equally likely. So one applies the classical notion and assign a probability of 1/15 to each of the possible outcomes. In particular, the probability of choosing two black balls (which is one of the 15 outcomes) is equal to 1/15.</p>
</div>
<div id="the-frequency-view-of-a-probability" class="section level2">
<h2><span class="header-section-number">1.3</span> The Frequency View of a Probability</h2>
<p>The classical view of probability is helpful only when we can construct a list of outcomes of the experiment in such a way where the outcomes are equally likely.<br />
The frequency interpretation of probability can be used in cases where outcomes are equally likely or not equally likely.
This view of probability is appropriate in the situation where one is able to repeat the random experiment many times under the same conditions.</p>

<p>Suppose someone is playing the popular game Monopoly and she lands in jail. To get out of jail on the next turn, she either pays $50 or roll “doubles” when she rolls two fair dice. Doubles means that the faces on the two dice are the same. If it is relatively unlikely to roll doubles, then the player may elect to roll two dice instead of paying $50 to get out of jail.</p>

<p></p>

<p>In this situation, the frequency notion can be applied to approximate the probability of rolling doubles. Imagine rolling two dice many times under similar conditions. Each time two dice are rolled, one observes if she get doubles or not. Then the probability of doubles is approximated by the relative frequency</p>
<p><span class="math display">\[
Prob({\rm doubles}) \approx \frac{{\rm Number} \, {\rm of} \, {\rm doubles}}{{\rm Number} \, {\rm of} \, {\rm experiments}}.
\]</span></p>

<p>Rolling two dice</p>
<p>The following R code can be used to simulate the rolling of two dice. The <code>two_rolls()</code> function simulates rolls of a pair of dice and the <code>replicate()</code> function repeats this process 1000 times and stores the outcomes in the variable <code>many_rolls</code>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">two_rolls &lt;-<span class="st"> </span><span class="cf">function</span>(){</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">  <span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb1-4" data-line-number="4">many_rolls &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>, <span class="kw">two_rolls</span>())</a></code></pre></div>
<p>The results of the first 20 experiments are shown in Table 1.1. For each experiment, one records if there is a match (YES) or no match (NO) in the two numbers that are rolled.</p>
<p>Table 1.1: The results of the first 20 experiments of rolling two dice.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">two_rolls &lt;-<span class="st"> </span><span class="cf">function</span>(){</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">  <span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">many_rolls &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>, <span class="kw">two_rolls</span>())</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Die_1 =</span> many_rolls[<span class="dv">1</span>, ],</a>
<a class="sourceLine" id="cb2-6" data-line-number="6">                 <span class="dt">Die_2 =</span> many_rolls[<span class="dv">2</span>, ])</a>
<a class="sourceLine" id="cb2-7" data-line-number="7">df<span class="op">$</span>Match &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df<span class="op">$</span>Die_<span class="dv">1</span> <span class="op">==</span><span class="st"> </span>df<span class="op">$</span>Die_<span class="dv">2</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>)</a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="kw">head</span>(df, <span class="dv">20</span>)</a></code></pre></div>
<pre><code>##    Die_1 Die_2 Match
## 1      5     3    No
## 2      2     2   Yes
## 3      5     1    No
## 4      3     4    No
## 5      3     3   Yes
## 6      1     2    No
## 7      6     2    No
## 8      2     3    No
## 9      6     3    No
## 10     2     5    No
## 11     3     4    No
## 12     6     4    No
## 13     4     1    No
## 14     6     4    No
## 15     3     5    No
## 16     4     2    No
## 17     6     6   Yes
## 18     2     3    No
## 19     5     1    No
## 20     5     6    No</code></pre>
<p>In the first 50 rolls we observed a match 6 times, so</p>
<p><span class="math inline">\(Prob(match) \approx\)</span> 6/50 =
0.12</p>
<p>Let’s now roll the two dice 10,000 times with R – this time, 1662 matches are observed, so</p>
<p><span class="math display">\[Prob(match) \approx 1662/10000 = 0.1662.\]</span></p>
<p>Is 0.1662 the actual probability of getting doubles? No, it is still only an approximation to the actual probability.
However, as one continues to roll dice, the relative frequency</p>
<p><span class="math display">\[
\frac{number \, of \,doubles}{number \, of  \, experiments}
\]</span></p>
<p>will approach the actual probability</p>
<p><span class="math inline">\(Prob\)</span>(doubles).</p>
<p>Here the actual probability of rolling doubles is</p>
<p><span class="math inline">\(Prob\)</span>(doubles) = 1/6,</p>
<p>which is very close to the relative frequency of doubles that we obtained by rolling the dice 10,000 times.</p>
<p>In this example, one can show that are <span class="math inline">\(6 \times 6 = 36\)</span> equally likely ways of rolling two distinguishable dice and there are exactly six ways of rolling doubles. So using the classical viewpoint, the probability of doubles is <span class="math inline">\(6/36 =1/6\)</span>.</p>
</div>
<div id="the-subjective-view-of-a-probability" class="section level2">
<h2><span class="header-section-number">1.4</span> The Subjective View of a Probability</h2>
<p>Two ways of thinking about probabilities have been described.</p>
<ul>
<li>The classical view. This is a useful way of thinking about probabilities when one lists all possible outcomes in such a way that each outcome is equally likely.</li>
<li>The frequency view. In the situation when one repeats a random experiment many times under similar conditions, one approximates a probability of an event by the relative frequency that the event occurs.</li>
</ul>
<p>What if one can’t apply these two interpretations of probability? That is, what if the outcomes of the experiment are not equally likely, and it is not feasible or possible to repeat the experiment many times under similar conditions?</p>
<p>In this case, one can rely on a third view of probabilities, the subjective view. This interpretation is arguably the most general way of thinking about a probability, since it can be used in a wide variety of situations.</p>
<p>Suppose one is interested in the probability of the event: &quot;Her team will win the conference title in basketball next season.</p>
<p>One can’t use the classical or frequency views to compute this probability. Why? Suppose there are eight teams in the conference. Each team is a possible winner of the conference, but these teams are not equally likely to win – some teams are stronger than the rest. So the classical approach won’t help in obtaining this probability.</p>
<p>The event of her team winning the conference next year is essentially a one-time event. Certainly, her team will have the opportunity to win this conference in future years, but the players on her team and their opponents will change and it won’t be the same basketball competition. So one can’t repeat this experiment under similar conditions, and so the frequency view is not helpful in this case.</p>
<p>What is a subjective probability in this case? The probability</p>
<p><span class="math inline">\(Prob\)</span>(Her team will win the conference in basketball next season)</p>
<p>represents the person’s belief in the likelihood that her team will win the basketball conference next season. If she believes that her school will have a great team next year and will win most of their conference games, she would give this probability a value close to 1. On the other hand, if she thinks that her school will have a relatively weak team, her probability of this event would be a small number close to 0. Essentially, this probability is a numerical statement about the person’s confidence in the truth of this event.</p>
<p>There are two important aspects of a subjective probability.</p>
<ol style="list-style-type: decimal">
<li><p>A subjective probability is personal. One person’s belief about her team winning the basketball conference is likely different from another person’s belief about the team winning the conference since the two people have different information. Perhaps the second person is not interested in basketball and knows little about the teams and the first person is very knowledgeable about college basketball. That means that beliefs about the truth of this event can be different for different people and so the probabilities for these two would also be different.</p></li>
<li><p>A subjective probability depends on one’s current information or knowledge about the event in question. Maybe the first person originally thinks that this probability is 0.7 since her school had a good team last year. But when she learns that many of the star players from last season have graduated, this may change her knowledge about the team, and she may now assign this probability a smaller number.</p></li>
</ol>
<div id="measuring-probabilities-subjectively" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Measuring probabilities subjectively</h3>
<p>Although one is used to expressing one’s opinions about uncertain events, using words like
likely, probably, rare, sure, maybe,
one typically is not used to assigning probabilities to quantify one’s beliefs about these events. To make any kind of measurement, one needs a tool like a scale or ruler. Likewise, one needs tools to help us assign probabilities subjectively. Next, a special tool, called a calibration experiment, will be introduced that will help to determine one’s subjective probabilities.</p>
<div id="a-calibration-experiment" class="section level4">
<h4><span class="header-section-number">1.4.1.1</span> A calibration experiment</h4>
<p>Consider the event <span class="math inline">\(W\)</span>: “a woman will be President of the United States in the next 20 years”.</p>
<p>A college student is interested in his subjective probability of <span class="math inline">\(W\)</span>. This probability is hard to specify precisely since he hasn’t had much practice doing it. We describe a simple procedure that will help in measuring this probability.</p>
<p>First consider the following calibration experiment – this is an experiment where the probabilities of outcomes are clear. One has a collection of balls, 5 red and 5 white in a box and one ball is selected at random.</p>
<p>Let <span class="math inline">\(B\)</span> denote the event that the student observes a red ball. Since each of the ten balls is equally likely to be selected, we think he would agree that <span class="math inline">\(Prob(B) = 5/10 = 0.5\)</span>.</p>
<p>Now consider the following two bets:</p>
<ul>
<li>BET 1 – If <span class="math inline">\(W\)</span> occurs (a women is president in the next 20 years), the student wins $100. Otherwise, the student wins nothing.</li>
<li>BET 2 – If <span class="math inline">\(B\)</span> occurs (a red ball is observed in the above experiment), the student wins $100. Otherwise, the student wins nothing.</li>
</ul>
<p>Based on the bet that the student prefers, one can determine an interval that contains his <span class="math inline">\(Prob(W)\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>If the student prefers BET 1, then his <span class="math inline">\(Prob(W)\)</span> must be larger than <span class="math inline">\(Prob(B) = 0.5\)</span> – that is, his <span class="math inline">\(Prob(W)\)</span> must fall between 0.5 and 1.</p></li>
<li><p>If the student prefers BET 2, then his <span class="math inline">\(Prob(W)\)</span> must be smaller than <span class="math inline">\(Prob(B) = 0.5\)</span> – that is, his probability of W must fall between 0 and 0.5.</p></li>
</ol>
<p>What the student does next depends on his answer to the second question.</p>
<ul>
<li><p>If his <span class="math inline">\(Prob(W)\)</span> falls in the interval (0, 0.5), then consider the “balls in box” experiment with 2 red and 8 white balls and one are interested in the probability of choosing a red ball.</p></li>
<li><p>If instead his <span class="math inline">\(Prob(W)\)</span> falls in the interval (0.5, 1), then consider the “balls in box” experiment with 8 red and 2 white balls and he is interested in the probability of choosing a red ball.</p></li>
</ul>
<p>Let’s suppose that the student believes <span class="math inline">\(Prob(W)\)</span> falls in the interval (0.5, 1). Then he would make a judgment between the two bets</p>
<ul>
<li>BET 1 – If <span class="math inline">\(W\)</span> occurs (a women is president in the next 20 years), he wins $100. Otherwise, he wins nothing.</li>
<li>BET 2 – If <span class="math inline">\(B\)</span> occurs (observe a red ball with a box with 8 red and 2 white balls), he wins $100. Otherwise, he wins nothing.</li>
</ul>
<p>The student decides to prefer BET 2, which means that his probability <span class="math inline">\(Prob(W)\)</span> is smaller than 0.8. Based on the information on the two comparisons, the student now believes that <span class="math inline">\(Prob(W)\)</span> falls between 0.5 and 0.8.</p>
<p>In practice, the student will continue to compare BET 1 and BET 2, where the box has a different number of red and white balls. By a number of comparisons, he will get an accurate measurement at his probability of <span class="math inline">\(W\)</span>.</p>
</div>
</div>
</div>
<div id="the-sample-space" class="section level2">
<h2><span class="header-section-number">1.5</span> The Sample Space</h2>
<p>A sample space lists all possible outcomes of a random experiment. There are different ways to write down the sample space, depending on how one thinks about outcomes.<br />
Let’s illustrate the variety of sample spaces by the simple experiment “roll two fair dice.”</p>
<p>Each die is the usual six-sided object that we are familiar with, with the numbers 1, 2, 3, 4, 5, 6 on each side. When one says “fair dice”, one is imagining that each die is constructed such that the six possible numbers are equally likely to come up when rolled.</p>
<p>What can happen when you roll two dice? The collection of all outcomes that are possible is the sample space. But there are different ways of representing the sample space depending on what “outcome” we are considering.</p>
<div id="roll-two-fair-indistinguishable-dice" class="section level3">
<h3><span class="header-section-number">1.5.1</span> Roll two fair, indistinguishable dice</h3>
<p>First, suppose one is interested in the sum of the numbers on the two dice. This would be of interest to a gambler playing the casino game craps. What are the possible sums? After some thought, it should be clear that the smallest possible sum is 2 (if you roll two ones) and the largest possible sum is 12 (with two sixes). Also every whole number between 2 and 12 is a possible sum. So the sample space, denoted by <span class="math inline">\(S\)</span>, would be</p>
<p><span class="math inline">\(S\)</span> = {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}.</p>
<p>Suppose instead that one wishes to record the rolls on each of the two dice. One possible outcome would be</p>
<p>(4 on one die, 3 on the other die)</p>
<p>or more simply (4, 3). What are the possible outcomes? Table 1.2 lists the twenty-one possibilities:</p>
<p>Table 1.2: The possible outcomes of rolling two fair, instinguishable dice.</p>
<table>
<tbody>
<tr class="odd">
<td>(1, 1)</td>
<td>(1, 2)</td>
<td>(1, 3)</td>
<td>(1, 4)</td>
</tr>
<tr class="even">
<td>(1, 5)</td>
<td>(1, 6)</td>
<td>(2, 2)</td>
<td>(2, 3)</td>
</tr>
<tr class="odd">
<td>(2, 4)</td>
<td>(2, 5)</td>
<td>(2, 6)</td>
<td>(3, 3)</td>
</tr>
<tr class="even">
<td>(3, 4)</td>
<td>(3, 5)</td>
<td>(3, 6)</td>
<td>(4, 4)</td>
</tr>
<tr class="odd">
<td>(4, 5)</td>
<td>(4, 6)</td>
<td>(5, 5)</td>
<td>(5, 6)</td>
</tr>
<tr class="even">
<td>(6, 6)</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Notice that one is not distinguishing between the two dice in this list. For example, the outcome (2, 3) was written only once, although there are two ways for this to happen – either the first die is 2 and the second die is 3, or the other way around.</p>

<p>Next suppose one distinguishes the two dice – perhaps one die is red and one die is white – and one are considering all of the possible rolls of both dice. We illustrate two ways of showing the sample space in this case.</p>
<p>One way of representing possible rolls of two distinct dice is by a tree diagram shown in Figure 1.1. On the left side of the diagram, the six possible rolls of the red die are represented by six branches of a tree. Then,on the right side, the six possible rolls of the white die are represented by by six smaller branches coming out of each roll of the red die. A single branch on the left and a single branch on the right represent one possible outcome of this experiment.</p>
<div class="figure"><span id="fig:unnamed-chunk-7"></span>
<img src="../LATEX/figures/chapter1/twodice.png" alt="Tree diagram representation of the rolls of two dice." width="265" />
<p class="caption">
Figure 1.1: Tree diagram representation of the rolls of two dice.
</p>
</div>
<p>There are alternative ways for representing the outcomes of this experiment of rolling two distinct dice. Suppose one writes down an outcome by the ordered pair</p>
<p>(roll on white die, roll on red die).</p>
<p>Then the possible outcomes are listed below.</p>
<p>Table 1.3. The possible outcomes of rolling two fair, distinguishable dice.</p>
<table>
<tbody>
<tr class="odd">
<td>(1, 1)</td>
<td>(1, 2)</td>
<td>(1, 3)</td>
<td>(1, 4)</td>
<td>(1, 5)</td>
<td>(1, 6)</td>
</tr>
<tr class="even">
<td>(2, 1)</td>
<td>(2, 2)</td>
<td>(2, 3)</td>
<td>(2, 4)</td>
<td>(2, 5)</td>
<td>(2, 6)</td>
</tr>
<tr class="odd">
<td>(3, 1)</td>
<td>(3, 2)</td>
<td>(3, 3)</td>
<td>(3, 4)</td>
<td>(3, 5)</td>
<td>(3, 6)</td>
</tr>
<tr class="even">
<td>(4, 1)</td>
<td>(4, 2)</td>
<td>(4, 3)</td>
<td>(4, 4)</td>
<td>(4, 5)</td>
<td>(4, 6)</td>
</tr>
<tr class="odd">
<td>(5, 1)</td>
<td>(5, 2)</td>
<td>(5, 3)</td>
<td>(5, 4)</td>
<td>(5, 5)</td>
<td>(5, 6)</td>
</tr>
<tr class="even">
<td>(6, 1)</td>
<td>(6, 2)</td>
<td>(6, 3)</td>
<td>(6, 4)</td>
<td>(6, 5)</td>
<td>(6, 6)</td>
</tr>
</tbody>
</table>
<p>Since these are ordered pairs, the order of the numbers does matter. The outcome (5, 1) (5 on the red, 1 on the white) is different from the outcome (1, 5) (1 on the red die and 5 on the white die).</p>
<p>Two representations of the sample space of possible rolls of two dice have been illustrated. These representations differ by how one records the outcome of rolling two dice. One either (1) records the sum of the two dice, (2) records the individual rolls, not distinguishing the two dice, or (3) records the individual rolls, distinguishing the two dice.</p>
<p>Which one is the best sample space to use? Actually, all of the sample spaces shown above are correct. Each sample space represents all possible outcomes of the experiment of rolling two dice and one cannot say that one sample space is better than another sample space. But one will see that in particular situations some sample spaces are more convenient than other sample spaces when one wishes to assign probabilities. In the current case of rolling two fair dice, the sample space with distinguishable dice is desirable from the viewpoint of computing probabilities since the outcomes are equally likely.</p>
<p>When one writes down sample spaces, one uses whatever method one likes. One can use a tree diagram or a table, or one might like to list the outcomes. The important thing is that one has displayed all of the possible outcomes in <span class="math inline">\(S\)</span>.</p>
</div>
</div>
<div id="assigning-probabilities" class="section level2">
<h2><span class="header-section-number">1.6</span> Assigning Probabilities</h2>
<p>When one has a random experiment, the first step is to list all of the possible outcomes in the sample space. The next step is to assign numbers, called probabilities, to the different outcomes that reflect the likelihoods that these outcomes can occur.</p>
<p>To illustrate different assignments of probabilities, suppose a school girl goes to an ice cream parlor and plans to order a single-dip ice cream cone. This particular parlor has four different ice cream flavors. Which flavor will the school girl order?</p>
<p>First, one writes down the sample space – the possible flavors that the school girl can order. Probabilities will be assigned to these four possible outcomes that reflect a person’s beliefs about her likes and dislikes.</p>
<p>Table 1.4. Writing down the space space: step 1.</p>
<table>
<thead>
<tr class="header">
<th>Flavor</th>
<th>Vanilla</th>
<th>Chocolate</th>
<th>Butter Pecan</th>
<th>Maple Walnut</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Can our probabilities be any numbers? Not exactly. Here are some basic facts (or laws) about probabilities:</p>
<ul>
<li>Any probability that is assigned must fall between 0 and 1<br />
</li>
<li>The sum of the probabilities across all outcomes must be equal to 1.</li>
<li>An outcome will be assigned a probability of 0 if one is sure that that outcome will never occur.<br />
</li>
<li>Likewise, if one assigns a probability of 1 to an event, then that event must occur all the time.</li>
</ul>
<p>With these facts in mind, consider some possible probability assignments for the flavor of ice cream that this school girl will order.</p>
<div id="scenario-1" class="section level4">
<h4><span class="header-section-number">1.6.0.1</span> Scenario 1</h4>
<p>Suppose that the school girl likes to be surprised. She has brought a hat in which she has placed many slips of paper – 10 slips are labeled “vanilla”, 10 slips are labeled “chocolate”, and 10 slips are “butter pecan”, and 10 are “maple walnut”. She makes her ice cream choice by choosing a slip at random. In this case, each flavor would have a probability of 10/40 = 1/4 .</p>
<p>Table 1.5. Assignment of probabilities in scenario 1.</p>
<table>
<thead>
<tr class="header">
<th>Flavor</th>
<th>Vanilla</th>
<th>Chocolate</th>
<th>Butter Pecan</th>
<th>Maple Walnut</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td>1/4</td>
<td>1/4</td>
<td>1/4</td>
<td>1/4</td>
</tr>
</tbody>
</table>
</div>
<div id="scenario-2" class="section level4">
<h4><span class="header-section-number">1.6.0.2</span> Scenario 2</h4>
<p>Let’s consider a different set of probabilities based on different assumptions about the school girl’s taste preferences. A person knows that she really doesn’t like “plain” flavors like vanilla or chocolate, and she really likes ice creams with nut flavors. In this case, he would assign “Vanilla” and “Chocolate” each a probability of 0, and assign the two other flavors probabilities that sum to one.</p>
<p>Here is one possible assignment.</p>
<p>Table 1.6. Assignment of probabilities in scenario 2.</p>
<table>
<thead>
<tr class="header">
<th>Flavor</th>
<th>Vanilla</th>
<th>Chocolate</th>
<th>Butter Pecan</th>
<th>Maple Walnut</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td>0</td>
<td>0</td>
<td>0.7</td>
<td>0.3</td>
</tr>
</tbody>
</table>
<p>Another possible assignment of probabilities that is consistent with these assumptions is the following:</p>
<p>Table 1.7. Another possible assignment of probabilities in scenario 2.</p>
<table>
<thead>
<tr class="header">
<th>Flavor</th>
<th>Vanilla</th>
<th>Chocolate</th>
<th>Butter Pecan</th>
<th>Maple Walnut</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td>0</td>
<td>0</td>
<td>0.2</td>
<td>0.8</td>
</tr>
</tbody>
</table>
</div>
<div id="scenario-3" class="section level4">
<h4><span class="header-section-number">1.6.0.3</span> Scenario 3</h4>
<p>Let’s consider an alternative probability assignment from a different person’s viewpoint. The worker at the ice cream shop has no idea what flavor the school girl will order. But the worker has been working at the shop all day and she has kept a record of how many cones of each type have been ordered – of 50 cones ordered, 10 are vanilla, 14 are chocolate, 20 are butter pecan, and 6 are maple walnut. If she believes that the school girl has similar tastes to the previous customers, then it would be reasonable to apply the frequency viewpoint to assign the probabilities.</p>
<p>Table 1.8. Assignment of probabilities in scenario 3.</p>
<table>
<thead>
<tr class="header">
<th>Flavor</th>
<th>Vanilla</th>
<th>Chocolate</th>
<th>Butter Pecan</th>
<th>Maple Walnut</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td>10/50</td>
<td>14/50</td>
<td>20/50</td>
<td>6/50</td>
</tr>
</tbody>
</table>
<p>Each of the above probability assignments used a different viewpoint of probability as described in previous sections. The first assignment used the classical viewpoint where each of the forty slips of paper had the same probability of being selected. The second assignment was an illustration of the subjective view where one’s assignment was based on one’s opinion about the favorite flavors of one’s daughter. The last assignment was based on the frequency viewpoint where the probabilities were estimated from the observed flavor preferences of 50 previous customers.</p>
</div>
<div id="events-and-event-operations" class="section level3">
<h3><span class="header-section-number">1.6.1</span> Events and Event Operations</h3>
<p>In this chapter, probability has been discussed in an informal way. Numbers called probabilities are assigned to outcomes in the sample space such that the sum of the numbers over all outcomes is equal to one. In this section, we look at probability from a more formal viewpoint. One defines probability as a function on events that satisfies three basic laws or axioms. Then all of the important facts about probabilities, including some facts that have been used above, can be derived once these three basic axioms are defined.</p>
<p>Suppose that the sample space for our random experiment is <span class="math inline">\(S\)</span>. An event, represented by a capital letter such as <span class="math inline">\(A\)</span>, is a subset of <span class="math inline">\(S\)</span>. Events, like sets, can be combined in various ways described as follows.</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(A \cap B\)</span> is the event that both A and B occur (the intersection of the two events)</li>
<li><span class="math inline">\(A \cup B\)</span> is the event that either A or B occur (the union of the two events)</li>
<li><span class="math inline">\(\bar A\)</span> (or <span class="math inline">\(A^c\)</span>) is the event that A does not occur (the complement of the event A)</li>
</ol>
<p>To illustrate these event operations, suppose one chooses a student at random from a class and records the month when she or he was born. The student could be born during 12 possible months and the sample space <span class="math inline">\(S\)</span> is the list of these months:</p>
<p><span class="math inline">\(S\)</span> = {January, February, March, April, May, June, July, August, September, October, November, December}.</p>
<p>Define the events <span class="math inline">\(L\)</span> that the student is born during the last half of the year and <span class="math inline">\(F\)</span> that the student is born during a month that is four letters long.</p>
<p><span class="math inline">\(L\)</span> = {July, August, September, October, November, December}.</p>
<p><span class="math inline">\(F\)</span> = {June, July}.</p>
<p>Various event operations can be illustrated using these events.</p>
<ul>
<li><span class="math inline">\(L \cap F\)</span> is the event that the student is born during the last half of the year AND is born in a four-letter month = {July}.</li>
<li><span class="math inline">\(L \cup F\)</span>, in contrast, is the event that the student is EITHER born during the last half of the year OR born in a four-letter month = {June, July, August, September, October, November, December}.</li>
<li><span class="math inline">\(\bar L\)</span> (or <span class="math inline">\(L^c\)</span>) is the event that the student is NOT born during the last half of the year = {January, February, March, April, May, June}</li>
</ul>
</div>
<div id="the-three-probability-axioms" class="section level3">
<h3><span class="header-section-number">1.6.2</span> The Three Probability Axioms</h3>
<p>Now that a sample space <span class="math inline">\(S\)</span> and events are defined, probabilities are defined to be numbers assigned to the events. There are three basic laws or axioms that define probabilities:</p>
<ul>
<li><strong>Axiom 1</strong>: For any event <span class="math inline">\(A\)</span>, <span class="math inline">\(P(A) \geq 0\)</span>. That is, all probabilities are nonnegative values.</li>
<li><strong>Axiom 2</strong>: <span class="math inline">\(P(S) = 1\)</span>. That is, the probability that you observe something in the sample space is one.</li>
<li><strong>Axiom 3:</strong> Suppose one has a sequence of events <span class="math inline">\(A_1, A_2, A_3, ...\)</span> that are mutually exclusive, which means that for any two events in the sequence, say <span class="math inline">\(A_2\)</span> and <span class="math inline">\(A_3\)</span> , the intersection of the two events is the empty set (i.e. <span class="math inline">\(A_2 \cap A_3 = \emptyset\)</span>). Then one finds the probability of the union of the events by adding the individual event probabilities:</li>
</ul>
<p><span class="math display" id="eq:probunion">\[\begin{equation}
P(A_1 \cup A_2 \cup A_3 \cup ...) = P(A_1) + P(A_2) + P(A_3) + ...
\tag{1.2}
\end{equation}\]</span></p>
<p>Given the three basic axioms, some additional facts about probabilities can be proven. These additional facts are called properties – these are not axioms, but rather additional facts that are derived knowing the axioms. Below several familiar properties about probabilities are stated and we prove how each property follows logically from the axioms.</p>

<p><strong>Property 1:</strong> If <span class="math inline">\(A\)</span> is a subset of <span class="math inline">\(B\)</span>, that is <span class="math inline">\(A \subset B\)</span>, then <span class="math inline">\(P(A) \le P(B)\)</span>.</p>
<p>This property states that if one has two events, such that one event is a subset of the other event, then the probability of the first set cannot exceed the probability of the second. This fact may seem pretty obvious, but how can one prove this from the axioms?</p>

<p><strong>Proof</strong>: The proof begins with a Venn diagram where a set <span class="math inline">\(A\)</span> is a subset of set <span class="math inline">\(B\)</span>. (See Figure 1.2.)</p>
<div class="figure"><span id="fig:unnamed-chunk-8"></span>
<img src="../LATEX/figures/chapter1/venn1.png" alt="Two sets where set $A$ is  a subset of set $B$." width="238" />
<p class="caption">
Figure 1.2: Two sets where set <span class="math inline">\(A\)</span> is a subset of set <span class="math inline">\(B\)</span>.
</p>
</div>
<p>Note that the larger set <span class="math inline">\(B\)</span> can be written as the union of <span class="math inline">\(A\)</span> and <span class="math inline">\(\bar A \cap B\)</span>, that is,
<span class="math display" id="eq:unionaac">\[\begin{equation}
B = A \cup (\bar A \cap B)
\tag{1.3}
\end{equation}\]</span>
Note that <span class="math inline">\(A\)</span> and <span class="math inline">\(\bar A \cap B\)</span> are mutually exclusive (i.e. they have no overlap). So one can apply Axiom 3 and write
<span class="math display" id="eq:axiom3">\[\begin{equation}
P(B) = P(A) + P(\bar A \cap B)
\tag{1.4}
\end{equation}\]</span>
Also, by Axiom 1, the probability of any event is nonnegative. So the probability of <span class="math inline">\(B\)</span> is equal to the probability of <span class="math inline">\(A\)</span> plus a nonnegative number. So this implies
<span class="math display" id="eq:probsubset">\[\begin{equation}
P(B) \ge P(A)
\tag{1.5}
\end{equation}\]</span>
which is what we wish to prove.</p>

<p><strong>Property 2:</strong> <span class="math inline">\(P(A) \le 1\)</span>.</p>
<p>This is pretty obvious – probabilities certainly cannot be larger than 1. But how can this property be shown given our known facts including the axioms and Property 1 that was just proved?</p>

<p><strong>Proof</strong>:
Actually this property is a consequence of Property 1. Consider the two events <span class="math inline">\(A\)</span> and the sample space <span class="math inline">\(S\)</span>. Obviously <span class="math inline">\(A\)</span> is a subset of the sample space – that is,
<span class="math display" id="eq:subsetS">\[\begin{equation}
A \subset S
\tag{1.6}
\end{equation}\]</span>
So applying Property 1,
<span class="math display" id="eq:probAS">\[\begin{equation}
P(A) \le P(S) = 1.
\tag{1.7}
\end{equation}\]</span>
It is known that <span class="math inline">\(P(S) = 1\)</span> from the second Axiom 2. So we have proved our result.</p>
</div>
<div id="the-complement-and-addition-properties" class="section level3">
<h3><span class="header-section-number">1.6.3</span> The Complement and Addition Properties</h3>
<p>There are two additional properties of probabilities that are useful in computation. Both of these properties will be stated without proof, but an outline of the proofs will be given in the end-of chapter exercises.
The first property, called the complement property, states that the probability of the complement of an event is simply one minus the probability of the event.</p>

<p><strong>Complement property:</strong> For an event <span class="math inline">\(A\)</span>,</p>
<p><span class="math display" id="eq:compp">\[\begin{equation}P(\bar A) = 1 - P(A).
\tag{1.8}\end{equation}\]</span></p>
<p>The second property, called the addition property, gives a formula for the probability of the union of two events.</p>

<p><strong>Addition property</strong>: For two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>,</p>
<p><span class="math display" id="eq:addprop">\[\begin{equation}P(A \cup B) = P(A) + P(B) - P(A \cap B).
\tag{1.9}\end{equation}\]</span></p>
<p>Both of these properties are best illustrated by an example. Let’s revisit the example where one was interested in the birth month of a student selected from a class. As before, let <span class="math inline">\(L\)</span> represent the event that the student is born during the last half of the year and <span class="math inline">\(F\)</span> denote the event that the student is born during a month that is four letters long.</p>
<p>There are 12 possible outcomes for the birth month. One can assume that each month is equally likely to occur, but actually in the U.S. population, the numbers of births during the different months do vary. Using data from the births in the U.S. in 1978, we obtain the following probabilities for the months. We see that August is the most likely birth month with a probability of 0.091 and February (the shortest month) has the smallest probability of 0.075.</p>
<p>Table 1.9. Probability table of birth months in the U.S. in 1978.</p>
<table>
<thead>
<tr class="header">
<th>Month</th>
<th>Jan</th>
<th>Feb</th>
<th>Mar</th>
<th>Apr</th>
<th>May</th>
<th>June</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prob</td>
<td>0.081</td>
<td>0.075</td>
<td>0.083</td>
<td>0.076</td>
<td>0.082</td>
<td>0.081</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Month</th>
<th>July</th>
<th>Aug</th>
<th>Sept</th>
<th>Oct</th>
<th>Nov</th>
<th>Dec</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prob</td>
<td>0.088</td>
<td>0.091</td>
<td>0.088</td>
<td>0.087</td>
<td>0.082</td>
<td>0.085</td>
</tr>
</tbody>
</table>
<p>Using this probability table, one finds …</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(L) = P\)</span>(July, August, September, October, November, December)
= 0.088 +0.091+0.088+0.098+0.082+0.085 = 0.521.</li>
<li><span class="math inline">\(P(F)\)</span> = <span class="math inline">\(P\)</span>(June, July) = <span class="math inline">\(0.081+0.088 = 0.169\)</span>.</li>
</ol>
<p>Now we are ready to illustrate the two probability properties.</p>
<ul>
<li><p>What is the probability the student is not born during the last half of the year? This can be found by summing the probabilities of the first six months of the year. It is easier to compute this probability by noting that the event of interest is the complement of the event <span class="math inline">\(L\)</span>, and the complement property can be applied to find the probability.
<span class="math display">\[
P(\bar L) = 1 - P(L).
\]</span></p></li>
<li><p>What is the probability the student is either born during the last six months of the year {} a month four letters long? In Figure 1.3, the sample space <span class="math inline">\(S\)</span> is displayed consisting of the twelve possible birth months, and the events <span class="math inline">\(F\)</span> and <span class="math inline">\(L\)</span> are shown by circling the relevant outcomes. The event <span class="math inline">\(F \cup L\)</span> is the union of the two circled events.</p></li>
</ul>
<p>Applying the addition property, one finds the probability of <span class="math inline">\(F \cup L\)</span> by adding the probabilities of <span class="math inline">\(F\)</span> and <span class="math inline">\(L\)</span> and subtracting the probability of the intersection event <span class="math inline">\(F \cap L\)</span> :</p>
<p><span class="math display">\[\begin{align*}
P(F \cup L)  &amp;= P(F) + P(L) - P(F \cap L) \\
  &amp;= 0.521 + 0.169 - 0.088 \\
  &amp;= 0.602
\end{align*}\]</span></p>
<div class="figure"><span id="fig:unnamed-chunk-9"></span>
<img src="../LATEX/figures/chapter1/venn2.png" alt="Representation of two sets $F$ and $L$ in birthday example." width="377" />
<p class="caption">
Figure 1.3: Representation of two sets <span class="math inline">\(F\)</span> and <span class="math inline">\(L\)</span> in birthday example.
</p>
</div>

<p>Looking at Figure , the formula should make sense. When one adds the probabilities of the events <span class="math inline">\(F\)</span> and <span class="math inline">\(L\)</span>, one adds the probability of the month July twice, and to get the correct answer, one needs to subtract the outcome (July) common to both <span class="math inline">\(F\)</span> and <span class="math inline">\(L\)</span>.</p>

<p><strong>Special Note:</strong> Is it possible to simply add the probabilities of two events, say <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, to get the probability of the union <span class="math inline">\(A \cup B\)</span>? Suppose the sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are mutually exclusive which means they have no outcomes in common. In this special case,<span class="math inline">\(A \cap B = \emptyset\)</span>, <span class="math inline">\(P(A \cap B) = 0\)</span> and <span class="math inline">\(P(A \cup B) = P(A) + P(B)\)</span>. For example, suppose one is interested in probability that the student is born in the last half the year (event <span class="math inline">\(L\)</span>) or in May (event <span class="math inline">\(M\)</span>). Here, it is not possible to be born in the last half of the year and in May so <span class="math inline">\(L \cap M = \emptyset\)</span>. In this case, <span class="math inline">\(P(L \cup M) = P(L) + P(M) = 0.521 + 0.082 = 0.603\)</span>.</p>
</div>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">1.7</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><strong>Probability Viewpoints</strong></li>
</ol>
<p>In the following problems, indicate if the given probability is found using the classical viewpoint, the frequency viewpoint, or the subjective viewpoint.</p>
<ol style="list-style-type: lower-alpha">
<li>Joe is doing well in school this semester – he is 90 percent sure that he will receive an A in all of his classes.</li>
<li>Two hundred raffle tickets are sold and one ticket is a winner. Someone purchased one ticket and the probability that her ticket is the winner is 1/200.</li>
<li>Suppose that 30% of all college women are playing an intercollegiate sport. If we contact one college woman at random, the chance that she plays a sport is 0.3.</li>
<li>Two Polish statisticians in 2002 were questioning if the new Belgium Euro coin was indeed fair. They had their students flip the Belgium Euro 250 times, and 140 came up heads.</li>
<li>Many people are afraid of flying. But over the decade 1987-96, the death risk per flight on a US domestic jet has been 1 in 7 million.</li>
<li>In a roulette wheel, there are 38 slots numbered 0, 00, 1, …, 36. There are 18 ways of spinning an odd number, so the probability of spinning an odd is 18/38.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><strong>Probability Viewpoints</strong></li>
</ol>
<p>In the following problems, indicate if the given probability is found using the classical viewpoint, the frequency viewpoint, or the subjective viewpoint.</p>
<ol style="list-style-type: lower-alpha">
<li>The probability that the spinner lands in the region A is 1/4.</li>
</ol>
<img src="../LATEX/figures/chapter1/spinner0.png" width="111" />

<ol start="2" style="list-style-type: lower-alpha">
<li>The meteorologist states that the probability of rain tomorrow is 0.5. You think it is more likely to rain and you think the chance of rain is 3/4.</li>
<li>A football fan is 100% certain that his high school football team will win their game on Friday.</li>
<li>Jennifer attends a party, where a prize is given to the person holding a raffle ticket with a specific number. If there are eight people at the party, the chance that Jennifer wins the prize is 1/8.</li>
<li>What is the chance that you will pass an English class? You learn that the professor passes 70% of the students and you think you are typical in ability among those attending the class.</li>
<li>If you toss a plastic cup in the air, what is the probability that it lands with the open side up? You toss the cup 50 times and it lands open side up 32 times, so you approximate the probability by 32/50</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li><strong>Equally Likely Outcomes</strong></li>
</ol>
<p>For the following experiments, a list of possible outcomes is given. Decide if one can assume that the outcomes are equally likely. If the equally likely assumption is not appropriate, explain which outcomes are more likely than others.</p>
<ol style="list-style-type: lower-alpha">
<li>A bowl contains six marbles of which two are red, three are white, and one is black. One marble is selected at random from the bowl and the color is observed.</li>
</ol>
<p>Outcomes: {red, white, black}</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>You observe the gender of a baby born today at your local hospital.</li>
</ol>
<p>Outcomes: {male, female}</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Your school’s football team is playing the top rated school in the country.</li>
</ol>
<p>Outcomes: {your team wins, your team loses}</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>A bag contains 50 slips of paper, 10 that are labeled “1”, 10 labeled “2”, 10 labeled “3”, 10 labeled “4”, and 10 labeled “5”. You choose a slip at random from the bag and notice the number on the slip.</li>
</ol>
<p>Outcomes: {1, 2, 3, 4, 5}</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Equally Likely Outcomes</strong></li>
</ol>
<p>For the following experiments, a list of possible outcomes is given. Decide if one can assume that the outcomes are equally likely. If the equally likely assumption is not appropriate, explain which outcomes are more likely than others.</p>
<ol style="list-style-type: lower-alpha">
<li><p>You wait at a bus stop for a bus. From experience, you know that you wait, on average, 8 minutes for this bus to arrive.</p>
<p>Outcomes: {wait less than 10 minutes, wait more than 10 minutes}</p></li>
<li><p>You roll two dice and observe the sum of the numbers.</p>
<p>Outcomes: {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}</p></li>
<li><p>You get a grade for an English course in college.</p></li>
</ol>
<p>Outcomes: {A, B, C, D, F}</p>
<ol start="4" style="list-style-type: lower-alpha">
<li><p>You interview a person at random at your college and ask for his or her age.</p>
<p>Outcomes: {17 to 20 years, 21 to 25 years, over 25 years}</p></li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li><strong>Flipping a Coin</strong></li>
</ol>
<p>Suppose you flip a fair coin until you observe heads. You repeat this experiment many times, keeping track of the number of flips it takes to observe heads. Here are the numbers of flips for 30 experiments.</p>
<pre><code>## 1 3 1 2 1 1 2 6 1 2 1 1 1 1 3 2 1 1 2 1 5 2 1 7 3 3 3 1 2 3</code></pre>
<ol style="list-style-type: lower-alpha">
<li>Approximate the probability that it takes you exactly two flips to observe heads.</li>
<li>Approximate the probability that it takes more than two flips to observe heads.</li>
<li>What is the most likely number of flips?</li>
</ol>
<ol start="6" style="list-style-type: decimal">
<li><strong>Driving to Work</strong></li>
</ol>
<p>You drive to work 20 days, keeping track of the commuting time (in minutes) for each trip. Here are the twenty measurements.</p>
<p>25.4, 27.8, 26.8, 24.1, 24.5, 23.0,
27.5, 24.3, 28.4, 29.0, 29.4, 24.9,
26.3, 23.5, 28.3, 27.8, 29.4, 25.7,
24.3, 24.2</p>
<ol style="list-style-type: lower-alpha">
<li>Approximate the probability that it takes you under 25 minutes to drive to work.</li>
<li>Approximate the probability it takes between 25 and 28 minutes to drive to work.</li>
<li>Suppose one day it takes you 23 minutes to get to work. Would you consider this unusual? Why?</li>
</ol>
<ol start="7" style="list-style-type: decimal">
<li><strong>A Man Sent to the Moon</strong></li>
</ol>
<p>Consider your subjective probability <span class="math inline">\(P(M)\)</span> where <span class="math inline">\(M\)</span> is the event that the United States will send a man to the moon in the next twenty years.</p>
<ol style="list-style-type: lower-alpha">
<li>Let <span class="math inline">\(B\)</span> denote the event that you select a red ball from a box of five red and five white balls. Consider the two bets</li>
</ol>
<ul>
<li>BET 1 – If <span class="math inline">\(M\)</span> occurs (United States will send a man to the moon in the next 20 years), you win $100. Otherwise, you win nothing.</li>
<li>BET 2 – If <span class="math inline">\(B\)</span> occurs (you observe a red ball in the above experiment), you win $100. Otherwise, you win nothing.</li>
</ul>
<p>Circle the bet that you prefer.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Let <span class="math inline">\(B\)</span> represent choosing red from a box of 7 red and 3 white balls. Again compare BET 1 with BET 2 – which bet do you prefer?</li>
<li>Let <span class="math inline">\(B\)</span> represent choosing red from a box of 3 red and 7 white balls. Again compare BET 1 with BET 2 – which bet do you prefer?</li>
<li>Based on your answers to (a), (b), (c), circle the interval of values that contain your subjective probability <span class="math inline">\(P(M)\)</span>.</li>
</ol>
<ol start="8" style="list-style-type: decimal">
<li><strong>What State Will You Be Living in the Future?</strong></li>
</ol>
<p>Consider your subjective probability <span class="math inline">\(P(S)\)</span> where <span class="math inline">\(S\)</span> is the event that at age 60 you will be living in the same state as you currently live.</p>
<ol style="list-style-type: lower-alpha">
<li>Let <span class="math inline">\(B\)</span> denote the event that you select a red ball from a box of five red and five white balls. Consider the two bets</li>
</ol>
<ul>
<li>BET 1 – If <span class="math inline">\(S\)</span> occurs (you live in the same state at age 60), you win $100. Otherwise, you win nothing.</li>
<li>BET 2 – If <span class="math inline">\(B\)</span> occurs (you observe a red ball in the above experiment), you win $100. Otherwise, you win nothing.</li>
</ul>
<p>Circle the bet that you prefer.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Let <span class="math inline">\(B\)</span> represent choosing red from a box of 7 red and 3 white balls. Again compare BET 1 with BET 2 – which bet do you prefer?</li>
<li>Let <span class="math inline">\(B\)</span> represent choosing red from a box of 3 red and 7 white balls. Again compare BET 1 with BET 2 – which bet do you prefer?</li>
<li>Based on your answers to (a), (b), (c), circle the interval of values that contain your subjective probability <span class="math inline">\(P(S)\)</span>.</li>
</ol>
<ol start="9" style="list-style-type: decimal">
<li><strong>Frequency of Vowels in Huckleberry Finn</strong></li>
</ol>
<p>Suppose you choose a page at random from the book Huckleberry Finn by Mark Twain and find the first vowel on the page.</p>
<ol style="list-style-type: lower-alpha">
<li>If you believe it is equally likely to find any one of the five possible vowels, fill in the probabilities of the vowels below.</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Vowel</th>
<th>a</th>
<th>e</th>
<th>i</th>
<th>o</th>
<th>u</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: lower-alpha">
<li>Based on your knowledge about the relative use of the different vowels, assign probabilities to the vowels.</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Vowel</th>
<th>a</th>
<th>e</th>
<th>i</th>
<th>o</th>
<th>u</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol start="3" style="list-style-type: lower-alpha">
<li><p>Do you think it is appropriate to apply the classical viewpoint to probability in this example? (Compare your answers to parts a and b.)</p></li>
<li><p>On each of the first fifty pages of Huckleberry Finn, your author found the first five vowels. Here is a table of frequencies of the five vowels:</p></li>
</ol>
<table>
<thead>
<tr class="header">
<th>Vowel</th>
<th>a</th>
<th>e</th>
<th>i</th>
<th>o</th>
<th>u</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Frequency</td>
<td>61</td>
<td>63</td>
<td>34</td>
<td>70</td>
<td>22</td>
</tr>
<tr class="even">
<td>Probability</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Use this data to find approximate probabilities for the vowels.</p>
<ol start="10" style="list-style-type: decimal">
<li><strong>Purchasing Boxes of Cereal</strong></li>
</ol>
<p>Suppose a cereal box contains one of four different posters denoted A, B, C, and D. You purchase four boxes of cereal and you count the number of posters (among A, B, C, D) that you do not have. The possible number of “missing posters” is 0, 1, 2, and 3.</p>
<ol style="list-style-type: lower-alpha">
<li>Assign probabilities if you believe the outcomes are equally likely.</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Number of missing posters</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td></td>
<td></td>
<td></td>
<td>\</td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: lower-alpha">
<li>Assign probabilities if you believe that the outcomes 0 and 1 are most likely to happen.</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Number of missing posters</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td></td>
<td></td>
<td></td>
<td>\</td>
</tr>
</tbody>
</table>
<ol start="3" style="list-style-type: lower-alpha">
<li>Suppose you purchase many groups of four cereals, and for each purchase, you record the number of missing posters. The number of missing posters for 20 purchases is displayed below. For example, in the first purchase, you had 1 missing poster, in the second purchase, you also had 1 missing poster, and so on.</li>
</ol>
<p>1, 1, 1, 2, 1, 1, 0, 0, 2, 1,
2, 1, 3, 1, 2, 1, 0, 1, 1, 1</p>
<p>Using these data, assign probabilities.</p>
<table>
<thead>
<tr class="header">
<th>Number of missing posters</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td></td>
<td></td>
<td></td>
<td>\</td>
</tr>
</tbody>
</table>
<ol start="4" style="list-style-type: lower-alpha">
<li>Based on your work in part c, is it reasonable to assume that the four outcomes are equally likely? Why?</li>
</ol>
<ol start="11" style="list-style-type: decimal">
<li><strong>Writing Sample Spaces</strong></li>
</ol>
<p>For the following random experiments, give an appropriate sample space for the random experiment. You can use any method (a list, a tree diagram, a two-way table) to represent the possible outcomes.</p>
<ol style="list-style-type: lower-alpha">
<li>You simultaneously toss a coin and roll a die.</li>
<li>Construct a word from the five letters a, a, e, e, s.</li>
<li>Suppose a person lives at point 0 and each second she randomly takes a step to the right or a step to the left. You observe the person’s location after four steps.</li>
<li>In the first round of next year’s baseball playoff, the two teams, say the Phillies and the Diamondbacks play in a best-of-five series where the first team to win three games wins the playoff.<br />
</li>
<li>A couple decides to have children until a boy is born.<br />
</li>
<li>A roulette game is played with a wheel with 38 slots numbered 0, 00, 1, …, 36. Suppose you place a $10 bet that an even number (not 0) will come up in the wheel. The wheel is spun.</li>
<li>Suppose three batters, Marlon, Jimmy, and Bobby, come to bat during one inning of a baseball game. Each batter can either get a hit, walk, or get out.</li>
</ol>
<ol start="12" style="list-style-type: decimal">
<li><strong>Writing Sample Spaces</strong></li>
</ol>
<p>For the following random experiments, give an appropriate sample space for the random experiment. You can use any method (a list, a tree diagram, a two-way table) to represent the possible outcomes.</p>
<ol style="list-style-type: lower-alpha">
<li>You toss three coins.</li>
<li>You spin the spinner (shown below) three times.</li>
</ol>
<p><img src="../LATEX/figures/chapter1/spinner1.png" width="121" /></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>When you are buying a car, you have a choice of three colors, two different engine sizes, and whether or not to have a CD player. You make each choice completely at random and go to the dealership to pick up your new car.</li>
<li>Five horses, Lucky, Best Girl, Stripes, Solid, and Jokester compete in a race. You record the horses that win, place, and show (finish first, second, and third) in the race.</li>
<li>You and a friend each think of a whole number between 0 and 9.</li>
<li>On your computer, you have a playlist of 4 songs denoted by a, b, c, d. You play them in a random order.</li>
<li>Suppose a basketball player takes a “one-and-one” foul shot. (This means that he attempts one shot and if the first shot is successful, he gets to attempt a second shot.)</li>
</ol>
<ol start="13" style="list-style-type: decimal">
<li><strong>Writing Sample Spaces</strong></li>
</ol>
<p>For the following random experiments, give an appropriate sample space for the random experiment. You can use any method (a list, a tree diagram, a two-way table) to represent the possible outcomes.</p>
<ol style="list-style-type: lower-alpha">
<li>Your school plays four football games in a month.</li>
<li>You call a “random” household in your city and record the number of hours that the TV was on that day.</li>
<li>You talk to an Ohio resident who has recently received her college degree. How many years did she go to college?</li>
<li>The political party of our next elected U.S. President.</li>
<li>The age of our next President when he/she is inaugurated.</li>
<li>The year a human will next land on the moon.</li>
</ol>
<ol start="14" style="list-style-type: decimal">
<li><strong>Writing Sample Spaces</strong></li>
</ol>
<p>For the following random experiments, give an appropriate sample space for the random experiment. You can use any method (a list, a tree diagram, a two-way table) to represent the possible outcomes.</p>
<ol style="list-style-type: lower-alpha">
<li>The time you arrive at your first class on Monday that begins at 8:30 AM.</li>
<li>You throw a ball in the air and record how high it is thrown (in feet).</li>
<li>Your cost of textbooks next semester.</li>
<li>The number of children you will have.</li>
<li>You take a five question true/false test.</li>
<li>You drive on the major street in your town and pass through four traffic lights.</li>
</ol>
<ol start="15" style="list-style-type: decimal">
<li><strong>Probability Assignments</strong></li>
</ol>
<p>Give reasonable assignments of probabilities based on the given information.</p>
<ol style="list-style-type: lower-alpha">
<li>In the United States, there were 4058 thousand babies born in the year 2000 and 1980 thousand were girls. Assign probabilities to the possible genders of your next child.</li>
</ol>
<table>
<thead>
<tr class="header">
<th>Gender</th>
<th>Boy</th>
<th>Girl</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Probability</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: lower-alpha">
<li>Next year, your school will be playing your neighboring school in football. Your neighboring school is a strong favorite to win the game.</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="left">Winner of Game</th>
<th align="center">Your school</th>
<th align="center">Your neighboring school</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Probability</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<ol start="3" style="list-style-type: lower-alpha">
<li>You have an unusual die that shows 1 on two sides, 2 on two sides, and 3 and 4 on the remaining two sides.</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="left">Roll</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Probability</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<ol start="16" style="list-style-type: decimal">
<li><strong>Probability Assignments</strong></li>
</ol>
<p>Based on the given information, decide if the stated probabilities are reasonable. If they are not, explain how they should be changed.</p>
<ol style="list-style-type: lower-alpha">
<li>Suppose you play two games of chess with a chess master. You can either win 0 games, 1 game, or 2 games, so the probability of each outcome is equal to 1/3.</li>
<li>Suppose 10% of cars in a car show are Corvettes and you know that red is the most popular Corvette color. So the chance that a randomly chosen car is a red Corvette must be larger than 10%.</li>
<li>In a Florida community, you are told that 30% of the residents play golf, 20% play tennis, and 40% of the residents play golf and tennis.</li>
<li>Suppose you are told that 10% of the students in a particular class get A, 20% get B, 20% get C, and 20% get D. That means that 30% of the class must fail the class.</li>
</ol>
<ol start="17" style="list-style-type: decimal">
<li><strong>Finding the Right Key</strong></li>
</ol>
<p>Suppose your key chain has five keys, one of which will open up your front door of your apartment. One night, you randomly try keys until the right one is found.</p>
<p>Here are the possible numbers of keys you will try until you get the right one:</p>
<p>1 key, 2 keys, 3 keys, 4 keys, 5 keys</p>
<ol style="list-style-type: lower-alpha">
<li>Circle the outcome that you think is most likely to occur.</li>
</ol>
<p>1 key, 2 keys, 3 keys, 4 keys, 5 keys</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Circle the outcome that you think is least likely to occur.</li>
</ol>
<p>1 key, 2 keys, 3 keys, 4 keys, 5 keys</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Based on your answers to parts a and b, assign probabilities to the six possible outcomes.</li>
</ol>

<ol start="18" style="list-style-type: decimal">
<li><strong>Playing Roulette</strong></li>
</ol>
<p>One night in Reno, you play roulette five times. Each game you bet $5 – if you win, you win $10; otherwise, you lose your $5. You start the evening with $25. Here are the possible amounts of money you will have after playing the five games.</p>
<p>$0, $10, $20, $30, $40, $50 .</p>
<ol style="list-style-type: lower-alpha">
<li>Circle the outcome that you think is most likely to occur.</li>
</ol>
<p>$0, $10, $20, $30, $40, $50 .</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Circle the outcome that you think is least likely to occur.</li>
</ol>
<p>$0, $10, $20, $30, $40, $50 .</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Based on your answers to parts a and b, assign probabilities to the six possible outcomes.</li>
</ol>
<p><span>| lcccccc |</span> Outcome&amp; (0&amp;)10 &amp; (20 &amp;)30 &amp;(40 &amp;)50<br />
Probability&amp; &amp; &amp; &amp; &amp; &amp;</p>
<ol start="19" style="list-style-type: decimal">
<li><strong>Cost of Your Next Car</strong></li>
</ol>
<p>Consider the cost of the next new car you will purchase in the future. There are five possibilities:</p>
<ul>
<li>cheapest: the car will cost less than $5000</li>
<li>cheaper: the car will cost between $5000 and $10,000.</li>
<li>moderate: the car will cost between $10,000 and $20,000</li>
<li>expensive: the car will cost between $20,000 and $30,000</li>
<li>really expensive: the car will cost over $30,0000</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Circle the outcome that you think is most likely to occur.</li>
</ol>
<p>cheapest, cheaper, moderate, expensive, really expensive</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Circle the outcome that you think is least likely to occur.</li>
</ol>
<p>cheapest, cheaper, moderate, expensive, really expensive</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Based on your answers to parts a and b, assign probabilities to the five possible outcomes.</li>
</ol>

<ol start="20" style="list-style-type: decimal">
<li><strong>Flipping a Coin</strong></li>
</ol>
<p>Suppose you flip a coin twice. There are four possible outcomes (<span class="math inline">\(H\)</span> stands for heads and <span class="math inline">\(T\)</span> stands for tails).</p>
<p><span class="math inline">\(HH, HT, TH, TT\)</span></p>
<ol style="list-style-type: lower-alpha">
<li>Circle the outcome that you think is most likely to occur.</li>
</ol>
<p><span class="math inline">\(HH, HT, TH, TT\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Circle the outcome that you think is least likely to occur.</li>
</ol>
<p><span class="math inline">\(HH, HT, TH, TT\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Based on your answers to parts a and b, assign probabilities to the four possible outcomes.</li>
</ol>

<ol start="21" style="list-style-type: decimal">
<li><strong>Playing Songs in Your iPod</strong></li>
</ol>
<p>Suppose you play three songs by Jewell (J), Madonna (M), and Plumb (P) in a random order.</p>
<ol style="list-style-type: lower-alpha">
<li>Write down all possible ordering of the three songs.</li>
<li>Let <span class="math inline">\(M\)</span> = event that the Madonna song is played first and <span class="math inline">\(B\)</span> = event that the Madonna song is played before the Jewell song. Find <span class="math inline">\(P(M)\)</span> and <span class="math inline">\(P(B)\)</span>.</li>
<li>Write down the outcomes in the event <span class="math inline">\(M \cap B\)</span> and find the probability <span class="math inline">\(P(M \cap B )\)</span>.</li>
<li>By use of the complement property, find <span class="math inline">\(P(\bar B)\)</span>.</li>
<li>By use of the addition property, find <span class="math inline">\(P(M \cup B)\)</span>.</li>
</ol>
<ol start="22" style="list-style-type: decimal">
<li><strong>Student of the Day</strong></li>
</ol>
<p>Suppose that students at a local high school are distributed by grade level and gender.</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">Freshmen</th>
<th align="center">Sophomores</th>
<th align="center">Juniors</th>
<th align="center">Seniors</th>
<th align="center">TOTAL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Male</td>
<td align="center">25</td>
<td align="center">30</td>
<td align="center">24</td>
<td align="center">19</td>
<td align="center">98</td>
</tr>
<tr class="even">
<td align="left">Female</td>
<td align="center">20</td>
<td align="center">32</td>
<td align="center">28</td>
<td align="center">15</td>
<td align="center">95</td>
</tr>
<tr class="odd">
<td align="left">TOTAL</td>
<td align="center">45</td>
<td align="center">62</td>
<td align="center">52</td>
<td align="center">34</td>
<td align="center">193</td>
</tr>
</tbody>
</table>
<p>Table of grade level and
gender.</p>
<p>Suppose that a student is chosen at random from the school to be the “student of the day”. Let <span class="math inline">\(F\)</span> = event that student is a freshmen, <span class="math inline">\(J\)</span> = event that student is a junior, and <span class="math inline">\(M\)</span> = event that student is a male.</p>
<ol style="list-style-type: lower-alpha">
<li>Find the probability <span class="math inline">\(P(\bar F)\)</span>.</li>
<li>Are events <span class="math inline">\(F\)</span> and <span class="math inline">\(J\)</span> mutually exclusive. Why?</li>
<li>Find <span class="math inline">\(P(F \cup J)\)</span> .</li>
<li>Find <span class="math inline">\(P(F \cap M)\)</span>.</li>
<li>Find <span class="math inline">\(P(F \cup M)\)</span>.</li>
</ol>
<ol start="23" style="list-style-type: decimal">
<li><strong>Proving Properties of Probabilities</strong></li>
</ol>
<p>Given the three probability axioms and the properties already proved, prove the complement property <span class="math inline">\(P(\bar A) = 1 - P(A)\)</span>. An outline of the proof is written below.</p>
<ol style="list-style-type: lower-alpha">
<li>Write the sample space <span class="math inline">\(S\)</span> as the union of the sets <span class="math inline">\(A\)</span> and <span class="math inline">\(\bar A\)</span>.</li>
<li>Apply Axiom 3.</li>
<li>Apply Axiom 2.</li>
</ol>
<ol start="24" style="list-style-type: decimal">
<li><strong>Proving Properties of Probabilities</strong></li>
</ol>
<p>Given the three probability axioms and the properties already proved, prove the addition property <span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span>. A Venn diagram and an outline of the proof are written below.</p>
<p><img src="../LATEX/figures/chapter1/venn3.png" width="236" />
</p>
<ol style="list-style-type: lower-alpha">
<li>Write the set <span class="math inline">\(A \cup B\)</span> as the union of three sets that are mutually exclusive.</li>
<li>Apply Axiom 2 to write <span class="math inline">\(P(A \cup B)\)</span> as the sum of three terms.</li>
<li>Write the set <span class="math inline">\(A\)</span> as the union of two mutually exclusive sets.</li>
<li>Apply Axiom 2 to write <span class="math inline">\(P(A)\)</span> as the sum of two terms.</li>
<li>By writing the set <span class="math inline">\(B\)</span> as the union of two mutually exclusive sets and applying Axiom 2, write <span class="math inline">\(P(B)\)</span> as the sum of two terms.</li>
<li>By making appropriate substitutions to the expression in part b, one obtains the desired result.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="counting-methods.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-probability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
