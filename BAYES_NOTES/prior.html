<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.309">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Bayesian Inference - 6&nbsp; Prior Distributions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<link href="./many_parameters.html" rel="next">
<link href="./single_parameter.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link id="quarto-text-highlighting-styles" href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Prior Distributions</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Bayesian Inference</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayes_rule.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes Rule</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./proportion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Learning About a Proportion</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./single_parameter.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Single Parameter Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prior.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Prior Distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./many_parameters.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Many Parameter Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayes_computation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Bayesian Computation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mcmc.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Markov Chain Monte Carlo</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hierarchical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Hierarchical Modeling</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model_selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Bayesian Testing and Model Selection</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#informative-prior" id="toc-informative-prior" class="nav-link active" data-scroll-target="#informative-prior"> <span class="header-section-number">6.1</span> Informative Prior</a>
  <ul class="collapse">
  <li><a href="#specifying-a-beta-prior" id="toc-specifying-a-beta-prior" class="nav-link" data-scroll-target="#specifying-a-beta-prior"> <span class="header-section-number">6.1.1</span> Specifying a Beta Prior</a></li>
  <li><a href="#predictive-assessment" id="toc-predictive-assessment" class="nav-link" data-scroll-target="#predictive-assessment"> <span class="header-section-number">6.1.2</span> Predictive Assessment</a></li>
  </ul></li>
  <li><a href="#noninformative-prior" id="toc-noninformative-prior" class="nav-link" data-scroll-target="#noninformative-prior"> <span class="header-section-number">6.2</span> Noninformative Prior</a>
  <ul class="collapse">
  <li><a href="#uniform-prior" id="toc-uniform-prior" class="nav-link" data-scroll-target="#uniform-prior"> <span class="header-section-number">6.2.1</span> Uniform prior</a></li>
  <li><a href="#improper-prior" id="toc-improper-prior" class="nav-link" data-scroll-target="#improper-prior"> <span class="header-section-number">6.2.2</span> Improper prior</a></li>
  <li><a href="#jeffreys-prior" id="toc-jeffreys-prior" class="nav-link" data-scroll-target="#jeffreys-prior"> <span class="header-section-number">6.2.3</span> Jeffreys prior</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Prior Distributions</span></h1>
</div>





<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="informative-prior" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="informative-prior"><span class="header-section-number">6.1</span> Informative Prior</h2>
<section id="specifying-a-beta-prior" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="specifying-a-beta-prior"><span class="header-section-number">6.1.1</span> Specifying a Beta Prior</h3>
<p>In a Bayesian analysis, one needs to specify a density <span class="math inline">\(g(\theta)\)</span> that reflects one’s prior beliefs about the location of the parameter <span class="math inline">\(\theta\)</span>. The problem is that one typically has only knowledge about a typical value of <span class="math inline">\(\theta\)</span> and some information about the sureness of this guess. The question is: “How can one construct a prior density that represents this imprecise prior information?”</p>
<p>In this section, we will talk about constructing a prior for a proportion, although the discussion will extend to any single parameter.</p>
<p>To use a concrete example, suppose I’m interested in the proportion of students <span class="math inline">\(p\)</span> at my university who send or receive text messages while driving. I wish to construct a prior for <span class="math inline">\(p\)</span> that reflects my beliefs about the size of this proportion.</p>
<p>A standard approach for constructing a prior assumes that <span class="math inline">\(p\)</span> has density that is a member of a familiar functional form, and one chooses the parameters of the density that match one’s beliefs. For a proportion, the usual choice for density is a beta curve with parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. This simplifies the prior assessment task considerably. Instead of constructing an entire density function, one needs only to assess two parameter values. The implicit assumption is that the beta family of distributions is sufficiently flexible to represent different beliefs about the proportion value.</p>
<p>To choose the parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, one matches these parameter values with statements about the location and spread of the density. We typically measure location by the mean and spread by the standard deviation – these moments have simple expressions for the beta family: <span class="math display">\[
E(p) = \frac{a}{a+b}, \, \, SD(p) = \sqrt{\frac{a b}{(a+b)^2 (a + b + 1)}}.
\]</span> One can guess at the mean and standard deviation of <span class="math inline">\(p\)</span>, then use the expressions to find values of the matching parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
<p>Unfortunately, there are problems using this method. It is generally hard to specify a mean and standard deviation of a parameter. The moments of a prior can be significantly affected by the tails of the distribution, but one typically has little information about the tail portion of the prior. It is typically easier to state beliefs about location and spread in terms of percentiles of the distribution.</p>
<p>In our example, it seems easy to first think about the median of my prior. I think of a value <span class="math inline">\(p_{0.5}\)</span>, such that the proportion of text-messaging drivers is equally likely to be smaller or larger than that value. After some reflection, I decide that <span class="math inline">\(p_{0.5}\)</span> = 0.10. Next, I express my belief about spread by thinking about a second percentile, say the 90th. I specify a proportion value <span class="math inline">\(p_{0.9}\)</span> such that it is unlikely (with 10% probability) that <span class="math inline">\(p\)</span> will larger than that value. This is a harder value to specify. After some thought, I decide on <span class="math inline">\(p_{0.9}\)</span> = 0.25. I then match these two percentiles with a beta curve. Using the {} function, I find that the beta curve with <span class="math inline">\(a = 1.41\)</span> and <span class="math inline">\(b = 10.15\)</span> match my beliefs.</p>
<p>Is the beta(1.41, 10.15) density a good representation of my prior beliefs? To check, one can assesses other percentiles of the prior and see if they match up with the beta density. In our example, suppose that I also believe that the 10th percentile of my prior is <span class="math inline">\(p_{0.1} = 0.05.\)</span>. Since the 10th percentile of the beta(1.41, 10.15) prior is 0.024, there is some incompatability of my prior information with the fitted beta curve. By several of these checks, I can adjust the values of the beta shape parameters so it seems to be a better representation of my beliefs.</p>
</section>
<section id="predictive-assessment" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="predictive-assessment"><span class="header-section-number">6.1.2</span> Predictive Assessment</h3>
<p>One difficulty in specifying a prior is that the parameter <span class="math inline">\(p\)</span> is relatively abstract. In this example, <span class="math inline">\(p\)</span> represents the proportion of {} students at my university who text while driving. It may be easier to think about the proportion of a {} of students who are texting.</p>
<p>Suppose you have a random sample of <span class="math inline">\(n = 20\)</span> students. Assuming a beta(<span class="math inline">\(a, b\)</span>) prior, the number <span class="math inline">\(y\)</span> of students who text while driving has a beta-binomial predictive distribution of the form <span class="math display">\[\begin{eqnarray*}
f(y | a, b) = \int_0^1 {n \choose y} p^y (1-p)^{n-y} \frac{1}{B(a, b)} p^{a-1} (1-p)^{b-1} dp
\nonumber \\
   =  {n \choose y} \frac{B(a+y, b+n-y)}{B(a, b)}, \, \, y = 0, ..., n \nonumber \\
\end{eqnarray*}\]</span></p>
<p>Suppose our initial assessment for <span class="math inline">\(p\)</span> resulted in a beta(1.41, 10.15) prior. Using the beta-binomial distribution, we can use this prior to predict the number of text message students in the sample of <span class="math inline">\(n = 20\)</span> students. By using the function {} in the LearnBayes package, we find that that <span class="math inline">\(P(y \le 4)= 0.827\)</span> and <span class="math inline">\(P(y \le 5)= 0.934\)</span>. If those probabilities don’t reflect your beliefs about the plausibility of the events <span class="math inline">\(y \le 4\)</span> and <span class="math inline">\(y \le 5\)</span>, then some adjustment needs to be made to the values of the beta shape parameters.</p>
</section>
</section>
<section id="noninformative-prior" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="noninformative-prior"><span class="header-section-number">6.2</span> Noninformative Prior</h2>
<section id="uniform-prior" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="uniform-prior"><span class="header-section-number">6.2.1</span> Uniform prior</h3>
<p>In the event that little or no information exists about a parameter, then one can assign a vague or noninformative prior. When Thomas Bayes wrote his famous Bayesian paper, he placed a uniform prior on an unknown proportion. This certainly seems like a reasonable choice since this reflects the belief that any subset of <span class="math inline">\(p\)</span> of the same length has the same probability.</p>
<p>Suppose instead of the proportion <span class="math inline">\(p\)</span>, we focus on the parameter <span class="math inline">\(p^2\)</span> that in our example represents the probability (conditional on <span class="math inline">\(p\)</span>) that two consecutive sampled students text while driving. Since <span class="math inline">\(p^2\)</span> is an unknown parameter on the unit interval, it certainly is reasonable to assign <span class="math inline">\(p^2\)</span> a uniform prior. But if <span class="math inline">\(p\)</span> has a uniform prior, it is straightforward to show using a transformation argument that <span class="math inline">\(\theta = p^2\)</span> has the density <span class="math display">\[
g(\theta) = \frac{1}{2 \sqrt{\theta}}, \, \, 0 &lt; \theta &lt; 1.
\]</span> So if the proportion has a uniform prior, then the proportion squared has a nonuniform prior that favors values of <span class="math inline">\(p^2\)</span> near zero.</p>
<p>A uniform prior is not transformation invariant. This means that the belief in uniformity of a parameter will change under a nonlinear transformation. Since it is unclear which parameter (in our example, <span class="math inline">\(p\)</span> or <span class="math inline">\(p^2\)</span>) should be uniform, this notion of uniformity will not lead to a unique choice of prior.</p>
</section>
<section id="improper-prior" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="improper-prior"><span class="header-section-number">6.2.2</span> Improper prior</h3>
<p>Sometimes improper priors, that is, prior densities that don’t integrate to one, will be chosen as noninformative priors. These type of priors can seem appropriate for use in particular applications. However, their use should be made with some caution, since the choice of an improper prior may lead to an improper posterior distribution.</p>
<p>Consider again the family of beta<span class="math inline">\((a, b)\)</span> priors for the proportion <span class="math inline">\(p\)</span>. The parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> can be viewed as the respective number of successes and number of failures in a preliminary experiment. The total amount of information in the experiment is measured by the “preliminary sample size” <span class="math inline">\(a+ b\)</span>. If we have little information about the proportion, it is reasonable to let both <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> approach zero, resulting in the improper prior <span class="math display">\[
g(p) \propto \frac{1}{p(1-p)}, \, \, 0 &lt; p &lt; 1.
\]</span> The corresponding posterior density, given <span class="math inline">\(y\)</span> successes in <span class="math inline">\(n\)</span> trials, is equal to <span class="math display">\[
g(p | y) \propto p^{y-1} (1-p)^{n-y-1} .
\]</span> This will be a proper posterior density only if the number of successes is in the interval from 1 to <span class="math inline">\(n-1\)</span>. If one observes no successes (<span class="math inline">\(y = 0\)</span>) or all failures (<span class="math inline">\(y = n\)</span>), the posterior density will be improper.</p>
<p>In the binomial situation, it is best to avoid these awkward situations and use a prior where both <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are positive. In the next section, we will derive one type of “optimal” prior which does not result in an improper posterior.</p>
</section>
<section id="jeffreys-prior" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3" class="anchored" data-anchor-id="jeffreys-prior"><span class="header-section-number">6.2.3</span> Jeffreys prior</h3>
<p>One popular way of defining a noninformative prior was suggested by Harold Jeffreys. To define this prior, we review the concept of information. If a single observation <span class="math inline">\(y\)</span> has a sampling density <span class="math inline">\(f(y | \theta)\)</span>, then we define the Fisher information as <span class="math display">\[
I(\theta) = - E\left[ \frac{\partial^2}{\partial \theta^2} \log f(y | \theta) \right],
\]</span> where the expectation is taken over the distribution of <span class="math inline">\(y\)</span>. As an example, suppose the binary observation <span class="math inline">\(y\)</span> has the density <span class="math display">\[
f(y | p) = p^y (1-p)^{1-y}, y = 0, 1.
\]</span> An easy calculation shows that the information is given by <span class="math display">\[
I(p) = \frac{1}{p(1-p)}.
\]</span> If we have independent observations <span class="math inline">\(y_1, ..., y_n\)</span> from <span class="math inline">\(f(y|\theta)\)</span> and <span class="math inline">\(I^*\)</span> denotes the information, then it can be shown that <span class="math inline">\(I^*(\theta) = n I(\theta)\)</span>, where <span class="math inline">\(I\)</span> is the information for a single observation. Applying this result, if we have a sample of Bernoulli(<span class="math inline">\(p\)</span>) observations <span class="math inline">\(y_1, ..., y_n\)</span>, then the information based on this sample is <span class="math display">\[
I(p) =  \frac{n}{p(1-p)}.
\]</span></p>
<p>Jeffreys suggests that a suitable noninformative prior is the square root of the information <span class="math display">\[
g(\theta) = \sqrt{I(\theta)}.
\]</span> The reasoning for this prior is based on the fact that this prior is invariant under transformation. Suppose <span class="math inline">\(\theta\)</span> is assigned this prior and one transforms <span class="math inline">\(\theta\)</span> to a new parameter <span class="math inline">\(\eta = h(\theta)\)</span>. Then one can show that the prior on <span class="math inline">\(\eta\)</span> is given by the same functional form <span class="math display">\[
g_1(\eta) = \sqrt{I(\eta)}.
\]</span></p>
<p>In the Bernoulli case, we have already shown that the information <span class="math inline">\(I(p) = 1/(p(1-p))\)</span>. So the Jeffreys prior is given by <span class="math display">\[
g(p) = \sqrt{I(p)} = \frac{1}{\sqrt{p(1-p)}} = p^{1/2-1} (1-p)^{1/2-1}.
\]</span></p>
<p>At this point, we have talked about three possible priors for a proportion that are all special or limiting cases of a beta density. The choice <span class="math inline">\(a = b = 1\)</span> leads to the uniform prior used by Bayes, <span class="math inline">\(a = b = 1/2\)</span> leads to the Jeffreys prior, and the limiting case where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> approach zero results in the improper prior proportional to <span class="math inline">\((p(1-p))^{-1}\)</span>.</p>


</section>
</section>

</main> <!-- /main -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./single_parameter.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Single Parameter Inference</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./many_parameters.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Many Parameter Inference</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>