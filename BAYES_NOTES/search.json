[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Bayesian Inference",
    "section": "",
    "text": "Statistics, the science of learning from data, is a relatively new discipline. One can divide the history of Statistics into three periods using the years 1900 and 1960.\n\nIn the early days of Statistics (before 1900), much of the statistical work was devoted to data analysis including the construction of graphical displays. There was little work done on inferential statistics. The foundations of Bayesian inference had been developed by Bayes and Laplace in the 18th century.\nThe foundations of statistical inference were developed in the period between 1900 and 1970. Karl Pearson developed the chi-square goodness of fit procedure around the year 1900 and R. A. Fisher developed the notions of sufficiency and maximum likelihood in this period. Statistical procedures are evaluated in terms of their long-run behavior in repeated sampling. For this reason, these procedures are known as frequentist methods. Properties such as unbiasedness and mean square error are used to evaluate procedures. Some prominent Bayesians such as Harold Jeffreys, Jimmie Savage, and I. J. Good made substantial contributions during this period, but the frequentist methods became the standard inferential methods in the statistician’s toolkit.\nIn the last 40 years, there has been a great development in new statistical methods, especially computational demanding methods such as the bootstrap and nonparametric smoothing. Due to the recent availability of high-speed computers together with new simulation-based fitted algorithms, Bayesian methods have become increasingly popular. In contrast to the middle period of statistics where frequentist methods were dominate, we currently live in a frequentist/Bayesian world where statisticians routinely use Bayesian methods in situations where this inferential perspective has particular advantages.\n\n\n\n\nOne fundamental inference problem is learning about the association pattern in a 2 by 2 contingency table. Suppose we sample data values that are categorized with respect to the presence and absence of two variables \\(A\\) and \\(B\\) and one observes the following table of counts.\n\n\n\n\nVar B\n\n\n\n\n\nVar A\nyes\nno\n\n\nyes\n\\(a\\)\n\\(b\\)\n\n\nno\n\\(c\\)\n\\(d\\)\n\n\n\nThere are two common questions that one is interested in answering. First, is there a significant association structure in the table? Second, if variables \\(A\\) and \\(B\\) are indeed dependent, one is interested in estimating the strength of the association.\nAs an example, suppose one observes the following table counts.\n\n\n\n\nVar B\n\n\n\n\n\nVar A\nyes\nno\n\n\nyes\n\\(10\\)\n\\(0\\)\n\n\nno\n\\(2\\)\n\\(5\\)\n\n\n\nOne constructs a statistical test of the hypothesis of independence to see if there is significant association in the table. The standard test of independence is based on the Pearson’s chi-squared test. One implements this testing procedure on R by the function chisq.test() and one observes the following output for these data.\n\ncounts <- matrix(c(10, 2, 0, 5), 2, 2)\nchisq.test(counts)\n\nWarning in chisq.test(counts): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  counts\nX-squared = 6.971, df = 1, p-value = 0.008284\n\n\nWe note that the p-value of the test statistic is 0.008284 which indicates that there is significant evidence that the two variables are dependent. But we see a warning in the output saying that the accuracy of this p-value computation is in doubt.\nWhat is going wrong? The chi-squared test is based on the test statistic \\[\nX = \\sum \\frac{(o - e)^2}{e},\n\\] where \\(o\\) and \\(e\\) represent, respectively, the observed cell count and estimated expected cell count under the independence assumption. Asymptotically, under the assumption of independence, \\(X\\) has a chi-squared distribution with one degree of freedom. The displayed p-value is the tail probability of a chi-square(1) random variable. When the cell counts are large, the distribution of \\(X\\) is approximately chi-square. But, when the counts are small (as in this example), the distribution of \\(X\\) may not be approximately chi-square(1) and so the accuracy of the p-value calculation is in doubt.\nWhat can one do in this situation? A standard alternative test procedure is Fisher’s exact test where the p-value is computed based on the hypergeometric distribution. If one implements this test using the R function fisher.test(), one sees the following output.\n\ncounts <- matrix(c(10, 2, 0, 5), 2, 2)\nfisher.test(counts)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  counts\np-value = 0.003394\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 2.164093      Inf\nsample estimates:\nodds ratio \n       Inf \n\n\nOne obtains a new p-value of 0.003394 which is significantly different from the ``large sample” p-value of 0.008284, indicating that the accuracy of the chi-square approximation was relatively poor. But this analysis raises new questions.\n\nWhat sampling model?\n\nThere are different sampling models that can produce the observed table counts. For example, one may be taking a single random sample of a particular size and classifying each observation with respect to the two variables – this is the multinomial sampling model. Alternatively, one may be taking two independent samples; the “A-sample” is classified with respect to variable B, and a second “not A-sample” is also classified with respect to variable B – this is the product of binomials sampling model. Or perhaps one assumes that the observed margins of the table are fixed and the only random quantity is the one count in the top left of the table – this gives rise to the hypergeometric distribution under independence that is the basis for Fisher’s exact test.\n\nDoes the choice of sampling model matter?\n\nIf one is unsure about the sampling method that produces the table, one might hope that the test of significance is insensitive to the choice of sampling model. But this is not the case. The p-value is dependent on the choice of model. Actually, there is a debate among frequentists on the “proper” choice of sampling model in the test of independence.\n\nWhat about estimating the association?\n\nIn this example, since the test of independence seems to be clearly rejected, the focus should be on the estimation of the association. A standard measure of association in a two by two table is the odds ratio defined by \\[\n\\alpha = \\frac{p_{11} p_{22}}{p_{12} p_{21}},\n\\] where (assuming a multinomial sampling model) \\(p_{ij}\\) is the probability of an observation in the \\(i\\)th row and \\(j\\)th column of the table. The maximum likelihood estimate of \\(\\alpha\\) is given by \\[\n\\hat \\alpha = \\frac{a d}{b c}.\n\\] For these data, we observe \\(a = 10\\), \\(b = 0\\), \\(c = 2\\) and \\(d = 5\\), resulting in an infinite estimate for \\(\\alpha\\). This is indicated by the fisher.exact() output. Also the standard (asymptotic) 95% confidence interval for \\(\\alpha\\) for these data is given by (2.164093, \\(\\infty)\\). We see that the observed zero count has made it difficult to get reasonable point and interval estimates of the odds ratio.\nIn this problem, we see some pitfalls in applying frequentist testing methods for this simple problem. Since there are small counts, standard methods relying on asymptotic approximations seem unsuitable. But the computation of an “exact” p-value is also unclear in this situation, since this computation relies on the sampling distribution which may be unknown.\nFrequentist methods also perform poorly for the estimation problem since the infinite estimate of \\(\\alpha\\) is not reasonable. If one thinks about the cell probabilities, then one would think that all of these probabilities would be positive, resulting in a finite value of the odds-ratio. But there are no ways to include these ``prior beliefs” that the probabilities are positive in the estimation problem. A standard ad-hoc solution to this problem is to add a fake count of 1/2 to each cell count, and estimate alpha by computing the maximum likelihood estimate on these adjusted counts: \\[\n\\hat \\alpha = \\frac{(a+1/2) (d+1/2)}{(b+1/2) (c+1/2)}.\n\\] But it is not obvious that 1/2 is the correct choice of fake count to get a “best” estimate of the odds ratio.\n\n\n\nThe previous example illustrates some of the problems in applying frequentist inferential methods and so it desirable to consider the alternative Bayesian paradigm for inference. Here is a short list of some positive and negative aspects of the frequentist and Bayesian approaches to inference.\nPositive Aspects of Frequentist Inference:\n\nThere are a number of good methods such as maximum likelihood and most powerful tests and good criteria for evaluating procedures such as unbiased and mean square error.\nThese methods are automatic to apply and have wide applicability.\nOne is generally interested in evaluating procedures by their performance in repeated sampling.\n\nNegative Aspects of Frequentist Inference:\n\nThere is no general method for inference. One has to be clever to devise good statistical procedures in situations where standard methods fail.\nFrequentist methods can perform poorly. For example, frequentist methods do not perform well for sparse contingency tables with one or more observed zeros.\nOne is unable to incorporate prior knowledge into the inference.\n\nPositive Aspects of Bayesian Inference:\n\nOne has one recipe (Bayes’ rule) for statistical inference.\nOne can formally incorporate prior information into the analysis.\nNuisance parameters are easily handled in a Bayesian analysis.\n\nNegative Aspects of Bayesian Inference:\n\nBayesian thinking requires more thought with the introduction of a prior distribution.\nFrom a calculation perspective, it can be difficult to implement Bayesian methods, although powerful computational tools exist."
  },
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "2  Probability",
    "section": "",
    "text": "Bayesian thinking is based on the subjective viewpoint of probability. In this chapter, we will talk about the different ways of thinking about probability."
  },
  {
    "objectID": "probability.html#measuring-uncertainty",
    "href": "probability.html#measuring-uncertainty",
    "title": "2  Probability",
    "section": "2.2 Measuring Uncertainty",
    "text": "2.2 Measuring Uncertainty\nWe live in a world of uncertain events and some events are more likely to occur than other events. Words such as “likely”, “probable”, “possible”, “rare”, and “maybe” are used to describe this uncertainty. It is natural to use numbers that we call probabilities to quantify this uncertainty. The probability of an event \\(A\\), denoted \\(P(A)\\), is a number between 0 and 1 assigned to the event \\(A\\) where a larger number indicates that the event is more likely to occur.\nSome uncertain events already have numbers assigned to them. In games of chance where dice are rolled or cards are dealt from a well-shuffled deck, outcomes have particular probabilities. For example, the chance of rolling two dice equal to double-sixes is 1/36 and the chance of dealing a four of diamonds in a regular deck is 1/52. In actuarial tables, there are assigned probabilities that a person’s life span will be a particular length based on one’s gender and age. These actuarial tables are used by insurance companies to write up a life insurance policy and decide on the cost of the policy to the customer.\nThere are two ways of viewing probabilities that allow us to assign probabilities in games of chance and actuarial tables. The classical or “equally-likely” probability view assumes that one can represent the outcomes of a random experiment in such a way such that the outcomes are equally likely. Then each outcome is assigned a probability equal to one divided by the total number of outcomes. In the dice example, there are 36 equally likely ways of representing the possible rolls of the dice, and the probability of one outcome (two sixes) is equal 1/36. In the card example, there are 52 possible draws in a deck of cards, and if the deck is well-shuffled, each outcome such as “four of diamonds” is assigned the probability of 1/52.\nA second way of thinking about probabilities is based on long-run relative frequencies. Suppose you are able to repeat a random experiment many times under similar conditions. Then the probability of an event is approximated by its relative frequency in the large number of trials. This viewpoint can be applied in games of chance. For example, the probability that the sum of two dice is equal to 7 can be approximated by the relative frequency of 7 in many rolls of the two dice. This definition can also be used for actuarial tables. The chance that a male of age 70 will survive ten years can be approximated by the relative frequency of 70-year old males who survive ten years.\nIs it possible use the relative frequency viewpoint to measure uncertainty for all random events? Lindley makes a distinction between two types of events. Statistical events are the events that can be repeated under similar conditions and non-statistical events are events that are essentially unique and can not be repeated. Games of chance are statistical events, while one-time events such as “Jones committed the murder” or “a Republican will be the next American president” are non-statistical events. One can use the relative frequency perspective to measure the probability of statistical events, but this viewpoint is clearly inappropriate in measuring the chance of non-statistical events. Also there are issues in applying the relative frequency viewpoint. Sometimes it is not clear how to repeat a random experiment under similar circumstances. For example, suppose one observes three flips of a coin with the first head on the third flip. How does one repeat this experiment. Does one consider sets of three flips, or instead consider flips that end with the first head?"
  },
  {
    "objectID": "probability.html#the-subjective-viewpoint",
    "href": "probability.html#the-subjective-viewpoint",
    "title": "2  Probability",
    "section": "2.3 The Subjective Viewpoint",
    "text": "2.3 The Subjective Viewpoint\nThere is a third viewpoint of probability, the subjective viewpoint, that is the basis for Bayesian thinking. We start with a proposition which is any statement that can be true or false. For example, consider the proposition “it will rain tomorrow.” A person’s belief in the truth in this proposition can vary; the person may believe it is certainly false or she may believe it is certainly true. A probability represents a number attached to the proposition “it will rain tomorrow” that reflects this belief. A probability of 1 means that the person believes the proposition is true, and a probability of 0 means that the person believes with certainty that the proposition is false. A probability of 0.5 means that the person believes that the propositions “rain tomorrow” and “no rain tomorrow” are equally likely.\nIn the above definition, it should be noted that we are assigning numerical measures to propositions, which are more general than events. A proposition is any statement that is either true or false. Both statistical events and non-statistical events are examples of propositions. Second, an assigned probability is personal in that it reflects one person’s belief about the truth of the proposition. Different people may assign different probabilities to a given proposition. Certainly if we consider the proposition “Susie is receiving a final grade of A in her statistics class”, Susie and her instructor may have different beliefs about the truth in this proposition. Also a person’s probabilities about a proposition may change over time. As she obtains more information, her belief and therefore her probabilities can change. In our example, as Suzie receives exam grades, she will have different information and therefore possibly different beliefs in the proposition that she will get a final grade of A.\nTo summarize, from the subjective viewpoint, a probability is a numerical measure of the degree of belief by a person in a proposition based on the person’s current information. If \\(E\\) is a proposition and \\(H\\) is the current information or history of the individual, then we represent a probability by the notation \\(P(E | H)\\)."
  },
  {
    "objectID": "probability.html#measuring-subjective-probabilities",
    "href": "probability.html#measuring-subjective-probabilities",
    "title": "2  Probability",
    "section": "2.4 Measuring Subjective Probabilities",
    "text": "2.4 Measuring Subjective Probabilities\nAt this point, all we know about a subjective probability \\(P(E|H)\\) is that it falls between the values of 0 and 1 and larger values correspond to stronger beliefs in the truth in the proposition. Since subjective probabilities are generally difficult to assess, it is appropriate to describe some measurement methods.\nThe direct measurement approach takes a measurement of an object by comparing it with a collection of reference objects. To learn about the length of a piece of string, a direct measurement method uses a ruler, and a direct measurement way of learning about the weight of an object places it on a scale. To directly measure probabilities, we need to consider a set of propositions where the probabilities are known.\nConsider the following “balls in bag” experiment. We have a bag with \\(r\\) red and \\(w\\) white balls and one ball is chosen from the bag. Let \\(R(r, w)\\) denote the proposition that the chosen ball is red. We assume that the balls are all identical in appearance except color, the bag is mixed well, and one makes the draw blindfold. Then we would agree that the probability of \\(R(r, w)\\) is equal to the fraction \\(r/(r+w)\\). Consider the set of reference propositions \\(R(0, 1), R(1, 0), R(1, 1), ...\"\\). The reference probabilities \\(r/(r+w)\\) cover all rational values between 0 and 1.\nTo use these reference propositions to measure your probability \\(P(E | H)\\), you compare the proposition \\(E\\) with the reference propositions {\\(R(r, w)\\)}. Suppose you have a stronger belief in the truth of \\(E\\) than \\(R(r, w)\\). This implies that your probability \\(P(E | H)\\) exceeds the fraction \\(r/(r+w)\\). By making a sequence of comparisons of \\(E\\) with \\(R(r, w)\\) for different choices of \\((r, w)\\), one can in theory get an accurate assessment of your probability \\(P(E | H)\\).\nI am a Phillies fan and I wish to assess my probability of the event \\(A =\\)“the Phillies will be in the World Series” this season. To using this direct approach of assessment, I make the following comparisons.\n\nI first compare “Phillies in the World Series” with the event \\(R(1, 1)\\), choosing a red out of a bowl with one red ball and one white ball. I believe \\(R(1, 1)\\) is more likely, so my probability of \\(A\\), \\(P(A) < 1/2\\).\nNext, I compare the event \\(A\\) with the event \\(R(1, 3)\\), choosing a red out of a bowl with one red and three white balls. I believe that \\(R(1, 3)\\) is more likely, so \\(P(A) < 1/4\\).\nI continue with comparing \\(A\\) with \\(R(1, 7)\\), choosing a red out of a bowl with one red and seven white balls. I believe that the Phillies in the World Series is more likely. So \\(P(A) > 1/8\\) and combining my comparisons, I now know that \\(P(A)\\) is in the interval \\((1/8, 1/4)\\).\nI continue with these assessments until it is difficult to make further comparisons. I will have a small interval that I believes contains my probability of the event.\n\nOther measurements are taken in an indirect manner. For example, one older style of thermometer is constructed by the use of mercury in a glass tube. Heat applied to the glass causes the mercury to expand and one measures the temperature by reading the location of the mercury on a printed numerical scale. For this type of thermometer, one indirectly measures temperature by use of the expansion and contraction of mercury. In a similar fashion, one can measure probabilities by means of bets that are indirectly related to probabilities.\nA bet consists of a proposition that determines the outcome of the bet, odds that are offered by the bookmaker, and the amount of money that you are willing to stake. If you decide to stake $\\(s\\) on the proposition \\(E\\) at odds \\(z\\), this means that\n\nif \\(E\\) is false, you will give the bookmaker $\\(s\\)\nif \\(E\\) is true, the bookmaker gives you $ \\(z s\\)\n\nThe stake is the amount that you can lose if the proposition \\(E\\) is false and the odds is the ratio of the amount you can win if \\(E\\) is true to the amount you lose if \\(E\\) is false.\nUsing this indirect method, one measures your probability \\(P(E | H)\\) by means of bets on \\(E\\) between you and a hypothetical bookmaker. One can fix a value of the stake, say \\(s = \\$5\\) and bet on \\(E\\) using different values of the odds \\(z\\). You decide which bets to accept and reject.\nHow can one obtain one’s probability on the basis of these bets? First, note that you will accept any bet if the odds \\(z\\) is sufficiently large. But as the odds \\(z\\) is decreased, one will be less inclined to accept the bet, and for small values of odds, you will reject the bet. There will be one odds value \\(z_0\\) where you will accept bets for odds \\(z > z_0\\), and reject bets for \\(z , z_0\\). The value \\(z_0\\) is often called the {} of the proposition \\(E\\) based on your current information, denoted by \\(O(E | H)\\). We transform odds to a probability by the expression \\[\nP(E | H) = \\frac{1}{1+O(E|H)}.\n\\]\nLet us illustrate this indirect method of measuring probability for assessing my probability of the event \\(A\\) that the Phillies are in the World Series. I decide on using the stake $5 and consider the following bets:\n\nBET 1: At odds \\(z = 1\\), I will either lose $5 if \\(A\\) is false or win $5 if \\(A\\) is true.\nBET 2: At odds \\(z = 2\\), I will either lose $5 if \\(A\\) is false or win $10 if \\(A\\) is true.\nBET 3: At odds \\(z = 4\\), I will either lose $5 if \\(A\\) is false or win $20 if \\(A\\) is true.\nBET 4: At odds \\(z = 10\\), I will either lose $5 if \\(A\\) is false or win $50 if \\(A\\) is true.\n\nI will definitely not accept Bets 1 or 2 (the winning amounts are too small), and would accept Bet 4 which seems to have a generous odds. After some thought, suppose I am satisfied with a bet between Bet 3 and Bet 4 where the odds are \\(z = 7\\). Then my fair odds would be \\(O(A | H) = 7\\) and my probability of “Phillies in the World Series” would be \\[\nP(A | H) = \\frac{1}{1+7} = 0.125.\n\\]"
  },
  {
    "objectID": "probability.html#true-and-measured-probabilities",
    "href": "probability.html#true-and-measured-probabilities",
    "title": "2  Probability",
    "section": "2.5 True and Measured Probabilities",
    "text": "2.5 True and Measured Probabilities\nWe have discussed two methods, a direct method and an indirect method, for measuring the subjective probability of a proposition. Generally people will have trouble applying these methods since they have little experience in specifying probabilities. So in a typical application, one will not be able to specify his/her probability with high accuracy. Here it is helpful to distinguish a person’s true probability and her measured probability. A person’s true probability is the value she would obtain if she were able to make very fine comparisons in the likelihoods of events and had an infinite amount of time to make the assessment. But in real life, the person is unable to make fine comparisons and will spend only a finite amount of time on this task. So the specified probability \\(P(E | H)\\) is simply a measured estimate at the true probability. Since our measuring methods, such as the balls in bag experiment, are relatively crude, there can be significant measurement error in the specification of this probability."
  },
  {
    "objectID": "bayes_rule.html",
    "href": "bayes_rule.html",
    "title": "3  Bayes Rule",
    "section": "",
    "text": "Here is a basic exposition of Bayes rule. Suppose you have events \\(E_1, ..., E_k\\) that form a partition of the sample space.\n\n\\(P(E_i), i = 1, ..., k\\)\n\\(P(A | E_i), i = 1, ..., k\\)\n\nOne is interested in computing the probabilities \\(P(E_i | A), i = 1, ..., k\\). By a standard manipulation of conditional probabilities, one obtains the result:\n\\[\nP(E_i | A) = \\frac{P(E_i) P(A | E_i)} {\\sum_{j=1}^k P(E_j) P(A | E_j)} .\n\\]"
  },
  {
    "objectID": "bayes_rule.html#illustrations-of-bayes-rule",
    "href": "bayes_rule.html#illustrations-of-bayes-rule",
    "title": "3  Bayes Rule",
    "section": "3.2 Illustrations of Bayes’ Rule",
    "text": "3.2 Illustrations of Bayes’ Rule\n\n3.2.1 Example: Student Takes a Test\nSuppose a student is taking a one-question multiple choice test with four possible choices. Either the student knows the material or she doesn’t; denote these two possibilities by \\(K\\) and “not \\(K\\)”. Based on previous work, the teacher decides the student likely knows the material and so assigns \\(P(K) = 0.7\\). Therefore, the probability the student doesn’t know the material is \\(P({\\rm not} \\, K) = 1 - 0.7 = 0.3.\\) The student will take the one-question test and either she will get it correct, which we denote by \\(C\\). If the student knows the material, then the chance she will get the question correct is 90%. On the other hand, if the student doesn’t know the material, then we will guess and obtain the correct answer with probability 25%. Suppose the student takes the test and gets the question correct – what is the probability she really knows the material?\nHere the events \\(K\\) and “not \\(K\\)” form a partition of the sample space and we are given the probabilities of these two events. The probability the student gets the question correct depends on whether she knows the material – we are given that\n\\[\nP(C | K) = 0.9, \\, P(C | {\\rm not} , K) = 0.25.\n\\]\nGiven that the student gets the question correct, we’re interested in determining the probability of \\(K\\); that is, we wish to compute \\(P(K | C)\\). By Bayes’ rule, this is given by\n\\[\nP(K | C) = \\frac{P(K) P(C | K)} {P(K) P(C | K) + P({\\rm not} , K) P(C | {\\rm not} , K)}.\n\\]\nSubstituting in the given values, we obtain\n\\[\nP(K | C) = \\frac{0.7 \\times 0.9} {0.7 \\times 0.9 + 0.3 \\times 0.25} = \\frac{0.63}{0.63+0.075} = 0.894 .\n\\]\nDoes this answer make sense? Before the test, the teacher believed that the student knew the material with probability 0.7. The student got the question correct which intuitively should increase the teacher’s probability that the student was a good student. Bayes’ rule allows us to explicitly compute how the probability should increase – the probability has increased from \\(P(K) = 0.7\\) to \\(P(K | C) = 0.894\\).\n\n\n3.2.2 Example: Balls in a Bag\nSuppose a bag contains exactly one white ball. You roll a die and if the outcome of the die roll is \\(i\\), you add \\(i\\) red balls to the bag. You then select a ball from the bag and the color of the ball is red. What is the chance that the die roll is \\(i\\)?\nIn this example, let \\(D_i\\) denote the outcome that the die roll lands \\(i\\) and let \\(R\\) denote the outcome that a red ball is chosen. If we assume a fair die, then the six possible die rolls are equally likely, so \\(P(D_1) = P(D_2) = ... = P(D_6) = 1/6\\).\nThe probability of observing a red depends on the die roll. If the die roll is \\(i\\), one adds \\(i\\) red balls to the bag and the chance of choosing a red will be \\(i/(i+1)\\), so\n\\[\nP(R | D_i) = \\frac{i}{i+1}, , i = 1, ..., 6.\n\\]\nIn this story, a red ball is observed and we are interested in computing \\(P(D_i | R)\\). By applying Bayes rule\n\\[\nP(D_i | R) = \\frac{P(D_i) P(R | D_i)}{\\sum_{j=1}^6 P(D_j) P(R | D_j)}.\n\\]\nBy substituting the known quantities, we have\n\\[\nP(D_i | R) = \\frac{\\frac{1}{6} \\times \\frac{i}{i+1}}{\\sum_{j=1}^6 \\frac{1}{6} \\times \\frac{j}{j+1}}.\n\\]\nA convenient way of computing the die roll probabilities is by use of a table. In Table 2.1, each row corresponds to a specific die roll – we call these alternatives in the table. For each die roll, the table gives the initial probability \\(P(D_i)\\) and the probability of observing red for that die roll \\(P(R | D_i)\\). The updated probability \\(P(D_i | R)\\) is proportional to the product \\(P(D_i) P(R | D_i)\\) and the products are shown in the table.\nOne computes the updated probabilities by dividing each product by the sum of the products. For example the updated probability \\(P(D_1 | R)\\) is given by the product (1/6)(1/(1+1)) divided by the sum of the products \\(1/12 + 2/18 + ... + 6/42 = 0.734\\) which is equal to 0.113.\n\n\n\nAlternative\nProbability\n\\(P(R | {\\rm Die \\, \\, Roll})\\)\nProduct\n\n\n\n\n\\(D_1\\)\n1/6\n1/(1+1)\n1/12\n\n\n\\(D_2\\)\n1/6\n2/(2+1)\n2/18\n\n\n\\(D_3\\)\n1/6\n3/(3+1)\n3/24\n\n\n\\(D_4\\)\n1/6\n4/(4+1)\n4/30\n\n\n\\(D_5\\)\n1/6\n5/(5+1)\n5/36\n\n\n\\(D_6\\)\n1/6\n6/(6+1)\n6/42\n\n\n\nTo make sense of these calculations, we started assuming that all six possible rolls of the die were equally likely.\nWith the observation of a red ball, the updated probabilities are unequal and give support for larger rolls of the die."
  },
  {
    "objectID": "bayes_rule.html#new-terminology",
    "href": "bayes_rule.html#new-terminology",
    "title": "3  Bayes Rule",
    "section": "3.3 New Terminology",
    "text": "3.3 New Terminology\nIn general, we are interested in learning about \\(k\\) different models that we denote by \\(M_1, ..., M_k\\). Initially, we have beliefs about the plausibility of these models that we express through the probabilities \\(P(M_1), ..., P(M_k)\\). We refer to these as prior probabilities since these express our opinions about the models before or prior to observing any data. Next, we observe data denoted by \\(D\\) that will give us information about the models. We are given the probabilities of each data outcome for each model, that is, \\(P(D|M_1), ..., P(D|M_k)\\); these are called the likelihoods.\nNow the a particular data result \\(D\\) is observed. How has this data result changed our beliefs about the \\(k\\) models? Bayes’ rule is the recipe for modifying the model probabilities. It says that the new probability for model \\(M_i\\) is proportional to the product of the prior probability and the likelihood:\n\\[\nP(M_i | D) \\propto P(M_i) P(D | M_i).\n\\]\nThe updated probabilities {\\(P(M_i | D)\\)} are called posterior probabilities since they reflect our opinions about the models _after observing the data. Using words, we can write\nPOSTERIOR \\(\\propto\\) PRIOR \\(\\times\\) LIKELIHOOD.\nA convenient way to performing the Bayes’ rule calculations is by use of a table similar to the example. We illustrate the use of the new terminology and the table calculations for two additional examples."
  },
  {
    "objectID": "bayes_rule.html#sequential-learning",
    "href": "bayes_rule.html#sequential-learning",
    "title": "3  Bayes Rule",
    "section": "3.6 Sequential Learning",
    "text": "3.6 Sequential Learning\nA machine in a small factory is producing a particular automotive component. Most of the time (specifically, 90% from historical records), the machine is working well and produces 95% good parts. Some days, the machine doesn’t work as well (it’s broken) and produces only 70% good parts. A worker inspects the first dozen parts produced by this machine on a particular morning and obtains the following results (\\(g\\) represents a good component and \\(b\\) a bad component):\n\\[\ng, b, g, g, g, g, g, g, g, b, g, b.\n\\]\nThe worker is interested in assessing the probability the machine is working well.\nIn this problem there are two models – either the machine is working well, or “working” for short, or it is “broken”.\nBased on the historical data, the worker assigns prior probabilities of 0.90 and 0.10 to the models “working” and “broken”. The data are the results of the inspection on the 12 parts. To understand the relationship between the data and the models, we compute the sampling probabilities, the probabilities of each data outcome for each model. If the machine is working, the probabilities of a good (g) part and a bad (b) part are 0.95 and 0.05, respectively. So\n\\[\nP(g | {\\rm working}) = 0.95,\\, P(b | {\\rm working}) = 0.05 .\n\\]\nIf instead the machine is broken, the probabilities of good and bad part are 0.70 and 0.30, respectively:\n\\[\nP(g | {\\rm broken}) = 0.70, \\, P(b | {\\rm broken}) = 0.30 .\n\\]\nNow we’re ready to do the Bayes’ rule computation. The outcomes of twelve inspections of parts are the data:\n\\[\nDATA = {g, b, g, g, g, g, g, g, g, b, g, b}.\n\\]\nThe likelihoods are the probabilities of this data result for each of the two models. Assuming independence of individual outcomes, the likelihood of the working model is given by\n\\[\nLIKE({\\rm working}) =  P(\\{g, b, g, g, g, g, g, g, g, b, g, b\\} | {\\rm working})\n\\] \\[\n=  P(g | {\\rm working}) \\times ... \\times P(b | {\\rm working})\n\\] \\[ =  0.95 \\times 0.05 \\times 0.95 \\times ... \\times 0.05\n\\] \\[\n=  0.00007878.\n\\]\nSimilarly, the likelihood of the broken model is\n\\[\nLIKE({\\rm broken}) =  P(\\{g, b, g, g, g, g, g, g, g, b, g, b\\} | {\\rm broken})\n\\] \\[\n=  0.70 \\times 0.30 \\times 0.70 \\times ... \\times 0.30\n\\] \\[\n= 0.00108955\n\\]\nUsing the “prior times likelihood” recipe, we compute the posterior probabilities in the following table.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.90\n0.00007878\n0.000070902\n0.3942\n\n\nBroken\n0.10\n0.00108955\n0.000108955\n0.6058\n\n\n\nWe see that the posterior probability that the machine is broken is over 60% and perhaps the machine should be stopped for inspection and repair.\nThere is another way to implement Bayes’ rule when the data are observed in a sequential manner. Before any data are collected, the inspector’s probabilities of the two states of the machine, working and broken, are given by 0.90 and 0.10. He observes the quality of the first part – “g” – and then he can immediately update his probabilities by Bayes’ rule.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.90\n0.95\n0.855\n0.9243\n\n\nBroken\n0.10\n0.70\n0.070\n0.0757\n\n\n\nAfter this single observation, he is slightly more confident (with probability 0.9243) that the machine is working.\nThe inspector’s current probabilities of the two models are 0.9243 and 0.0757. He observes the quality of the next part – “b” – and again he can update his probabilities by Bayes’ rule. In this table “Prior” refers to his beliefs before observing the data.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.9243\n0.05\n0.046215\n0.6705\n\n\nBroken\n0.0757\n0.30\n0.022710\n0.3295\n\n\n\nWe see that, after observing two parts, the inspector’s probability that the machine is working is 0.6705.\nOne can continue learning in this sequential manner. As one observes the quality of each single part, the inspector can update his probability of the two models by Bayes’ rule. Table 2.9 summarizes the results of this sequential learning. The first row of the table displays the prior probabilities of the working and broken models and the following rows display the probabilities after each outcome is observed. Note that the final row indicates that the probabilities after observing the 12 parts are equal to 0.3942 and 0.6058. As expected, these posterior probabilities are the same as the ones computed using the group of 12 observations as data.\n\n\n\nObservation\nP(Working)\nP(Broken)\n\n\n\n\nPrior\n0.9000\n0.1000\n\n\ng\n0.9243\n0.0757\n\n\nb\n0.6706\n0.3294\n\n\ng\n0.7342\n0.2658\n\n\ng\n0.7894\n0.2106\n\n\ng\n0.8358\n0.1642\n\n\ng\n0.8735\n0.1265\n\n\ng\n0.9036\n0.0964\n\n\ng\n0.9271\n0.0729\n\n\ng\n0.9452\n0.0548\n\n\nb\n0.7421\n0.2579\n\n\ng\n0.7961\n0.2039\n\n\nb\n0.3942\n0.6058"
  },
  {
    "objectID": "bayes_rule.html#example-testing-for-a-disease",
    "href": "bayes_rule.html#example-testing-for-a-disease",
    "title": "3  Bayes Rule",
    "section": "3.4 Example: Testing for a Disease",
    "text": "3.4 Example: Testing for a Disease\nSuppose you are one of the many people who are tested for a rare disease. From reports, you known the the incidence of this disease is 1 out of 5000. You take the test and there are two results: either you are told “ok” or “see your doctor for further checks.” How should you feel on the basis of these two results?\nThere are two possible models in this example: you are either “diseased” or “not disease”. Assuming that you are a representative person from your community, your prior beliefs are that\n\\[\nP({\\rm diseased}) = \\frac{1}{5000} = 0.0002, , P({\\rm not \\, diseased}) = \\frac{4999}{5000} = 0.9998 .\n\\]\nThe “data” in this example is the screening test result. There are two outcomes: either the test will be “positive” or “+”, which is some indication that you have the disease, or “negative” or “-” which is good news. From past experience, the screening test has 5% false positives and 2% false negatives.\nThis means that if you really don’t have the disease, the chance you get a positive result is 0.05; that is,\n\\[\nP(+ , {\\rm result} | {\\rm not \\, diseased}) = 0.05,  P(- , {\\rm result} | {\\rm not \\, diseased}) = 0.95.\n\\]\nSimilarly, if you really have the disease, the chance of an incorrect negative result is 0.02:\n\\[\nP(- , {\\rm result} | {\\rm diseased}) = 0.02, \\, P(+ , {\\rm result} | {\\rm diseased}) = 0.98.\n\\]\nThese values are the likelihoods – the probabilities of the data outcomes for each model.\nSuppose you have a positive test result (\\(+\\)). We can find the new probabilities of diseased and not diseased by Bayes’ rule that we present in a table format in Table 2.2.\n\n\n\nPrior\nProbability\n\\(P(+ | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\nNot diseased\n0.9998\n0.05\n0.04999\n0.9961\n\n\nDiseased\n0.0002\n0.98\n0.000196\n0.0039\n\n\n\nBefore the test, your probability of having the disease was 0.02 and after getting the positive test result, this probability has increased to 0.039. This new probability is almost twice the initial probability, but you are still very unlikely to have the disease.\nWhat if you received a negative test result? We repeat the Bayes’ rule calculations in Table 2.3 with a change in the likelihood values.\n\n\n\nModel\nPrior\n\\(P(- | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\nNot diseased\n0.9998\n0.95\n0.949810\n0.999996\n\n\nDiseased\n0.0002\n0.02\n0.000004\n0.000004\n\n\n\nThe probability of having the disease has decreased from 0.0002 to 0.000004.\nThese results are usually surprising to doctors and patients. It seems difficult to update probabilities accurately and people typically have a much stronger opinion they have the disease when faced with a positive test result."
  },
  {
    "objectID": "bayes_rule.html#example-the-three-door-problem",
    "href": "bayes_rule.html#example-the-three-door-problem",
    "title": "3  Bayes Rule",
    "section": "3.5 Example: The Three Door Problem",
    "text": "3.5 Example: The Three Door Problem\nThere is a famous probability problem, called The Three Door Problem or The Car and the Goats that can be addressed by Bayes’ rule. There is a TV show where a contestant is showed three numbered doors, Door 1, Door 2, and Door 3, where one door is hiding a car and the other two doors hiding goats. The contestant is allowed to choose a door and win the corresponding prize. The contestant chooses Door 1. The host, who knows which door hides the car, then opens Door 2 to reveal a goat. The contestant is given the opportunity to change her selection. Should she switch her choice to Door 3?\nIn this example the unknown model is the location of the car. We will let \\(C_i\\) denote the event that the car is behind Door \\(i, i = 1, 2, 3.\\) Initially, the constestant believes the car is equally likely to be behind each of the three doors, so\n\\[\nP(C_1) = P(C_2) = P(C_3) = \\frac{1}{3}.\n\\]\nHere the data is the event that the host showed Door 2 – we’ll call this event \\(H\\). We wish to find the new probabilities of \\(C_1, C_2\\) and \\(C_3\\) conditional on the new information \\(H\\). We put the given information in the “Bayes’ table”:\n\n\n\nModel\nPrior\n\\(P(H | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\n\\(C_1\\)\n1/3\n\\(P(H | C_1)\\)\n\n\n\n\n\\(C_2\\)\n1/3\n\\(P(H | C_2)\\)\n\n\n\n\n\\(C_3\\)\n1/3\n\\(P(H | C_3)\\)\n\n\n\n\n\nLet’s consider the likelihood \\(P(H | C_i)\\) that represents the probability the host shows Door 2 if the car is behind Door \\(i\\). Remember that the contestant chose Door 1, so the host cannot choose this door.\n\nIf the car is really behind door 1, the host can either show Door 2 or Door 3. We will assume that the probability he shows Door 2 is a number \\(q\\) between 0 and 1, so \\(P(H | C_1) = q\\).\nIf the car is behind door 2, the host cannot show this door. So \\(P(H | C_2) = 0\\).\nIf the car is behind door 3, the host cannot show this door -- he has to show Door 2. So \\(P(H | C_3) = 1\\).\n\nWe complete the table in Table 2.5 by filling in the likelihoods and computing the posterior probabilities.\n\n\n\nModel\nPrior\n\\(P(H | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\n\\(C_1\\)\n1/3\n\\(q\\)\n\\(q/3\\)\n\\(q/(q+1)\\)\n\n\n\\(C_2\\)\n1/3\n0\n0\n0\n\n\n\\(C_3\\)\n1/3\n1\n1/3\n\\(1/(q+1)\\)\n\n\n\nLet’s return to our question. Remember the contestant chose Door 1 and has the opportunity to switch to Door 3. Given the data “host shows Door 2”, we have found that the probability the car is behind Door 1 is \\(q/(q+1)\\) and the probability the car is behind Door 3 is \\(1/(q+1)\\). The contestant should switch if the probability of \\(C_3\\) is greater than the probability of \\(C_1\\), that is,\n\\[\nP(C_3 | H) > P(C_1 | H)\n\\]\nor\n\\[\n\\frac{1}{q+1} > \\frac{q}{q+1}\n\\]\nwhich is true if \\(q > 0\\). So the contestant will increase her probability of winning by switching. Remember \\(q\\) is the probability the host will show Door 2 instead of Door 3 if he has a choice. If we assume \\(q = 1/2\\), that is, the host chooses a door at random, then the probability the car is behind Door 3 is \\(1/(1/2 + 1) = 2/3\\)."
  },
  {
    "objectID": "proportion.html",
    "href": "proportion.html",
    "title": "4  Learning About a Proportion",
    "section": "",
    "text": "Suppose data \\(y\\) is observed from a sampling distribution \\(f(y | \\theta)\\) that depends on an unknown parameter \\(\\theta\\). We assume that one has beliefs about \\(\\theta\\) before sampling that are expressed through a prior density \\(g(\\theta | y)\\). Once a value of \\(y\\) is observed, then one’s updated beliefs about the parameter \\(\\theta\\) are reflected in the posterior density, the conditional density of \\(\\theta\\) given \\(y\\): \\[\ng(\\theta | y) = \\frac{f(y | \\theta)g(\\theta) }{f(y)},\n\\] where \\(f(y)\\) is the marginal density of \\(y\\) \\[\nf(y) = \\int  f(y | \\theta) g(\\theta) d\\theta .\n\\]\nIn the computation of the posterior density, note that the only terms involving the unknown parameter \\(\\theta\\) are the likelihood function \\(L(\\theta) = f(y | \\theta)\\) and the prior density \\(g(\\theta)\\). Bayes’ rule says that the posterior density is proportional to the product of the likelihood and the prior, or \\[\ng(\\theta | y) \\propto L(\\theta) g(\\theta).\n\\]\nIn a Bayesian analysis, both the posterior density and the marginal density play important roles. The posterior density contains all information about the parameter contained in both the prior density and the data. One performs different types of inference by computing relevant summaries of the posterior density. The marginal density \\(f(y)\\) reflects the distribution of the data \\(y\\) before observing any data. This density is often called the predictive density since \\(f(y)\\) is used to make predictions about future data values."
  },
  {
    "objectID": "proportion.html#an-example-on-learning-about-a-proportion",
    "href": "proportion.html#an-example-on-learning-about-a-proportion",
    "title": "4  Learning About a Proportion",
    "section": "4.2 An Example on Learning About a Proportion",
    "text": "4.2 An Example on Learning About a Proportion\nIn this chapter, we discuss the basic elements of a Bayesian analysis through the problem of learning about a population proportion \\(p\\). We take a random sample from the population of size \\(n\\) and observe \\(y\\) successes – for a given value of \\(p\\), the probability of \\(y\\) is given by the binomial formula \\[\nf(y | p) = {n \\choose y} p^y (1-p)^{n - y}.\n\\]\nAs an example, suppose that coordinator of developmental math courses at a particular university is concerned about the proportion of students in these courses who have math anxiety, where “math anxiety” is defined by obtaining a particular score on an anxiety rating instrument. A sample of 30 students takes the instrument and 10 have math anxiety. What can be said about the proportion of all developmental math course students who have math anxiety?\nThe standard estimate of \\(p\\) is the proportion of successes in the sample \\(\\hat p = y/n\\) and the traditional Wald “large-sample” confidence interval for \\(p\\) is given by \\[\n\\left(\\hat p - z_{\\alpha/2} \\sqrt{\\frac{\\hat p (1- \\hat p)}{n}}, \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p (1- \\hat p)}{n}}\\right),\n\\] where \\(z_\\alpha\\) is the \\(1-\\alpha\\) quantile of the standard normal distribution.\nFor large samples, this interval will cover the unknown proportion in repeated sampling with probability \\(1 - \\alpha\\). However this interval estimate has questionable value for samples with very few observed successes or failures. Suppose that no students in our sample have math anxiety. Then \\(y = 0\\), \\(\\hat p = 0/30 = 0\\) and the confidence interval will be degenerate at zero. (Similarly, if all the students have math anxiety, then \\(\\hat p = 30/30 = 1\\) and the confidence interval will be degenerate at one.) Since one certainly believes that the proportion is larger than zero, this degenerate interval at zero doesn’t make any sense.\nOne ad-hoc solution to the “zero successes” problem is to initially add two artificial successes and two artificial failures to the data, and then apply the Wald interval to this adjusted data. This is a recommended approach in the literature and the resulting confidence interval has good sampling probabilities. We will see that this ad-hoc procedure has a natural correspondence with a Bayesian interval that incorporates prior information about the proportion."
  },
  {
    "objectID": "proportion.html#using-a-discrete-prior",
    "href": "proportion.html#using-a-discrete-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.3 Using a Discrete Prior",
    "text": "4.3 Using a Discrete Prior\nOne simple way of incorporating prior information about \\(p\\) is by use of a discrete prior. One makes a list of plausible values \\(p_1, ..., p_k\\) for the proportion and then assigns probabilities \\(P(p_1), ..., P(p_k)\\) to these values. It may be difficult to directly assess the individual prior probabilities, but it may be easier to think about the probability of one proportion value relative to the probabilities of other values. One might first assign a large integer value, say 10, to the value of \\(p\\) that is believed most likely, and then assess the probabilities of the remaining values relative to the probability of the most likely value. Once the relative probabilities are determined, then the probabilities are normalized to obtain the prior probabilities.\nIn the example, suppose one lists the possible values for the proportion of mathematics students with math anxiety displayed in the following table.\n\n\n\n\\(p\\)\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n\n\n\n\nPrior\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose one’s best guess at the proportion of students with math anxiety is \\(p = 0.20\\) so this value is assigned a “prior weight” of 10.\nThe values \\(p = 0.15\\) and \\(p = 0.25\\) are believed to half as likely as \\(p = 0.20\\) so each value is assigned a prior weight of 5. The value \\(p = 0.30\\) is thought to be only 30% as likely as \\(p = 0.20\\) so this proportion value is assigned a weight of 3. Continuing in this fashion, one obtains the table of prior weights for \\(p\\) as shown in Table \\(\\ref{table:priortable}\\). One converts these prior weights to probabilities by dividing each weight by its sum. Since the sum of prior weights is 31, the prior probability of \\(p = 0.5\\) is equal to \\(P(.05) = 1/31 = 0.32\\). The third row of the table display the prior probabilities.\n\n\n\n\\(p\\)\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n\n\n\n\nPrior Weight\n1\n2\n5\n10\n5\n3\n2\n1\n1\n1\n\n\nPrior\n.032\n.065\n.161\n.323\n.161\n.097\n.065\n.032\n.032\n.032\n\n\n\nOnce this prior distribution is assigned, one can compute the posterior probabilities by use of Bayes’ rule. One observes \\(y\\) successes in \\(n\\) trials. The likelihood of \\(p = p_i\\) given this result is given by \\[\nL(p_i) = p_i^y (1- p_i)^{n-y},\n\\] and the posterior probability of \\(p_i\\) will be given (up to a proportionality constant) by multiplying the prior probability by the likelihood. \\[\nP(p_i | {\\rm data}) \\propto P(p_i) L(p_i) = P(p_i)  p_i^y (1- p_i)^{n-y}.\n\\] The following table displays the posterior distribution calculations in the familiar table format. The columns of the table include the values of the proportion, the values of the prior, the likelihoods, and the products of the prior and the likelihood. One normalizes the probabilities by first computing the sum of the products (denoted by SUM in the table), and then dividing each product by this sum.\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\n\\(p_1\\)\n\\(P(p_1)\\)\n\\(p_1^y(1-p_1)^{n-y}\\)\n\\(P(p_1)\\) \\(p_1^y(1-p_1)^{n-y}\\)\n\\(P(p_1)\\) \\(p_1^y(1-p_1)^{n-y}/SUM\\)\\\n\n\n\\(p_2\\)\n\\(P(p_2)\\)\n\\(p_2^y(1-p_2)^{n-y}\\)\n\\(P(p_2)\\) \\(p_2^y(1-p_2)^{n-y}\\)\n\\(P(p_2)\\) \\(p_2^y(1-p_2)^{n-y}/SUM\\) \\\n\n\n–\n–\n–\n–\n–\n\n\n–\n–\n–\n–\n–\n\n\n–\n–\n–\n–\n–\n\n\n\\(p_k\\)\n\\(P(p_k)\\)\n\\(p_k^y(1-p_k)^{n-y}\\)\n\\(P(p_k)\\) \\(p_k^y(1-p_k)^{n-y}\\)\n\\(P(p_k)\\) \\(p_k^y(1-p_k)^{n-y}/SUM\\) \\ \n\n\n–\n–\n–\nSUM\n–\n\n\n\nThe Bayes’ rule calculations are illustrated in the following table for our math anxiety example. For the example, we observed \\(y = 10\\) who had math anxiety in a sample of \\(n = 30\\) and the likelihood is \\(p^{10} (1-p)^{20}\\). The computed values of the likelihood are very small so they have been multiplied by \\(10^{12}\\) in the table to obtain integer values.\n\n\n\n\\(p\\)\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\n0.05\n0.032\n0\n0\n0.000\n\n\n0.10\n0.065\n12\n1\n0.000\n\n\n0.15\n0.161\n224\n36\n0.019\n\n\n0.20\n0.323\n1181\n381\n0.200\n\n\n0.25\n0.161\n3024\n487\n0.255\n\n\n0.30\n0.097\n4712\n457\n0.239\n\n\n0.35\n0.065\n5000\n325\n0.170\n\n\n0.40\n0.032\n3834\n123\n0.064\n\n\n0.45\n0.032\n2185\n70\n0.037\n\n\n0.50\n0.032\n931\n30\n0.016\n\n\n\nTo interpret the posterior probabilities, remember that initially we believed that the proportion of math anxiety students was about 0.20, although we were unsure about its true value and the prior was relatively diffuse about \\(p = 0.20\\). The most likely value of \\(p\\) from the posterior distribution is \\(p = 0.25\\). The observed proportion of math anxiety values from the sample is \\(y/n = 10/30 = 0.33\\) and the posterior estimate is a compromise between the sample proportion and the prior mode. We can use the posterior distribution to find an interval estimate for the proportion. Note from the table that the most likely values of \\(p\\) are \\[\np = 0.20, 0.25, 0.30, 0.35\n\\] with total probability \\[\n0.200 + 0.255 + 0.239 + 0.170 = 0.864.\n\\] So the interval (0.20, 0.35) is a 86.4% interval estimate for \\(p\\) – the posterior probability \\[\nP(0.20 \\le p \\le 0.35| {\\rm data}) = 0.864.\n\\]"
  },
  {
    "objectID": "proportion.html#using-a-noninformative-prior",
    "href": "proportion.html#using-a-noninformative-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.4 Using a Noninformative Prior",
    "text": "4.4 Using a Noninformative Prior\nThere are some advantages to using a discrete prior for a proportion. It provides a starting point for finding a prior distribution that reflects one’s knowledge, before sampling, about the location of the proportion. Also it is easy to summarize a discrete posterior distribution. But since the proportion \\(p\\) is a continuous parameter, one’s prior should be a continuous distribution on the interval from 0 to 1.\nFirst, suppose one has little knowledge about the location of the proportion. In our example, suppose that one has little information about the proportion of students in the class who have math anxiety. How can one construct a prior distribution that reflects little or imprecise knowledge about the location of the parameter? This type of distribution is called a noninformative prior or ignorance prior. Using this type of prior, the posterior distribution will typically be more influenced by the data than the prior information.\nOne possible choice for a noninformative prior assumes that \\(p\\) has a uniform distribution \\[\ng(p) = 1, 0 < p < 1.\n\\] This distribution implies that every subset of \\(p\\) of a given length has the same probability.\nIf we observe \\(y\\) successes in \\(n\\) trials, we wish to find the posterior density of \\(p\\), the density of the proportion conditional on \\(y\\). By Bayes’ rule, this density is given by \\[\ng(p | y) = \\frac{f(y | p) g(p)}{\\int_0^1 f(y | p) g(p) dp} \\propto f(y|p) g(p),\n\\] which gives the familiar POSTERIOR \\(\\propto\\) LIKELIHOOD \\(\\times\\) PRIOR recipe.\nIf we use a uniform prior for \\(p\\), then the posterior density is given by \\[\ng(p | y) \\propto p^y (1-p)^{n-y}, \\, 0 < p < 1.\n\\] If we view this function as a function of the proportion \\(p\\) where \\(y\\) and \\(n\\) are fixed, then we recognize this density as a beta density of the form \\[\ng(p | y) = \\frac{1}{B(a^*, b^*)} p^{a^* - 1} (1-p)^{b^*-1}, \\, 0 < p < 1,\n\\] where \\(a = y+1\\) and \\(b = n - y + 1\\)"
  },
  {
    "objectID": "proportion.html#using-a-conjugate-prior",
    "href": "proportion.html#using-a-conjugate-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.5 Using a Conjugate Prior",
    "text": "4.5 Using a Conjugate Prior\nIn many situations, the use of noninformative priors is appropriate since the user does not have any knowledge about the parameter from previous experience. But in other situations such as the math anxiety example, the user does have knowledge about the unknown proportion before sampling and one wishes to construct a continuous prior on the unit interval that represents this prior knowledge.\nOne convenient family of prior distributions is the beta family with shape parameters \\(a\\) and \\(b\\): \\[\ng(p) = \\frac{1}{B(a, b)} p^{a - 1} (1-p)^{b-1}, \\, 0 < p < 1.\n\\] As demonstrated by the graphs in Figure ???, the beta family can have many shapes and can reflect a variety of information about the proportion \\(p\\). In practice, one chooses the parameters \\(a\\) and \\(b\\) that matches one’s beliefs about the proportion.\nOne way of assessing values of \\(a\\) and \\(b\\) is to guess at the values of the prior mean and variance of \\(p\\). Suppose these guesses are \\(M\\) and \\(V\\), respectively. The prior mean and standard deviation of a beta(\\(a, b\\)) distribution are \\(a/(a+b)\\) and \\(ab/(a+b)^2/(a+b+1)\\). Then by solving the equations\n\\[\nM  = \\frac{a}{a+b},  \\, \\,     \n   V  =  \\frac{a b}{(a+b)^2 (a+b+1)}\n\\]\nfor \\(a\\) and \\(b\\), one obtains the beta prior distribution. The problem with this method is that it may be difficult for a user to specify the prior moments of the distribution since moments can be affected by the shape or tail behavior of the distribution which may be unknown.\nAn alternative approach is to assess the parameters \\(a\\) and \\(b\\) indirectly through the specification of prior quantiles. In our example, suppose that the user believes that the median of the prior for the proportion of students is \\(q_0.5 = 0.23\\). This means that he/she believes that the proportion is equally likely to be smaller or larger than 0.23. Then the user makes a statement about the sureness of this guess at the median by the statement about a second quantile. Suppose the user says that he/she is 90% confident that the proportion \\(p\\) is less than 0.38. So the prior information is given by \\[\nP(p < 0.23) = 0.50, \\, \\, P(p < 0.38) = 0.90.\n\\] By use of a program such as the function beta.select() in the LearnBayes package, one matches these prior quantiles with the beta parameters \\(a = 4.0, b = 12.5\\).\nOnce one assesses the values of the beta parameters, it is easy to compute the posterior distribution. By multiplying the prior and the likelihood, one obtains that the posterior density of \\(p\\) is proportional to \\[\ng(p | y)  \\propto  L(p) g(p)  \n\\] \\[\n       =  p^y (1-p)^{n-y} \\times p^{a-1} (1-p)^{b-1}\n\\] \\[\n       =  p^{a + y -1} (1-p)^{b + n - y -1},\n\\]\nwhich we recognize as a beta density with updated parameters \\(a^* = a + y\\) and \\(b^* = b + n - y\\). We say that the beta density is a conjugate prior density since the prior and posterior have the same functional form.\nIn our example, if our prior is beta(4.0, 12.5) and we have \\(y = 10\\) math anxious students in a sample of \\(n = 30\\), then the posterior distribution is beta(4.0 + 10, 12.5 + 20) or beta( 14.0, 32.5)."
  },
  {
    "objectID": "proportion.html#inference",
    "href": "proportion.html#inference",
    "title": "4  Learning About a Proportion",
    "section": "4.6 Inference",
    "text": "4.6 Inference\nAfter one observes data, then all knowledge about the parameter is contained in the posterior distribution. It is common to simply display the posterior density and the reader can learn about the location and spread by simply looking at this curve. To obtain different types of statistical inferences, one summarizes the posterior distribution in various ways. We illustrate using the posterior distribution to obtain point and interval estimates of the parameter.\n\n4.6.1 Point Inference\nA suitable point estimate of a parameter is a single-number summary of the posterior density. The posterior mean is the mean of the posterior distribution given by the integral \\[\nE(p | y) = \\int p \\, g(p | y) dp.\n\\] The posterior median is the median of the posterior distribution, the value \\(p_{0.5}\\) such that the proportion is equally likely to be smaller or larger than \\(p\\). \\[\nP(p < p_{0.5}) = 0.5.\n\\] The posterior mode is the value \\(\\hat p\\) where the posterior density is maximized: \\[\ng(\\hat p | y) = \\max_p g(p | y).\n\\]\nIn the case where a beta(\\(a, b\\)) prior is assigned to a proportion \\(p\\), the posterior distribution is also in the beta family with updated parameters \\(a^* = a + y\\) and \\(b^* = b + n - y\\). The posterior mean of \\(p\\) is the mean of the beta density \\[\nE(p | y) = \\frac{a^*}{a^*+b^*} = \\frac{y + a}{n + a + b}.\n\\] The posterior median \\(p_M\\) is the 0.5 fractile of the beta curve. It is not expressible in closed form, but is easily available by use of software. The posterior mode is found by finding the value of \\(p\\) that maximizes the density \\(p^{a^*-1} (1-p)^{b^*-1}\\). A straightforward calculation shows the posterior mode is \\[\n\\hat p = \\frac{a^*-1}{a^*+b^*-2}.\n\\] For our example, our posterior density is beta(14.0, 32.5). The posterior mean is given by \\(E(p | y) = 14.0/(14.0 + 32.5) = 0.301\\). By use of the R command qbeta, the posterior median is found to be \\(p_M = 0.298\\), and the posterior mode is \\(\\hat p = (14.0 -1 )/(14.0 + 32.5 - 2) = 0.292\\).\nIn the case where the posterior density is approximately symmetric, as in this example, the posterior mean, posterior median, and posterior mode will be approximately equal. In other situations where the posterior density is right or left skewed, these summary values can be different. One nice feature of the posterior median is its clear interpretation as the value that divides the posterior probability in half.\n\n\n4.6.2 Interval Estimation\nTypically, a point estimate such as a posterior median is insufficient for understanding the location of a parameter. A Bayesian interval estimate or credible interval is an interval that contains the parameter with a given probability. Specifically, a \\(100 (1-\\gamma)\\) percent credible interval is any interval \\((a, b)\\) such that \\[\nP( a < p < b) = \\gamma.\n\\] There are many intervals that contain \\(100 (1-\\gamma)\\) percent of the posterior probability. A convenient estimate is an equal-tail interval estimate whose endpoints are the \\(\\gamma/2\\) and \\(1-\\gamma/2\\) quantiles of the posterior distribution. \\[\n(p_{\\gamma/2}, p_{1-\\gamma/2}).\n\\] An alternative is the highest posterior density interval or HPD interval which is the shortest interval that contains this probability content.\nIn our example, the posterior for \\(p\\) was beta(14.0, 32.5). If we wish to construct a 90% interval estimate, then one possible interval would be (0, \\(p_{.90}\\)) = (0, 0.389) and another would be \\((p_{.10}, 1) = (0.217, 1)\\). These would be undesirable intervals since they both would have long widths. The equal-tail interval would be formed from the 5th and 95th percentiles that is equal to (0.197, 0.415). Using the function hpd in the TeachingDemos package, one computes the HPD interval (0.191, 0.409). Since the posterior density is approximately symmetric, the equal-tail and HPD intervals are approximately equal.\n\n\n4.6.3 Estimation of Probabilities\nOne attractive feature of the Bayesian approach is that one can see if the parameter falls in different regions by simply computing the posterior probabilities of these regions. In the math anxiety example, suppose we are interested in the plausibility that the proportion falls in the intervals (0, 0.2), (0.2, 0.4), (0.4, 0.6), (0.6, 0.8), (0.8, 1). The posterior distribution for the proportion of math anxious students is beta(14.0, 32.5) and by use of the R pbeta command, we can compute the probabilities of these regions and these probabilities are displayed in Table \\(\\ref{table:postprobs}\\). Is it likely that the proportion of math anxious students is larger than 0.4? The answer would be no, since the posterior probability that \\(p > 0.4\\) is only 0.08. We see from this table that it is very likely that the proportion falls between 0.4 and 0.6.\n\n\n\nInterval\nPosterior Probability\n\n\n\n\n(0, 0.2)\n0.06\n\n\n(0.2, 0.4)\n0.87\n\n\n(0.4, 0.6)\n0.08\n\n\n(0.6, 0.8)\n0.00\n\n\n(0.8, 1.0)\n0.00"
  },
  {
    "objectID": "proportion.html#using-alternative-priors",
    "href": "proportion.html#using-alternative-priors",
    "title": "4  Learning About a Proportion",
    "section": "4.7 Using Alternative Priors",
    "text": "4.7 Using Alternative Priors\nThe choice of a beta prior is made by convenience. By use of a beta prior, the posterior has the same functional (beta) form and it is easy to summarize the posterior distribution. But Bayes’ rule can be applied for any continuous prior density of \\(p\\) on the unit interval. We illustrate this point by using an alternative density for the proportion based on prior beliefs about the logit proportion.\nIn some situations, one may have prior beliefs about the logit of \\(p\\) defined by \\[\n\\theta = \\log \\frac{p}{1-p}.\n\\] Suppose that one believes, before sampling, that \\(\\theta\\) is normally distributed with mean \\(\\mu = -1.21\\) and standard deviation \\(\\tau = 0.55\\). By transforming the logit \\(\\theta\\) to \\(p\\) by \\[\np = \\frac{\\exp(\\theta)}{1+\\exp(\\theta)},\n\\] one can show that the induced prior on \\(p\\) is given by \\[\ng(p) = \\phi(\\log \\frac{p}{1-p}; \\mu, \\tau) \\frac{1}{p(1-p)}, \\, \\, 0 < p < 1,\n\\] where \\(\\phi(x; \\mu, \\tau)\\) is the normal density with mean \\(\\mu\\) and standard deviation \\(\\tau\\).\nAs before, the likelihood function is \\(L(p) = p^y (1-p)^{n-y}\\), where \\(n = 30\\) and \\(y = 10\\). By using the “prior times likelihood” recipe, the posterior density of \\(p\\) is given by \\[\ng(p | y) \\propto L(p) g(p) = \\left(p^y (1-p)^{n-y}\\right) \\times \\left( \\phi(\\log \\frac{p}{1-p}; \\mu, \\tau) \\frac{1}{p(1-p)} \\right).\n\\]\nIn this situation, we no longer have a conjugate analysis, since the prior and posterior densities have different functional forms. Moreover, the posterior has a functional form that we do not recognize as a member of a familiar family such as the beta. However, this just means that we will need alternative tools to summarize the posterior distribution to perform inferences."
  },
  {
    "objectID": "proportion.html#prediction",
    "href": "proportion.html#prediction",
    "title": "4  Learning About a Proportion",
    "section": "4.8 Prediction",
    "text": "4.8 Prediction\nIn this chapter, we have focused on the use of the posterior distribution to make inferences about the proportion \\(p\\). It is also possible to learn about the plausibility of future outcomes by inspection of the predictive distribution. In our math anxiety example, suppose we administer the exam to a new sample of 30 students. How many students in the new sample will be math anxious?\nLet \\(y^*\\) denote the number of math anxious students in a future sample of size \\(n^*\\). Conditional on \\(p\\), the distribution of \\(y^*\\) will be binomial(\\(n^*, p\\)). If our current beliefs about the proportion are represented by the density \\(g(p)\\), then the predictive density of \\(y^*\\) will be given by the integral\n\\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 f(y^*|p) g(p) dp \\nonumber \\\\\n       =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} g(p) dp.  \\nonumber \\\\\n\\end{eqnarray*}\\]\nSuppose we assign \\(p\\) a uniform prior; that is, \\(g(p) = 1\\). If we substitute this prior for \\(g(p)\\), then the predictive density is given by \\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} dp. \\nonumber \\\\\n       =  {n^* \\choose y^*} B(y^*+1, B(n^* - y^*+1)  \\nonumber \\\\\n       =  \\frac{1}{n^*+1}. \\nonumber \\\\\n\\end{eqnarray*}\\] If we use a uniform prior, then each of the \\(n^*+1\\) possible values of \\(y^*\\) are equally likely.\nSuppose our current knowledge about the proportion is contained in a beta(\\(a, b\\)) density. Then the predictive density is given by \\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} \\frac{1}{B(a, b)} p^{a-1}(1-p)^{b-1} dp  \\nonumber \\\\\n       =  {n^* \\choose y^*}  \\frac{B(a + y^*, b + n^* - y^*)}{B(a, b)}, y^* = 0, ..., n^*. \\nonumber \\\\\n\\end{eqnarray*}\\] This is called a beta-binomial density since it is a mixture of binomial densities, where the proportion \\(p\\) follows a beta density.\nIn our example, after observing the sample, the beliefs about the proportion of math anxious students is represented by a beta(14.0, 32.5) distribution. By use of the R function pbetap(), one can compute the predictive density for the number of math anxious students in a future sample of \\(n^* = 30\\). The figure shows that there is a sizable variation in \\(y^*\\); a 90% prediction interval for \\(y^*\\) is given by {4, 5, …, 13, 15}. Why is the prediction interval so wide? There are two sources of variability in prediction. First, there is uncertainty about the proportion of math anxious students \\(p\\) as reflected in the posterior density \\(g\\), and there is uncertainty in the number of anxious students \\(y^*\\) for a fixed value of \\(p\\) as reflected in the sampling density \\(f\\). The prediction distribution incorporates both types of uncertainty and therefore results in a relatively wide prediction interval estimate."
  },
  {
    "objectID": "single_parameter.html",
    "href": "single_parameter.html",
    "title": "5  Single Parameter Inference",
    "section": "",
    "text": "In this chapter, we introduce Bayesian thinking for several one-parameter problems. We first consider normally distributed data and discuss learning about the normal mean given a known value of the variance and learning about the normal variance given a known mean. These situations are artificial, but we will learn particular forms of posterior distributions that will be used in the situation where both parameters of the normal population are unknown. We continue by illustrating Bayesian inference for a Poisson mean and an exponential location parameter. In all examples, the parameter is assigned a conjugate prior and the posterior density has a convenient functional form and easy to summarize. One way of generalizing the class of conjugate priors is by use of mixtures and we illustrate the use of a simple mixture in estimating a Poisson mean."
  },
  {
    "objectID": "single_parameter.html#learning-about-a-normal-mean-with-known-variance",
    "href": "single_parameter.html#learning-about-a-normal-mean-with-known-variance",
    "title": "5  Single Parameter Inference",
    "section": "5.2 Learning about a Normal Mean with Known Variance",
    "text": "5.2 Learning about a Normal Mean with Known Variance\n\n5.2.1 A single observation\nA basic problem in statistics is to learn about the mean of a normal population. Suppose we observe a single observation \\(y\\) from a normal population with mean \\(\\theta\\) and known variance \\(\\sigma^2\\). Here the likelihood function is the sampling density of \\(y\\) viewed as a function of the parameter \\(\\theta\\). \\[\nL(\\theta) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(y-\\theta)^2}{2 \\sigma^2}\\right).\n\\] As an example, suppose Joe takes an IQ test and his score is \\(y\\). Joe’s ``true IQ” is \\(\\theta\\) – this would represent Joe’s average IQ test score if he were able to take the test an infinite number of times. We assume that his test score \\(y\\) is normally distributed with mean equal to his true IQ and standard deviation \\(\\sigma\\). Here \\(\\sigma\\) represents the measurement error of the IQ test and we know from published reports that the standard deviation \\(\\sigma = 10\\).\nSuppose one has some prior beliefs about the location of the mean and one represents these beliefs by a normal curve with mean \\(\\mu\\) and standard deviation \\(\\tau\\). That is, \\[\ng(\\mu) = \\frac{1}{\\sqrt{2 \\pi \\tau^2}} \\exp\\left(-\\frac{(\\theta-\\mu)^2}{2 \\tau^2}\\right).\n\\] Here \\(\\mu\\) represents the person’s best guess at the value of the normal mean, and \\(\\tau\\) reflects the sureness of this guess. In our IQ example, suppose one believes that Joe has average intelligence so one sets the prior mean \\(\\mu = 100\\). Moreover, one is pretty confident (with probability 0.90) that \\(\\mu\\) falls in the interval (81, 119). This information can be matched with the standard deviation \\(\\tau = 15\\).\nAfter we observe the observation \\(y\\), we wish to find the posterior density of the mean \\(\\theta\\). By Bayes’ rule, the posterior density is proportional to the product of the prior of the likelihood. \\[\ng(\\theta | y) \\propto g(\\theta) L(\\theta).\n\\] To find the functional form of this posterior, we combine the terms in the exponent. \\[\\begin{eqnarray*}\ng(\\theta | y)  \\propto  \\exp\\left(-\\frac{(\\theta-\\mu)^2}{2 \\tau^2}\\right) \\times \\exp\\left(-\\frac{(y-\\theta)^2}{2 \\sigma^2}\\right) \\\\\n       =  \\exp\\left(-\\frac{(\\theta-\\mu)^2}{2 \\tau^2}-\\frac{(y-\\theta)^2}{2 \\sigma^2}\\right).  \\nonumber \\\\\n\\end{eqnarray*}\\] By completing the square, one can show that the exponent is equal to \\[\n-\\frac{1}{2}\\left(\\frac{1}{\\tau^2}+\\frac{1}{\\sigma^2}\\right)\n\\left[\\theta^2 - 2 \\left(\\frac{\\mu/\\tau^2 + y/\\sigma^2}{1/\\tau^2+1/\\sigma^2}\\right) +\n\\left(\\frac{\\mu/\\tau^2 + y/\\sigma^2}{1/\\tau^2+1/\\sigma^2}\\right)^2 \\right]\n\\] \\[\n= -\\frac{1}{2}\\left(\\frac{1}{\\tau^2}+\\frac{1}{\\sigma^2}\\right)\n\\left(\\theta -  \\frac{\\mu/\\tau^2 + y/\\sigma^2}{1/\\tau^2+1/\\sigma^2} \\right)^2 .\n\\] We see then that, up to a proportionality constant, the posterior density has the normal functional form \\[\ng(\\theta | y) \\propto \\exp\\left(-\\frac{1}{2 \\tau_1^2} (\\theta - \\mu_1)^2 \\right),\n\\] where the posterior mean and posterior variance have the form \\[\n\\mu_1 = \\frac{\\mu/\\tau^2 + y/\\sigma^2}{1/\\tau^2+1/\\sigma^2}, \\,\\, \\tau_1^2 = \\frac{1}{1/\\tau^2+1/\\sigma^2}.\n\\]\nOne can see how the posterior combines the information in the prior and the data by using the notion of {}. The precision is defined to be the reciprocal of the variance. The prior precision, denoted \\(P_0\\), is the reciprocal of the prior variance \\[\nP_0 = 1/\\tau^2.\n\\] In a similar fashion, the data precision, denoted by \\(P_D\\), is the reciprocal of the data variance \\[\nP_D = 1/\\sigma^2.\n\\] The posterior precision, denoted by \\(P_1 = 1/\\tau_1^2\\), is found simply by adding the prior precision and the data precision: \\[\nP_1 = P_0 + P_D.\n\\] The posterior mean \\(\\mu_1\\) is the weighted average of the prior mean \\(\\mu\\) and the observation \\(y\\), where the weights are proportional to the precisions: \\[\n\\mu_1 = \\frac{P_0}{P_0 + P_D} \\mu + \\frac{P_D}{P_0 + P_D} y .\n\\]\nReturning to our example, suppose Joe’s score on the IQ test is \\(y = 120\\). What have we learned about his true IQ \\(\\theta\\)? Table 4.1 illustrates the calculations of the posterior distribution.\n\nWe first compute the precision \\(P_0 = 1/\\tau^2\\) of the prior and the precision \\(P_D = 1/\\sigma^2\\) of the data.\nThe posterior precision \\(P_1\\) is the sum of the prior precision and the data precision. \\[\nP_1 = P_0 + P_D = 0.0044 + 0.0100 = 0.0144 .\n\\]\nThe variance of the posterior \\(\\tau_1^2\\) is the reciprocal of the posterior precision.\nWe compute the posterior mean \\(\\mu_1\\) that is a weighted average of the prior mean and the observation: \\[\n\\mu_1 = \\frac{0.0100}{0.0144} \\times 100 + \\frac{0.0044}{0.0144} \\times 113.8\n\\]\n\n\n\n\nEstimate\nVariance\nPrecision\n\n\n\n\nPrior\n100\n225\n\n\nData\n120\n100\n\n\nPosterior\n113.8\n69.23\n\n\n\nBefore sampling, one believed that Joe was of average intelligence and the prior mean was \\(\\mu = 100\\). After the IQ test \\(y = 120\\) is observed, one’s opinion about Joe’s intelligence has changed and the posterior mean is now at \\(\\mu_1 = 113.8\\). The posterior mean, as expected, falls between the prior mean and the observed test score. The posterior mean is closer to the test score than the prior mean – this is due to the fact that there is more information (measured by the precision) in the data value than the prior mean. Also note that the posterior variance is smaller than either the prior variance and the data variance. Since the posterior precision is the sum of the prior precision and data precision, one gains information by adding the information from the two sources, and this will result in a smaller posterior variance.\nAlthough we have focused on learning about Joe’s true IQ \\(\\theta\\), one may be interested in predicting Joe’s test score on a future test. Denote a future test score by \\(\\tilde y\\). We are interested in obtaining the predictive density of \\(\\tilde y\\) denoted by \\(f(\\tilde y)\\). To obtain this density, we apply some results from normal sampling theory. By adding and subtracting \\(\\theta\\) we write the random variable \\(\\tilde y\\) as \\[\n\\tilde y = W + \\theta,\n\\] where \\(W = \\tilde y - \\theta\\). Suppose the current beliefs about \\(\\theta\\) are represented by a normal density with mean \\(\\mu\\) and variance \\(\\tau^2\\). For a given value of \\(\\theta\\), the future observation \\(\\tilde y\\) is normal with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Equivalently, the distribution of \\(W = \\tilde y - \\theta\\) is normal with mean 0 and variance \\(\\sigma^2\\). Since this distribution of W doesn’t depend on \\(\\theta\\), this also represents the unconditional distribution of W. It can be shown that the random variables \\(W\\) and \\(\\theta\\) are independent. Since \\(\\tilde y\\) is the sum of two independent normal variates, it follows that the distribution for \\(\\tilde y\\) will also be normal with mean \\(\\mu\\) and variance \\(\\sigma^2 + \\tau^2\\).\nWe have already observed Joe’s test score of 120 and the posterior distribution of his true IQ \\(\\theta\\) is \\(N(113.8, \\sqrt{69.23})\\). We wish to construct a 90% prediction interval for the score of a future test \\(\\tilde y\\). Applying the above result, the future test score will be normal with mean \\(\\mu_1 = 113.8\\) and variance \\(\\sigma^2 + \\tau_1^2 = 100 + 69.23 = 169.23\\). So the interval \\[\n(113.8 - 1.645 \\sqrt{169.23}, 113.8 + 1.645 \\sqrt{169.23})\n\\] will cover 90% of the predictive distribution of the future test score.\n\n\n5.2.2 Multiple observations\nIn our discussion, we observed only a single observation. Suppose now that we observe a random sample \\(y_1, ..., y_n\\) from a normal distribution with mean \\(\\theta\\) and variance \\(\\sigma^2\\). In this case, the likelihood function for \\(\\theta\\) is the product of the sampling densities \\[\nL(\\theta) = \\prod_{i=1}^n \\exp\\left(-\\frac{(y_i-\\theta)^2}{2 \\sigma^2}\\right).\n\\] Suppose we subtract and add the sample mean \\(\\bar y = \\frac{1}{n}\\sum_{i=1}^n y_i\\) to the term in parentheses in the exponent: \\[\nL(\\theta) = \\prod_{i=1}^n \\exp\\left(-\\frac{(y_i - \\bar y + \\bar y -\\theta)^2}{2 \\sigma^2}\\right).\n\\] If we expand the quadratic term and simplify, ignoring multiplicative constants not depending on \\(\\theta\\), one can show that \\[\nL(\\theta) = \\exp\\left(-\\frac{n (\\bar y - \\theta)^2}{2 \\sigma^2}\\right).\n\\] What we have shown is that \\(\\bar y\\) is a sufficient statistic for \\(\\theta\\). Also it shows that the multiple observation situation is really equivalent to observing the {} data value \\(\\bar y\\) that is normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2/n\\).\nSuppose a normal(\\(\\mu, \\tau^2\\)) prior is chosen for \\(\\theta\\). Then, by applying the results of the previous section, the posterior distribution will be normal(\\(\\mu_1, \\tau_1^2)\\) where the mean and variance are given by \\[\n\\mu_1 = \\frac{\\mu/\\tau^2 + \\bar y n/\\sigma^2}{1/\\tau^2+n/\\sigma^2}, \\,\\, \\tau_1^2 = \\frac{1}{1/\\tau^2+n/\\sigma^2}.\n\\]\n\n\n5.2.3 Inference with a noninformative prior\nSuppose that one has little prior information about the location of the normal mean. This means one believes that every possible IQ value (within reasonable limits) is equally likely. This lack of knowledge can be represented by a uniform curve \\[\ng(\\theta) = c, \\, \\, \\infty < \\theta < \\infty .\n\\] One might object to this choice of prior since \\(g\\) is not a proper probability density. However this choice results in a posterior density for \\(\\theta\\) that is indeed proper. In the case where a random sample of \\(n\\) is taken, then the posterior density will be given by \\[\\begin{eqnarray*}\ng(\\theta | y)  \\propto  L(\\theta) g(\\theta)  \\nonumber \\\\\n  =  \\exp\\left(-\\frac{n (\\bar y - \\theta)^2}{2 \\sigma^2}\\right)\n\\end{eqnarray*}\\] We recognize this posterior as a normal density with mean \\(\\bar y\\) and variance \\(\\sigma^2/n\\).\nIf we use this uniform prior, then Bayesian inference will mimic the usual frequentist inference about a mean with known variance. For example, suppose we want to construct a 95% Bayesian interval estimate. The ``equal-tails” interval \\[\n(\\bar y - 1.96 \\frac{\\sigma}{\\sqrt{n}}, \\bar y + 1.96 \\frac{\\sigma}{\\sqrt{n}})\n\\] covers the central 95% of the posterior distribution of \\(\\theta\\). This interval also has a frequentist 95% probability of coverage in repeated sampling\n\n\n5.2.4 Inference with large samples\nSuppose one’s prior beliefs about a mean are modeled by a normal distribution and one observes a very large sample. What is the impact of this large sample size on the posterior distribution? As an example, suppose I’m interested in learning about the mean height \\(\\theta\\) of undergraduate female students at my university. Based on my knowledge, my ``best guess” at \\(\\theta\\) is 65.5 inches and I am 90% confident that the mean is within 2 inches of my best guess. I can represent this information by a normal curve with mean \\(\\mu = 65.5\\) and standard deviation \\(\\tau = 1.2\\). A large sample of \\(n = 427\\) female students are asked about their height and we observe a sample mean of \\(\\bar y = 64.71\\) inches. What have we learned about the population mean height \\(\\theta\\)? For this example, we will assume that we know the the standard deviation of the population of female heights is \\(\\sigma = 3\\) inches.\nTable 4.2 shows the posterior calculations for this example. The first row contains the mean, standard deviation, variance and precision for our prior, and the second row contains the same quantities for the data. Here the standard error of the mean is \\(\\sigma/\\sqrt{n} = 3/\\sqrt{427} = 0.145\\), the data variance is \\(\\sigma^2/n = 0.021\\) and the data precision is \\(n/\\sigma^2 = 47.56\\). The posterior mean is given by \\[\nE(\\theta | y) = \\frac{0.69}{0.69 + 47.56} \\times 65.5 + \\frac{47.56}{0.69 + 47.56} \\times 64.71 = 64.72.\n\\]\n\n\n\n\nEstimate\nStandard Deviation\nVariance\nPrecision\n\n\n\n\nPrior\n65.5\n1.2\n1.44\n0.69\n\n\nData\n64.71\n0.145\n0.021\n47.56\n\n\nPosterior\n64.72\n0.144\n0.0207\n48.25\n\n\n\nRecall the precision is a measure of the amount of information and it is clear in this example that there is much more information about \\(\\theta\\) contained in the sample of \\(427\\) students than the prior. As a result, the likelihood function is much more precise than the prior and the posterior is essentially controlled by the data. In other words, since the data is so precise relative to the prior, the prior acts like a constant noninformative prior. The posterior mean and posterior standard deviation are approximately equal to the sample mean and classical standard error, respectively.\nIn this particular example, there was some conflict between the information in the prior and the data. My prior beliefs about the average female height was approximately one inch too high. But since a large sample was collected, my ``wrong” prior information has little impact on the posterior inference. In other words, the posterior inference in this case is robust or insensitive to the choice of prior distribution."
  },
  {
    "objectID": "single_parameter.html#learning-about-a-normal-variance-with-known-mean",
    "href": "single_parameter.html#learning-about-a-normal-variance-with-known-mean",
    "title": "5  Single Parameter Inference",
    "section": "5.3 Learning About a Normal Variance with Known Mean",
    "text": "5.3 Learning About a Normal Variance with Known Mean\n\n5.3.1 Inference using an informative prior\nSuppose we observe \\(y_1, ..., y_n\\) from a normal population with known mean \\(\\theta\\) and unknown variance \\(\\sigma^2\\). The likelihood function for \\(\\sigma^2\\) is given by \\[\\begin{eqnarray*}\nL(\\sigma^2)  =  \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left( -\\frac{1}{2 \\sigma^2}(y_i - \\theta)^2\\right)  \\nonumber \\\\\n       \\propto  \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\theta)^2\\right). \\nonumber \\\\\n\\end{eqnarray*}\\]\nA conjugate prior for a variance is the inverse gamma distribution. Suppose \\(X\\) has a gamma distribution with shape \\(\\alpha\\) and rate \\(\\beta\\) with density \\[\nf(x) = \\frac{ x^{\\alpha-1} \\exp(-\\beta x) \\beta^\\alpha}{\\Gamma(\\alpha)}, \\, \\, x > 0.\n\\] If we let \\(W = 1/X\\), then \\(W\\) has an inverse gamma distribution with parameters \\(\\alpha\\) and \\(\\beta\\) with density \\[\nf(w) = \\frac{\\exp(-\\beta/w) \\beta^\\alpha}{w^{\\alpha+1} \\Gamma(\\alpha)}, \\, \\, w > 0.\n\\]\nNow we assume that one’s prior beliefs about \\(\\sigma^2\\) can be represented by an inverse gamma(\\(\\alpha, \\beta)\\) density \\[\ng(\\sigma^2) = \\frac{\\exp(-\\beta/\\sigma^2) \\beta^\\alpha}{(\\sigma^2)^{\\alpha+1} \\Gamma(\\alpha)}.\n\\] Then by combining prior and likelihood, the posterior of \\(\\sigma^2\\) is equal to \\[\\begin{eqnarray*}\ng(\\sigma^2 | y)  \\propto  L(\\sigma^2) \\times g(\\sigma^2) \\\\\n       \\propto  \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\theta)^2\\right)\n          \\times \\frac{\\exp(-\\beta/\\sigma^2) }{(\\sigma^2)^{\\alpha+1} }  \\nonumber \\\\\n       =  \\frac{1}{(\\sigma^2)^{\\alpha+n/2+1}} \\exp\\left(-\\frac{1}{ \\sigma^2}\\left[\\beta+ \\frac{1}{2}\\sum_{i=1}^n (y_i - \\theta)^2\\right]\\right),\\nonumber \\\\\n\\end{eqnarray*}\\] which we recognize as a inverse gamma density with updated parameters \\(\\alpha_1 = \\alpha + n/2\\) and \\(\\beta_1 = \\beta+ \\frac{1}{2} \\sum_{i=1}^n (y_i - \\theta)^2\\).\nIt is common to represent the inverse gamma prior and posterior densities in terms of the ``scale times inverse chi-square” density. A chi-square random variable with \\(\\nu\\) degrees of freedom has density \\[\nf(w) \\propto w^{\\nu/2-1} \\exp(-w/2), \\, w > 0.\n\\] The random variable \\(V = c / W\\) has the density \\[\nf(v) \\propto \\frac{1}{v^{\\nu/2+1}} \\exp\\left(-\\frac{c}{2 v}\\right), \\, v > 0.\n\\] Since the density of \\(V\\) is derived as a constant divided by a chi-squared variable, we write \\[\nV \\sim c \\chi^{-2}_\\nu .\n\\] Using this notation, our inverse gamma prior can represented as $ 2 ^{-2}_{2 }$ and likewise the posterior is represented as $ 2 1 ^{-2}{2 _1}$.\n\n\n5.3.2 Inference using a noninformative prior\nIn the case where one has little prior information about a variance, the standard noninformative prior is given by the improper density \\[\ng(\\sigma^2) = \\frac{1}{\\sigma^2}, \\, \\, \\sigma^2 > 0.\n\\] This can viewed as a limiting case of the inverse gamma density as the shape parameter \\(\\alpha\\) and the rate parameter \\(\\beta\\) both approach zero. If this prior is combined with the likelihood, one obtains the posterior density \\[\\begin{eqnarray*}\ng(\\sigma^2 | y)\n       =  \\frac{1}{(\\sigma^2)^{n/2+1}} \\exp\\left(-\\frac{1}{ \\sigma^2}\\left[\\frac{1}{2}\\sum_{i=1}^n (y_i - \\theta)^2\\right]\\right),\\nonumber \\\\\n\\end{eqnarray*}\\] which is inverse gamma with parameters \\(\\alpha_1 = n/2\\) and \\(\\beta_1 = \\frac{1}{2} \\sum_{i=1}^n (y_i - \\theta)^2\\). Relating the posterior to the inverse chi-squared distribution, we can say that \\[\n\\sigma^2 \\sim (\\sum_{i=1}^n (y_i - \\theta)^2) \\chi^{-2}_{n}.\n\\]\n\n\n5.3.3 An example\nTo illustrate learning about a variance, consider the following winning percentages for all Major League Baseball teams in the 1964 season. These can be considered a random sample of percentages from a normal distribution with mean \\(\\mu = 50\\) and unknown variance \\(\\sigma^2\\). The value of the variance is a measure of the level of competition in the baseball league where small values of \\(\\sigma^2\\) correspond to teams that are relatively equal in ability.\n57.4 56.8 56.8 55.6 54.3 49.4 49.4 46.9 40.7 32.7 \n61.1 60.5 59.9 52.5 50.6 48.8 48.8 44.4 38.3 35.2\nSuppose one has some prior knowledge about the value of \\(\\sigma^2\\). The value of the sample variance of the team winning percentages during the previous season is equal to 69.2 and you are pretty confident (with probability 0.90) that the variance \\(\\sigma^2\\) is within 20% of 69.2. With some trial and error, one finds that the inverse gamma density with \\(\\alpha = 70\\) and \\(\\beta = 4500\\) approximately matches this prior information.\nFrom the observed data, we compute \\[\nn = 20, \\, \\, \\sum_{i=1}^n (y_i - 50)^2 = 1321.45.\n\\] So the posterior density will be inverse gamma(\\(\\alpha_1, \\beta_1)\\) with \\[\n\\alpha_1 = 70 + 20/2 = 80, \\, \\, \\beta_1 = 4500 + 1321.45/2 = 5160.725\n\\]\nOne can summarize the posterior by computing suitable percentiles. Statistics packages like R typically have functions for computing percentiles of a gamma distribution and these functions can be used to find percentiles of the inverse gamma distribution. For example, suppose one wishes to find the pth percentile \\(x_p\\) of a inverse gamma(\\(\\alpha, \\beta\\)) density – the median satisfies the relationship \\[\nP( X < x_p) = p,\n\\] where \\(X\\) is inverse gamma(\\(\\alpha, \\beta\\)). One can rewrite this statement as \\[\nP(1/X > 1/x_p) = p,\n\\] where \\(Y = 1/X\\) has a gamma(\\(\\alpha, \\beta\\)) density. Using this relationship, it is straightforward to show that the inverse gamma percentile satifies \\[\nx_p = \\frac{1}{y_{1-p}},\n\\] where \\(y_{1-p}\\) is the \\((1-p)\\) percentile of a gamma(\\(\\alpha, \\beta\\)) density.\nThe 5th, 50th, and 95th percentiles of the inverse gamma posterior distribution are displayed in Table 3.3. The median (50th percentile) of 64.78 is a reasonable point estimate at \\(\\sigma^2\\) and the 5th and 95th percentiles, 54.17 and 78.34, form a ``equal-tails” interval estimate. In the case where prior information is not available for the variance, one can place a noninformative prior with \\(\\alpha = 0, \\beta = 0\\) on \\(\\sigma^2\\) and the table also shows the posterior percentiles for this choice of prior. In this situation, the informative prior information has a substantial impact on the posterior inference and the posterior interval estimate with the informative prior is significantly shorter than the interval estimate with the vague prior.\n\n\n\nPrior\n5th Percentile\nMedian\n95th Percentile\n\n\n\n\nInverse Gamma(70, 4500)\n54.17\n64.78\n78.34\n\n\nNoninformative\n42.07\n68.34\n121.78"
  },
  {
    "objectID": "single_parameter.html#learning-about-a-poisson-mean",
    "href": "single_parameter.html#learning-about-a-poisson-mean",
    "title": "5  Single Parameter Inference",
    "section": "5.4 Learning About a Poisson Mean",
    "text": "5.4 Learning About a Poisson Mean\n\n5.4.1 Introduction\nThe author has a website for one of his books and Google Analytics ({}) records the number of visits to this particular website every day.\nThe author records the following counts of weekday visits for a 21-day period during May and June of 2009.\n 20 30 22 20 20 17 21 26 22 30 36\n 15 30 27 22 23 18 24 28 23 12\nA common model for count data such as these is the Poisson. Suppose the counts \\(y_1, ..., y_n\\) represent a random sample from a Poisson distribution with parameter \\(\\lambda\\) with probability mass function \\[\np(y | \\lambda) = \\frac{\\exp(-\\lambda) \\lambda^y}{y!}, \\, \\, y = 0, 1, 2, ...\n\\] One objective is to learn about the mean parameter \\(\\lambda\\). In the example, \\(\\lambda\\) would represent the average number of hits to this website over a long period of days. Also we are interested in predicting the number of website counts in future days.\nSuppose that the author has been observing the counts for daily visits to this website and so he has some beliefs about the location of \\(\\lambda\\) before sampling. In particular, he believes that the quartiles of \\(\\lambda\\) are 21.3 and 26.4. Equivalently, one believes \\[\nP(\\lambda < 21.3) = 0.25, \\, \\, P(\\lambda < 26.4) = 0.75.\n\\] Any prior density \\(g(\\lambda)\\) that matches this prior information would suitable for use in this example. But we’ll shortly see that it is convenient to choose a gamma density. After some trial and error, the author finds that the gamma prior density \\[\ng(\\lambda) = \\frac{\\exp(-\\beta \\lambda) \\lambda^{\\alpha-1} \\beta^\\alpha}{\\Gamma(\\alpha)}, \\lambda > 0,\n\\] where the shape parameter \\(\\alpha = 40\\) and the rate parameter \\(\\beta = 1.67\\) approximately matches these prior quartiles.\n\n\n5.4.2 Learning about the Mean\nAfter counts have been observed, one’s opinion about \\(\\lambda\\) is based on the posterior distribution. First, one finds the likelihood \\(L(\\lambda)\\). By the independence assumption, the joint mass function of the counts \\(y_1, ..., y_n\\) is given by the product \\[\np(y_1, ..., y_n | \\lambda) = \\prod_{i=1}^n \\frac{\\exp(-\\lambda) \\lambda^y_i}{y_i!}.\n\\] Once the counts are observed, then the likelihood function is this joint mass function, viewed as a function of \\(\\lambda\\). \\[\\begin{eqnarray*}\nL(\\lambda)  =  \\prod_{i=1}^n \\frac{\\exp(-\\lambda) \\lambda^y_i}{y_i!} \\nonumber \\\\\n            =  C \\exp(-n \\lambda) \\lambda ^s,  \\nonumber \\\\\n\\end{eqnarray*}\\] where \\(n\\) is the sample size, $s = _{i=1}^n y_i $ is the sum of observations, and \\(C\\) is a constant not depending on the parameter \\(\\lambda\\).\nThe posterior of \\(\\lambda\\) is found by multiplying the prior and the likelihood: \\[\\begin{eqnarray*}\ng(\\lambda| y)  \\propto  g(\\lambda) \\times L(\\lambda) \\nonumber \\\\\n          =  \\exp(-\\beta \\lambda) \\lambda^{\\alpha-1} \\times \\exp(-n \\lambda) \\lambda ^s \\nonumber \\\\\n            =  \\exp(-(\\beta + n) \\lambda) \\lambda^{\\alpha + s -1}.\n\\end{eqnarray*}\\] One sees that the posterior density of \\(\\lambda\\) is also of the gamma functional form with updated parameters \\[\n\\alpha_1 = \\alpha + s, \\, \\, \\beta_1 = \\beta + n .\n\\] For our example, a Gamma(\\(\\alpha, \\beta\\)) prior was assigned with \\(\\alpha = 40\\) and \\(\\beta = 1.67\\). From the observed data, there are \\(n = 21\\) observations and the sum of the counts is \\(s = \\sum_{i=1}^n y_i = 486\\). So the posterior density for \\(\\lambda\\) will be gamma(\\(\\alpha_1, \\beta_1)\\) where \\[\n\\alpha_1 = 40 + 486 = 526, \\, \\, \\beta_1 = \\beta + n = 1.67 + 21 = 22.67.\n\\]\nOne can estimate \\(\\lambda\\) by the posterior median that is 23.19. A 90% interval estimate for \\(\\lambda\\) is formed from the 0.05 and 0.95 quantiles of the gamma(526, 22.67) density given by 21.56 and 24.89. So the mean number of website visits falls in the interval (21.56, 24.89) with probability 0.90.\n\n\n5.4.3 Prediction\nNext, suppose we are interested in predicting the number of websites \\(\\tilde y\\) on a future weekday. If our current beliefs about the mean \\(\\lambda\\) are given by a Gamma(\\(\\alpha, \\beta\\)) distribution, then the predictive density of \\(\\tilde y\\) is given by \\[\\begin{eqnarray*}\nf(\\tilde y)  =  \\int_0^\\infty f(\\tilde y | \\lambda) g(\\lambda) d\\lambda\\nonumber \\\\\n            =  \\int_0^\\infty \\frac{\\lambda^{\\tilde y} \\exp(-\\lambda)}{\\tilde y!} \\times\n                               \\frac{\\lambda^{\\alpha-1} \\exp(-\\beta \\lambda) \\beta^\\alpha}{\\Gamma(\\alpha)}  d\\lambda \\nonumber \\\\\n\\end{eqnarray*}\\] One can analytically integrate out \\(\\lambda\\), obtaining the predictive density \\[\nf(\\tilde y) = \\frac{\\beta^\\alpha \\Gamma(\\alpha + \\tilde y)}{(\\beta + 1)^{\\alpha + \\tilde y} \\Gamma(\\alpha) y!}, \\, y = 0, 1, 2, ...\n\\]\nIn our example, after observing the data, the current beliefs about \\(\\lambda\\) are contained in the Gamma(526, 22.67) posterior density. The corresponding {} density is the distribution of a future number of website visits for a future weekday. Using R, we compute values of \\(f(\\tilde y)\\) for values of \\(\\tilde y\\) from 0 to 200. We find that the most likely value of \\(\\tilde y\\), the value with the largest predictive probability, is equal to 23. But there is much uncertainty about this prediction since (1) we are uncertain about the mean number of hits \\(\\lambda\\) and (2) there is Poisson variability about the number of hits \\(\\tilde y\\) given a value of \\(\\lambda\\).\nUsing the R function {}, we find that \\[\nP( 15 \\le \\tilde y \\le 31) = 0.917,\n\\] so (15, 31) is a 91.7% prediction interval for this future count.\nThe predictive density is useful for making predictions about future data. It is also helpful in judging the suitability of our Poisson/gamma model. The basic idea is that our model is reasonable if the actual observed data is consistent with predictions made from the model. We just saw that approximately 90% of the predictions fall between 15 and 31 visits. Looking at our data, we see that only 2 of the 21 observations (namely 12 and 36) fall outside of the interval (15, 31). Since the observed data appears consistent with the posterior predictive distribution, the model with Poisson sampling and a gamma(40, 1.67) prior seems to be a reasonable description of the observed counts."
  },
  {
    "objectID": "single_parameter.html#learning-about-an-exponential-threshold-parameter",
    "href": "single_parameter.html#learning-about-an-exponential-threshold-parameter",
    "title": "5  Single Parameter Inference",
    "section": "5.5 Learning About an Exponential Threshold Parameter",
    "text": "5.5 Learning About an Exponential Threshold Parameter\nIn a reliability application, suppose that one observes the times to failure for a sample of washing machines. We assume that the failure times \\(y_1, ..., y_n\\) represent a random sample from an exponential distribution with threshold \\(\\theta\\) and known rate \\(\\beta\\). The sampling density is given by \\[\nf(y | \\theta) = \\beta \\exp(-\\beta (y - \\theta)), \\, \\, y \\ge \\theta.\n\\] In this application, the parameter \\(\\theta\\) can represent the length of a warranty period where no failures can occur.\nTo simplify the problem, we are assuming that one does not know the warranty period but knows the parameter \\(\\beta\\) that describes the pattern of failures after the warranty period.\nFirst, suppose that little information exists about the value of the positive parameter \\(\\theta\\), and so we assign this parameter a uniform prior on positive values: \\[\ng(\\theta) = 1, \\, \\, \\theta > 0.\n\\] The likelihood function is given by \\[\\begin{eqnarray*}\nL(\\theta)  =  \\prod_{i=1}^n f(y_i | \\theta) \\nonumber \\\\\n            =  \\prod_{i=1}^n \\left( \\beta \\exp(-\\beta (y_i - \\theta)) I(y_i \\ge \\theta) \\right) \\nonumber \\\\\n            \\propto  \\exp(n \\beta \\theta) I(\\theta \\le \\min y_i)  \\nonumber \\\\\n\\end{eqnarray*}\\] Combining the likelihood and prior, we see that the posterior density is defined, up to a proportional constant, by \\[\\begin{eqnarray*}\ng(\\theta | y)  \\propto  L(\\theta) g(\\theta) \\nonumber \\\\\n            \\propto  \\exp(n \\beta \\theta) I(0 < \\theta \\le \\min y_i). \\nonumber \\\\\n\\end{eqnarray*}\\] We see that the posterior density is an exponential density with rate \\(n \\beta\\) that is truncated to the right by \\(\\min y_i\\).\nAs an example, suppose that one observes the following failure times (in months) for 15 refrigerators:\n 51.8  50.8  20.6  42.4  20.5  18.7  27.9  18.7  \n 42.9 123.7  62.7  22.8  89.6  21.4  49.4\nFrom past experience, one knows that \\(\\beta = 1/24\\) – this indicates the belief that the average failure time for a refrigerator will be 24 months after the warranty time. If one assigns a uniform prior, then the posterior density for the warranty time \\(\\theta\\) is given by \\[\\begin{eqnarray*}\ng(\\theta | y)  \\propto  \\exp(n \\beta \\theta) I(0 < \\theta \\le \\min y_i) \\nonumber \\\\\n            \\propto  \\exp(15/24 \\theta) I(0 < \\theta \\le 18.7). \\nonumber \\\\\n\\end{eqnarray*}\\] When one normalizes the density, one finds the posterior density is equal to \\[\ng(\\theta | y) = \\frac{\\exp(15/24 \\theta)}{1- \\exp(15/24 \\times 18.7)}, \\, \\, 0 < \\theta < 18.7.\n\\]\nIf one graphs this density, one sees that the posterior density for \\(\\theta\\) is strongly left skewed with a mode at 18.7 months.\nA HPD interval for the threshold clearly will have the form \\((\\theta_0, 18.7)\\) where \\(\\theta_0\\) is chosen so that the probability content has the given level of \\(\\gamma\\). If one desires a 90% interval estimate where \\(\\gamma = 0.90\\), then a straightforward calculation shows that the HPD interval for \\(\\theta\\) is given by (16.0, 18.7).\n Exercise: Assume \\(\\theta\\) has the prior \\[\ng(\\theta) \\propto \\exp(a \\theta), \\, \\, \\theta < b .\n\\]\n\nFind the posterior density for \\(\\theta\\).\nShow that the posterior has the same functional form as the prior with updated parameters \\[\na_1 = n \\beta + a, \\, \\, b_1 = \\min(\\min y_i, b)).\n\\]\nSuppose one believes that the threshold \\(\\theta\\) is definitely smaller than 24 months and you are 90% sure the threshold is larger than 15 months. Find values of the parameters \\(a\\) and \\(b\\) that match these prior beliefs.\nUsing the prior constructed in part (c) and the refrigerator failure data, find a 90% interval estimate for the threshold parameter \\(\\theta\\). Compare this interval estimate with the interval estimate using a noninformative prior."
  },
  {
    "objectID": "single_parameter.html#using-mixtures-of-conjugate-priors",
    "href": "single_parameter.html#using-mixtures-of-conjugate-priors",
    "title": "5  Single Parameter Inference",
    "section": "5.6 Using Mixtures of Conjugate Priors",
    "text": "5.6 Using Mixtures of Conjugate Priors\nOne way of extending the class of conjugate priors is by the use of discrete mixtures. We illustrate the use of mixtures for the Poisson scenario, although this approach can be applied to any sampling model where there is a conjugate prior.\nSuppose we assign the Poisson parameter \\(\\lambda\\) the discrete mixture prior \\[\ng(\\lambda) = p g_1(\\lambda) + (1 - p) g_2(\\lambda)\n\\] where \\(g_1\\) is gamma(\\(\\alpha_1, \\beta_1\\)), \\(g_2\\) is gamma(\\(\\alpha_2, \\beta_2)\\), and \\(p\\) is a known mixing probability between 0 and 1.\nSuppose we observe (\\(y, t\\)), where \\(y\\) is the count in the time interval \\(t\\). We assume that \\(y\\) is Poisson(\\(t \\lambda\\)) with density \\[\nf(y | \\lambda) = \\frac{(t \\lambda)^y \\exp(-t \\lambda)}{y!}, \\, \\, y = 0, 1, 2, ...\n\\]\nIn the following computation, we include all of the terms to motivate a special expression for the posterior density. The posterior density for \\(\\lambda\\) is given by \\[\\begin{eqnarray*}\ng(\\lambda| y)  =  \\frac{g(\\lambda) \\times f(y | \\lambda)}{f(y)} \\nonumber \\\\\n          =  \\frac{\\left(p g_1(\\lambda) + (1-p) g_2(\\lambda)\\right)\\times f(y | \\lambda)}{f(y)} \\nonumber \\\\\n          =  \\frac{p g_1(\\lambda)f(y | \\lambda) + (1-p) g_2(\\lambda)f(y | \\lambda)}{f(y)}. \\nonumber \\\\\n\\end{eqnarray*}\\] The predictive density \\(f(y)\\) can be written as \\[\\begin{eqnarray*}\nf(y)  =  \\int_0^\\infty g(\\lambda) f(y|\\lambda) d\\lambda \\nonumber \\\\\n          =  \\int_0^\\infty \\left( p g_1(\\lambda)f(y | \\lambda) + (1-p) g_2(\\lambda)f(y | \\lambda)\\right) d\\lambda \\nonumber \\\\\n          =  p f_1(y) + (1-p) f_2(y) \\nonumber ,\\\\\n\\end{eqnarray*}\\] where \\(f_1\\) and \\(f_2\\) are respectively the predictive densities for \\(y\\) when \\(\\lambda\\) is assigned the priors \\(g_1\\) and \\(g_2\\), respectively. If we substitute this expression into the posterior density expression and rearrange terms, one can see that the posterior density has the representation \\[\ng(\\lambda | y) = p(y) g_1(\\lambda | y) + (1- p(y)) g_2 (\\lambda | y),\n\\] where \\(g_1(\\lambda | y)\\) and \\(g_2(\\lambda | y)\\) are the posterior densities assuming the priors \\(g_1\\) and \\(g_2\\) and \\[\np(y) = \\frac{ p f_1(y)}{p f_1(y) + (1-p) f_2(y)}.\n\\] When \\(g_1\\) and \\(g_2\\) are gamma (conjugate) priors, then the posterior density will also be a mixture of gamma distributions, where the mixing weights \\(p(y)\\) and \\(1 - p(y)\\) depend on the mixing probability \\(p\\) and the predictive densities \\(f_1(y)\\) and \\(f_2(y)\\) using the two priors.\nTo illustrate the use of mixtures, suppose I am interested in learning about the home run rate \\(\\lambda\\) for the baseball player Derek Jeter before the start of the 2004 season. (A home run rate is the proportion of official at-bats that are home runs.) Suppose my prior beliefs are that the median of \\(\\lambda\\) is equal to 0.05 and the 90th percentile is equal to 0.081. Here are two priors that match this information. The first is a conjugate Gamma prior and the second is a mixture of two conjugate Gamma priors with mixing probabilities 0.88 and 0.12.\n\nPrior 1: Gamma(shape = 6, rate = 113.5)\nPrior 2: 0.88 x Gamma(shape = 10, rate = 193.5) + 0.12 x Gamma(shape = 0.2, rate = 0.415)\n\nOne can check that these two priors match the prior beliefs. If one graphs the two priors, they are similar in location and spread but the mixture prior (Prior 2) has flatter tails.\nNow we observe some data – Jeter hit \\(y = 23\\) homeruns in \\(t = 643\\) at-bats. If one assumes Prior 1, then one can show that the posterior density for \\(\\lambda\\) will be Gamma with shape \\(29\\) and rate \\(756.5\\). If one uses the mixture Prior 2, then the posterior density can be shown to be \\[\ng(\\lambda|y) = 0.98 \\times Gamma(33.0, 836.5) + 0.02 \\times Gamma(23.3, 643.4).\n\\] Does the choice of prior make a difference in this situation? If one plots the two posterior densities on the same scale, they look barely distinguishable, indicating that inference about \\(\\lambda\\) is robust or insensitive to the choice of prior.\nBut this robustness of the inference with respect to the prior depends on the observed data. Suppose that Jeter is a ``steriod slugger” during the 2004 season and hits 70 home runs in 500 at-bats. If we again use the same two priors, the posterior density for \\(\\lambda\\) using Prior 1 will be Gamma(76, 693.5). The posterior using Prior 2 is given by the mixture \\[\ng(\\lambda | y) = 0.23 \\times Gamma(80, 693.5) + 0.77 \\times Gamma(70.2, 500.4).\n\\] If one draws the two posteriors on the same scale, one sees that the two posterior densities are significantly different, indicating that the inference depends on the choice of prior."
  },
  {
    "objectID": "prior.html",
    "href": "prior.html",
    "title": "6  Prior Distributions",
    "section": "",
    "text": "In a Bayesian analysis, one needs to specify a density \\(g(\\theta)\\) that reflects one’s prior beliefs about the location of the parameter \\(\\theta\\). The problem is that one typically has only knowledge about a typical value of \\(\\theta\\) and some information about the sureness of this guess. The question is: “How can one construct a prior density that represents this imprecise prior information?”\nIn this section, we will talk about constructing a prior for a proportion, although the discussion will extend to any single parameter.\nTo use a concrete example, suppose I’m interested in the proportion of students \\(p\\) at my university who send or receive text messages while driving. I wish to construct a prior for \\(p\\) that reflects my beliefs about the size of this proportion.\nA standard approach for constructing a prior assumes that \\(p\\) has density that is a member of a familiar functional form, and one chooses the parameters of the density that match one’s beliefs. For a proportion, the usual choice for density is a beta curve with parameters \\(a\\) and \\(b\\). This simplifies the prior assessment task considerably. Instead of constructing an entire density function, one needs only to assess two parameter values. The implicit assumption is that the beta family of distributions is sufficiently flexible to represent different beliefs about the proportion value.\nTo choose the parameters \\(a\\) and \\(b\\), one matches these parameter values with statements about the location and spread of the density. We typically measure location by the mean and spread by the standard deviation – these moments have simple expressions for the beta family: \\[\nE(p) = \\frac{a}{a+b}, \\, \\, SD(p) = \\sqrt{\\frac{a b}{(a+b)^2 (a + b + 1)}}.\n\\] One can guess at the mean and standard deviation of \\(p\\), then use the expressions to find values of the matching parameters \\(a\\) and \\(b\\).\nUnfortunately, there are problems using this method. It is generally hard to specify a mean and standard deviation of a parameter. The moments of a prior can be significantly affected by the tails of the distribution, but one typically has little information about the tail portion of the prior. It is typically easier to state beliefs about location and spread in terms of percentiles of the distribution.\nIn our example, it seems easy to first think about the median of my prior. I think of a value \\(p_{0.5}\\), such that the proportion of text-messaging drivers is equally likely to be smaller or larger than that value. After some reflection, I decide that \\(p_{0.5}\\) = 0.10. Next, I express my belief about spread by thinking about a second percentile, say the 90th. I specify a proportion value \\(p_{0.9}\\) such that it is unlikely (with 10% probability) that \\(p\\) will larger than that value. This is a harder value to specify. After some thought, I decide on \\(p_{0.9}\\) = 0.25. I then match these two percentiles with a beta curve. Using the {} function, I find that the beta curve with \\(a = 1.41\\) and \\(b = 10.15\\) match my beliefs.\nIs the beta(1.41, 10.15) density a good representation of my prior beliefs? To check, one can assesses other percentiles of the prior and see if they match up with the beta density. In our example, suppose that I also believe that the 10th percentile of my prior is \\(p_{0.1} = 0.05.\\). Since the 10th percentile of the beta(1.41, 10.15) prior is 0.024, there is some incompatability of my prior information with the fitted beta curve. By several of these checks, I can adjust the values of the beta shape parameters so it seems to be a better representation of my beliefs.\n\n\n\nOne difficulty in specifying a prior is that the parameter \\(p\\) is relatively abstract. In this example, \\(p\\) represents the proportion of {} students at my university who text while driving. It may be easier to think about the proportion of a {} of students who are texting.\nSuppose you have a random sample of \\(n = 20\\) students. Assuming a beta(\\(a, b\\)) prior, the number \\(y\\) of students who text while driving has a beta-binomial predictive distribution of the form \\[\\begin{eqnarray*}\nf(y | a, b) = \\int_0^1 {n \\choose y} p^y (1-p)^{n-y} \\frac{1}{B(a, b)} p^{a-1} (1-p)^{b-1} dp\n\\nonumber \\\\\n   =  {n \\choose y} \\frac{B(a+y, b+n-y)}{B(a, b)}, \\, \\, y = 0, ..., n \\nonumber \\\\\n\\end{eqnarray*}\\]\nSuppose our initial assessment for \\(p\\) resulted in a beta(1.41, 10.15) prior. Using the beta-binomial distribution, we can use this prior to predict the number of text message students in the sample of \\(n = 20\\) students. By using the function {} in the LearnBayes package, we find that that \\(P(y \\le 4)= 0.827\\) and \\(P(y \\le 5)= 0.934\\). If those probabilities don’t reflect your beliefs about the plausibility of the events \\(y \\le 4\\) and \\(y \\le 5\\), then some adjustment needs to be made to the values of the beta shape parameters."
  },
  {
    "objectID": "prior.html#noninformative-prior",
    "href": "prior.html#noninformative-prior",
    "title": "6  Prior Distributions",
    "section": "6.2 Noninformative Prior",
    "text": "6.2 Noninformative Prior\n\n6.2.1 Uniform prior\nIn the event that little or no information exists about a parameter, then one can assign a vague or noninformative prior. When Thomas Bayes wrote his famous Bayesian paper, he placed a uniform prior on an unknown proportion. This certainly seems like a reasonable choice since this reflects the belief that any subset of \\(p\\) of the same length has the same probability.\nSuppose instead of the proportion \\(p\\), we focus on the parameter \\(p^2\\) that in our example represents the probability (conditional on \\(p\\)) that two consecutive sampled students text while driving. Since \\(p^2\\) is an unknown parameter on the unit interval, it certainly is reasonable to assign \\(p^2\\) a uniform prior. But if \\(p\\) has a uniform prior, it is straightforward to show using a transformation argument that \\(\\theta = p^2\\) has the density \\[\ng(\\theta) = \\frac{1}{2 \\sqrt{\\theta}}, \\, \\, 0 < \\theta < 1.\n\\] So if the proportion has a uniform prior, then the proportion squared has a nonuniform prior that favors values of \\(p^2\\) near zero.\nA uniform prior is not transformation invariant. This means that the belief in uniformity of a parameter will change under a nonlinear transformation. Since it is unclear which parameter (in our example, \\(p\\) or \\(p^2\\)) should be uniform, this notion of uniformity will not lead to a unique choice of prior.\n\n\n6.2.2 Improper prior\nSometimes improper priors, that is, prior densities that don’t integrate to one, will be chosen as noninformative priors. These type of priors can seem appropriate for use in particular applications. However, their use should be made with some caution, since the choice of an improper prior may lead to an improper posterior distribution.\nConsider again the family of beta\\((a, b)\\) priors for the proportion \\(p\\). The parameters \\(a\\) and \\(b\\) can be viewed as the respective number of successes and number of failures in a preliminary experiment. The total amount of information in the experiment is measured by the “preliminary sample size” \\(a+ b\\). If we have little information about the proportion, it is reasonable to let both \\(a\\) and \\(b\\) approach zero, resulting in the improper prior \\[\ng(p) \\propto \\frac{1}{p(1-p)}, \\, \\, 0 < p < 1.\n\\] The corresponding posterior density, given \\(y\\) successes in \\(n\\) trials, is equal to \\[\ng(p | y) \\propto p^{y-1} (1-p)^{n-y-1} .\n\\] This will be a proper posterior density only if the number of successes is in the interval from 1 to \\(n-1\\). If one observes no successes (\\(y = 0\\)) or all failures (\\(y = n\\)), the posterior density will be improper.\nIn the binomial situation, it is best to avoid these awkward situations and use a prior where both \\(a\\) and \\(b\\) are positive. In the next section, we will derive one type of “optimal” prior which does not result in an improper posterior.\n\n\n6.2.3 Jeffreys prior\nOne popular way of defining a noninformative prior was suggested by Harold Jeffreys. To define this prior, we review the concept of information. If a single observation \\(y\\) has a sampling density \\(f(y | \\theta)\\), then we define the Fisher information as \\[\nI(\\theta) = - E\\left[ \\frac{\\partial^2}{\\partial \\theta^2} \\log f(y | \\theta) \\right],\n\\] where the expectation is taken over the distribution of \\(y\\). As an example, suppose the binary observation \\(y\\) has the density \\[\nf(y | p) = p^y (1-p)^{1-y}, y = 0, 1.\n\\] An easy calculation shows that the information is given by \\[\nI(p) = \\frac{1}{p(1-p)}.\n\\] If we have independent observations \\(y_1, ..., y_n\\) from \\(f(y|\\theta)\\) and \\(I^*\\) denotes the information, then it can be shown that \\(I^*(\\theta) = n I(\\theta)\\), where \\(I\\) is the information for a single observation. Applying this result, if we have a sample of Bernoulli(\\(p\\)) observations \\(y_1, ..., y_n\\), then the information based on this sample is \\[\nI(p) =  \\frac{n}{p(1-p)}.\n\\]\nJeffreys suggests that a suitable noninformative prior is the square root of the information \\[\ng(\\theta) = \\sqrt{I(\\theta)}.\n\\] The reasoning for this prior is based on the fact that this prior is invariant under transformation. Suppose \\(\\theta\\) is assigned this prior and one transforms \\(\\theta\\) to a new parameter \\(\\eta = h(\\theta)\\). Then one can show that the prior on \\(\\eta\\) is given by the same functional form \\[\ng_1(\\eta) = \\sqrt{I(\\eta)}.\n\\]\nIn the Bernoulli case, we have already shown that the information \\(I(p) = 1/(p(1-p))\\). So the Jeffreys prior is given by \\[\ng(p) = \\sqrt{I(p)} = \\frac{1}{\\sqrt{p(1-p)}} = p^{1/2-1} (1-p)^{1/2-1}.\n\\]\nAt this point, we have talked about three possible priors for a proportion that are all special or limiting cases of a beta density. The choice \\(a = b = 1\\) leads to the uniform prior used by Bayes, \\(a = b = 1/2\\) leads to the Jeffreys prior, and the limiting case where \\(a\\) and \\(b\\) approach zero results in the improper prior proportional to \\((p(1-p))^{-1}\\)."
  },
  {
    "objectID": "many_parameters.html",
    "href": "many_parameters.html",
    "title": "7  Many Parameter Inference",
    "section": "",
    "text": "In this chapter, we illustrate Bayesian learning from several two parameter problems. Building on the one-parameter posteriors of Chapter 4, we first illustrate learning about both parameters of the normal density with noninformative and informative priors. To compare two independent Poisson samples, we illustrate computing the marginal posterior density of the ratio of Poisson means. Last, we illustrate learning about both the sample size and the probability of success for binomial data where only the number of successes is observed. In this final example, we illustrate constructing a dependent prior for the two parameters in a baseball setting where historical data is available."
  },
  {
    "objectID": "many_parameters.html#normal-sampling-with-both-parameters-unknown",
    "href": "many_parameters.html#normal-sampling-with-both-parameters-unknown",
    "title": "7  Many Parameter Inference",
    "section": "7.2 Normal Sampling with Both Parameters Unknown",
    "text": "7.2 Normal Sampling with Both Parameters Unknown\n\n7.2.1 Noninformative Prior\nSuppose we observe \\(y_1, ..., y_n\\) from a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), where both parameters are unknown. We assume that we have little prior knowledge about the location of either the mean or the variance, and so we assign \\((\\mu, \\sigma^2)\\) the usual noninformative prior \\[\ng(\\mu, \\sigma^2) = \\frac{1}{\\sigma^2}.\n\\]\nBefore we consider this situation, let’s review some results from the previous chapter.\n\nSuppose we wish to learn about the normal mean \\(\\mu\\) when the variance \\(\\sigma^2\\) is assumed known. If we assign \\(\\mu\\) the noninformative uniform prior, then the posterior distribution for \\(\\mu\\) is normal with mean \\(\\bar y\\) and variance \\(\\sigma^2/n\\).\nSuppose instead that we are interested in the variance \\(\\sigma^2\\) when the mean \\(\\mu\\) is known and the typical noninformative prior of the form \\(1/\\sigma^2\\) is assigned to the variance. Then \\(\\sigma^2\\) is distributed \\(S \\chi^{-2}_v\\) where \\(v=n\\) and \\(S = \\sum_{i=1}^n (y_i-\\mu)^2\\). \\end{enumerate}\n\nIn the general case where both parameters are unknown, the likelihood function is given by \\[\\begin{eqnarray*}\nL(\\mu, \\sigma^2)  =  \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (y_i - \\mu)^2\\right) \\nonumber \\\\\n                  \\propto  \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2\\right) \\nonumber \\\\\n\\end{eqnarray*}\\] If the likelihood is combined with the noninformative prior, we obtain the joint posterior density \\[\\begin{eqnarray*}\ng(\\mu, \\sigma^2 | y) \\propto  \\frac{1}{(\\sigma^2)^{n/2+1}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2\\right) \\nonumber \\\\\n\\end{eqnarray*}\\] Suppose one subtracts and adds the sample mean \\(\\bar y = \\frac{1}{n} \\sum_{i=1}^n y_i\\) in the expression \\(\\sum_{i=1}^n (y_i - \\mu)^2\\). Then one obtains the identity \\[\n\\sum_{i=1}^n (y_i - \\mu)^2 = \\sum_{i=1}^n (y_i - \\bar y)^2 + n (\\mu - \\bar y)^2 .\n\\] Using this identity and rearranging some terms, one obtains the following representation of the joint posterior density: \\[\\begin{eqnarray*}\ng(\\mu, \\sigma^2 | y) \\propto  \\frac{1}{(\\sigma^2)^{1/2}} \\exp\\left(-\\frac{n}{2 \\sigma^2} (\\mu - \\bar y)^2 \\right)\n                     \\times  \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\bar y)^2\\right). \\nonumber \\\\\n\\end{eqnarray*}\\]\nWhat we have done is represent the joint posterior density as the product of terms \\[\ng(\\mu, \\sigma^2 | y) = g(\\mu | \\sigma^2, y) \\times g(\\sigma^2 | y) .\n\\] The first term in the product represents the posterior density of the mean \\(\\mu\\) conditional on the variance \\(\\sigma^2\\) – we recognize this as a normal density with mean \\(\\bar y\\) and variance \\(\\sigma^2/n\\). The second term in the product is proportional to the marginal posterior density of \\(\\sigma^2\\). From our earlier work, we recognize this marginal density as the ``scale times inverse chi-square” form \\[\n\\sigma^2 \\sim S \\chi^{-2}_v,\n\\] where the degrees of freedom is \\(v=n-1\\) and the sum of squares \\(S = \\sum_{i=1}^n (y_i-\\bar y)^2\\). This posterior density is commonly called the {} distribution.\nIn this setting, typically one is interested in inferences about the normal mean \\(\\mu\\) and we base this inference on its marginal posterior density. This is obtained by integrating out \\(\\sigma^2\\) from the joint density. Using our earlier expressions, we write this integral as \\[\ng(\\mu | y) \\propto \\int_0^\\infty \\frac{1}{(\\sigma^2)^{n/2+1}}\n                      \\exp\\left(-\\frac{1}{2 \\sigma^2}\\left[ S + (\\mu - \\bar y)^2 \\right] \\right) d\\sigma^2.\n\\] At this point, it is helpful to recall the following integral identity for an inverse gamma integral \\[\n\\int_0^\\infty \\frac{1}{y^{a+1}} \\exp(-b y) dy = \\frac{\\Gamma(a)}{b^a} .\n\\] Since the above integral has this form with \\[\na = n/2, \\, \\, b = S + (\\mu - \\bar y)^2,\n\\] we see the marginal posterior density for \\(\\mu\\) is given by \\[\ng(\\mu | y) \\propto \\frac{1}{(S + (\\mu - \\bar y)^2)^{n/2}},\n\\] which has the t functional form. After some manipulation, one can show that the standardized random variable \\[\n\\frac{\\sqrt{n}(\\mu - \\bar y)}{\\sqrt{S/(n-1)}} = \\frac{\\sqrt{n}(\\mu - \\bar y)}{s},\n\\] where \\(s\\) is the sample standard deviation, has a standardized t distribution with \\(n-1\\) degrees of freedom.\nThis is a familiar result from sampling theory. If one samples from a normal population, then it is well-known that the ``t-statistic” \\[\nT = \\frac{\\sqrt{n}(\\bar y - \\mu)}{s}\n\\] has a t distribution with \\(n-1\\) degrees of freedom. Our result switches the role of the data \\(y\\) and the parameter \\(\\mu\\). Assuming the noninformative prior on \\(\\mu, \\sigma^2\\), the standardized marginal posterior of \\(\\mu\\) (with \\(y\\) fixed) has the same t distribution.\nWhat is the implication of this similarity of frequentist and Bayesian distribution results? It means that classical and Bayesian inferential procedures will agree in this setting. For example, suppose one is interested in a 95% interval estimate for the mean \\(\\mu\\). Then standard frequentist interval has the form \\[\n\\left(\\bar y - t_{n-1, .025}\\frac{s}{\\sqrt{n}}, \\bar y + t_{n-1, .025}\\frac{s}{\\sqrt{n}}\\right),\n\\] where \\(t_{n-1, .025}\\) is the upper .025 quantile of a t distribution with \\(n-1\\) degrees of freedom. In repeated sampling from a normal distribution, this interval will have 95% frequentist coverage. This is equivalant to saying that \\[\nP^{Data}\\left(\\bar y - t_{n-1, .025}\\frac{s}{\\sqrt{n}} < \\mu < \\bar y + t_{n-1, .025}\\frac{s}{\\sqrt{n}}\\right) = 0.95,\n\\] where the probability is taken over the {} observations \\(y_1, ..., y_n\\). From a Bayesian viewpoint, one can say that \\[\nP^\\mu\\left(\\bar y - t_{n-1, .025}\\frac{s}{\\sqrt{n}} < \\mu < \\bar y + t_{n-1, .025}\\frac{s}{\\sqrt{n}} | y \\right) = 0.95,\n\\] This means that the posterior probability that \\(\\mu\\) is contained in this fixed interval is 95%. The actual computed intervals of the standard frequentist and Bayesian procedures are identical. But the frequentist and Bayesian interpretations are very different. The frequentist statement refers to the characteristics of this interval in repeated sampling and the Bayesian statement refers to the property of this interval conditional on a particular set of observations \\(y_1, ..., y_n\\).\nA similar correspondence is true for inferences about the normal variance \\(\\sigma^2\\). We earlier noted that the marginal posterior density for the variance has the form \\(\\sigma^2 \\sim S \\chi^{-2}_{n-1}\\). Equivalently, one can say that the posterior of the function \\[\n\\frac{S}{\\sigma^2} = \\frac{\\sum_{i=1}^n (y_i - \\bar y)^2}{\\sigma^2}\n\\] is chi-squared with \\(n-1\\) degrees of freedom. From a frequentist perspective, if \\(\\sigma^2\\) is fixed, then the statistic \\[\nY = \\frac{\\sum_{i=1}^n (y_i - \\bar y)^2}{\\sigma^2}\n\\] has a chi-square (\\(n-1\\)) sampling distribution. Again this correspondence means that Bayesian inferential statements about a variance (assuming a noninformative prior) will be numerically equivalent to the corresponding frequentist inferential statements. But the interpretation of these statements will be different. For an interval estimate, the posterior probability that a particular interval contains \\(\\sigma^2\\) is the given level. In contrast, the ``confidence” of the frequentist interval refers to the probability of containing the parameter in repeated sampling.\n\n\n7.2.2 Using a Informative Prior\nThe form for the posterior distribution for \\((\\mu, \\sigma^2)\\) in the noninformative case suggests the form for an informative conjugate prior. We assume that the prior for the mean \\(\\mu\\) conditional on the variance \\(\\sigma^2\\) has a normal distribution with mean \\(\\mu_0\\) and variance \\(\\sigma^2/n_0\\). Then we assume the marginal prior on \\(\\sigma^2\\) is distributed \\(S_0 \\chi^{-2}_{v_0}\\).\nHow do we interpret these parameters?\n\nThe prior mean \\(\\mu_0\\) is a guess at the normal mean and \\(n_0\\) is a number of ``prior observations” representing the sureness of this guess.\nA prior guess at the variance \\(\\sigma^2\\) is \\(S_0/v_0\\) and \\(v_0\\) represents the precision of this guess expressed again in term of prior observations.\n\nIf we apply this prior density, then it can be shown that the posterior density for \\((\\mu, \\sigma^2)\\) has the same normal-inverse-chisquare form. First, if we condition on \\(\\sigma^2\\), and combine the normal prior on \\(\\mu\\) with the normal likelihood, then the posterior density of \\(\\mu\\) is normal(\\(\\mu_1, \\sigma^2/n_1\\)), where \\[\n\\mu_1 = \\frac{n_0}{n_0 + n} \\mu_0 + \\frac{n}{n_0 + n} \\bar y,\n\\] and \\(n_1 = n_0 + n\\). Second, one can show that \\[\n\\sigma^2 \\sim S_1 \\chi^{-2}_{v_1},\n\\] where \\(v_1 = v_0 + n\\) and \\[\nS_1 = S_0 + S + \\frac{n_0 n}{n_1} (\\bar y - \\mu_0)^2 .\n\\]"
  },
  {
    "objectID": "many_parameters.html#comparing-two-poisson-means",
    "href": "many_parameters.html#comparing-two-poisson-means",
    "title": "7  Many Parameter Inference",
    "section": "7.3 Comparing Two Poisson Means",
    "text": "7.3 Comparing Two Poisson Means\nIn Chapter 4, we considered the problem of learning about the mean number of visits to a particular website during weekdays in Summer 2009. We only included the visit counts during the weekdays, since we suspected that there was a different pattern of visits between weekdays and weekends (Saturday and Sunday). We suspect that there are fewer visits on weekends, but would be interested in estimating the magnitude of the ``weekend effect.”\nSuppose we observe two independent Poisson samples. Counts {\\(y_{Ai}\\)} from the weekend days are assumed Poisson with mean \\(\\lambda_A\\) and counts {\\(y_{Bj}\\)} from the weekday days are assumed Poisson with mean \\(\\lambda_B\\). We are interested in learning about the ratio of means \\[\n\\gamma=\\frac{\\lambda_B}{\\lambda_A}.\n\\]\nThe first step is to find the likelihood of the parameters. Using the assumption of independence, the joint density of the counts {\\(y_{Ai}\\)} and {\\(y_{Bj}\\)} is given by \\[\nf(\\{y_{Ai}\\}, \\{y_{Bj}\\}|\\lambda_A, \\lambda_B) = \\left(\\prod_i\\frac{ \\lambda_A^{y_{Ai}}\\exp(-\\lambda_A)}{y_{Ai}!}\\right)\n                            \\left(\\prod_j\\frac{ \\lambda_B^{y_{Bi}}\\exp(-\\lambda_B)}{y_{Bj}!}\\right).\n\\] Following the work in Chapter 4, the likelihood can be expressed as \\[\nL(\\lambda_A, \\lambda_B) = \\exp(-n_A \\lambda_A) \\lambda_A^{s_A} \\exp(-n_B \\lambda_B) \\lambda_B^{s_B},\n\\] where \\(n_A\\) and \\(s_A\\) are respectively the sample size and the sum of observations from the first sample, and \\(n_B\\) and \\(s_B\\) are the analogous quantities from the second sample.\nSuppose we reparametrize the likelihood in terms of the first Poisson mean \\(\\theta = \\lambda_A\\) and the ratio of means \\(\\gamma=\\frac{\\lambda_B}{\\lambda_A}\\). Since \\(\\lambda_B = \\theta \\gamma\\), the likelihood function in terms of the new parameters is given by \\[\nL(\\theta, \\gamma) = \\exp(-n_A \\theta) \\theta^{s_A} \\exp(-n_B (\\theta\\gamma)) (\\theta\\gamma)^{s_B}.\n\\]\nSuppose prior information about the means is expressed through the parameters \\(\\theta\\) and \\(\\gamma\\). We assume that \\(\\theta\\) and \\(\\gamma\\) are independent with \\[\n\\theta \\sim Gamma(a_0, b_0), \\, \\, \\gamma \\sim Gamma(a_g, b_g).\n\\] Then the posterior density of \\((\\theta, \\gamma)\\) is given, up to a proportionality constant, by \\[\\begin{eqnarray*}\ng(\\theta, \\gamma | {\\rm data})  \\propto  \\exp(-n_A \\theta) \\theta^{s_A} \\exp(-n_B (\\theta\\gamma)) (\\theta\\gamma)^{s_B} \\nonumber \\\\\n                  \\times  \\theta^{a_0-1} \\exp(-b_0 \\theta) \\gamma^{a_g-1} \\exp(-b_g \\gamma) .\\nonumber \\\\\n\\end{eqnarray*}\\] Our interest is in the ratio of means \\(\\gamma\\) and \\(\\theta\\) is a nuisance parameter. We learn about \\(\\gamma\\) by its marginal posterior density obtained from integrating out \\(\\theta\\) from the joint posterior density. \\[\ng(\\gamma | {\\rm data}) = \\int_0^\\infty  g(\\theta, \\gamma | {\\rm data}) d\\theta .\n\\] When one combines terms, one sees that, for a fixed value of \\(\\gamma\\), the integral has a gamma form in \\(\\theta\\). So one is able to analytically integrate out \\(\\theta\\), resulting in the marginal posterior density \\[\ng(\\gamma | {\\rm data}) \\propto \\frac{\\gamma^{s_B+a_g-1} \\exp(-b_g \\gamma)}{(n_A+n_B \\gamma + b_0)^{s_A + s_B + a_0}}.\n\\]\nIn our example, we first construct priors for \\(\\theta\\), the mean number of website visits during weekend days, and \\(\\gamma\\), the ratio of the mean weekday visits and the mean weekday visits. We choose the independent priors \\[\n\\theta \\sim Gamma(2, 1), \\, \\, \\gamma \\sim Gamma(8, 8).\n\\] The prior for \\(\\theta\\) reflects vague information about the mean number of visits during weekends, and the prior for \\(\\gamma\\) reflects the belief that website visits for weekends and weekdays are similar in size.\nNext, we observe the following individual counts of visits for \\(n_A = 10\\) weekend days and \\(n_B = 21\\) weekdays.\nweekend counts\n 7 12 11 12 12 17 17 18 20 17\n\nweekday counts\n20 30 22 20 20 17 21 26 22 30 36 15 30 27 22 23 18 24 28 23 12\nFrom these data, we compute \\(s_A = 143\\) and \\(s_B = 486\\). With the appropriate substitutions, the marginal posterior density of \\(\\gamma\\) is given by \\[\ng(\\gamma | {\\rm data}) \\propto \\frac{\\gamma^{486+8-1} \\exp(-8 \\gamma)}{(10 + 21 \\gamma + 1)^{143 + 486 + 2}}.\n\\]\nIn summarizing this marginal posterior for \\(\\gamma\\), we learn that the posterior mode is 1.66. So the website visits tend to be 66% higher on weekdays than on the weekends. In addition, a 90% interval estimate for \\(\\gamma\\) is given by (1.44, 1.92). Since both values are larger than 1, one is pretty confident that there are more visits on weekdays than weekends."
  },
  {
    "objectID": "many_parameters.html#learning-about-a-sample-size-and-a-probability",
    "href": "many_parameters.html#learning-about-a-sample-size-and-a-probability",
    "title": "7  Many Parameter Inference",
    "section": "7.4 Learning about a Sample Size and a Probability",
    "text": "7.4 Learning about a Sample Size and a Probability\nIn the game of baseball, a batter gets an opportunity at the plate called an {}. He wants to get a base hit and a standard measure of hitting performance is the batting average \\[\nAVG = \\frac{H}{AB},\n\\] where \\(H\\) is the number of hits and \\(AB\\) the number of at-bats during a baseball season. A standard model for hitting assumes the number of hits \\(H\\) follows a binomial distribution with sample size \\(AB\\) and probability of success \\(p\\). The hitting ability of the batter can be measured by the probability of a hit \\(p\\).\nSuppose the player has obtained 200 hits during the season. What have you learned about the number of at-bats and probability of hit for this player? Can you predict the number of hits this player will get for the following season?\nThis problem is a bit unusual since one does not know the number of at-bats AB or the probability \\(p\\) for this player. But we have prior knowledge about the number of at-bats and the hitting probability that we can model by a prior distribution \\(g(AB, p)\\). By combining this prior with the likelihood, we can learn about the at-bats and probability of success by the posterior distribution, and we can use the predictive distribution to learn about the number of hits in the following season.\n\n7.4.1 Construction of a prior\nWe construct a prior for the pair (\\(AB, p\\)) by decomposing the prior as the product \\[\ng(AB, p) = g(AB) g(p | AB),\n\\] and separately construct the marginal prior for the at-bats \\(AB\\) and the prior of the hitting probability \\(p\\) conditional on the at-bats \\(AB\\).\nThe player is known to be a full-time player which means that the player obtains between 400 and 700 at-bats in a season. We can construct a prior for \\(AB\\) by looking at the distribution of at-bats for all players in a particular season. Figure 1 shows a histogram of the at-bats and the smooth curve represents a density estimate. We can use this density estimate as our prior density for \\(AB\\).\nNext, we construct a prior on the hitting probability \\(p\\) conditional on the number of at-bats \\(AB\\). We don’t know the player’s hitting probability, but we can collect the batting averages \\(AVG = H/AB\\) for all full-time players. Figure 2 shows a scatterplot of \\(AVG\\) against the at-bats \\(AB\\). We see from the superimposed least-squares fit that there is a positive relationship between the batting average and at-bats. So our prior mean for \\(p\\) will depend on \\(AB\\). We will use a beta density for \\(p\\) of the form \\[\ng(p | AB) \\propto p^{K \\eta - 1} (1 - p)^{K(1-\\eta)-1},\n\\] where \\(\\eta\\) is the mean and \\(K\\) is the precision parameter. We use the least-squares fit to obtain the prior mean \\[\n\\eta = E(p | AB) = 0.2208886 +   0.0001148 \\times AB .\n\\] It is more difficult to assess \\(K\\) since this reflects the variability in the hitting probability and Figure ?? shows the variability in the batting average \\(AVG = H/AB\\). Using techniques from the hierarchical modeling chapter, we choose the precision value \\(K = 400\\).\nFigure 3 displays a contour plot of the joint prior on \\((AB, p)\\). Note that the beliefs about the number of at-bats are pretty vague and \\(AB\\) and the hitting probability \\(p\\) are positively correlated as expected.\n\n\n7.4.2 Computation of the posterior and inference\nThe construction of the prior distribution was the biggest task in this problem. It is straightforward to compute and summarize the posterior distribution.\nWe observe the number of hits \\(H\\) for our player. The likelihood is simply the probability of obtaining \\(H\\) hits given values of the parameters \\(AB\\) and \\(p\\) which is given by the binomial form \\[\nL(AB, p) = {AB \\choose H} p^H (1- p)^{AB - H}.\n\\] Once \\(H\\) is observed, the posterior density of \\((AB, p)\\) is equal to the product of the prior and the likelihood: \\[\ng(AB, p | H) \\propto g(AB, p) L(AB, p)\n\\] In the following we will pretend that the number of at-bats \\(AB\\) is continuous. This will simplify the computational strategy in summarizing the posterior distribution.\nOur player is observed to get \\(H = 200\\) hits during the season. Figure 4 displays the joint posterior of \\((AB, p)\\). Comparing Figure 3 and Figure 4, it appears that 200 hits indicates that the player had a large number of at-bats and is a good hitter and the posterior is concentrated on large values of \\(AB\\) and \\(p\\). By computing the joint posterior density on a fine grid, and then simulating from the grid, one can obtain simulated draws from the marginal posterior densities of \\(AB\\) and \\(p\\). Figure 5 presents density estimates of these marginal posterior densities. The simulated samples can easily be used to construct interval estimates for each parameter.\n\n\n7.4.3 Prediction\nRecall that we were interested in predicting the number of hits our player would get in the following season. If we denote this future hit value by \\(\\tilde H\\), then we learn about \\(\\tilde H\\) by its posterior predictive density \\(f(\\tilde H | H)\\). One can express this by the integral \\[\nf(\\tilde H | H) \\int f(\\tilde H | AB, p, H) g(AB, p | H) dAB dp,\n\\] where \\(f(\\tilde H | AB, p, H)\\) is the binomial probability \\[\nf(\\tilde H | AB, p, H) = {AB \\choose \\tilde H} p^{\\tilde H} (1-p)^{AB - \\tilde H},\n\\] and \\(g(AB, p | H)\\) is the joint posterior density of at-bats and probability of a hit. It is not possible to compute this integral analytically, but it is straightforward to simulate from this distribution by first simulating a pair (\\(AB, p)\\) from the joint posterior distribution, and then simulating a value of \\(\\tilde H\\) from the binomial\\((AB, p)\\) density."
  },
  {
    "objectID": "bayes_computation.html",
    "href": "bayes_computation.html",
    "title": "8  Bayesian Computation",
    "section": "",
    "text": "In this chapter, several strategies for computing and summarizing posterior distributions are discussed. One basic strategy is to find the posterior mode and then approximate the density with a “matching” normal density. A second strategy is to devise an algorithm for simulating directing from the posterior distribution. We describe the use of a popular simulation algorithm, rejection sampling, to implement this sampling."
  },
  {
    "objectID": "bayes_computation.html#normal-approximation",
    "href": "bayes_computation.html#normal-approximation",
    "title": "8  Bayesian Computation",
    "section": "8.2 Normal Approximation",
    "text": "8.2 Normal Approximation\n\n8.2.1 One parameter problem\nWe derive a basic normal approximation to a posterior density in the single parameter case. Suppose we observe data \\(y\\) from a sampling density \\(f(y | \\theta)\\) and the parameter \\(\\theta\\) is assigned a prior density \\(g(\\theta)\\). We are interested in developing an approximation to the posterior density \\[\ng(\\theta | y) \\propto g(\\theta) f(y | \\theta).\n\\] For simplicity of notation, let \\(h(\\theta)\\) denote the logarithm of the posterior density, that is, \\(h(\\theta) = \\log g(\\theta | y)\\). If \\(\\hat \\theta\\) denotes the posterior mode of \\(\\theta\\), suppose we expand \\(h(\\theta)\\) in a second-order Taylor’s series about the mode. We obtain the approximation \\[\n\\log g(\\theta | y) = h(\\theta) \\approx h(\\hat \\theta) + \\frac{1}{2} h''(\\hat \\theta) (\\theta - \\hat \\theta)^2 ,\n\\] where \\(h''(\\hat \\theta)\\) is the second derivative of the function \\(h(\\theta)\\) evaluated at the posterior mode. This gives the following approximation to the posterior density: \\[\ng(\\theta | y) \\approx \\exp\\left(\\frac{1}{2} h''(\\hat \\theta) (\\theta - \\hat \\theta)^2\\right),\n\\] which we recognize as a normal density with mean \\(\\mu = \\hat \\theta\\) and variance \\(\\sigma^2 = \\left(-h''(\\hat \\theta)\\right)^{-1}\\).\n\n\n8.2.2 A proportion problem\nLet’s illustrate this normal approximation for a proportion problem. Suppose we observe \\(y\\) from a binomial(\\(n, p\\)) distribution and a uniform prior is chosen for \\(p\\). Then \\(p\\) will have a beta(\\(y+1, n-y+1\\)) of the form \\[\ng(p|y) \\propto p^y (1-p)^{n-y}, \\, \\, 0 < p < 1.\n\\] First we compute the log posterior density \\(h(p) = \\log g(p|y)\\) to be \\[\nh(p) = y log(p) + (n - y) log(1-p).\n\\] Taking a derivative, we find that \\[\nh'(p) = \\frac{y}{p} - \\frac{n-y}{1-p}.\n\\] The posterior mode is found by setting \\(h'(p) = 0\\) and, solving this equation, we find that \\(\\hat p = y/n\\). Next, we find the second derivative of \\(h\\) to be \\[\nh''(p) = \\frac{y}{p^2}-\\frac{n-y}{(1-p)^2} .\n\\] Evaluating \\(h''(p)\\) at the posterior mode, we obtain \\[\nh''(\\hat p) = \\frac{y}{\\hat p^2}-\\frac{n-y}{(1-\\hat p)^2} = -\\frac{n}{\\hat p(1-\\hat p)}.\n\\] So the approximation is the posterior for \\(p\\) is normal(\\(\\mu, \\sigma^2\\)), where \\(\\mu = \\hat p\\) and \\[\n\\sigma^2 = \\left(-h''(\\hat p)\\right)^{-1} = \\frac{\\hat p(1-\\hat p)}{n}.\n\\]\nFigure 1 displays the exact beta posterior density and the normal approximation. Clearly, the normal approximation does not reflect the substantial skewed shape in the beta density.\n\n\n8.2.3 Improving the accuracy of the approximation\nOne reason why the normal approximation is not suitable is that the support of a proportion is (0, 1) and we are approximating the posterior by a real-valued normal distribution. One way of improving the accuracy of the approximation is to transform the proportion to a real-valued parameter, and then apply the normal approximation to the posterior of the transformed parameter.\nIn this example, suppose we transform the proportion \\(p\\) to the logit \\[\n\\theta = \\log \\frac{p}{1-p}.\n\\] The inverse of this transformation is \\(p = \\exp(\\theta)/(1+\\exp(\\theta))\\) and the Jacobian of this transformation is \\(J = \\exp(\\theta)/(1+\\exp(\\theta))^2\\). The posterior of \\(\\theta\\) is given by \\[\ng(\\theta | y) \\propto \\left(\\frac{\\exp(\\theta)}{1+\\exp(\\theta)}\\right)^{y+1}\n                      \\left(1 - \\frac{\\exp(\\theta)}{1+\\exp(\\theta)}\\right)^{n-y+1}.\n\\]\nSuppose we apply our normal approximation to the posterior of the reexpressed parameter \\(\\theta\\). One can show that the posterior density is approximately \\(N(\\mu, \\sigma^2)\\) where \\[\n\\mu = \\log\\left(\\frac{\\tilde p}{ 1-\\tilde p}\\right), \\, \\sigma^2 = \\frac{1}{(n+2)\\tilde p (1-\\tilde p)}, \\, \\, \\tilde p = \\frac{y+1}{n+2}.\n\\]\nFigure 2 displays the exact posterior density of \\(\\theta\\) together with the normal approximation. This illustrates that the accuracy of the normal approximation is better for the real-valued parameter \\(\\theta\\) than for the proportion \\(p\\)."
  },
  {
    "objectID": "bayes_computation.html#normal-approximation-for-multivariate-posterior-distributions",
    "href": "bayes_computation.html#normal-approximation-for-multivariate-posterior-distributions",
    "title": "8  Bayesian Computation",
    "section": "8.3 Normal Approximation for Multivariate Posterior Distributions",
    "text": "8.3 Normal Approximation for Multivariate Posterior Distributions\nThe normal approximation developed in Section 7.1 can be generalized for a multivariate posterior density. If \\(h(\\theta)\\) is the logarithm of the joint posterior density of a vector-valued parameter \\(\\theta\\), then we have the approximation \\[\nh(\\theta) \\approx h(\\hat \\theta) + (\\theta - \\hat \\theta)' h''(\\hat \\theta)(\\theta - \\hat \\theta)/2,\n\\] where \\(\\hat \\theta\\) is the mode of the joint density and \\(h''(\\hat \\theta)\\) is the Hessian of the log density evaluated at the mode. Using this expansion, the posterior density is approximated by a multivariate normal density with mean \\(\\hat \\theta\\) and variance-covariance matrix \\[\n\\Sigma = (-h''(\\hat \\theta))^{-1}.\n\\]\nTo illustrate this approximation in the multivariate case, consider the familiar problem of estimating the parameters of a normal density. We observe \\(y_1, ..., y_n\\) from a normal distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). For ease of exposition, denote the sampling variance as \\(V = \\sigma^2\\) and we focus on the estimation of \\((\\mu, V)\\). Assuming the usual noninformative prior \\(g(\\mu, V) = 1/V\\), the posterior density has the form \\[\ng(\\mu, V) \\propto \\frac{1}{V^{n/2+1}} \\exp\\left(-\\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2V}\\right).\n\\] To develop the approximation, we need to find partial derivatives of the log posterior density \\(h(\\mu, V) = \\log g(\\mu, V)\\) given by \\[\nh(\\mu, V) = -(n/2 + 1) \\log V - \\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2 V}.\n\\] The first partial derivatives are given by \\[\nh^{10} = \\frac{\\partial h}{d \\mu} = \\frac{\\sum_{i=1}^n (y_i - \\mu)}{V}, \\, \\,\nh^{01} = \\frac{\\partial h}{d V} = -\\frac{n/2+1}{V} + \\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{2 V^2}.\n\\] When we solve the equations \\(h^{10} = 0, h^{01} = 0,\\) we find the mode of the posterior to be \\[\n\\hat \\mu = \\bar y, \\, \\hat V = \\frac{\\sum_{i=1}^n (y_i - \\hat \\mu)^2}{n+2}.\n\\] To get the approximation to the variance-covariance matrix, we need to compute the second partial derivatives and evaluate them at the posterior mode. The second partial derivatives are given by \\[\nh^{20} = -\\frac{n}{V}, \\, h^{11} = -\\frac{\\sum_{i=1}^n (y_i - \\mu)}{V^2}, \\, h^{02} = \\frac{n+2}{2V^2} -\n\\frac{\\sum_{i=1}^n (y_i - \\mu)^2}{V^3}.\n\\] When we evaluate these partial derivatives at the posterior mode \\((\\mu, V) = (\\hat \\mu, \\hat V)\\), we obtain \\[\nh^{20} = -\\frac{n}{\\hat V}, \\, h^{11} = 0, \\, h^{02} = -\\frac{n+2}{2\\hat V^2}.\n\\] The Hessian matrix is given by [ h’’() = ] and the approximate variance-covariance matrix is found by inverting \\(-h''(\\theta)\\): [ = ] We have that the posterior density of \\((\\mu, V)\\) is approximately normal with mean vector \\((\\hat y, \\hat V)\\) and variance-covariance matrix \\(\\Sigma\\).\nWe illustrate this approximation using a sample of completion times for 20 male participants at the New York Marathon. The logarithm of the exact posterior density of \\((\\mu, V)\\) is contained in the function {} and we define a new function {} that computes the logarithm of a multivariate normal density. Figure 3 displays two contour plots – the solid line corresponds to the exact posterior and the dashed line corresponds to the normal approximation. Clearly, the accuracy of the normal approximation is relatively poor in this case, since it does not account for the right skewness in the variance \\(V\\). One could improve the accuracy of the normal approximation by reexpressing \\((\\mu, V)\\) to \\((\\mu, \\log V)\\)\ndata(marathontimes)\nattach(marathontimes)\nmycontour(normchi2post,c(225,330,10,9000),time,col=\"red\",xlab=\"MU\",ylab=\"V\")\nn=length(time)\nmu.est=mean(time)\nvar.est=sum((time-mu.est)^2)/(n+2)\nSigma=diag(c(var.est/n,2*var.est^2/(n+2)))\nlog.dmnorm=function(x, pars) \n  dmnorm(x, pars$mean, pars$varcov, log = TRUE)\npars=list(mean=c(mu.est,var.est),varcov=Sigma)\nmycontour(log.dmnorm,c(225,330,10,9000),pars,add=TRUE,lty=2)"
  },
  {
    "objectID": "bayes_computation.html#modeling-with-cauchy-errors",
    "href": "bayes_computation.html#modeling-with-cauchy-errors",
    "title": "8  Bayesian Computation",
    "section": "8.4 Modeling with Cauchy errors",
    "text": "8.4 Modeling with Cauchy errors\nOne advantage of the normal approximation is that it gives quick, often accurate, summaries of posterior distributions. As we have seen, the accuracy of the approximation is improved by transforming parameters to the real line.\nAlthough we have discussed the common situation of sampling from a normal population, it is relatively common to observe outliers and statistical procedures based on the normal distribution assumption can be sensitive to outliers. An alternative error sampling distribution for symmetric data is the Cauchy family. This family has much flatter tails than the normal family and statistical procedures based on Cauchy error distributions will be relatively insensitive to the presence of outliers.\nSuppose we observe \\(y_1, ..., y_n\\) from a Cauchy density with location \\(\\mu\\) and scale \\(\\sigma\\). The likelihood function of \\((\\mu, \\sigma)\\) is given by \\[\nL(\\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\pi \\sigma} \\frac{1}{1 + (y_i - \\mu)^2/\\sigma^2}.\n\\] If we assign the noninformative prior of the form \\(1/\\sigma\\) to \\((\\mu, \\sigma\\)), then the posterior density is given, up to a proportionality constant, by \\[\ng(\\mu, \\sigma | y) = \\frac{1}{\\sigma} L(\\mu, \\sigma).\n\\] To improve the accuracy of a normal approximation, we transform \\((\\mu, \\sigma)\\) to \\((\\mu, \\log \\sigma)\\), obtaining the posterior density \\[\ng(\\mu, \\log \\sigma | y) = L(\\mu, \\sigma).\n\\]\nLet’s return to the problem of learning about the population of completion times for male runners in the New York Marathon. Suppose we add the completion time of 600 minutes for an unusually slow runner to the dataset. What impact does this outlier have on our inference about the population location parameter \\(\\mu\\)?\nfit=normpostsim(time2,10000)\ncfit=laplace(cauchyerrorpost,c(0,0),time2)\nplot(density(fit$mu),xlim=c(200,610),ylim=c(0,.04),xlab=\"MU\",main=\"\",lwd=3)\ncurve(dnorm(x,cfit$mode[1],sqrt(cfit$var[1,1])),add=TRUE,lwd=3)\ntext(locator(1),\"Normal\")\ntext(locator(1),\"Cauchy\")\npoints(time2,0*time2,pch=19,cex=1.5)\nThe R function cauchyerrorpost() in the LearnBayes package contains the definition of the logarithm of the posterior density of \\((\\mu, \\log \\sigma)\\). One can numerically obtain the normal approximation to the posterior function by the use of the laplace() function. The inputs to laplace() are the function defining the log posterior, a starting guess at the posterior mode, and the data that is used in the log posterior function. When one runs this function, one obtains the approximation that [ = (\n\\[\\begin{array}{c}\\mu \\\\ \\log \\theta\\end{array}\\]\n) N( (\n\\[\\begin{array}{c}  278.77 \\\\  3.38 \\end{array}\\]\n), (\n\\[\\begin{array}{cc}  94.49 & -0.254 \\\\  -0.254 & 0.0859 \\end{array}\\]\n) ) ] As a byproduct of this approximation, one obtains that the marginal posterior density of \\(\\mu\\) is approximately normal with mean 278.77 and standard deviation \\(\\sqrt{94.49}\\).\nFigure 4 displays two densities, the leftmost density is the posterior density of \\(\\mu\\) with Cauchy sampling, and the rightmost density is the posterior density of \\(\\mu\\) with the usual normal sampling assumption. The observed completion times are displayed as dots along the horizontal axis. Note that the inferences about the population location are significantly different with Normal and Cauchy errors. With the normal assumption, the point estimate at \\(\\mu\\) is the sample mean \\(\\bar y\\) and the posterior density is shifted to the right, trying to accommodate the large outlier. In contrast, with Cauchy sampling errors, the posterior density essentially ignores the outlier and the density better reflects the center of the remaining observations.\nIn this “single outlier” example, the normal approximation to the marginal posterior density of the location parameter \\(\\mu\\) is pretty accurate. But for other examples, the normal approximation is clearly unsuitable. To illustrate a nonnormal posterior, suppose that one observes the following data:\n 0.1 -0.9 -0.1 -2.1  1.4 -0.2  0.5 -1.7  1.5 -0.6 \n40.5 39.8 40.6 39.5 38.7 39.1 40.9 40.6 39.8 39.8\nNote that ten of the observations are in a neighborhood of zero and ten observations are in a neighborhood of 40. Again we assume the the observations are a random sample from a Cauchy(\\(\\mu, \\sigma\\)) distribution and the usual noninformative prior is placed on \\((\\mu, \\sigma)\\). Figure 5 displays contours of the exact joint posterior density and Figure 6 displays the marginal posterior density of \\(\\mu\\). Clearly, the joint posterior density does not display the elliptical shaped contours of a bivariate normal density and the marginal posterior density of \\(\\mu\\) is clearly bimodal. In future chapters, we will discuss the use of general-purpose simulation algorithms that are suitable when the posterior distribution has unusual shapes."
  },
  {
    "objectID": "mcmc.html",
    "href": "mcmc.html",
    "title": "9  Markov Chain Monte Carlo",
    "section": "",
    "text": "Let’s revisit the problem of comparing the means from two independent Poisson samples. Counts {\\(y_{Ai}\\)} from the weekend days are assumed Poisson with mean \\(\\lambda_A\\) and counts {\\(y_{Bj}\\)} from the weekday days are assumed Poisson with mean \\(\\lambda_B\\). We are interested in learning about the ratio of means \\[\n\\gamma=\\frac{\\lambda_B}{\\lambda_A}.\n\\] We showed that the likelihood function in terms of the first Poisson mean \\(\\theta = \\lambda_A\\) and \\(\\gamma\\) is given by \\[\nL(\\theta, \\gamma) = \\exp(-n_A \\theta) \\theta^{s_A} \\exp(-n_B (\\theta\\gamma)) (\\theta\\gamma)^{s_B}.\n\\] Assuming that \\(\\theta\\) and \\(\\gamma\\) are independent with \\[\n\\theta \\sim Gamma(a_0, b_0), \\, \\, \\gamma \\sim Gamma(a_g, b_g),\n\\] Then the posterior density of \\((\\theta, \\gamma)\\) is given, up to a proportionality constant, by \\[\\begin{eqnarray*}\ng(\\theta, \\gamma | {\\rm data}) & \\propto & \\exp(-n_A \\theta) \\theta^{s_A} \\exp(-n_B (\\theta\\gamma)) (\\theta\\gamma)^{s_B} \\nonumber \\\\\n                 & \\times & \\theta^{a_0-1} \\exp(-b_0 \\theta) \\gamma^{a_g-1} \\exp(-b_g \\gamma) \\nonumber \\\\\n\\end{eqnarray*}\\] By combining terms, we obtain the expression \\[\\begin{eqnarray*}\ng(\\theta, \\gamma | {\\rm data}) & \\propto & \\exp\\left(-(b_0+n_A+n_B \\gamma)\\theta\\right) \\theta^{a_0+s_A+s_B-1} \\nonumber \\\\\n                 & \\times & \\exp(-b_g \\gamma) \\gamma^{a_g+s_B-1}. \\nonumber \\\\\n\\end{eqnarray*}\\]\nAlthough this is a complicated joint density, the conditional posterior densities have familiar expressions. Suppose we fix a value of the first Poisson mean \\(\\theta\\). Then the posterior density of \\(\\gamma\\), conditional on \\(\\theta\\), has the expression \\[\ng(\\gamma | \\theta, {\\rm data}) \\propto \\exp(-(b_g + n_B \\theta) \\gamma) \\gamma^{a_g+s_B-1},\n\\] which we recognize as a gamma density with shape \\(a_g + s_B\\) and rate \\(b_g + n_B \\theta\\). Next, suppose we fix a value of the ratio of means \\(\\gamma\\). Then the posterior of \\(\\theta\\), conditional on \\(\\gamma\\), has the form \\[\ng(\\theta | \\gamma, {\\rm data}) \\propto \\exp\\left(-(b_0+n_A+n_B \\gamma)\\theta\\right) \\theta^{a_0+s_A+s_B-1},\n\\] which is a gamma(\\(a_0+s_A+s_B, b_0 + n_A + n_B \\gamma\\)) density.\nSince the conditional posterior distributions are simple, this suggests the following Gibbs sampling algorithm.\nSuppose the \\(k\\)th simulated values of the parameters are \\((\\gamma^{(k)}, \\theta^{(k)})\\). Then we simulate the next set of parameters by\n\n[Step A:] simulating \\(\\gamma^{(k+1)}\\) from a gamma(\\(a_g + s_B, b_g + n_B \\theta^{(k)}\\)) distribution\n[Step B:] simulating \\(\\theta^{(k+1)}\\) from a gamma(\\(a_0+s_A+s_B, b_0 + n_A + n_B \\gamma^{(k+1)})\\) distribution\n\nIn practice, one begins with a starting value for \\(\\theta\\), say \\(\\theta^{0} = s_A/n_A\\), and then iterate through \\(m\\) cycles of the Step A and Step B simulations, obtaining the simulated draws {\\((\\theta^{(j)}, \\gamma^{(j)}), j = 1, ..., m\\}\\). Assuming a relatively short burn-in period, the complete set of simulated draws can be regarded as a sample from the joint posterior distribution of \\(g(\\theta, \\gamma | y)\\).\nThis algorithm is easy to program in R. Suppose {} is the current simulated draw of \\(\\theta\\), and \\(\\tt a0, b0, ag, bg\\) are the prior parameters and {} are the sample quantities. Then one cycle of Gibbs sampling is programmed by two applications of the {} function.\n  gamma=rgamma(1, shape=ag+s.B, rate=bg+n.B*theta)\n  theta=rgamma(1, shape=a0+s.A+s.B, rate=b0+n.A+n.B*gamma)\nFor the website hit data, the algorithm was started with the initial value \\(\\theta^{0} = s_A/n_A\\) and run for 1000 cycles. Figure 1 displays a contour plot of the joint posterior density of \\((\\theta, \\gamma)\\) and the simulated sample is displayed. It appears that the Gibbs sampler draws are a reasonable approximation to the exact posterior."
  },
  {
    "objectID": "hierarchical.html",
    "href": "hierarchical.html",
    "title": "10  Hierarchical Modeling",
    "section": "",
    "text": "The Ohio Graduation Test (OGT) is a test administered to all high school students in the state of Ohio. To graduate from high school, a student must develop a proficiency in reading, science, mathematics, social studies and writing as measured by his/her performance on the OGT. This test is used to assess the quality of schools in the state and the State of Ohio releases summary OGT scores for all public and private schools in the state.\nA student receives a grade on each of the five sections of the OGT. The raw score for each section is categorized as Advanced, Accelerated, Proficient, Basic, or Limited. A student needs to have a grade of Proficient, Accelerated, or Advanced on all sections to pass the OGT.\nWe focus on the performance of the students from the nine public school districts in Wood County. For each school district, we collect the number of students taking the exam, and the number who received an Advanced score (the highest category) on the Writing section of the OGT.\n\n\n\nSchool.District\nN\nADVANCED\nProportion\n\n\n\n\nBowling Green City Sd\n259\n5\n0.019\n\n\nEastwood Local Sd\n145\n10\n0.069\n\n\nElmwood Local Sd\n95\n3\n0.032\n\n\nLake Local Sd\n138\n2\n0.014\n\n\nNorth Baltimore Local Sd\n53\n0\n0.000\n\n\nNorthwood Local Sd\n82\n4\n0.049\n\n\nOtsego Local Sd\n140\n2\n0.014\n\n\nPerrysburg Ex Vill Sd\n355\n16\n0.045\n\n\nRossford Ex Vill Sd\n139\n4\n0.029\n\n\n\nOverall, only 3% of the students received an Advanced score on the Writing test for this county, so clearly this was a challenging test. One can compare schools by computing the proportion of Advanced that are given in the last column of the table. Several questions arise when one tries to make sense of these proportions. First, we note that none of the North Baltimore Local students received an Advanced score. Does this mean that the population proportion of students from North Baltimore Local who received this score is equal to zero? Although it is unlikely for these students to receive this grade, one would expect at least a few students to get “Advanced” in future years. Second, we note that Eastwood’s proportion of Advanced (0.069) is higher than Perrysburg (0.045). Does this mean that Eastwood’s Advanced population proportion is higher than Perrysburg? Since the actual success counts are small, it is possible that there is no difference in the quality of the Eastwood and Perrysburg schools and we are simply observing sampling variability.\n\n\n\nIn the OGT testing example, the general problem is to estimate the proportions \\(p_1, ..., p_9\\), where \\(p_j\\) represents the proportion of students from the \\(j\\)th school district who score at an Advanced level on the writing section of the OGT. We observe \\((y_j, n_j)\\), where \\(y_j\\) is the number of Advanced students in a sample of size \\(n_j\\) from the \\(j\\)th district. The typical estimate of the proportion \\(p_j\\) is the sample proportion \\[\n\\hat{p_j} = \\frac{y_j}{n_j}\n\\] and the sample proportions are displayed in Table ???. As discussed in the introduction, there are some problems with these estimates. Due to the relatively small sample sizes, it is possible to get a sample proportion \\(\\hat{p_j}\\) equal to zero, although we believe that the corresponding population proportion \\(p_j\\) is positive. Generally, the variability of the sample proportions can be high, and so it may be problematic to make decisions solely on the sample proportions. For example, it may be difficult to say that Elmwood truly has a higher Advanced rate than Rossford since the corresponding sample proportions (0.32 and 0.29) have high sample variability.\nHow can we improve the individual sample proportion estimates? If we believe that the proportions are equal, that is, \\[\np_1 = ... = p_9,\n\\] then we can pool the data to get “improved” estimates. The pooled estimate of the common proportion value is given by \\[\n\\tilde{p} = \\frac{\\sum_{i-1}^9 y_j}{\\sum_{i-1}^9 n_j}.\n\\] Here this estimate is \\(\\tilde p = 46/1406 = 0.0327\\). Certainly this estimate improves the “zero estimate problem”. But this estimate is based on the strong assumption that the schools have equal ability to get an Advanced score on the writing component of the OGT.\nFrom a frequentist perspective, the usual procedure is to (1) fit a model that describes the relationship between the parameters, (2) decide whether or not to accept the model by means of a statistical test, and then (3) estimate the parameters on the basis of the best fitting model. Here one would be interested in testing the hypothesis \\(H\\) that the proportions are equal: \\[\nH:  p_1 = ... = p_9.\n\\] A standard test of this hypothesis is the chi-square procedure that tests whether the school district is independent of the score (Advanced or not Advanced) on the OCT writing test. On the basis of the procedure, we will decide either to accept or reject the hypothesis. If we accept the hypothesis \\(H\\), then we would use the pooled estimate $ = . $ Instead if we decide to reject \\(H\\), then we would use the sample proportion estimates \\(\\hat{p_j} = \\frac{y_j}{n_j}\\). This procedure is sometimes called a testimator, since we are deciding on the appropriate estimate by using a statistical test.\nIf one applies this test to these data, one obtains a Person chi-squared test statistic of 14.69. The p-value is the probability a chi-square variate with 8 degrees of freedom exceeds 14.69 – the p-value for these data is 0.065. If one uses the typical 0.05 cutoff to decide on the significance of this test, then one would decide that there is insufficient evidence to conclude that the proportions are different and would use the pooled estimate. But this p-value is close to 0.05; if a p-value of 10% or smaller was deemed “significant”, then we would conclude the proportions are different and use the sample proportion estimates.\nIs there anything else that could be done? It appears that both the sample proportions and the pooled estimate are undesirable, and so it may be more appropriate to use a compromise estimate. One possibility is to estimate \\(p_j\\) by a weighted average of the two extreme estimates: \\[\nw \\hat{p_j} + ( 1- w) \\tilde{p},\n\\] where \\(w\\) is a weight between 0 and 1 that determines the relative importance of the two extreme estimates. The value of the weight intuitively should be a function of the test statistic of the hypothesis \\(H\\). If the p-value for the test is large, then one would like the value of \\(w\\) to be small, indicating a greater weight on the pooled estimate. Alternately, if the p-value is very small, then the constant \\(p\\) model would seem to be inappropriate, and the value of \\(w\\) would be close to 1, reflecting more support on the sample proportion. It will be seen that this compromise estimate will be a by-product of the use of a hierarchical prior distribution placed on the proportions.\n\n\n\nWhat prior beliefs are available when one is estimating a set of proportions? In Chapter ???, we considered prior beliefs about a single proportion \\(p\\). In the case when one has prior information about the location and spread, we discussed the use of a beta(\\(a, b\\)) to approximate these beliefs. But when one is estimating many proportions, it may be difficult to think about locations and spreads for all of the parameters.\nSuppose one believes that the proportions \\(p_1, ..., p_9\\) represent a random sample from a single beta(\\(a, b\\)) distribution where the parameters \\(a\\) and \\(b\\) are unknown. Then if historical data is available, then one could use the data to estimate the parameters of the beta density. In our example, suppose one had the school district sizes and number of students receiving Advanced on the writing component for a previous years’ administration of the OGT. Then one could use this previous year’s data to estimate \\(a\\) and \\(b\\). For example, one could estimate the prior mean \\(a/(a+b)\\) by using the mean success rate for the schools in the previous year. Also one could use the variability of the success rates to estimate the variance of the beta density.\nIs it appropriate to use historical data in this case? It would be appropriate if one had some prior beliefs about the similarity of the success proportions for the past year and the success proportions for the current year. For example, if {\\(q_j\\)} represent the proportions of students receiving the Advanced grade for schools in a previous year, then one may believe that the sizes of the {\\(q_j\\)} were similar to the sizes of the proportions {\\(p_j\\)} of the nine schools in the current year.\nOne way of constructing a prior distribution that reflects a belief in similarity is based on the notion of {}. We say that a set of random variables \\(X = X_1, ..., X_n\\) is exchangeable if the distribution of \\(X\\) does not change if we change the order of the subscripts. That is, if \\(s(1), ..., s(n)\\) represent a permutation of the components of \\(X\\), then \\((X_1, ..., X_n)\\) has the same distribution of \\(X_{s(1)}, ..., X_{s(n)}\\).\nIn our example, suppose we believe that the proportions \\(p_1, ..., p_9\\) are exchangeable. If \\(p\\) is the vector of proportions, a belief of exchangeability means that our belief in \\(p\\) is the same if we change the order of the subscripts of the components of \\(p\\). Also a belief in exchangeability implies that our beliefs about any two different proportions is the same – that is, the prior for \\(p_i\\) will be the same as the prior for \\(p_j\\) for \\(i \\neq j\\). This belief also implies that the joint prior for any two proportions, say \\((p_i, p_j)\\) for \\(i \\neq j\\), does not change if we replace \\(i\\) and \\(j\\) by two other subscripts.\nThe famous probabilist deFinetti showed that if one believes that a set of random variables is exchangeable, then the corresponding distribution is constructed by means of a hierarchical structure. In our situation, this means that if \\(p_1, ..., p_9\\) is exchangeable, then one can construct the prior in a two-stage process as follows.\n\nSTAGE I: The proportions \\(p_1, ..., p_9\\) are independently distributed from a prior \\(g_1(p | \\phi)\\) depending on an unknown parameter vector \\(\\phi\\).\nSTAGE II: The unknown parameter vector \\(\\phi\\) has a completely specified distribution \\(g_2(\\phi)\\)\n\nThis two-stage structure implies that the proportion vector has the mixture prior \\[\ng(p_1, ..., p_9) = \\int \\left(\\prod_{j=1}^9 g_1(p_j | \\phi)\\right) g_2(\\phi) d\\phi.\n\\]\nMany possible distributions can be chosen for \\(g_1\\) and \\(g_2\\). For computational convenience, we will let \\(g_1\\) be a beta density with parameters \\(a\\) and \\(b\\). Then the unknown parameter vector \\(\\phi = (a, b)\\) and \\(g_2\\) will be a completely specified distribution on the beta parameters. In this case, the proportions will have the prior \\[\ng(p_1, ..., p_9) = \\int\\int \\left(\\prod_{j=1}^9 \\frac{1}{B(a, b)} p_j^{a-1} (1-p_j)^{b-1}\\right) g_2(a, b) da \\, db.\n\\]\nHow should we choose the second-stage prior \\(g_2\\)? First, it is useful to reparameterize the beta parameters \\(a\\) and \\(b\\) to the prior mean \\(\\eta\\) and the precision parameter \\(K\\) where \\[\n\\eta = \\frac{a}{a+b}, \\, \\, K = a + b .\n\\] Then we assume \\(\\eta\\) and \\(K\\) are independent, so \\[\ng_2(\\eta, K) = g_2(\\eta) g_2(K).\n\\] We will assign \\(\\eta\\) the noninformative prior proportional to \\(\\eta^{-1}(1-\\eta)^{-1}\\) and \\(K\\) the proper, but vague prior density \\((1+K)^{-1}\\). So the joint prior at the second-stage is given by \\[\ng_2(\\eta, K) = \\frac{1}{\\eta(1-\\eta)} \\frac{1}{(1+K)^2}, \\, \\, 0 < \\eta < 1, K > 0.\n\\] Later we will discuss alternative “noninformative” choices for these parameters. The joint prior of the proportions and the hyperparameters is given by \\[\\begin{eqnarray*}\ng(p_1, ..., p_k,\\eta, K)  =  \\left(\\prod_{j=1}^9 \\frac{1}{B(K \\eta, K (1-\\eta))} p_j^{K \\eta -1} (1-p_j)^{K(1-\\eta)-1}\\right)\n                \\nonumber \\\\\n            \\times  \\frac{1}{\\eta(1-\\eta)} \\frac{1}{(1+K)^2} \\nonumber \\\\\n\\end{eqnarray*}\\] where the beta parameters \\(a\\) and \\(b\\) are written in terms of the new \\((\\eta, K)\\) parameterization.\n\n\n\nIn the exchangeable model, the unknown parameters are the \\(k\\) proportions \\(p_1, ..., p_k\\) and the unknown second-stage hyperparameters \\(\\eta\\) and \\(K\\). For the \\(j\\)th sample, we observe \\(y_j\\) successes in \\(n_j\\) trials. The likelihood of the proportions is given by \\[\nL(p_1, ..., p_k) = \\prod_{j=1}^k  p_j^{y_j} (1-p_j)^{n_j-y_j}.\n\\] By multiplying the joint prior of \\((p_1, ..., p_k, \\eta, K)\\) by the likelihood, we obtain that the joint posterior is given by\n\\[\\begin{eqnarray*}\ng(p_1, ..., p_k,\\eta, K  {\\rm data})  \\propto  \\left(\\prod_{j=1}^9 \\frac{1}{B(K \\eta, K (1-\\eta))} p_j^{K \\eta -1} (1-p_j)^{K(1-\\eta)-1}\\right)\n                \\nonumber \\\\\n            \\times  \\frac{1}{\\eta(1-\\eta)} \\frac{1}{(1+K)^2}\\prod_{j=1}^k  p_j^{y_j} (1-p_j)^{n_j-y_j} \\nonumber \\\\\n\\end{eqnarray*}\\]\nTo simplify the posterior computation, we decompose this joint posterior into the product \\[\ng(p_1, ..., p_k,\\eta, K | {\\rm data}) = g(p_1, ..., p_k|\\eta, K,  {\\rm data}) g(\\eta, K | {\\rm data}).\n\\]\nFirst consider the first term, the joint posterior of the proportions given the hyperparameters \\(\\eta\\) and \\(K\\). If we fix values of the hyperparameters, then the proportions have the joint density \\[\\begin{eqnarray*}\ng(p_1, ..., p_k,  \\eta, K,{\\rm data})  \\propto  \\left(\\prod_{j=1}^9 p_j^{K \\eta -1} (1-p_j)^{K(1-\\eta)-1}\\right)\n                \\nonumber \\\\\n            \\times  \\prod_{j=1}^k  p_j^{y_j} (1-p_j)^{n_j-y_j} \\nonumber \\\\\n\\end{eqnarray*}\\] We regrouping terms, we see that the proportions \\(p_1, .., p_k\\), conditional on the hyperparameters, are independent with \\(p_j\\) distributed beta with parameters \\(a_1 = K\\eta + y_j\\) and \\(b_1 = K(1-\\eta) + n_j - y_j\\).\nNext consider the marginal posterior density of \\((\\eta, K)\\). We obtain this distribution by integrating out the proportions from the joint posterior density. Recall the identity \\[\n\\int_0^1 p^{a-1} (1- p)^{b-1} dp = B(a, b).\n\\] If we integrate each proportion out using this identity, we obtain the marginal posterior density \\[\\begin{eqnarray*}\ng(\\eta, K | {\\rm data})  \\propto  \\left(\\prod_{j=1}^9 \\frac{B(K \\eta + y_j, K(1-\\eta) + n_j - y_j)}{B(K \\eta, K (1-\\eta))} \\right)\n    \\frac{1}{\\eta(1-\\eta)} \\frac{1}{(1+K)^2} .\\nonumber \\\\\n\\end{eqnarray*}\\]\nSuppose we are interested in learning about the \\(j\\)th proportion \\(p_j\\) that we can summarize by a posterior mean and posterior variance. We can use the posterior representation to obtain simple expressions for these moments. We compute the posterior mean of \\(p_j\\) by using the conditional expectation formula: \\[\nE(p_j | {\\rm data}) = E \\left[ E(p_j | \\eta, K, {\\rm data})\\right],\n\\] where the outer expectation is taken with respect to the posterior distribution of \\((\\eta, K)\\). Since the posterior density of \\(p_j\\), conditional on \\((\\eta, K)\\) is beta(\\(K\\eta + y_j, K(1-\\eta) + n_j-y_j\\)), we have \\[\\begin{eqnarray*}\nE(p_j | \\eta, K, {\\rm data})  =  \\frac{y_j + K\\eta}{n_j+K}  \\nonumber \\\\\n                              =  \\frac{n_j}{n_j + K} \\hat{p_j} + \\frac{K}{n_j+K} \\eta . \\nonumber \\\\\n\\end{eqnarray*}\\] So the posterior mean of \\(p_j\\) can be expressed as \\[\nE(p_j | {\\rm data}) = E\\left(\\frac{n_j}{n_j + K}\\right) \\hat{p_j} + E\\left(\\frac{K}{n_j+K} \\eta\\right),\n\\] where the expectations on the right hand side are taken with respect to the posterior density of \\((\\eta, K)\\). In a similar fashion, by using the conditioning rule for variances, the posterior variance of \\(p_j\\) can be expressed as \\[\nVar(p_j | {\\rm data}) = Var \\left[ E(p_j | \\eta, K, {\\rm data})\\right] + E \\left[ Var(p_j | \\eta, K, {\\rm data})\\right].\n\\] Conditional on \\((\\eta, K)\\), we know the variance of \\(p_j\\) is given by \\[\nVar(p_j | \\eta, K, {\\rm data}) = \\frac{a_1 b_1}{(a_1 + b_1)^2 (a_1 +b_1 + 1)},\n\\] where \\(a_1 = K\\eta + y_j\\) and \\(b_1 = K(1-\\eta) + n_j - y_j\\). Substituting in the conditional posterior moments, we obtain \\[\nVar(p_j | {\\rm data}) = Var \\left[ \\frac{a_1}{a_1+b_1} \\right] + E \\left[ \\frac{a_1 b_1}{(a_1 + b_1)^2 (a_1 +b_1 + 1)}\\right],\n\\] where again the variance and expectation on the right hand side are taken with respect to the posterior distribution of \\((\\eta, K)\\).\n\n\n\nRecall that the exchangeable model is a compromise between two models, the “separate proportions” model and the “one proportion” model where one assumes the proportions are equal. Table 6.1 displays summaries of the posterior distributions of logit\\((\\eta)\\) and \\(\\log K\\). The hyperparameter \\(\\eta\\) represents the common proportion value. In the table, the posterior median of logit(\\(\\eta\\)) is \\(-3.35\\), so the posterior median of \\(\\eta\\) is \\(\\exp(-3.35)/(1+\\exp(-3.35)) = 0.0339.\\) So generally 3.4% of the students received an Advanced score on the writing section of the OGT.\nThe hyperparameter \\(K\\) is informative about the degree of shrinkage of the separate proportions model towards the one proportion model. From the table, we see that the posterior median of \\(\\log K\\) is 4.36 which translates to a posterior median of \\(K\\) of \\(\\exp(4.36) = 78.3\\). If we substitute these estimates for \\(\\eta\\) and \\(K\\) in the expression for the posterior mean for \\(p_j\\), we get the approximation \\[\nE(p_j | {\\rm data}) \\approx \\frac{n_j}{n_j + 78.3} \\hat{p_j} + \\frac{78.3}{n_j+78.3} (0.0339).\n\\] One can measure the shrinkage of the estimate \\(\\hat{p_j}\\) towards the pooled estimate by the fraction \\[\n\\frac{78.3}{n_j+78.3}.\n\\] For the nine schools, the shrinkage values range between 18% and 60%, reflecting substantial movement towards the pooled estimate. The size of the shrinkage depends on the sample size – the largest shrinkage is for North Baltimore School District where only 53 students took the test.\nTable 6.2 gives summaries of the posteriors for the proportions of success for the nine schools. To better understand the values, consider the proportion of students from the Bowling City School District who were successful. The 90% naive Wald confidence interval for \\(p_1\\) based on the data \\((y_1, n_1) = (5, 259)\\) is given by \\[\n(0.019 - 1.645 \\sqrt{\\frac{0.019 (1-0.019)}{259}}, 0.019 + 1.645 \\sqrt{\\frac{0.019 (1-0.019)}{259}})\n\\] \\[\n= (0.0051, 0.0329)\n\\] If we assumed the proportions for the nine schools were equal, then the estimate for \\(p_1\\) would be the combined estimate 0.0327 with a sample size of 1406 and the 90% Wald interval would have the form \\[\n(0.0327 - 1.645 \\sqrt{\\frac{0.0327 (1-0.0327)}{1406}}, 0.0327 + 1.645 \\sqrt{\\frac{0.0327 (1-0.0327)}{1406}})\n\\] \\[\n= (0.0199, 0.0456)\n\\] From the table, the 90% interval estimate of \\(p_1\\) (from the 5th and 95th percentiles of the marginal posterior) is given by (0.011, 0.038).\nThe lengths of the separate proportion, one proportion, and Bayesian intervals are respectively 0.0278, 0.0257, and 0.027. By “borrowing strength”, the exchangeable model gives more precise estimates than the separate proportion estimates, although not as precise as the one proportion estimate.\n\n\n\nSchool District\n\\(E(p)\\)\n\\(SD(p)\\)\n\\(p_{.05}\\)\n\\(p_{.95}\\)\n\n\n\n\nBowling Green City Sd\n0.023\n0.008\n0.011\n0.038\n\n\nEastwood Local Sd\n0.055\n0.017\n0.031\n0.088\n\n\nElmwood Local Sd\n0.033\n0.014\n0.013\n0.058\n\n\nLake Local Sd\n0.022\n0.010\n0.007\n0.040\n\n\nNorth Baltimore Local Sd\n0.020\n0.013\n0.002\n0.043\n\n\nNorthwood Local Sd\n0.041\n0.017\n0.019\n0.073\n\n\nOtsego Local Sd\n0.022\n0.010\n0.007\n0.040\n\n\nPerrysburg Ex Vill Sd\n0.042\n0.010\n0.028\n0.060\n\n\nRossford Ex Vill Sd\n0.031\n0.012\n0.014\n0.052\n\n\n\nFigure 6.1 graphically illustrates the shrinkage behavior of the Bayesian estimates using the exchangeable model. The open circles represent the individual proportion estimates {\\(\\hat {p_j}\\)} and the solid circles represent the Bayesian posterior means. The horizontal line represents the pooled estimate assuming the proportions are equal. The arrows show the shrinkage of the individual estimates towards the pooled estimate. Note from the figure that the shrinkage sizes are largest for the smaller schools with a small \\(n_j\\)."
  },
  {
    "objectID": "hierarchical.html#a-normalnormal-exchangeable-model",
    "href": "hierarchical.html#a-normalnormal-exchangeable-model",
    "title": "10  Hierarchical Modeling",
    "section": "10.2 A Normal/Normal Exchangeable Model",
    "text": "10.2 A Normal/Normal Exchangeable Model\nIn many situations, one is interested in combining normally distributed data from a group of related experiments. Suppose one observes independent random variables \\(y_1, ..., y_k\\), where \\(y_i\\) is distributed from a normal population with mean \\(\\theta_i\\) and known variance \\(\\sigma^2\\). (Note that we are assuming the variabilities for the \\(k\\) experiments are equal.) The prior belief is that \\(\\theta_1, .., \\theta_k\\) are exchangeable. We model this belief by a hierarchical model where at stage I, we assume that the {\\(\\theta_i\\)} are a random sample from a normal density with mean \\(\\mu\\) and variance \\(\\tau^2\\), and at stage II, we assign the prior parameters \\((\\mu, \\tau^2)\\) a distribution \\(g(\\mu, \\tau^2)\\).\nIn a famous example described by Efron and Morris, one is interested in simultaneously estimating the batting abilities for 18 baseball players shown in Table 1. For the \\(i\\)th player, one observes \\(x_i\\), the number of hits in 45 at-bats (opportunities), and one assumes \\(x_i\\) is binomial(45, \\(p_i\\)), where \\(p_i\\) is the hitting probability. We are interested in estimating the 18 hitting probabilities \\(p_1, ..., p_{18}\\). To make the data approximately normal, we transform \\(x_i\\) by the logit transformation \\(y_i = \\log(x_i/(45-x_i))\\). The reexpressed random variable \\(x_i\\) is approximately N(\\(\\theta_i, \\sigma^2\\)), where \\(\\theta_i = \\log(p_i/(1-p_i))\\) and \\(\\sigma^2 = 0.11\\).\n\n\n\n\nName\n\\(x_i\\)\n\\(AB\\)\n\n\n\n\n1\nAlvardo\n12\n45\n\n\n2\nAlvis\n7\n45\n\n\n3\nBerry\n14\n45\n\n\n4\nCampaneris\n9\n45\n\n\n5\nClemente\n18\n45\n\n\n6\nHoward\n16\n45\n\n\n7\nJohnstone\n15\n45\n\n\n8\nKessinger\n13\n45\n\n\n9\nMunson\n8\n45\n\n\n10\nPetrocelli\n10\n45\n\n\n11\nRobinson\n17\n45\n\n\n12\nRodriguez\n10\n45\n\n\n13\nSanto\n11\n45\n\n\n14\nScott\n10\n45\n\n\n15\nSpencer\n14\n45\n\n\n16\nSwoboda\n11\n45\n\n\n17\nUnser\n10\n45\n\n\n18\nWilliams\n10\n45\n\n\n\nIn this problem, there are \\(k+2\\) unknowns, the \\(k\\) normal means and the second-stage prior parameters \\((\\mu, \\tau^2)\\). The joint posterior density of these unknowns is given by \\[\ng(\\{\\theta_i\\}, \\mu, \\tau^2 | y) \\propto \\prod_{i=1}^k \\left[ \\phi(y_i; \\theta_i, \\sigma^2) \\phi(\\theta_i;  \\mu, \\tau^2)\\right] g(\\mu, \\tau^2),\n\\] where \\(\\phi(y; \\mu, \\sigma^2)\\) denotes a normal density with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nWe summarize this joint posterior by considering two distributions, the posterior distribution of the normal means conditional on the parameters \\((\\mu, \\tau^2)\\), and the marginal distribution of the second-stage parameters.\n\n10.2.1 Conditional posterior distribution of the normal means\nIf we condition on the parameters \\((\\mu, \\tau^2)\\), then the posterior density of the means \\(\\{\\theta_i\\}\\) has the form \\[\ng(\\{\\theta_i\\} | \\mu, \\tau^2, y) \\propto \\prod_{i=1}^k \\left[ \\phi(y_i; \\theta_i, \\sigma^2) \\phi(\\theta_i;  \\mu, \\tau^2)\\right].\n\\] We see that \\(\\theta_1, ..., \\theta_k\\) are independent and the marginal density of \\(\\theta_i\\) has a normal density with parameters given by the familiar normal/normal updating formula: \\[\nE(\\theta_i | \\mu, \\tau^2, y) = \\frac{y_i/\\sigma^2 + \\mu/\\tau^2}{1/\\sigma^2 + 1/\\tau^2},\n\\] and \\[\nVar(\\theta_i | \\mu, \\tau^2, y) = \\frac{1}{1/\\sigma^2 + 1/\\tau^2}.\n\\]\n\n\n10.2.2 Posterior distribution of the second-stage parameters\nTo obtain the marginal posterior distribution of \\((\\{\\mu, \\tau^2\\}\\), we need to integrate out the means \\(\\{\\theta_i\\}\\) from the joint posterior. From our work with the normal sampling/normal prior model, we know that \\[\n\\int \\phi(y_i; \\theta_i, \\sigma^2) \\phi(\\theta_i;  \\mu, \\tau^2) \\theta_i = \\phi(y_i; \\mu, \\sigma^2 + \\tau^2).\n\\] This is just the statement that for a normal/normal model, the predictive density of \\(y_i\\) is normal with mean equal to the prior mean and a variance given by the sum of the sampling variance and the prior variance. When we integrate out all \\(k\\) means from the joint posterior, we obtain an expression for the posterior of the second-stage parameters: \\[\ng(\\mu, \\tau^2 | y) \\propto \\left(\\prod_{i=1}^k \\phi(y_i; \\mu, \\sigma^2 + \\tau^2)\\right) g(\\mu, \\tau^2).\n\\]\nSuppose we assume \\(\\mu\\) and \\(\\tau^2\\) are independent, with \\(\\mu\\) assigned a uniform prior and \\(\\tau^2\\) assigned the proper density \\[\ng(\\tau^2) = \\frac{1}{1+\\tau^2}, \\, \\, \\tau^2 > 0.\n\\] Then the posterior density of \\((\\{\\mu, \\tau^2\\}\\) simplifies as the product \\[\ng(\\mu, \\tau^2 | y) = g(\\mu | \\tau^2, y) g(\\tau^2 | y),\n\\] where \\(g(\\mu | \\tau^2, y)\\) is normal with mean \\(\\bar y\\) and variance \\((\\sigma^2 + \\tau^2)/k\\), and \\(g(\\tau^2 | y)\\) has the form \\[\ng(\\tau^2 | y) \\propto \\frac{1}{(\\sigma^2 + \\tau^2)^{(k-1)/2}}\n\\exp\\left(-\\frac{1}{2(\\sigma^2 + \\tau^2)} \\sum_{i=1}^k (y_i - \\bar y)^2 \\right)\\frac{1}{1+\\tau^2}.\n\\]\n\n\n10.2.3 Posterior means\nLet’s focus on the posterior mean of the \\(i\\)th normal mean \\(\\theta_i\\). By the conditional expectation formula, one has \\[\nE(\\theta_i | y) = E^{\\mu, \\tau^2} \\left[ E(\\theta_i | y, \\mu, \\tau^2) \\right],\n\\] where the outer expectation is taken over the posterior distribution of \\(\\{\\mu, \\tau^2\\}\\). Since the posterior distribution of \\(\\theta_i\\) conditional on the second-stage parameters is normal, we have \\[\nE(\\theta_i | y) = E^{\\mu, \\tau^2} \\left[  \\frac{y_i/\\sigma^2 + \\mu/\\tau^2}{1/\\sigma^2 + 1/\\tau^2} \\right].\n\\] Using a similar conditional expectation formula, we can write \\[\\begin{eqnarray*}\nE(\\theta_i | y)  =  E^{\\tau^2} E^{\\mu|\\tau^2} \\left[  \\frac{y_i/\\sigma^2 + \\mu/\\tau^2}{1/\\sigma^2 + 1/\\tau^2} \\right] \\nonumber \\\\\n                 =  E^{\\tau^2} \\left[  \\frac{y_i/\\sigma^2 + \\bar y/\\tau^2}{1/\\sigma^2 + 1/\\tau^2} \\right]\\nonumber \\\\\n                 =  (1 - F)y_i  +   F \\bar y,  \\nonumber \\\\\n\\end{eqnarray*}\\] where \\(F\\) is the shrinkage \\[\nF = E^{\\tau^2}\\left(\\frac{1/\\tau^2}{1/\\tau^2 + 1/\\sigma^2} \\right) = \\int_0^\\infty \\frac{1/\\tau^2}{1/\\tau^2 + 1/\\sigma^2} g(\\tau^2 | y) d\\tau^2.\n\\]\nTo illustrate the posterior calculations, we consider the problem of estimating the collection of hitting probabilities. In Table 2, the column \\(x/45\\) contains the batting averages, the proportions of hits in the 45 at-bats. The column \\(y\\) contains the transformed proportions \\(y = \\log(x/(45-x))\\).\nWe focus on the computation of the posterior means of the normal means \\(\\{\\theta_j\\}\\). The shrinkage of the posterior mean estimate is controlled by the variance parameter \\(\\tau^2\\) and Figure 1 displays its posterior density. Since the parameter \\(\\tau^2\\) affects the posterior mean through the shrinkage function \\[\nF(\\tau^2) = \\frac{1/\\tau^2}{1/\\tau^2 + 1/\\sigma^2},\n\\] one is interested in the posterior density of \\(F(\\tau^2)\\) and Figure 2 displays its posterior density. Note that the posterior density of the shrinkage function is concentrated on the interval (0.6, 0.8), indicating substantial shrinkage of the individual estimates towards the combined estimate \\(\\bar y\\). One can compute \\[\nF = E^{\\tau^2} (F(\\tau)) = 0.68.\n\\] This means that the individual estimate \\(y_i\\) is shrunk 68% towards the pooled estimate \\(\\bar y\\). Table 2 displays the posterior means \\[\nE(\\theta_i | y) = (1 - 0.68) y_i + 0.68 \\bar y.\n\\] By transforming these logit estimates back to the proportion scale \\[\np = \\exp(\\theta)/(1+\\exp(\\theta)),\n\\] one obtains the Bayesian proportion estimates {\\(\\hat p_i\\)}.\n\n\n\n\nPlayer\n\\(x/45\\)\n\\(y\\)\n\\(E(\\theta|y)\\)\n\\(\\hat p\\)\n\n\n\n\n1\nAlvardo\n0.267\n-1.012\n-1.035\n0.262\n\n\n2\nAlvis\n0.156\n-1.692\n-1.251\n0.222\n\n\n3\nBerry\n0.311\n-0.795\n-0.966\n0.276\n\n\n4\nCampaneris\n0.200\n-1.386\n-1.154\n0.240\n\n\n5\nClemente\n0.400\n-0.405\n-0.842\n0.301\n\n\n6\nHoward\n0.356\n-0.595\n-0.902\n0.289\n\n\n7\nJohnstone\n0.333\n-0.693\n-0.934\n0.282\n\n\n8\nKessinger\n0.289\n-0.901\n-1.000\n0.269\n\n\n9\nMunson\n0.178\n-1.531\n-1.200\n0.231\n\n\n10\nPetrocelli\n0.222\n-1.253\n-1.112\n0.248\n\n\n11\nRobinson\n0.378\n-0.499\n-0.872\n0.295\n\n\n12\nRodriguez\n0.222\n-1.253\n-1.112\n0.248\n\n\n13\nSanto\n0.244\n-1.128\n-1.072\n0.255\n\n\n14\nScott\n0.222\n-1.253\n-1.112\n0.248\n\n\n15\nSpencer\n0.311\n-0.795\n-0.966\n0.276\n\n\n16\nSwoboda\n0.244\n-1.128\n-1.072\n0.255\n\n\n17\nUnser\n0.222\n-1.253\n-1.112\n0.248\n\n\n18\nWilliams\n0.222\n-1.253\n-1.112\n0.248\n\n\n\n\n\n10.2.4 Priors\nIn the specification of priors, we did not say much about the choice of priors on the hyperparameters \\((\\mu, \\tau^2)\\). That raises some obvious questions. Can we place any vague prior on these parameters? Does the choice of prior matter?\nA traditional choice of prior on a variance parameter is the improper form \\[\ng(\\tau^2) = \\frac{1}{\\tau^2}, \\, \\, \\tau^2 > 0.\n\\] Unfortunately, this choice may result in an improper posterior distribution for \\(\\tau^2\\). We used a random walk Metropolis algorithm to simulate 10,000 variates and Figure 4 shows trace and density plots for the parameters \\(\\mu\\) and \\(\\log \\tau^2\\). The trace plot for \\(\\log \\tau^2\\) shows much instability in the simulated draws and this reflects the fact that the posterior density is not well-behaved.\nBy the above investigation, it is clear that a proper prior needs to be chosen for the variance parameter \\(\\tau^2\\). But how does the choice of prior matter? Suppose we slightly generalize the prior of \\(\\tau^2\\) to the log logistic form \\[\ng(\\tau^2) = \\frac{M}{(M + \\tau^2)^2}, \\, \\, \\tau^2 > 0.\n\\] The parameter \\(M\\) is the prior median of \\(\\tau^2\\). In the above analysis we chose \\(M = 1\\) and it natural to ask about the sensitivity of the posterior analysis to the choice of different values for \\(M\\).\nSuppose we are interested in the sensitivity of the shrinkage parameter \\(F\\) with respect to the prior median \\(M\\). In our earlier analysis, we found that the posterior mode of \\(F\\) was 0.686 when \\(M = 1\\) or when \\(\\log M = 0\\). In Figure 5, we plot the posterior mode of \\(F\\) as a function of \\(\\log M\\). We see that the posterior shrinkage is relatively insensitive to the prior parameter for “large” values of \\(\\log M\\) between 0 and 2. Indeed, if we choose the very large value \\(\\log M = 10\\), the posterior mode of the shrinkage changes only slightly to 0.655. However, the posterior shrinkage is sensitive to the choice of small values of \\(\\log M\\).\nSince the posterior shrinkage is sensitive to the choice of small \\(M\\), that raises a new question. If we had knowledge about batting averages, what would be a reasonable prior for the variance parameter \\(\\tau^2\\)? The author is a baseball fan and he believes that most of the hitting probabilities for players fall in the interval (0.240, 0.320). If we equate the range of this interval with \\(4 \\tau\\) (corresponding to 95% confidence), we obtain the estimate \\(0.02\\) for \\(\\tau\\) which would correspond to a prior median of \\(M = 0.02^2 = 0.0004\\) for \\(\\tau^2\\). With this choice of \\(M\\), the posterior mode of the shrinkage \\(F\\) is essentially 1, which means that the observed batting averages are shrunk completely towards the pooled estimate. This is not a surprising result, since the observed batting averages are only based on a few weeks of baseball (45 at-bats), and it makes sense that the prior information about the hitting probabilities will swamp the data information in this case."
  },
  {
    "objectID": "model_selection.html",
    "href": "model_selection.html",
    "title": "11  Bayesian Testing and Model Selection",
    "section": "",
    "text": "We begin by reviewing some basic notations of frequentist testing. As a simple example, suppose we observe a random sample \\(y_1, ..., y_n\\) from a normal population with mean \\(\\theta\\) and known variance \\(\\sigma^2\\). We wish to test the simple hypothesis \\(H: \\theta = \\theta_0\\) against the simple alternative \\(A: \\theta = \\theta_1\\) where \\(\\theta_0 < \\theta_1\\).\nSince the sample mean \\(\\bar y\\) is sufficient, we can consider the single observation \\(\\bar y\\) that is normal with mean \\(\\theta\\) and variance \\(\\sigma^2/n\\). The likelihood function is \\[\nL(\\theta) = \\phi(\\bar y; \\theta, \\sigma^2/n),\n\\] where \\(\\phi(y; \\theta, \\sigma^2)\\) is the normal density with mean \\(\\theta\\) and variance \\(\\sigma^2\\). The most-powerful test of \\(H\\) against \\(A\\) is based on the likelihood ratio \\[\n\\Lambda = \\frac{L(\\theta_1)}{L(\\theta_0)}.\n\\] This test rejects \\(H\\) when \\(\\Lambda \\ge k\\) which is equivalent to rejecting when \\(\\bar y \\ge c\\). We set a Type I error probability of \\(\\alpha\\) and choose the constant \\(c\\) so that \\(P(\\bar y \\ge c | \\theta = \\theta_0) = \\alpha\\). The most-powerful test of size \\(\\alpha\\) rejects \\(H\\) when \\[\n\\bar y \\ge \\theta_0 + z_{1-\\alpha} \\frac{\\sigma}{\\sqrt{n}},\n\\] where \\(z_\\alpha\\) is the \\(\\alpha\\) percentile of a standard normal random variable.\nHere are some comments about this testing procedure.\n\nTwo types of error? There are two mistakes one can make with a test – one can incorrectly reject \\(H\\) when \\(H\\) is true (\\(\\theta = \\theta_0\\)) or one can incorrectly accept \\(H\\) when \\(A\\) is true (\\(\\theta = \\theta_1\\)). In a frequentist test, one is controlling only the probability of the first error.\nConfidence? This test has a repeated sampling validity. If one performs many tests when \\(H\\) is true, that is, \\(\\theta = \\theta_0\\), then the proportion of times one will incorrectly reject is \\(\\alpha\\).\nMeasure of evidence? Suppose one observes an extreme value of \\(\\bar y\\), a value that is unusual if the hypothesis \\(H\\) is true. The frequentist test, as constructed, does not provide a measure of evidence given this extreme value of \\(\\bar y\\). (All one has is the repeated sampling interpretation.) R. A. Fisher proposed the p-value that is the probability of obtaining the observed value \\(\\bar y\\) or more extreme if indeed \\(H\\) was true. \\[\n{\\rm p-value} = P(\\bar Y \\ge \\bar y | \\theta = \\theta_0).\n\\] In practice, one typically computes a p-value. This computation allows one to accept or reject the hypothesis \\(H\\) for any value of \\(\\alpha\\) and provides a measure of the strength of evidence against the null hypothesis \\(H\\)."
  },
  {
    "objectID": "model_selection.html#introduction-to-bayesian-testing",
    "href": "model_selection.html#introduction-to-bayesian-testing",
    "title": "11  Bayesian Testing and Model Selection",
    "section": "11.2 Introduction to Bayesian Testing",
    "text": "11.2 Introduction to Bayesian Testing\nLet’s consider the problem of testing a simple null hypothesis \\(H: \\theta=\\theta_0\\) against the simple alternative hypothesis \\(A: \\theta = \\theta_1\\) for normal data, known variance, from a Bayesian perspective. Here there are two possible values of the mean, \\(\\theta_0\\) and \\(\\theta_1\\). Suppose we assign the prior probabilities \\[\ng(\\theta_0), \\, \\, g(\\theta_1) = 1 - g(\\theta_0).\n\\] The prior odds of \\(H\\) is the ratio of the prior probabilities of the two hypotheses \\[\nO(H) = \\frac{g(H)}{g(A)}.\n\\] Suppose we observe the sample mean \\(\\bar y\\). The posterior probability of the mean \\(\\theta\\) is given, by Bayes’ rule, by \\[\ng(\\theta | y) \\propto L(\\theta) P(\\theta) = \\phi(\\bar y; \\theta, \\sigma^2/n).\n\\] The posterior odds of \\(H\\) is the ratio of the posterior probabilities of \\(H\\) and \\(A\\) \\[\nO(H | y) = \\frac{g(H| y)}{g(A | y)} = \\frac{g(\\theta_0) L(\\theta_0)}{g(\\theta_1) L(\\theta_1)}.\n\\] Note that we can write the posterior odds of \\(H\\) as \\[\nO(H | y) = O(H) \\times BF_{HA},\n\\] where \\(O(H)\\) is the prior odds of \\(H\\) and \\(BF_{HA}\\) is the {} \\[\nBF_{HA} = \\frac{L(\\theta_0)}{L(\\theta_1)},\n\\] the ratio of the likelihoods of the two hypotheses.\nAs a simple example, let’s return to the example of determining the true IQ for our friend Joe. Our friend is taking a IQ test and his score \\(y\\) is normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2 = 100\\). We wish to test the hypothesis \\(H: \\theta = 100\\) (Joe has average intelligence against the alternative hypothesis \\(A: \\theta = 130\\) (Joe is a genius). Before the IQ test is given, we strongly believe Joe has average intelligence and assign \\(g(100) = 0.95, g(130) = 0.05\\). The prior odds that Joe has average intelligence is given by \\[\nO(H) = \\frac{0.95}{0.05} = 19.\n\\] Joe scores 120 on the IQ test. We compute the Bayes factor, the ratio of the likelihoods under the average and genius hypotheses \\[\nBF_{HA} = \\frac{\\phi(120; 100, 100)}{\\phi(120; 130, 100)} = \\frac{ 0.00540}{0.02420} = 0.223.\n\\] The posterior odds of “average” is given by the product of the prior odds and the Bayes factor \\[\nO(H | 120) = 19 \\times 0.223 = 4.24.\n\\] It might be helpful to convert the odds of “average” to a probability: \\[\nP(H | 120) = \\frac{O(H|120)}{O(H|120) + 1} = \\frac{4.24}{4.24+1} = 0.809.\n\\] Although the data provided some evidence that Joe is a genius, we still strongly believe Joe has average intelligence."
  },
  {
    "objectID": "model_selection.html#testing-about-a-normal-mean",
    "href": "model_selection.html#testing-about-a-normal-mean",
    "title": "11  Bayesian Testing and Model Selection",
    "section": "11.3 Testing about a Normal Mean",
    "text": "11.3 Testing about a Normal Mean\n\n11.3.1 The one-sided hypothesis\nAs a slight generalization, suppose we again have normal sampling \\(y_1, ..., y_n\\) with unknown mean \\(\\theta\\) and known variance \\(\\sigma^2\\) and we are interested in testing the one-sided hypothesis \\(H: \\theta \\le \\theta_0\\) against the alternative hypothesis \\(A: \\theta > \\theta_0\\).\nSuppose one assigns a normal(\\(\\mu, \\tau^2\\)) prior. Then the prior odds is the ratio of the prior probabilities of \\(H\\) and \\(A\\): \\[\nO(H) = \\frac{P(H)}{P(A)} = \\frac{P(\\theta \\le \\theta_0)}{P(\\theta > \\theta_0)}.\n\\] After one observes the data \\(\\bar y\\), the new opinions about the mean \\(\\theta\\) are reflected in the posterior density N(\\(\\mu_1, \\tau_1^2\\)), where \\[\n\\mu_1 = \\frac{\\mu/\\tau^2 + n \\bar y/\\sigma^2}{1/\\tau^2+n/\\sigma^2}, \\,\\, \\tau_1^2 = \\frac{1}{1/\\tau^2+n/\\sigma^2}.\n\\] The posterior odds is the ratio of the posterior probabilities of the two hypotheses \\[\nO(H|y) = \\frac{P(H|y)}{P(A|y)} = \\frac{P(\\theta \\le \\theta_0|y)}{P(\\theta > \\theta_0|y)},\n\\] and the Bayes factor is the ratio of the posterior odds to the prior odds \\[\nBF_{HA} = \\frac{O(H|y)}{O(H)}.\n\\]\nLet’s return to the Joe IQ example. If \\(\\theta\\) represents Joe’s true IQ, suppose we are interested in testing the hypotheses \\(H: \\theta \\le 100\\), Joe has at most average intelligence, against the alternative hypothesis \\(A: \\theta > 100\\), Joe has above-average intelligence. If our prior beliefs are normal with mean \\(\\mu = 100\\) and \\(\\tau^2 = 225\\), then the prior probability of \\(H\\) is equal to \\[\nP(H) = P(\\theta \\le 100) =  1/2,\n\\] and so the prior odds is \\[\nO(H) = 1\\]. If Joe’s observed IQ test score is \\(y = 120\\), we showed in Chapter ??? that the posterior density for \\(\\theta\\) is normal with mean \\(\\mu_1 = 113.8\\) and variance \\(\\tau_1^2 = 69.23.\\) The posterior probability of \\(H\\) is equal to \\[\nP(H | y=120) = P(\\theta \\le 100 | y=120) = \\Phi\\left(\\frac{100-120}{69.23}\\right) = \\Phi(-0.29) = 0.386,\n\\] and the posterior odds of \\(H\\) is \\[\nO(H | y=120) = \\frac{0.386}{1-0.386} = 0.639.\n\\] In this example, since the prior odds is 1, the Bayes factor \\(BF_{HA}\\) is also equal to 0.639, indicating that the data supports the alternative hypothesis that Joe has above-average intelligence. Since the posterior probability of \\(A\\) is relatively small (0.386), this single test result has not provided decisive evidence that Joe has an above-average true IQ.\n\n11.3.1.1 P-values and posterior probabilities of hypotheses}\nIn this setting, suppose we place a uniform, noninformative prior on \\(\\theta\\). Then the posterior density of \\(\\theta\\) is N(\\(\\bar y, \\sigma^2/n\\)) and the posterior probability of the null hypothesis is given by\n\\[\\begin{eqnarray*}\nP(H|y)  = P(\\theta \\le \\theta_0 | y)  \\nonumber \\\\\n                 =  P\\left( Z < \\frac{\\sqrt{n} (\\theta_0 - \\bar y)} {\\sigma} | y \\right) \\nonumber \\\\\n                 =  \\Phi \\left(\\frac{\\sqrt{n} (\\theta_0 - \\bar y)} {\\sigma}\\right), \\nonumber \\\\\n\\end{eqnarray*}\\] where \\(Z\\) is a standard normal random variable and \\(\\Phi()\\) is a standard normal cdf. This expression should look slightly familiar. If we observe \\(\\bar y\\), the p-value is the probability, under the hypothesis \\(\\theta = \\theta_0\\), of observing a result at least as extreme as \\(\\bar y\\): \\[\\begin{eqnarray*}\n{\\rm p-value}  =  P(\\bar Y \\ge \\bar y | \\theta = \\theta_0)\\nonumber \\\\\n  =  P\\left( Z > \\frac{\\sqrt{n}(\\bar y - \\theta_0)}{\\sigma} \\right) \\nonumber \\\\\n                =  1 - \\Phi \\left(\\frac{\\sqrt{n} (\\bar y-\\theta_0)} {\\sigma}\\right), \\nonumber \\\\\n              =  \\Phi \\left(\\frac{\\sqrt{n} (\\theta_0 - \\bar y)} {\\sigma}\\right). \\nonumber \\\\\n\\end{eqnarray*}\\] We obtain an interesting result. When we place a uniform prior on the parameter, the posterior probability of the null hypothesis is equal to the p-value. This means that it actually makes sense to think about the p-value as a posterior probability in the one-sided testing situation. We will shortly see that this computational equivalence between a p-value and a posterior probability isn’t always true.\n\n\n\n11.3.2 The two-sided hypothesis\nWe next consider the common situation where one is interested in testing the “point” null hypothesis \\(H: \\theta = \\theta_0\\) against the two-sided alternative \\(A: \\theta \\neq \\theta_0\\). In the example of coin flipping, we may wish to test the common hypothesis of fairness that is equivalent to testing the null hypothesis that the probability of flipping heads \\(p\\) is exactly equal to 0.5.\nWe focus on normal sampling and think about an appropriate prior on the normal mean \\(\\theta\\). Here we can’t simply place a continuous prior on \\(\\theta\\) since the prior probability of the point null hypothesis would be equal to zero. Instead we place a mixed distribution, that is, a combination of a discrete and a continuous distribution, to reflect the belief in these two hypotheses.\nSuppose we assign a probability \\(\\gamma\\) to the hypothesis \\(\\theta = \\theta_0\\), and so the alternative hypothesis has a prior probability of \\(1 - \\gamma\\). We then assign a continuous prior \\(g_1(\\theta)\\) to the values of \\(\\theta\\) under the hypothesis \\(A\\). With this “mixed” prior, we wish to compute the posterior probability of the hypotheses.\nLet \\[\nL(\\theta) = \\exp\\left(   -\\frac{n}{2 \\sigma^2}(\\bar y - \\theta)^2 \\right)\n\\] denote the likelihood of \\(\\theta\\). The posterior probability that \\(\\theta = \\theta_0\\) is proportional to \\[\nP(H | y) \\propto \\gamma L(\\theta_0),\n\\] and the posterior probability that \\(\\theta \\neq \\theta_0\\) is proportional to \\[\nP(A | y) \\propto (1 - \\gamma) \\int L(\\theta) g_1(\\theta) d\\theta.\n\\] So the posterior probability of \\(H\\) has the expression \\[\nP(H| y) = \\frac{\\gamma L(\\theta_0)}{\\gamma L(\\theta_0) + (1 - \\gamma) \\int L(\\theta) g_1(\\theta) d\\theta}.\n\\]\nIn practice, one has to specify two quantities, \\(\\gamma\\), the prior probability that \\(\\theta = \\theta_0\\), and \\(g_1(\\theta)\\), the prior density of the normal mean under the alternative hypothesis that \\(\\theta \\neq \\theta_0\\). It is reasonable to set \\(\\gamma = 0.5\\), indicating that one believes that the hypotheses \\(H\\) and \\(A\\) are equally likely. To specify \\(g_1(\\theta)\\), suppose that when \\(\\theta \\neq \\theta_0\\) is true, values of \\(\\theta\\) close to \\(\\theta_0\\) are more likely than values of \\(\\theta\\) far from \\(\\theta_0\\). Under this assumption, then one could let \\(g_1\\) be normal with mean \\(\\theta_0\\) and standard deviation \\(\\tau\\). With this choice, a straightforward calculation shows that \\[\nP(H|y) = \\frac{ \\phi(\\bar y; \\theta_0, \\sigma^2/n)}{\\phi(\\bar y; \\theta_0, \\sigma^2/n) + \\phi(\\bar y; \\theta_0, \\sigma^2/n+\\tau^2)},\n\\] where \\(\\phi(y; \\theta, \\sigma^2)\\) is the normal density with mean \\(\\theta\\) and variance \\(\\sigma^2\\).\nIn our IQ example, suppose we wish to test the hypothesis \\(H: \\theta = 100\\) that Joe has “average” intelligence, against the hypothesis \\(A: \\theta \\neq 100\\) that Joe’s intelligence is not average. One observes the IQ test score \\(y\\) that is normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2 = 100\\). Suppose \\(\\gamma = 0.5\\) and \\(\\theta\\) has a N(100, 225) distribution when \\(\\theta \\neq 100\\). One observes the test score \\(y = 120\\) and the posterior probability that Joe is average is given by \\[\\begin{eqnarray*}\nP(H|120)  =  \\frac{ \\phi(120; 100, 100)}{\\phi(120; 100, 100) + \\phi(120; 100, 100 + 225)} \\nonumber \\\\\n  = 0.311. \\nonumber \\\\\n\\end{eqnarray*}\\] Since the posterior probability of \\(H\\) is pretty close to 0.5, there is little evidence from this single test score that Joe does not have average intelligence.\nTo use this procedure, one needs to specify \\(\\tau\\), the standard deviation of the prior when the alternative hypothesis \\(\\theta \\neq \\theta_0\\) is true. Since it seems that the value \\(\\tau = 15\\) was made arbitrarily, we should investigate the sensitivity of the posterior probability with respect to this standard deviation. Table ?? displays values of the posterior probability \\(P(H| 120)\\) for a range of values of \\(\\tau\\). Note that the minimum value of this posterior probability in the table is equal to \\(0.311\\) which implies that \\(P(H | 120) \\ge 0.311\\) for all \\(\\tau\\). This calculation shows that Joe’s score of 120 only provides a small amount of evidence against the hypothesis that Joe’s true IQ is 100.\n\n\n\n\n\\(\\tau\\)\n\\(P(H)\\)\n\n\n\n\n1\n1.000\n0.496\n\n\n2\n2.000\n0.486\n\n\n3\n4.000\n0.450\n\n\n4\n8.000\n0.370\n\n\n5\n15.000\n0.311\n\n\n6\n30.000\n0.343\n\n\n7\n60.000\n0.465\n\n\n8\n600.000\n0.890\n\n\n\nHow does this Bayesian calculation compare with a p-value? For a two-sided test, the p-value is equal to two times the tail probability of \\(\\bar y\\) when \\(\\theta = \\theta_0\\). Here the p-value is twice the probability of observing an IQ score at least as extreme as 120 when \\(y\\) is distributed as N(100, 100): \\[\n{\\rm p-value} = 2 \\times P(\\bar Y \\ge 120 | \\theta = 100) = 2 \\times (1 - \\Phi(2)) = 0.0455  \n\\] The Bayesian posterior probability of \\(\\theta = 100\\) is significantly larger than the p-value. This suggests that the p-value overstates the evidence against the point null hypothesis."
  },
  {
    "objectID": "model_selection.html#comparing-models-by-bayes-factors",
    "href": "model_selection.html#comparing-models-by-bayes-factors",
    "title": "11  Bayesian Testing and Model Selection",
    "section": "11.4 Comparing Models by Bayes Factors",
    "text": "11.4 Comparing Models by Bayes Factors\nBayes factors provide a general way of comparing two Bayesian models. Let \\(y\\) denote the vector of observations whose distribution depends on a (possibly) vector-valued parameter \\(\\theta\\). A Bayesian model is a specification for the sampling density \\(f(y | \\theta)\\) and the prior density \\(g(\\theta)\\). Suppose we wish to compare models \\(M_1\\) and \\(M_2\\) where \\[\nM_i:  y \\sim f_i(y | \\theta), \\, \\, \\theta \\sim g_i(\\theta).\n\\] For each model, we define the predictive or marginal density of \\(y\\), \\(f_i (y)\\) defined by \\[\nf_i(y) = \\int f_i(y | \\theta) g_i(\\theta) d\\theta.\n\\] The the Bayes factor in support of model \\(M_1\\) over model \\(M_2\\) is the ratio of the corresponding predictive densities of the two models: \\[\nB_{12} = \\frac{f_1(y)}{f_2(y)} = \\frac {\\int f_1(y | \\theta) g_1(\\theta) d\\theta}{\\int f_2(y | \\theta) g_2(\\theta) d\\theta}.\n\\]\nTo illustrate Bayes factors, we return to the problem of estimating the mean number of hits per weekday on a particular website. The daily counts of website hits \\(y_1, ..., y_n\\) are assumed to follow a Poisson distribution with mean \\(\\lambda\\). We describe two models that differ with respect to the prior placed on the mean parameter \\(\\lambda\\).\nModel \\(M_1\\): \\(y_1, ..., y_n \\sim P(\\lambda), \\lambda \\sim {\\rm Gamma}(40, 2)\\).\nModel \\(M_2\\): \\(y_1, ..., y_n \\sim P(\\lambda), \\lambda \\sim {\\rm Gamma}(20, 2)\\).\nThe prior for model \\(M_1\\) says that the mean website hit count \\(\\lambda\\) is likely to fall between 15 and 25, and the prior for \\(M_2\\) says that \\(\\lambda\\) is likely a smaller value between 8 and 12. If we observe the website counts\n20 30 22 20 20 17 21 26 22 30 36 15 30 27 22 23 18 24 28 23 12,\nwe are interested in comparing the models by means of a Bayes factor.\nIn this example of Poisson sampling,we are using a conjugate gamma prior and we can compute the predictive density analytically. If \\(\\lambda\\) has a Gamma(\\(a, b\\)) prior, then the predictive density of \\(y_1, ..., y_n\\) is given by \\[\\begin{eqnarray*}\nf(y)  =  \\int \\prod_{i=1}^n \\left(\\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!}\\right) \\frac{b^a \\lambda^{a-1} \\exp(-b \\lambda)}{\\Gamma(a)} d\\lambda \\nonumber \\\\\n  =  \\frac{\\Gamma(a + s) b^a}{\\Gamma(a) \\left(\\prod_{i=1}^n y_i\\right) (b+n)^{a+s}},  \\nonumber \\\\\n\\end{eqnarray*}\\] where \\(s = \\sum y_i\\) and \\(n\\) is the sample size. It is convenient to express marginal densities and Bayes factors on the log scale. The logarithm of the marginal density is given by \\[\n\\log f(y) = \\log\\Gamma(a+s)-\\log\\Gamma(a)-\\sum_{i=1}^n \\log (y_i!)+a \\log(b) - (a+s)\\log(b+n).\n\\]\nUsing this expression, we compute the log marginal density for each of the two priors in models \\(M_1\\) and \\(M_2\\). Here \\(s = 486\\), \\(n = 21\\), and \\[\n\\log f_1(y) = -67.83, \\, \\, \\log f_2(y) = -76.59.\n\\] On the log scale, the Bayes factor in favor of model \\(M_1\\) over \\(M_2\\) is equal to \\[\n\\log B_{12} = -67.83 - (- 76.59) = 8.76,\n\\] and the Bayes factor in support of model \\(M_1\\) is equal to \\(BF_{12} = \\exp(8.76) = 6574\\).\nThe value of the Bayes factor can be understand by looking at Figure 1. This figure displays the likelihood and the two priors. Note that the first prior that reflects the belief that \\(\\lambda\\) is between 15 and 25 is consistent with the likelihood. In contrast, there is substantial conflict of the likelihood function with the second prior that says that \\(\\lambda\\) is around 10. The Bayes factor of 6574 indicates that the observed values of \\(y\\) are much more likely with the first prior than the second prior.\nIn many situations, it will not be possible to integrate out the parameter analytically to compute the predictive density. Fortunately, there are several good approximations available for computing \\(f(y)\\).\nOne approximation method is based on the Laplace method illustrated in Chapter 5. As in that chapter, let \\(h(\\theta)\\) denote the logarithm of the joint density of \\((y, \\theta)\\), that is, \\(h(\\theta) = \\log \\left( f(y|\\theta) g(\\theta) \\right)\\). We approximate \\(h(\\theta)\\) by a Taylor series about the posterior mode \\(\\hat \\theta\\): \\[\nh(\\theta) \\approx h(\\hat \\theta) + (\\theta - \\hat \\theta)' h''(\\hat \\theta)(\\theta - \\hat \\theta)/2.\n\\] Using this approximation, one can integrate out \\(\\theta\\) to get the following approximation to the predictive density: \\[\nf(y) = \\int \\exp(h(y, \\theta)) d\\theta \\approx (2\\pi)^{d/2} g(\\hat \\theta) f(y | \\hat \\theta) |-h''(\\hat \\theta)|^{-1/2},\n\\] where \\(d\\) is the number of parameters and \\(h''(\\hat \\theta)\\) is the Hessian matrix evaluated at the mode.\nContinuing with our web site hit example, consider the comparison of several models for the web site counts collected on weekdays and weekends.\nRecall that the counts {\\(y_{Ai}\\)} from the weekend days are assumed Poisson with mean \\(\\lambda_A\\) and counts {\\(y_{Bj}\\)} from the weekday days are assumed Poisson with mean \\(\\lambda_B\\). Since we are interested primarily in comparing the two means, consider the reparameterization \\[\n\\theta_1 = \\log \\lambda_A - \\log \\lambda_B, \\, \\, \\theta_2 = \\log \\lambda_A + \\log \\lambda_B.\n\\] The parameter \\(\\theta_1\\) measures the difference between the Poisson means on the log scale and \\(\\theta_2\\) represents the overall size of the means.\nConsider the following two prior distributions for \\((\\theta_1, \\theta_2)\\):\nModel \\(M_1\\): \\(\\theta_1, \\theta_2\\) independent, \\(\\theta_1 \\sim N(0, 0.5)\\), \\(\\theta_2 \\sim N(5, 5)\\).\nModel \\(M_2\\): \\(\\theta_1, \\theta_2\\) independent, \\(\\theta_1 \\sim N(0, 0.05)\\), \\(\\theta_2 \\sim N(5, 5)\\).\nFigure 2 displays contour plots of the two prior models. Both priors state that the overall size of the means (as measured by the parameter \\(\\theta_2\\)) is in the neighborhood of 5. The priors differ by the distribution placed on the difference in means \\(\\theta_1\\). Model 1 places a relatively diffuse prior on \\(\\theta_1\\) centered at zero, and Model 2 assigns a prior on \\(\\theta_1\\) concentrated about zero. The prior for Model 2 is concentrated about the hypothesis \\(H\\) that \\(\\lambda_1 = \\lambda_2\\) and the prior for Model 1 places more of its mass on the alternative hypothesis \\(A\\) that \\(\\lambda_1 \\neq \\lambda_2\\).\nBy using the function laplace() in the LearnBayes package, one can compute the log predictive density for each of the two models. We find \\[\n\\log f(y | M_1) =  -100.23, \\, \\, \\log f(y | M_2) = -108.79,\n\\] and the log Bayes factor in support of Model \\(M_1\\) over Model \\(M_2\\) is \\[\n\\log BF_{12} = \\log f(y | M_1) - \\log f(y | M_2) = -100.23 - (-108.79) = 8.56.\n\\] Since the Bayes factor in support of \\(M_1\\) is \\(\\exp(8.56) = 5218\\), there is strong evidence against the hypothesis \\(H\\) that the Poisson means for the weekend and weekday web counts are equal.\n\n11.4.1 Comparing Geometric and Poisson Distributions\n(From Link and Barker (2010))\nSuppose we observe a random sample \\(y_1, ..., y_n\\) that is either distributed from the geometric density \\[\nf_G(y) = p (1-p)^y, y = 0, 1, 2, ...\n\\] or the Poisson density \\[\nf_P(y) = \\frac{e^{\\lambda} \\lambda^y}{y!}, y = 0, 1, 2, ...\n\\] We observe the sample of values \\[\n0, 1, 2, 3, 8\n\\] What is the evidence in support of the geometric density over the Poisson density?\nFirst, to complete define the two models, a prior needs to be assigned to the parameters \\(p\\) and \\(\\lambda\\). To make the priors comparable, assume the mean \\(\\mu = E(Y)\\) has a uniform distribution on the interval from 0 to a large value \\(T\\). For the Poisson sampling model, the mean is given by \\(\\mu = \\lambda\\), so this results in the prior \\[\ng(\\lambda) = \\frac{1}{T}, 0 < \\lambda < T.\n\\] For the geometric model, the mean of \\(Y\\) is given by \\(\\mu = (1-p)/p\\). If we assign \\(\\mu\\) a uniform(0, \\(T\\)), then by a transformation argument, one can show the prior is given by \\[\ng(p) = \\frac{1}{T p^2}, \\, \\, \\frac{1}{T+1} < p < 1.\n\\]\n\n11.4.1.1 Direct calculation\nNow that the priors are defined, we can compute the marginal densities. Generally, if the sampling density is defined in terms of the parameter \\(\\theta\\) and a prior \\(g(\\theta)\\) is defined, the marginal density is given by \\[\nf(y) = \\int g(\\theta) \\prod_{i=1}^n f(y_i | \\theta) d\\theta .\n\\]\nIn the following, it is convenient to let \\(s = \\sum_{i=1}^n y_i\\) be the sum of the observations. For the Poisson model, we obtain \\[\\begin{eqnarray*}\nf_P(y) | = | \\int_0^T \\frac{e^{-ny} \\lambda^s}{\\prod y_i!} \\frac{1}{T} d\\lambda.\n                \\nonumber \\\\\n\\end{eqnarray*}\\] We recognize the kernel of the integrand as a gamma density with shape parameter \\(s+1\\) and rate parameter \\(n\\), so the integral can be evaluated in terms of a gamma cdf. We obtain \\[\\begin{eqnarray*}\nf_P(y)  =  \\frac{ F_G(T; s+1, n) \\Gamma(s+1)}{T n^{s+1}\\prod y_i! },\n                \\nonumber \\\\\n\\end{eqnarray*}\\] where \\(F_G(x; a, b)\\) is the cdf of a Gamma(\\(a, b\\)) density evaluated at \\(x\\).\nThe marginal density for the geometric model is given by \\[\\begin{eqnarray*}\nf_G(y)  =  \\int_{1/(T+1)}^1 p^n (1-p)^s \\frac{1}{T p^2} dp\n                \\nonumber \\\\\n        =  \\frac{1}{T} \\int_{1/(T+1)}^1 p^{n-2} (1-p)^s dp.\n\\end{eqnarray*}\\] We recognize the integrand as the kernel of a beta(\\(n-1, s+1)\\) density and we obtain \\[\\begin{eqnarray*}\nf_G(y)  =  \\frac{(1-F_B(1/(T+1), n-1, s+1)) B(n-1, s+1)}{T},\n                \\nonumber \\\\\n\\end{eqnarray*}\\] where \\(F_B(x; a, b)\\) is the cdf of a Beta(\\(a, b\\)) density.\nThe Bayes factor in support of the geometric model over the Poisson is given by \\[\nBF_{GP} = \\frac{f_G(y)}{f_B(y)}.\n\\]\nA short function compute.bf() is used to compute the Bayes factor. We assume the data is stored in the vector y and the single argument of the function is the value of \\(T\\).\ncompute.bf=function(T)\n{\nn=length(y); s=sum(y)\nf1=(1/T)*(1-pbeta(1/(T+1),n-1,s+1))*beta(n-1,s+1)\nf2=(1/T)/prod(gamma(y+1))*pgamma(T,shape=s+1,rate=n)*gamma(s+1)/n^(s+1)\nf1/f2\n}\nBy use of the function\ncurve(compute.bf(x),from=2,to=40)\nwe plot the Bayes factor as a function of \\(T\\) for values from 2 to 40 (see Figure 1).\nNote that as \\(T\\) approaches infinity, the Bayes factor approaches the limiting value of 13.84. There is some support for the geometric model on the basis of this small dataset.\n\n\n11.4.1.2 Simulation estimate\nThere is an attractive Gibbs sampling approach for computing the Bayes factor. Define a model variable \\(M\\) that is equal to 1 for the geometric model and 2 for the Poisson model. One places the prior probabilities \\(P(M = 1) = \\pi, P(M = 2) = (1-\\pi)\\). Let \\(\\mu\\) denote the mean parameter \\(E(Y)\\). The joint posterior density of (\\(M, \\mu)\\) is given by \\[\ng(M, \\mu | y) \\propto I(M = 1) \\pi \\prod_{i=1}^n f_G(y_i | \\mu) g_G(\\mu) + I(M = 2)(1-\\pi) \\prod_{i=1}^n f_P(y_i | \\mu) g_P(\\mu).\n\\] Both of the conditional distributions \\(g(M | \\mu, y)\\) and \\(g(\\mu | M, y)\\) have simple forms.\nHere is an outline of the Gibbs sampler. We begin with a starting estimate at \\(\\mu\\) – a reasonable estimate is the sample mean \\(\\mu^{(0)} = \\bar y\\). If the initial model probability vector is stored in the vector {}, then we simulate a value of the model \\(M\\) by the following R code.\nlog.M1=sum(dgeom(y,1/(1+theta),log=TRUE))+log(prior[1])\nlog.M2=sum(dpois(y,theta,log=TRUE))+log(prior[2])\nprob=exp(log.M1)/(exp(log.M1)+exp(log.M2))\nM=ifelse(runif(1)<prob,1,2)\nNext, we simulate a value of \\(\\mu\\) from either a beta posterior or a gamma posterior depending on the value of \\(M\\):\nif(M==2) theta=rgamma(1,shape=s+1,rate=n) else {\n     p=rbeta(1,n-1,s+1); theta=(1-p)/p}\nThese two steps are cycled \\(m\\) times and one obtains a simulated sample denoted by \\((M^{(j)}, \\mu^{(j)}), j = 1, ..., m\\).\nSuppose that the simulated sample of the model indicator \\(M\\) is taken as a sample from its posterior density. The posterior odds of \\(M = 1\\) is estimated by the ratio \\[\n\\frac{\\sum_{j=1}^m I(M^{(j)} = 1)}{\\sum_{j=1}^m I(M^{(j)} = 2)}.\n\\] The estimate at the Bayes factor in support of the geometric model is estimated by the ratio of the estimate of the posterior odds to the prior odds: \\[\n\\hat{BF} = \\frac{\\sum_{j=1}^m I(M^{(j)} = 1)}{\\sum_{j=1}^m I(M^{(j)} = 2)} \\div \\frac{\\pi}{1-\\pi}.\n\\]\nA function gibbs.MS was written to implement the Gibbs sampler. The inputs are prior model vector pi, the data vector y, and the number of iterations of the sampler iter. The output is a list consisting of model, a vector of the simuated values of \\(M\\), and theta, a vector of the simulated draws of \\(\\mu\\). In the following output, we run the sampler for 100,000 iterations using the prior input values \\((\\pi, 1-\\pi) = (0.1, 0.9)\\) . We use the table() function to tabulate the model values, and compute the posterior odds from the tabled values.\nprior=c(.1,.9)\ny=c(0,1,2,3,8)\nS=gibbs.MS(prior,y,100000)\nmodel.freq=table(S$model)\npost.odds=model.freq[\"1\"]/model.freq[\"2\"]\nBF=post.odds/(prior[1]/prior[2])\nBF\nThe output is \\(BF = 13.98322\\) which is very close to the exact value of 13.84 in the previous calculation.\n\n\n11.4.1.3 Model averaging\nWe have focused on comparing the geometric and Poisson models by a Bayes factor. What if we are interested in inference about the mean parameter \\(\\mu\\)?\nIf the data have a Poisson distribution and \\(\\mu\\) has a uniform prior, we have already seen that the posterior density for \\(\\mu\\) is Gamma with shape \\(s = \\sum y_i+1\\) and rate \\(n\\). If instead the data have a geometric distribution and a uniform prior is place on the mean, then the posterior distribution of the proportion \\(p\\) is beta with parameters \\(a = n-1\\) and \\(b = s+1\\). The corresponding posterior density for the mean \\(\\mu = (1-p)/p\\) is given by \\[\ng(\\mu | y, M=1) = f_B\\left(\\frac{1}{1+\\theta}\\right) \\frac{1}{(1+\\theta)^2}.\n\\]\nWhat if one is unsure about the correct sampling density? If one places prior probabilities \\(\\pi\\) and \\(1-\\pi\\) on the geometric (Model 1) and Poisson (Model 2) models, respectively, then the posterior density for the mean \\(\\mu\\) has the form \\[\ng(\\mu|y) = \\pi(y) g(\\mu | M = 1) + (1- \\pi(y)) g(\\mu | M = 2),\n\\] where \\(g(\\mu | M = m)\\) is the posterior of \\(\\mu\\) conditional on model \\(m\\), and \\(\\pi(y)\\) is the posterior probability of Model 1. This posterior model probability is given by \\[\n\\pi(y) = \\frac{\\pi BF_{12}}{\\pi BF_{12}+1-\\pi},\n\\] where \\(BF_{12}\\) is the Bayes factor in support of Model 1.\nFigure 2 illustrates inference about the mean \\(\\mu\\) for the same data set and uniform prior where the prior probability of Model 1 (geometric) is \\(\\pi = 0.1\\). Two of the curves represent posterior densities conditional on the geometric and Poisson sampling models. The third curve is a “modeled averaged” posterior density, where the two conditional posterior densities are averaged by the model posterior probabilities."
  }
]