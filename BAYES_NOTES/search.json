[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Bayesian Inference",
    "section": "",
    "text": "Statistics, the science of learning from data, is a relatively new discipline. One can divide the history of Statistics into three periods using the years 1900 and 1960.\n\nIn the early days of Statistics (before 1900), much of the statistical work was devoted to data analysis including the construction of graphical displays. There was little work done on inferential statistics. The foundations of Bayesian inference had been developed by Bayes and Laplace in the 18th century.\nThe foundations of statistical inference were developed in the period between 1900 and 1970. Karl Pearson developed the chi-square goodness of fit procedure around the year 1900 and R. A. Fisher developed the notions of sufficiency and maximum likelihood in this period. Statistical procedures are evaluated in terms of their long-run behavior in repeated sampling. For this reason, these procedures are known as frequentist methods. Properties such as unbiasedness and mean square error are used to evaluate procedures. Some prominent Bayesians such as Harold Jeffreys, Jimmie Savage, and I. J. Good made substantial contributions during this period, but the frequentist methods became the standard inferential methods in the statistician’s toolkit.\nIn the last 40 years, there has been a great development in new statistical methods, especially computational demanding methods such as the bootstrap and nonparametric smoothing. Due to the recent availability of high-speed computers together with new simulation-based fitted algorithms, Bayesian methods have become increasingly popular. In contrast to the middle period of statistics where frequentist methods were dominate, we currently live in a frequentist/Bayesian world where statisticians routinely use Bayesian methods in situations where this inferential perspective has particular advantages.\n\n\n\n\nOne fundamental inference problem is learning about the association pattern in a 2 by 2 contingency table. Suppose we sample data values that are categorized with respect to the presence and absence of two variables \\(A\\) and \\(B\\) and one observes the following table of counts.\n\n\n\n\nVar B\n\n\n\n\n\nVar A\nyes\nno\n\n\nyes\n\\(a\\)\n\\(b\\)\n\n\nno\n\\(c\\)\n\\(d\\)\n\n\n\nThere are two common questions that one is interested in answering. First, is there a significant association structure in the table? Second, if variables \\(A\\) and \\(B\\) are indeed dependent, one is interested in estimating the strength of the association.\nAs an example, suppose one observes the following table counts.\n\n\n\n\nVar B\n\n\n\n\n\nVar A\nyes\nno\n\n\nyes\n\\(10\\)\n\\(0\\)\n\n\nno\n\\(2\\)\n\\(5\\)\n\n\n\nOne constructs a statistical test of the hypothesis of independence to see if there is significant association in the table. The standard test of independence is based on the Pearson’s chi-squared test. One implements this testing procedure on R by the function chisq.test() and one observes the following output for these data.\n\ncounts <- matrix(c(10, 2, 0, 5), 2, 2)\nchisq.test(counts)\n\nWarning in chisq.test(counts): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  counts\nX-squared = 6.971, df = 1, p-value = 0.008284\n\n\nWe note that the p-value of the test statistic is 0.008284 which indicates that there is significant evidence that the two variables are dependent. But we see a warning in the output saying that the accuracy of this p-value computation is in doubt.\nWhat is going wrong? The chi-squared test is based on the test statistic \\[\nX = \\sum \\frac{(o - e)^2}{e},\n\\] where \\(o\\) and \\(e\\) represent, respectively, the observed cell count and estimated expected cell count under the independence assumption. Asymptotically, under the assumption of independence, \\(X\\) has a chi-squared distribution with one degree of freedom. The displayed p-value is the tail probability of a chi-square(1) random variable. When the cell counts are large, the distribution of \\(X\\) is approximately chi-square. But, when the counts are small (as in this example), the distribution of \\(X\\) may not be approximately chi-square(1) and so the accuracy of the p-value calculation is in doubt.\nWhat can one do in this situation? A standard alternative test procedure is Fisher’s exact test where the p-value is computed based on the hypergeometric distribution. If one implements this test using the R function fisher.test(), one sees the following output.\n\ncounts <- matrix(c(10, 2, 0, 5), 2, 2)\nfisher.test(counts)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  counts\np-value = 0.003394\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 2.164093      Inf\nsample estimates:\nodds ratio \n       Inf \n\n\nOne obtains a new p-value of 0.003394 which is significantly different from the ``large sample” p-value of 0.008284, indicating that the accuracy of the chi-square approximation was relatively poor. But this analysis raises new questions.\n\nWhat sampling model?\n\nThere are different sampling models that can produce the observed table counts. For example, one may be taking a single random sample of a particular size and classifying each observation with respect to the two variables – this is the multinomial sampling model. Alternatively, one may be taking two independent samples; the “A-sample” is classified with respect to variable B, and a second “not A-sample” is also classified with respect to variable B – this is the product of binomials sampling model. Or perhaps one assumes that the observed margins of the table are fixed and the only random quantity is the one count in the top left of the table – this gives rise to the hypergeometric distribution under independence that is the basis for Fisher’s exact test.\n\nDoes the choice of sampling model matter?\n\nIf one is unsure about the sampling method that produces the table, one might hope that the test of significance is insensitive to the choice of sampling model. But this is not the case. The p-value is dependent on the choice of model. Actually, there is a debate among frequentists on the “proper” choice of sampling model in the test of independence.\n\nWhat about estimating the association?\n\nIn this example, since the test of independence seems to be clearly rejected, the focus should be on the estimation of the association. A standard measure of association in a two by two table is the odds ratio defined by \\[\n\\alpha = \\frac{p_{11} p_{22}}{p_{12} p_{21}},\n\\] where (assuming a multinomial sampling model) \\(p_{ij}\\) is the probability of an observation in the \\(i\\)th row and \\(j\\)th column of the table. The maximum likelihood estimate of \\(\\alpha\\) is given by \\[\n\\hat \\alpha = \\frac{a d}{b c}.\n\\] For these data, we observe \\(a = 10\\), \\(b = 0\\), \\(c = 2\\) and \\(d = 5\\), resulting in an infinite estimate for \\(\\alpha\\). This is indicated by the fisher.exact() output. Also the standard (asymptotic) 95% confidence interval for \\(\\alpha\\) for these data is given by (2.164093, \\(\\infty)\\). We see that the observed zero count has made it difficult to get reasonable point and interval estimates of the odds ratio.\nIn this problem, we see some pitfalls in applying frequentist testing methods for this simple problem. Since there are small counts, standard methods relying on asymptotic approximations seem unsuitable. But the computation of an “exact” p-value is also unclear in this situation, since this computation relies on the sampling distribution which may be unknown.\nFrequentist methods also perform poorly for the estimation problem since the infinite estimate of \\(\\alpha\\) is not reasonable. If one thinks about the cell probabilities, then one would think that all of these probabilities would be positive, resulting in a finite value of the odds-ratio. But there are no ways to include these ``prior beliefs” that the probabilities are positive in the estimation problem. A standard ad-hoc solution to this problem is to add a fake count of 1/2 to each cell count, and estimate alpha by computing the maximum likelihood estimate on these adjusted counts: \\[\n\\hat \\alpha = \\frac{(a+1/2) (d+1/2)}{(b+1/2) (c+1/2)}.\n\\] But it is not obvious that 1/2 is the correct choice of fake count to get a “best” estimate of the odds ratio.\n\n\n\nThe previous example illustrates some of the problems in applying frequentist inferential methods and so it desirable to consider the alternative Bayesian paradigm for inference. Here is a short list of some positive and negative aspects of the frequentist and Bayesian approaches to inference.\nPositive Aspects of Frequentist Inference:\n\nThere are a number of good methods such as maximum likelihood and most powerful tests and good criteria for evaluating procedures such as unbiased and mean square error.\nThese methods are automatic to apply and have wide applicability.\nOne is generally interested in evaluating procedures by their performance in repeated sampling.\n\nNegative Aspects of Frequentist Inference:\n\nThere is no general method for inference. One has to be clever to devise good statistical procedures in situations where standard methods fail.\nFrequentist methods can perform poorly. For example, frequentist methods do not perform well for sparse contingency tables with one or more observed zeros.\nOne is unable to incorporate prior knowledge into the inference.\n\nPositive Aspects of Bayesian Inference:\n\nOne has one recipe (Bayes’ rule) for statistical inference.\nOne can formally incorporate prior information into the analysis.\nNuisance parameters are easily handled in a Bayesian analysis.\n\nNegative Aspects of Bayesian Inference:\n\nBayesian thinking requires more thought with the introduction of a prior distribution.\nFrom a calculation perspective, it can be difficult to implement Bayesian methods, although powerful computational tools exist."
  },
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "2  Probability",
    "section": "",
    "text": "Bayesian thinking is based on the subjective viewpoint of probability. In this chapter, we will talk about the different ways of thinking about probability."
  },
  {
    "objectID": "probability.html#measuring-uncertainty",
    "href": "probability.html#measuring-uncertainty",
    "title": "2  Probability",
    "section": "2.2 Measuring Uncertainty",
    "text": "2.2 Measuring Uncertainty\nWe live in a world of uncertain events and some events are more likely to occur than other events. Words such as “likely”, “probable”, “possible”, “rare”, and “maybe” are used to describe this uncertainty. It is natural to use numbers that we call probabilities to quantify this uncertainty. The probability of an event \\(A\\), denoted \\(P(A)\\), is a number between 0 and 1 assigned to the event \\(A\\) where a larger number indicates that the event is more likely to occur.\nSome uncertain events already have numbers assigned to them. In games of chance where dice are rolled or cards are dealt from a well-shuffled deck, outcomes have particular probabilities. For example, the chance of rolling two dice equal to double-sixes is 1/36 and the chance of dealing a four of diamonds in a regular deck is 1/52. In actuarial tables, there are assigned probabilities that a person’s life span will be a particular length based on one’s gender and age. These actuarial tables are used by insurance companies to write up a life insurance policy and decide on the cost of the policy to the customer.\nThere are two ways of viewing probabilities that allow us to assign probabilities in games of chance and actuarial tables. The classical or “equally-likely” view assumes that one can represent the outcomes of a random experiment in such a way such that the outcomes are equally likely. Then each outcome is assigned a probability equal to one divided by the total number of outcomes. In the dice example, there are 36 equally likely ways of representing the possible rolls of the dice, and the probability of one outcome (two sixes) is equal 1/36. In the card example, there are 52 possible draws in a deck of cards, and if the deck is well-shuffled, each outcome such as “four of diamonds” is assigned the probability of 1/52.\nA second way of thinking about probabilities is based on long-run relative frequencies. Suppose you are able to repeat a random experiment many times under similar conditions. Then the probability of an event is approximated by its relative frequency in the large number of trials. This viewpoint can be applied in games of chance. For example, the probability that the sum of two dice is equal to 7 can be approximated by the relative frequency of 7 in many rolls of the two dice. This definition can also be used for actuarial tables. The chance that a male of age 70 will survive ten years can be approximated by the relative frequency of 70-year old males who survive ten years.\nIs it possible use the relative frequency viewpoint to measure uncertainty for all random events? Lindley makes a distinction between two types of events. Statistical events are the events that can be repeated under similar conditions and non-statistical events are events that are essentially unique and can not be repeated. Games of chance are statistical events, while one-time events such as “Jones committed the murder” or “a Republican will be the next American president” are non-statistical events. One can use the relative frequency perspective to measure the probability of statistical events, but this viewpoint is clearly inappropriate in measuring the chance of non-statistical events. Also there are issues in applying the relative frequency viewpoint. Sometimes it is not clear how to repeat a random experiment under similar circumstances. For example, suppose one observes three flips of a coin with the first head on the third flip. How does one repeat this experiment. Does one consider sets of three flips, or instead consider flips that end with the first head?"
  },
  {
    "objectID": "probability.html#the-subjective-viewpoint",
    "href": "probability.html#the-subjective-viewpoint",
    "title": "2  Probability",
    "section": "2.3 The Subjective Viewpoint",
    "text": "2.3 The Subjective Viewpoint\nThere is a third viewpoint of probability, the subjective viewpoint, that is the basis for Bayesian thinking. We start with a proposition which is any statement that can be true or false. For example, consider the proposition “it will rain tomorrow.” A person’s belief in the truth in this proposition can vary; the person may believe it is certainly false or she may believe it is certainly true. A probability represents a number attached to the proposition “it will rain tomorrow” that reflects this belief. A probability of 1 means that the person believes the proposition is true, and a probability of 0 means that the person believes with certainty that the proposition is false. A probability of 0.5 means that the person believes that the propositions “rain tomorrow” and “no rain tomorrow” are equally likely.\nIn the above definition, it should be noted that we are assigning numerical measures to propositions, which are more general than events. A proposition is any statement that is either true or false. Both statistical events and non-statistical events are examples of propositions. Second, an assigned probability is personal in that it reflects one person’s belief about the truth of the proposition. Different people may assign different probabilities to a given proposition. Certainly if we consider the proposition “Susie is receiving a final grade of A in her statistics class”, Susie and her instructor may have different beliefs about the truth in this proposition. Also a person’s probabilities about a proposition may change over time. As she obtains more information, her belief and therefore her probabilities can change. In our example, as Suzie receives exam grades, she will have different information and therefore possibly different beliefs in the proposition that she will get a final grade of A.\nTo summarize, from the subjective viewpoint, a probability is a numerical measure of the degree of belief by a person in a proposition based on the person’s current information. If \\(E\\) is a proposition and \\(H\\) is the current information or history of the individual, then we represent a probability by the notation \\(P(E | H)\\)."
  },
  {
    "objectID": "probability.html#measuring-subjective-probabilities",
    "href": "probability.html#measuring-subjective-probabilities",
    "title": "2  Probability",
    "section": "2.4 Measuring Subjective Probabilities",
    "text": "2.4 Measuring Subjective Probabilities\nAt this point, all we know about a subjective probability \\(P(E|H)\\) is that it falls between the values of 0 and 1 and larger values correspond to stronger beliefs in the truth in the proposition. Since subjective probabilities are generally difficult to assess, it is appropriate to describe some measurement methods.\nThe direct measurement approach takes a measurement of an object by comparing it with a collection of reference objects. To learn about the length of a piece of string, a direct measurement method uses a ruler, and a direct measurement way of learning about the weight of an object places it on a scale. To directly measure probabilities, we need to consider a set of propositions where the probabilities are known.\nConsider the following “balls in bag” experiment. We have a bag with \\(r\\) red and \\(w\\) white balls and one ball is chosen from the bag. Let \\(R(r, w)\\) denote the proposition that the chosen ball is red. We assume that the balls are all identical in appearance except color, the bag is mixed well, and one makes the draw blindfold. Then we would agree that the probability of \\(R(r, w)\\) is equal to the fraction \\(r/(r+w)\\). Consider the set of reference propositions \\(R(0, 1), R(1, 0), R(1, 1), ...\"\\). The reference probabilities \\(r/(r+w)\\) cover all rational values between 0 and 1.\nTo use these reference propositions to measure your probability \\(P(E | H)\\), you compare the proposition \\(E\\) with the reference propositions {\\(R(r, w)\\)}. Suppose you have a stronger belief in the truth of \\(E\\) than \\(R(r, w)\\). This implies that your probability \\(P(E | H)\\) exceeds the fraction \\(r/(r+w)\\). By making a sequence of comparisons of \\(E\\) with \\(R(r, w)\\) for different choices of \\((r, w)\\), one can in theory get an accurate assessment of your probability \\(P(E | H)\\).\nI am a Phillies fan and I wish to assess my probability of the event \\(A =\\)“the Phillies will be in the World Series” this season. To using this direct approach of assessment, I make the following comparisons.\n\nI first compare “Phillies in the World Series” with the event \\(R(1, 1)\\), choosing a red out of a bowl with one red ball and one white ball. I believe \\(R(1, 1)\\) is more likely, so my probability of \\(A\\), \\(P(A) < 1/2\\).\nNext, I compare the event \\(A\\) with the event \\(R(1, 3)\\), choosing a red out of a bowl with one red and three white balls. I believe that \\(R(1, 3)\\) is more likely, so \\(P(A) < 1/4\\).\nI continue with comparing \\(A\\) with \\(R(1, 7)\\), choosing a red out of a bowl with one red and seven white balls. I believe that the Phillies in the World Series is more likely. So \\(P(A) > 1/8\\) and combining my comparisons, I now know that \\(P(A)\\) is in the interval \\((1/8, 1/4)\\).\nI continue with these assessments until it is difficult to make further comparisons. I will have a small interval that I believes contains my probability of the event.\n\nOther measurements are taken in an indirect manner. For example, one older style of thermometer is constructed by the use of mercury in a glass tube. Heat applied to the glass causes the mercury to expand and one measures the temperature by reading the location of the mercury on a printed numerical scale. For this type of thermometer, one indirectly measures temperature by use of the expansion and contraction of mercury. In a similar fashion, one can measure probabilities by means of bets that are indirectly related to probabilities.\nA bet consists of a proposition that determines the outcome of the bet, odds that are offered by the bookmaker, and the amount of money that you are willing to stake. If you decide to stake $\\(s\\) on the proposition \\(E\\) at odds \\(z\\), this means that\n\nif \\(E\\) is false, you will give the bookmaker $\\(s\\)\nif \\(E\\) is true, the bookmaker gives you $ \\(z s\\)\n\nThe stake is the amount that you can lose if the proposition \\(E\\) is false and the odds is the ratio of the amount you can win if \\(E\\) is true to the amount you lose if \\(E\\) is false.\nUsing this indirect method, one measures your probability \\(P(E | H)\\) by means of bets on \\(E\\) between you and a hypothetical bookmaker. One can fix a value of the stake, say \\(s = \\$5\\) and bet on \\(E\\) using different values of the odds \\(z\\). You decide which bets to accept and reject.\nHow can one obtain one’s probability on the basis of these bets? First, note that you will accept any bet if the odds \\(z\\) is sufficiently large. But as the odds \\(z\\) is decreased, one will be less inclined to accept the bet, and for small values of odds, you will reject the bet. There will be one odds value \\(z_0\\) where you will accept bets for odds \\(z > z_0\\), and reject bets for \\(z , z_0\\). The value \\(z_0\\) is often called the {} of the proposition \\(E\\) based on your current information, denoted by \\(O(E | H)\\). We transform odds to a probability by the expression \\[\nP(E | H) = \\frac{1}{1+O(E|H)}.\n\\]\nLet us illustrate this indirect method of measuring probability for assessing my probability of the event \\(A\\) that the Phillies are in the World Series. I decide on using the stake $5 and consider the following bets:\n\nBET 1: At odds \\(z = 1\\), I will either lose $5 if \\(A\\) is false or win $5 if \\(A\\) is true.\nBET 2: At odds \\(z = 2\\), I will either lose $5 if \\(A\\) is false or win $10 if \\(A\\) is true.\nBET 3: At odds \\(z = 4\\), I will either lose $5 if \\(A\\) is false or win $20 if \\(A\\) is true.\nBET 4: At odds \\(z = 10\\), I will either lose $5 if \\(A\\) is false or win $50 if \\(A\\) is true.\n\nI will definitely not accept Bets 1 or 2 (the winning amounts are too small), and would accept Bet 4 which seems to have a generous odds. After some thought, suppose I am satisfied with a bet between Bet 3 and Bet 4 where the odds are \\(z = 7\\). Then my fair odds would be \\(O(A | H) = 7\\) and my probability of “Phillies in the World Series” would be \\[\nP(A | H) = \\frac{1}{1+7} = 0.125.\n\\]"
  },
  {
    "objectID": "probability.html#true-and-measured-probabilities",
    "href": "probability.html#true-and-measured-probabilities",
    "title": "2  Probability",
    "section": "2.5 True and Measured Probabilities",
    "text": "2.5 True and Measured Probabilities\nWe have discussed two methods, a direct method and an indirect method, for measuring the subjective probability of a proposition. Generally people will have trouble applying these methods since they have little experience in specifying probabilities. So in a typical application, one will not be able to specify his/her probability with high accuracy. Here it is helpful to distinguish a person’s true probability and her measured probability. A person’s true probability is the value she would obtain if she were able to make very fine comparisons in the likelihoods of events and had an infinite amount of time to make the assessment. But in real life, the person is unable to make fine comparisons and will spend only a finite amount of time on this task. So the specified probability \\(P(E | H)\\) is simply a measured estimate at the true probability. Since our measuring methods, such as the balls in bag experiment, are relatively crude, there can be significant measurement error in the specification of this probability."
  },
  {
    "objectID": "bayes_rule.html",
    "href": "bayes_rule.html",
    "title": "3  Bayes Rule",
    "section": "",
    "text": "Here is a basic exposition of Bayes rule. Suppose you have events \\(E_1, ..., E_k\\) that form a partition of the sample space.\n\n\\(P(E_i), i = 1, ..., k\\)\n\\(P(A | E_i), i = 1, ..., k\\)\n\nOne is interested in computing the probabilities \\(P(E_i | A), i = 1, ..., k\\). By a standard manipulation of conditional probabilities, one obtains the result:\n\\[\nP(E_i | A) = \\frac{P(E_i) P(A | E_i)} {\\sum_{j=1}^k P(E_j) P(A | E_j)} .\n\\]"
  },
  {
    "objectID": "bayes_rule.html#illustrations-of-bayes-rule",
    "href": "bayes_rule.html#illustrations-of-bayes-rule",
    "title": "3  Bayes Rule",
    "section": "3.2 Illustrations of Bayes’ Rule",
    "text": "3.2 Illustrations of Bayes’ Rule\n\n3.2.1 Example: Student Takes a Test\nSuppose a student is taking a one-question multiple choice test with four possible choices. Either the student knows the material or she doesn’t; we denote these two possibilities by \\(K\\) and “not \\(K\\)”. Based on previous work, the teacher decides the student likely knows the material and so assigns \\(P(K) = 0.7\\). Therefore, the probability the student doesn’t know the material is \\(P({\\rm not} \\, K) = 1 - 0.7 = 0.3.\\) The student will take the one-question test and either she will get it correct, which we denote by \\(C\\). If the student knows the material, then the chance she will get the question correct is 90%. On the other hand, if the student doesn’t know the material, then we will guess and obtain the correct answer with probability 25%. Suppose the student takes the test and gets the question correct – what is the probability she really knows the material?\nHere the events \\(K\\) and “not \\(K\\)” form a partition of the sample space and we are given the probabilities of these two events. The probability the student gets the question correct depends on whether she knows the material – we are given that\n\\[\nP(C | K) = 0.9, \\, P(C | {\\rm not} , K) = 0.25.\n\\]\nGiven that the student gets the question correct, we’re interested in determining the probability of \\(K\\); that is, we wish to compute \\(P(K | C)\\). By Bayes’ rule, this is given by\n\\[\nP(K | C) = \\frac{P(K) P(C | K)} {P(K) P(C | K) + P({\\rm not} , K) P(C | {\\rm not} , K)}.\n\\]\nSubstituting in the given values, we obtain\n\\[\nP(K | C) = \\frac{0.7 \\times 0.9} {0.7 \\times 0.9 + 0.3 \\times 0.25} = \\frac{0.63}{0.63+0.075} = 0.894 .\n\\]\nDoes this answer make sense? Before the test, the teacher believed that the student knew the material with probability 0.7. The student got the question correct which intuitively should increase the teacher’s probability that the student was a good student. Bayes’ rule allows us to explicitly compute how the probability should increase – the probability has increased from \\(P(K) = 0.7\\) to \\(P(K | C) = 0.894\\).\n\n\n3.2.2 Example: Balls in a Bag\nSuppose a bag contains exactly one white ball. You roll a die and if the outcome of the die roll is \\(i\\), you add \\(i\\) red balls to the bag. You then select a ball from the bag and the color of the ball is red. What is the chance that the die roll is \\(i\\)?\nIn this example, let \\(D_i\\) denote the outcome that the die roll lands \\(i\\) and let \\(R\\) denote the outcome that a red ball is chosen. If we assume a fair die, then the six possible die rolls are equally likely, so \\(P(D_1) = P(D_2) = ... = P(D_6) = 1/6\\).\nThe probability of observing a red depends on the die roll. If the die roll is \\(i\\), one adds \\(i\\) red balls to the bag and the chance of choosing a red will be \\(i/(i+1)\\), so\n\\[\nP(R | D_i) = \\frac{i}{i+1}, , i = 1, ..., 6.\n\\]\nIn this story, a red ball is observed and we are interested in computing \\(P(D_i | R)\\). By applying Bayes rule\n\\[\nP(D_i | R) = \\frac{P(D_i) P(R | D_i)}{\\sum_{j=1}^6 P(D_j) P(R | D_j)}.\n\\]\nBy substituting the known quantities, we have\n\\[\nP(D_i | R) = \\frac{\\frac{1}{6} \\times \\frac{i}{i+1}}{\\sum_{j=1}^6 \\frac{1}{6} \\times \\frac{j}{j+1}}.\n\\]\nA convenient way of computing the die roll probabilities is by use of a table. In Table 2.1, each row corresponds to a specific die roll – we call these alternatives in the table. For each die roll, the table gives the initial probability \\(P(D_i)\\) and the probability of observing red for that die roll \\(P(R | D_i)\\). The updated probability \\(P(D_i | R)\\) is proportional to the product \\(P(D_i) P(R | D_i)\\) and the products are shown in the table.\nOne computes the updated probabilities by dividing each product by the sum of the products. For example the updated probability \\(P(D_1 | R)\\) is given by the product (1/6)(1/(1+1)) divided by the sum of the products \\(1/12 + 2/18 + ... + 6/42 = 0.734\\) which is equal to 0.113.\n\n\n\nAlternative\nProbability\n\\(P(R | {\\rm Die \\, \\, Roll})\\)\nProduct\n\n\n\n\n\\(D_1\\)\n1/6\n1/(1+1)\n1/12\n\n\n\\(D_2\\)\n1/6\n2/(2+1)\n2/18\n\n\n\\(D_3\\)\n1/6\n3/(3+1)\n3/24\n\n\n\\(D_4\\)\n1/6\n4/(4+1)\n4/30\n\n\n\\(D_5\\)\n1/6\n5/(5+1)\n5/36\n\n\n\\(D_6\\)\n1/6\n6/(6+1)\n6/42\n\n\n\nTo make sense of these calculations, we started assuming that all six possible rolls of the die were equally likely.\nWith the observation of a red ball, the updated probabilities are unequal and give support for larger rolls of the die."
  },
  {
    "objectID": "bayes_rule.html#new-terminology",
    "href": "bayes_rule.html#new-terminology",
    "title": "3  Bayes Rule",
    "section": "3.3 New Terminology",
    "text": "3.3 New Terminology\nIn general, we are interested in learning about \\(k\\) different models that we denote by \\(M_1, ..., M_k\\). Initially, we have beliefs about the plausibility of these models that we express through the probabilities \\(P(M_1), ..., P(M_k)\\). We refer to these as prior probabilities since these express our opinions about the models before or prior to observing any data. Next, we observe data denoted by \\(D\\) that will give us information about the models. We are given the probabilities of each data outcome for each model, that is, \\(P(D|M_1), ..., P(D|M_k)\\); these are called the likelihoods.\nNow the a particular data result \\(D\\) is observed. How has this data result changed our beliefs about the \\(k\\) models? Bayes’ rule is the recipe for modifying the model probabilities. It says that the new probability for model \\(M_i\\) is proportional to the product of the prior probability and the likelihood:\n\\[\nP(M_i | D) \\propto P(M_i) P(D | M_i).\n\\]\nThe updated probabilities {\\(P(M_i | D)\\)} are called posterior probabilities since they reflect our opinions about the models _after observing the data. Using words, we can write\nPOSTERIOR \\(\\propto\\) PRIOR \\(\\times\\) LIKELIHOOD.\nA convenient way to performing the Bayes’ rule calculations is by use of a table similar to the example. We illustrate the use of the new terminology and the table calculations for two additional examples."
  },
  {
    "objectID": "bayes_rule.html#sequential-learning",
    "href": "bayes_rule.html#sequential-learning",
    "title": "3  Bayes Rule",
    "section": "3.6 Sequential Learning",
    "text": "3.6 Sequential Learning\nA machine in a small factory is producing a particular automotive component. Most of the time (specifically, 90% from historical records), the machine is working well and produces 95% good parts. Some days, the machine doesn’t work as well (it’s broken) and produces only 70% good parts. A worker inspects the first dozen parts produced by this machine on a particular morning and obtains the following results (\\(g\\) represents a good component and \\(b\\) a bad component):\n\\[\ng, b, g, g, g, g, g, g, g, b, g, b.\n\\]\nThe worker is interested in assessing the probability the machine is working well.\nIn this problem there are two models – either the machine is working well, or “working” for short, or it is “broken”.\nBased on the historical data, the worker assigns prior probabilities of 0.90 and 0.10 to the models “working” and “broken”. The data are the results of the inspection on the 12 parts. To understand the relationship between the data and the models, we compute the sampling probabilities, the probabilities of each data outcome for each model. If the machine is working, the probabilities of a good (g) part and a bad (b) part are 0.95 and 0.05, respectively. So\n\\[\nP(g | {\\rm working}) = 0.95,\\, P(b | {\\rm working}) = 0.05 .\n\\]\nIf instead the machine is broken, the probabilities of good and bad part are 0.70 and 0.30, respectively:\n\\[\nP(g | {\\rm broken}) = 0.70, \\, P(b | {\\rm broken}) = 0.30 .\n\\]\nNow we’re ready to do the Bayes’ rule computation. The outcomes of twelve inspections of parts are the data:\n\\[\nDATA = {g, b, g, g, g, g, g, g, g, b, g, b}.\n\\]\nThe likelihoods are the probabilities of this data result for each of the two models. Assuming independence of individual outcomes, the likelihood of the working model is given by\n\\[\nLIKE({\\rm working}) =  P(\\{g, b, g, g, g, g, g, g, g, b, g, b\\} | {\\rm working})\n\\] \\[\n=  P(g | {\\rm working}) \\times ... \\times P(b | {\\rm working})\n\\] \\[ =  0.95 \\times 0.05 \\times 0.95 \\times ... \\times 0.05\n\\] \\[\n=  0.00007878.\n\\]\nSimilarly, the likelihood of the broken model is\n\\[\nLIKE({\\rm broken}) =  P(\\{g, b, g, g, g, g, g, g, g, b, g, b\\} | {\\rm broken})\n\\] \\[\n=  0.70 \\times 0.30 \\times 0.70 \\times ... \\times 0.30\n\\] \\[\n= 0.00108955\n\\]\nUsing the “prior times likelihood” recipe, we compute the posterior probabilities in the following table.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.90\n0.00007878\n0.000070902\n0.3942\n\n\nBroken\n0.10\n0.00108955\n0.000108955\n0.6058\n\n\n\nWe see that the posterior probability that the machine is broken is over 60% and perhaps the machine should be stopped for inspection and repair.\nThere is another way to implement Bayes’ rule when the data are observed in a sequential manner. Before any data are collected, the inspector’s probabilities of the two states of the machine, working and broken, are given by 0.90 and 0.10. He observes the quality of the first part – “g” – and then he can immediately update his probabilities by Bayes’ rule.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.90\n0.95\n0.855\n0.9243\n\n\nBroken\n0.10\n0.70\n0.070\n0.0757\n\n\n\nAfter this single observation, he is slightly more confident (with probability 0.9243) that the machine is working.\nThe inspector’s current probabilities of the two models are 0.9243 and 0.0757. He observes the quality of the next part – “b” – and again he can update his probabilities by Bayes’ rule. In this table “Prior” refers to his beliefs before observing the data.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.9243\n0.05\n0.046215\n0.6705\n\n\nBroken\n0.0757\n0.30\n0.022710\n0.3295\n\n\n\nWe see that, after observing two parts, the inspector’s probability that the machine is working is 0.6705.\nOne can continue learning in this sequential manner. As one observes the quality of each single part, the inspector can update his probability of the two models by Bayes’ rule. Table 2.9 summarizes the results of this sequential learning. The first row of the table displays the prior probabilities of the working and broken models and the following rows display the probabilities after each outcome is observed. Note that the final row indicates that the probabilities after observing the 12 parts are equal to 0.3942 and 0.6058. As expected, these posterior probabilities are the same as the ones computed using the group of 12 observations as data.\n\n\n\nObservation\nP(Working)\nP(Broken)\n\n\n\n\nPrior\n0.9000\n0.1000\n\n\ng\n0.9243\n0.0757\n\n\nb\n0.6706\n0.3294\n\n\ng\n0.7342\n0.2658\n\n\ng\n0.7894\n0.2106\n\n\ng\n0.8358\n0.1642\n\n\ng\n0.8735\n0.1265\n\n\ng\n0.9036\n0.0964\n\n\ng\n0.9271\n0.0729\n\n\ng\n0.9452\n0.0548\n\n\nb\n0.7421\n0.2579\n\n\ng\n0.7961\n0.2039\n\n\nb\n0.3942\n0.6058"
  },
  {
    "objectID": "bayes_rule.html#example-testing-for-a-disease",
    "href": "bayes_rule.html#example-testing-for-a-disease",
    "title": "3  Bayes Rule",
    "section": "3.4 Example: Testing for a Disease",
    "text": "3.4 Example: Testing for a Disease\nSuppose you are one of the many people who are tested for a rare disease. From reports, you known the the incidence of this disease is 1 out of 5000. You take the test and there are two results: either you are told “ok” or “see your doctor for further checks.” How should you feel on the basis of these two results?\nThere are two possible models in this example: you are either “diseased” or “not disease”. Assuming that you are a representative person from your community, your prior beliefs are that\n\\[\nP({\\rm diseased}) = \\frac{1}{5000} = 0.0002, , P({\\rm not \\, diseased}) = \\frac{4999}{5000} = 0.9998 .\n\\]\nThe “data” in this example is the screening test result. There are two outcomes: either the test will be “positive” or “+”, which is some indication that you have the disease, or “negative” or “-” which is good news. From past experience, the screening test has 5% false positives and 2% false negatives.\nThis means that if you really don’t have the disease, the chance you get a positive result is 0.05; that is,\n\\[\nP(+ , {\\rm result} | {\\rm not \\, diseased}) = 0.05,  P(- , {\\rm result} | {\\rm not \\, diseased}) = 0.95.\n\\]\nSimilarly, if you really have the disease, the chance of an incorrect negative result is 0.02:\n\\[\nP(- , {\\rm result} | {\\rm diseased}) = 0.02, \\, P(+ , {\\rm result} | {\\rm diseased}) = 0.98.\n\\]\nThese values are the likelihoods – the probabilities of the data outcomes for each model.\nSuppose you have a positive test result (\\(+\\)). We can find the new probabilities of diseased and not diseased by Bayes’ rule that we present in a table format in Table 2.2.\n\n\n\nPrior\nProbability\n\\(P(+ | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\nNot diseased\n0.9998\n0.05\n0.04999\n0.9961\n\n\nDiseased\n0.0002\n0.98\n0.000196\n0.0039\n\n\n\nBefore the test, your probability of having the disease was 0.02 and after getting the positive test result, this probability has increased to 0.039. This new probability is almost twice the initial probability, but you are still very unlikely to have the disease.\nWhat if you received a negative test result? We repeat the Bayes’ rule calculations in Table 2.3 with a change in the likelihood values.\n\n\n\nModel\nPrior\n\\(P(- | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\nNot diseased\n0.9998\n0.95\n0.949810\n0.999996\n\n\nDiseased\n0.0002\n0.02\n0.000004\n0.000004\n\n\n\nThe probability of having the disease has decreased from 0.0002 to 0.000004.\nThese results are usually surprising to doctors and patients. It seems difficult to update probabilities accurately and people typically have a much stronger opinion they have the disease when faced with a positive test result."
  },
  {
    "objectID": "bayes_rule.html#example-the-three-door-problem",
    "href": "bayes_rule.html#example-the-three-door-problem",
    "title": "3  Bayes Rule",
    "section": "3.5 Example: The Three Door Problem",
    "text": "3.5 Example: The Three Door Problem\nThere is a famous probability problem, called The Three Door Problem or The Car and the Goats that can be addressed by Bayes’ rule. There is a TV show where a contestant is showed three numbered doors, Door 1, Door 2, and Door 3, where one door is hiding a car and the other two doors hiding goats. The contestant is allowed to choose a door and win the corresponding prize. The contestant chooses Door 1. The host, who knows which door hides the car, then opens Door 2 to reveal a goat. The contestant is given the opportunity to change her selection. Should she switch her choice to Door 3?\nIn this example the unknown model is the location of the car. We will let \\(C_i\\) denote the event that the car is behind Door \\(i, i = 1, 2, 3.\\) Initially, the constestant believes the car is equally likely to be behind each of the three doors, so\n\\[\nP(C_1) = P(C_2) = P(C_3) = \\frac{1}{3}.\n\\]\nHere the data is the event that the host showed Door 2 – we’ll call this event \\(H\\). We wish to find the new probabilities of \\(C_1, C_2\\) and \\(C_3\\) conditional on the new information \\(H\\). We put the given information in the “Bayes’ table”:\n\n\n\nModel\nPrior\n\\(P(H | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\n\\(C_1\\)\n1/3\n\\(P(H | C_1)\\)\n\n\n\n\n\\(C_2\\)\n1/3\n\\(P(H | C_2)\\)\n\n\n\n\n\\(C_3\\)\n1/3\n\\(P(H | C_3)\\)\n\n\n\n\n\nLet’s consider the likelihood \\(P(H | C_i)\\) that represents the probability the host shows Door 2 if the car is behind Door \\(i\\). Remember that the contestant chose Door 1, so the host cannot choose this door.\n\nIf the car is really behind door 1, the host can either show Door 2 or Door 3. We will assume that the probability he shows Door 2 is a number \\(q\\) between 0 and 1, so \\(P(H | C_1) = q\\).\nIf the car is behind door 2, the host cannot show this door. So \\(P(H | C_2) = 0\\).\nIf the car is behind door 3, the host cannot show this door -- he has to show Door 2. So \\(P(H | C_3) = 1\\).\n\nWe complete the table in Table 2.5 by filling in the likelihoods and computing the posterior probabilities.\n\n\n\nModel\nPrior\n\\(P(H | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\n\\(C_1\\)\n1/3\n\\(q\\)\n\\(q/3\\)\n\\(q/(q+1)\\)\n\n\n\\(C_2\\)\n1/3\n0\n0\n0\n\n\n\\(C_3\\)\n1/3\n1\n1/3\n\\(1/(q+1)\\)\n\n\n\nLet’s return to our question. Remember the contestant chose Door 1 and has the opportunity to switch to Door 3. Given the data “host shows Door 2”, we have found that the probability the car is behind Door 1 is \\(q/(q+1)\\) and the probability the car is behind Door 3 is \\(1/(q+1)\\). The contestant should switch if the probability of \\(C_3\\) is greater than the probability of \\(C_1\\), that is,\n\\[\nP(C_3 | H) > P(C_1 | H)\n\\]\nor\n\\[\n\\frac{1}{q+1} > \\frac{q}{q+1}\n\\]\nwhich is true if \\(q > 0\\). So the contestant will increase her probability of winning by switching. Remember \\(q\\) is the probability the host will show Door 2 instead of Door 3 if he has a choice. If we assume \\(q = 1/2\\), that is, the host chooses a door at random, then the probability the car is behind Door 3 is \\(1/(1/2 + 1) = 2/3\\)."
  },
  {
    "objectID": "proportion.html",
    "href": "proportion.html",
    "title": "4  Learning About a Proportion",
    "section": "",
    "text": "Suppose data \\(y\\) is observed from a sampling distribution \\(f(y | \\theta)\\) that depends on an unknown parameter \\(\\theta\\). We assume that one has beliefs about \\(\\theta\\) before sampling that are expressed through a prior density \\(g(\\theta | y)\\). Once a value of \\(y\\) is observed, then one’s updated beliefs about the parameter \\(\\theta\\) are reflected in the posterior density, the conditional density of \\(\\theta\\) given \\(y\\): \\[\ng(\\theta | y) = \\frac{f(y | \\theta)g(\\theta) }{f(y)},\n\\] where \\(f(y)\\) is the marginal density of \\(y\\) \\[\nf(y) = \\int  f(y | \\theta) g(\\theta) d\\theta .\n\\]\nIn the computation of the posterior density, note that the only terms involving the unknown parameter \\(\\theta\\) are the likelihood function \\(L(\\theta) = f(y | \\theta)\\) and the prior density \\(g(\\theta)\\). Bayes’ rule says that the posterior density is proportional to the product of the likelihood and the prior, or \\[\ng(\\theta | y) \\propto L(\\theta) g(\\theta).\n\\]\nIn a Bayesian analysis, both the posterior density and the marginal density play important roles. The posterior density contains all information about the parameter contained in both the prior density and the data. One performs different types of inference by computing relevant summaries of the posterior density. The marginal density \\(f(y)\\) reflects the distribution of the data \\(y\\) before observing any data. This density is called the predictive density since \\(f(y)\\) is used to make predictions about future data values."
  },
  {
    "objectID": "proportion.html#an-example-on-learning-about-a-proportion",
    "href": "proportion.html#an-example-on-learning-about-a-proportion",
    "title": "4  Learning About a Proportion",
    "section": "4.2 An Example on Learning About a Proportion",
    "text": "4.2 An Example on Learning About a Proportion\nIn this chapter, we discuss the basic elements of a Bayesian analysis through the problem of learning about a population proportion \\(p\\). We take a random sample from the population of size \\(n\\) and observe \\(y\\) successes – for a given value of \\(p\\), the probability of \\(y\\) is given by the binomial formula \\[\nf(y | p) = {n \\choose y} p^y (1-p)^{n - y}.\n\\]\nAs an example, suppose that coordinator of developmental math courses at a particular university is concerned about the proportion of students in these courses who have math anxiety, where “math anxiety” is defined by obtaining a particular score on an anxiety rating instrument. A sample of 30 students takes the instrument and 10 have math anxiety. What can be said about the proportion of all developmental math course students who have math anxiety?\nThe standard estimate of \\(p\\) is the proportion of successes in the sample \\(\\hat p = y/n\\) and the traditional Wald “large-sample” confidence interval for \\(p\\) is given by \\[\n\\left(\\hat p - z_{\\alpha/2} \\sqrt{\\frac{\\hat p (1- \\hat p)}{n}}, \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p (1- \\hat p)}{n}}\\right),\n\\] where \\(z_\\alpha\\) is the \\(1-\\alpha\\) quantile of the standard normal distribution.\nFor large samples, this interval will cover the unknown proportion in repeated sampling with probability \\(1 - \\alpha\\). However this interval estimate has questionable value for samples with very few observed successes or failures. Suppose that no students in our sample have math anxiety. Then \\(y = 0\\), \\(\\hat p = 0/30 = 0\\) and the confidence interval will be degenerate at zero. (Similarly, if all the students have math anxiety, then \\(\\hat p = 30/30 = 1\\) and the confidence interval will be degenerate at one.) Since one certainly believes that the proportion is larger than zero, this degenerate interval at zero doesn’t make any sense.\nOne ad-hoc solution to the “zero successes” problem is to initially add two artificial successes and two artificial failures to the data, and then apply the Wald interval to this adjusted data. This is a recommended approach in the literature and the resulting confidence interval has good sampling probabilities. We will see that this ad-hoc procedure has a natural correspondence with a Bayesian interval that incorporates prior information about the proportion."
  },
  {
    "objectID": "proportion.html#using-a-discrete-prior",
    "href": "proportion.html#using-a-discrete-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.3 Using a Discrete Prior",
    "text": "4.3 Using a Discrete Prior\nOne simple way of incorporating prior information about \\(p\\) is by use of a discrete prior. One makes a list of plausible values \\(p_1, ..., p_k\\) for the proportion and then assigns probabilities \\(P(p_1), ..., P(p_k)\\) to these values. It may be difficult to directly assess the individual prior probabilities, but it may be easier to think about the probability of one proportion value relative to the probabilities of other values. One might first assign a large integer value, say 10, to the value of \\(p\\) that is believed most likely, and then assess the probabilities of the remaining values relative to the probability of the most likely value. Once the relative probabilities are determined, then the probabilities are normalized to obtain the prior probabilities.\nIn the example, suppose one lists the possible values for the proportion of mathematics students with math anxiety displayed in the following table.\n\n\n\n\\(p\\)\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n\n\n\n\nPrior\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose one’s best guess at the proportion of students with math anxiety is \\(p = 0.20\\) so this value is assigned a “prior weight” of 10.\nThe values \\(p = 0.15\\) and \\(p = 0.25\\) are believed to half as likely as \\(p = 0.20\\) so each value is assigned a prior weight of 5. The value \\(p = 0.30\\) is thought to be only 30% as likely as \\(p = 0.20\\) so this proportion value is assigned a weight of 3. Continuing in this fashion, one obtains the table of prior weights for \\(p\\) as shown in Table \\(\\ref{table:priortable}\\). One converts these prior weights to probabilities by dividing each weight by its sum. Since the sum of prior weights is 31, the prior probability of \\(p = 0.5\\) is equal to \\(P(.05) = 1/31 = 0.32\\). The third row of the table display the prior probabilities.\n\n\n\n\\(p\\)\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n\n\n\n\nPrior Weight\n1\n2\n5\n10\n5\n3\n2\n1\n1\n1\n\n\nPrior\n.032\n.065\n.161\n.323\n.161\n.097\n.065\n.032\n.032\n.032\n\n\n\nOnce this prior distribution is assigned, one can compute the posterior probabilities by use of Bayes’ rule. One observes \\(y\\) successes in \\(n\\) trials. The likelihood of \\(p = p_i\\) given this result is given by \\[\nL(p_i) = p_i^y (1- p_i)^{n-y},\n\\] and the posterior probability of \\(p_i\\) will be given (up to a proportionality constant) by multiplying the prior probability by the likelihood. \\[\nP(p_i | {\\rm data}) \\propto P(p_i) L(p_i) = P(p_i)  p_i^y (1- p_i)^{n-y}.\n\\] The following table displays the posterior distribution calculations in the familiar table format. The columns of the table include the values of the proportion, the values of the prior, the likelihoods, and the products of the prior and the likelihood. One normalizes the probabilities by first computing the sum of the products (denoted by SUM in the table), and then dividing each product by this sum.\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\n\\(p_1\\)\n\\(P(p_1)\\)\n\\(p_1^y(1-p_1)^{n-y}\\)\n\\(P(p_1)\\) \\(p_1^y(1-p_1)^{n-y}\\)\n\\(P(p_1)\\) \\(p_1^y(1-p_1)^{n-y}/SUM\\)\\\n\n\n\\(p_2\\)\n\\(P(p_2)\\)\n\\(p_2^y(1-p_2)^{n-y}\\)\n\\(P(p_2)\\) \\(p_2^y(1-p_2)^{n-y}\\)\n\\(P(p_2)\\) \\(p_2^y(1-p_2)^{n-y}/SUM\\) \\\n\n\n–\n–\n–\n–\n–\n\n\n–\n–\n–\n–\n–\n\n\n–\n–\n–\n–\n–\n\n\n\\(p_k\\)\n\\(P(p_k)\\)\n\\(p_k^y(1-p_k)^{n-y}\\)\n\\(P(p_k)\\) \\(p_k^y(1-p_k)^{n-y}\\)\n\\(P(p_k)\\) \\(p_k^y(1-p_k)^{n-y}/SUM\\) \\ \n\n\n–\n–\n–\nSUM\n–\n\n\n\nThe Bayes’ rule calculations are illustrated in the following table for our math anxiety example. For the example, we observed \\(y = 10\\) who had math anxiety in a sample of \\(n = 30\\) and the likelihood is \\(p^{10} (1-p)^{20}\\). The computed values of the likelihood are very small so they have been multiplied by \\(10^{12}\\) in the table to obtain integer values.\n\n\n\n\\(p\\)\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\n0.05\n0.032\n0\n0\n0.000\n\n\n0.10\n0.065\n12\n1\n0.000\n\n\n0.15\n0.161\n224\n36\n0.019\n\n\n0.20\n0.323\n1181\n381\n0.200\n\n\n0.25\n0.161\n3024\n487\n0.255\n\n\n0.30\n0.097\n4712\n457\n0.239\n\n\n0.35\n0.065\n5000\n325\n0.170\n\n\n0.40\n0.032\n3834\n123\n0.064\n\n\n0.45\n0.032\n2185\n70\n0.037\n\n\n0.50\n0.032\n931\n30\n0.016\n\n\n\nTo interpret the posterior probabilities, remember that initially we believed that the proportion of math anxiety students was about 0.20, although we were unsure about its true value and the prior was relatively diffuse about \\(p = 0.20\\). The most likely value of \\(p\\) from the posterior distribution is \\(p = 0.25\\). The observed proportion of math anxiety values from the sample is \\(y/n = 10/30 = 0.33\\) and the posterior estimate is a compromise between the sample proportion and the prior mode. We can use the posterior distribution to find an interval estimate for the proportion. Note from the table that the most likely values of \\(p\\) are \\[\np = 0.20, 0.25, 0.30, 0.35\n\\] with total probability \\[\n0.200 + 0.255 + 0.239 + 0.170 = 0.864.\n\\] So the interval (0.20, 0.35) is a 86.4% interval estimate for \\(p\\) – the posterior probability \\[\nP(0.20 \\le p \\le 0.35| {\\rm data}) = 0.864.\n\\]"
  },
  {
    "objectID": "proportion.html#using-a-noninformative-prior",
    "href": "proportion.html#using-a-noninformative-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.4 Using a Noninformative Prior",
    "text": "4.4 Using a Noninformative Prior\nThere are some advantages to using a discrete prior for a proportion. It provides a starting point for finding a prior distribution that reflects one’s knowledge, before sampling, about the location of the proportion. Also it is easy to summarize a discrete posterior distribution. But since the proportion \\(p\\) is a continuous parameter, one’s prior should be a continuous distribution on the interval from 0 to 1.\nFirst, suppose one has little knowledge about the location of the proportion. In our example, suppose that one has little information about the proportion of students in the class who have math anxiety. How can one construct a prior distribution that reflects little or imprecise knowledge about the location of the parameter? This type of distribution is called a noninformative prior or ignorance prior. Using this type of prior, the posterior distribution will typically be more influenced by the data than the prior information.\nOne possible choice for a noninformative prior assumes that \\(p\\) has a uniform distribution \\[\ng(p) = 1, 0 < p < 1.\n\\] This distribution implies that every subset of \\(p\\) of a given length has the same probability.\nIf we observe \\(y\\) successes in \\(n\\) trials, we wish to find the posterior density of \\(p\\), the density of the proportion conditional on \\(y\\). By Bayes’ rule, this density is given by \\[\ng(p | y) = \\frac{f(y | p) g(p)}{\\int_0^1 f(y | p) g(p) dp} \\propto f(y|p) g(p),\n\\] which gives the familiar POSTERIOR \\(\\propto\\) LIKELIHOOD \\(\\times\\) PRIOR recipe.\nIf we use a uniform prior for \\(p\\), then the posterior density is given by \\[\ng(p | y) \\propto p^y (1-p)^{n-y}, \\, 0 < p < 1.\n\\] If we view this function as a function of the proportion \\(p\\) where \\(y\\) and \\(n\\) are fixed, then we recognize this density as a beta density of the form \\[\ng(p | y) = \\frac{1}{B(a^*, b^*)} p^{a^* - 1} (1-p)^{b^*-1}, \\, 0 < p < 1,\n\\] where \\(a = y+1\\) and \\(b = n - y + 1\\)"
  },
  {
    "objectID": "proportion.html#using-a-conjugate-prior",
    "href": "proportion.html#using-a-conjugate-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.5 Using a Conjugate Prior",
    "text": "4.5 Using a Conjugate Prior\nIn many situations, the use of noninformative priors is appropriate since the user does not have any knowledge about the parameter from previous experience. But in other situations such as the math anxiety example, the user does have knowledge about the unknown proportion before sampling and one wishes to construct a continuous prior on the unit interval that represents this prior knowledge.\nOne convenient family of prior distributions is the beta family with shape parameters \\(a\\) and \\(b\\): \\[\ng(p) = \\frac{1}{B(a, b)} p^{a - 1} (1-p)^{b-1}, \\, 0 < p < 1.\n\\] As demonstrated by the graphs in Figure ???, the beta family can have many shapes and can reflect a variety of information about the proportion \\(p\\). In practice, one chooses the parameters \\(a\\) and \\(b\\) that matches one’s beliefs about the proportion.\nOne way of assessing values of \\(a\\) and \\(b\\) is to guess at the values of the prior mean and variance of \\(p\\). Suppose these guesses are \\(M\\) and \\(V\\), respectively. The prior mean and standard deviation of a beta(\\(a, b\\)) distribution are \\(a/(a+b)\\) and \\(ab/(a+b)^2/(a+b+1)\\). Then by solving the equations\n\\[\nM  = \\frac{a}{a+b},  \\, \\,     \n   V  =  \\frac{a b}{(a+b)^2 (a+b+1)}\n\\]\nfor \\(a\\) and \\(b\\), one obtains the beta prior distribution. The problem with this method is that it may be difficult for a user to specify the prior moments of the distribution since moments can be affected by the shape or tail behavior of the distribution which may be unknown.\nAn alternative approach is to assess the parameters \\(a\\) and \\(b\\) indirectly through the specification of prior quantiles. In our example, suppose that the user believes that the median of the prior for the proportion of students is \\(q_0.5 = 0.23\\). This means that he/she believes that the proportion is equally likely to be smaller or larger than 0.23. Then the user makes a statement about the sureness of this guess at the median by the statement about a second quantile. Suppose the user says that he/she is 90% confident that the proportion \\(p\\) is less than 0.38. So the prior information is given by \\[\nP(p < 0.23) = 0.50, \\, \\, P(p < 0.38) = 0.90.\n\\] By use of a program such as the function beta.select() in the LearnBayes package, one matches these prior quantiles with the beta parameters \\(a = 4.0, b = 12.5\\).\nOnce one assesses the values of the beta parameters, it is easy to compute the posterior distribution. By multiplying the prior and the likelihood, one obtains that the posterior density of \\(p\\) is proportional to \\[\ng(p | y)  \\propto  L(p) g(p)  \n\\] \\[\n       =  p^y (1-p)^{n-y} \\times p^{a-1} (1-p)^{b-1}\n\\] \\[\n       =  p^{a + y -1} (1-p)^{b + n - y -1},\n\\]\nwhich we recognize as a beta density with updated parameters \\(a^* = a + y\\) and \\(b^* = b + n - y\\). We say that the beta density is a conjugate prior density since the prior and posterior have the same functional form.\nIn our example, if our prior is beta(4.0, 12.5) and we have \\(y = 10\\) math anxious students in a sample of \\(n = 30\\), then the posterior distribution is beta(4.0 + 10, 12.5 + 20) or beta( 14.0, 32.5)."
  },
  {
    "objectID": "proportion.html#inference",
    "href": "proportion.html#inference",
    "title": "4  Learning About a Proportion",
    "section": "4.6 Inference",
    "text": "4.6 Inference\nAfter one observes data, then all knowledge about the parameter is contained in the posterior distribution. It is common to simply display the posterior density and the reader can learn about the location and spread by simply looking at this curve. To obtain different types of statistical inferences, one summarizes the posterior distribution in various ways. We illustrate using the posterior distribution to obtain point and interval estimates of the parameter.\n\n4.6.1 Point Inference\nA suitable point estimate of a parameter is a single-number summary of the posterior density. The posterior mean is the mean of the posterior distribution given by the integral \\[\nE(p | y) = \\int p \\, g(p | y) dp.\n\\] The posterior median is the median of the posterior distribution, the value \\(p_{0.5}\\) such that the proportion is equally likely to be smaller or larger than \\(p\\). \\[\nP(p < p_{0.5}) = 0.5.\n\\] The posterior mode is the value \\(\\hat p\\) where the posterior density is maximized: \\[\ng(\\hat p | y) = \\max_p g(p | y).\n\\]\nIn the case where a beta(\\(a, b\\)) prior is assigned to a proportion \\(p\\), the posterior distribution is also in the beta family with updated parameters \\(a^* = a + y\\) and \\(b^* = b + n - y\\). The posterior mean of \\(p\\) is the mean of the beta density \\[\nE(p | y) = \\frac{a^*}{a^*+b^*} = \\frac{y + a}{n + a + b}.\n\\] The posterior median \\(p_M\\) is the 0.5 fractile of the beta curve. It is not expressible in closed form, but is easily available by use of software. The posterior mode is found by finding the value of \\(p\\) that maximizes the density \\(p^{a^*-1} (1-p)^{b^*-1}\\). A straightforward calculation shows the posterior mode is \\[\n\\hat p = \\frac{a^*-1}{a^*+b^*-2}.\n\\] For our example, our posterior density is beta(14.0, 32.5). The posterior mean is given by \\(E(p | y) = 14.0/(14.0 + 32.5) = 0.301\\). By use of the R command qbeta, the posterior median is found to be \\(p_M = 0.298\\), and the posterior mode is \\(\\hat p = (14.0 -1 )/(14.0 + 32.5 - 2) = 0.292\\).\nIn the case where the posterior density is approximately symmetric, as in this example, the posterior mean, posterior median, and posterior mode will be approximately equal. In other situations where the posterior density is right or left skewed, these summary values can be different. One nice feature of the posterior median is its clear interpretation as the value that divides the posterior probability in half.\n\n\n4.6.2 Interval Estimation\nTypically, a point estimate such as a posterior median is insufficient for understanding the location of a parameter. A Bayesian interval estimate or credible interval is an interval that contains the parameter with a given probability. Specifically, a \\(100 (1-\\gamma)\\) percent credible interval is any interval \\((a, b)\\) such that \\[\nP( a < p < b) = \\gamma.\n\\] There are many intervals that contain \\(100 (1-\\gamma)\\) percent of the posterior probability. A convenient estimate is an equal-tail interval estimate whose endpoints are the \\(\\gamma/2\\) and \\(1-\\gamma/2\\) quantiles of the posterior distribution. \\[\n(p_{\\gamma/2}, p_{1-\\gamma/2}).\n\\] An alternative is the highest posterior density interval or HPD interval which is the shortest interval that contains this probability content.\nIn our example, the posterior for \\(p\\) was beta(14.0, 32.5). If we wish to construct a 90% interval estimate, then one possible interval would be (0, \\(p_{.90}\\)) = (0, 0.389) and another would be \\((p_{.10}, 1) = (0.217, 1)\\). These would be undesirable intervals since they both would have long widths. The equal-tail interval would be formed from the 5th and 95th percentiles that is equal to (0.197, 0.415). Using the function hpd in the TeachingDemos package, one computes the HPD interval (0.191, 0.409). Since the posterior density is approximately symmetric, the equal-tail and HPD intervals are approximately equal.\n\n\n4.6.3 Estimation of Probabilities\nOne attractive feature of the Bayesian approach is that one can see if the parameter falls in different regions by simply computing the posterior probabilities of these regions. In the math anxiety example, suppose we are interested in the plausibility that the proportion falls in the intervals (0, 0.2), (0.2, 0.4), (0.4, 0.6), (0.6, 0.8), (0.8, 1). The posterior distribution for the proportion of math anxious students is beta(14.0, 32.5) and by use of the R pbeta command, we can compute the probabilities of these regions and these probabilities are displayed in Table \\(\\ref{table:postprobs}\\). Is it likely that the proportion of math anxious students is larger than 0.4? The answer would be no, since the posterior probability that \\(p > 0.4\\) is only 0.08. We see from this table that it is very likely that the proportion falls between 0.4 and 0.6.\n\n\n\nInterval\nPosterior Probability\n\n\n\n\n(0, 0.2)\n0.06\n\n\n(0.2, 0.4)\n0.87\n\n\n(0.4, 0.6)\n0.08\n\n\n(0.6, 0.8)\n0.00\n\n\n(0.8, 1.0)\n0.00"
  },
  {
    "objectID": "proportion.html#using-alternative-priors",
    "href": "proportion.html#using-alternative-priors",
    "title": "4  Learning About a Proportion",
    "section": "4.7 Using Alternative Priors",
    "text": "4.7 Using Alternative Priors\nThe choice of a beta prior is made by convenience. By use of a beta prior, the posterior has the same functional (beta) form and it is easy to summarize the posterior distribution. But Bayes’ rule can be applied for any continuous prior density of \\(p\\) on the unit interval. We illustrate this point by using an alternative density for the proportion based on prior beliefs about the logit proportion.\nIn some situations, one may have prior beliefs about the logit of \\(p\\) defined by \\[\n\\theta = \\log \\frac{p}{1-p}.\n\\] Suppose that one believes, before sampling, that \\(\\theta\\) is normally distributed with mean \\(\\mu = -1.21\\) and standard deviation \\(\\tau = 0.55\\). By transforming the logit \\(\\theta\\) to \\(p\\) by \\[\np = \\frac{\\exp(\\theta)}{1+\\exp(\\theta)},\n\\] one can show that the induced prior on \\(p\\) is given by \\[\ng(p) = \\phi(\\log \\frac{p}{1-p}; \\mu, \\tau) \\frac{1}{p(1-p)}, \\, \\, 0 < p < 1,\n\\] where \\(\\phi(x; \\mu, \\tau)\\) is the normal density with mean \\(\\mu\\) and standard deviation \\(\\tau\\).\nAs before, the likelihood function is \\(L(p) = p^y (1-p)^{n-y}\\), where \\(n = 30\\) and \\(y = 10\\). By using the “prior times likelihood” recipe, the posterior density of \\(p\\) is given by \\[\ng(p | y) \\propto L(p) g(p) = \\left(p^y (1-p)^{n-y}\\right) \\times \\left( \\phi(\\log \\frac{p}{1-p}; \\mu, \\tau) \\frac{1}{p(1-p)} \\right).\n\\]\nIn this situation, we no longer have a conjugate analysis, since the prior and posterior densities have different functional forms. Moreover, the posterior has a functional form that we do not recognize as a member of a familiar family such as the beta. However, this just means that we will need alternative tools to summarize the posterior distribution to perform inferences."
  },
  {
    "objectID": "proportion.html#prediction",
    "href": "proportion.html#prediction",
    "title": "4  Learning About a Proportion",
    "section": "4.8 Prediction",
    "text": "4.8 Prediction\nIn this chapter, we have focused on the use of the posterior distribution to make inferences about the proportion \\(p\\). It is also possible to learn about the plausibility of future outcomes by inspection of the predictive distribution. In our math anxiety example, suppose we administer the exam to a new sample of 30 students. How many students in the new sample will be math anxious?\nLet \\(y^*\\) denote the number of math anxious students in a future sample of size \\(n^*\\). Conditional on \\(p\\), the distribution of \\(y^*\\) will be binomial(\\(n^*, p\\)). If our current beliefs about the proportion are represented by the density \\(g(p)\\), then the predictive density of \\(y^*\\) will be given by the integral\n\\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 f(y^*|p) g(p) dp \\nonumber \\\\\n       =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} g(p) dp.  \\nonumber \\\\\n\\end{eqnarray*}\\]\nSuppose we assign \\(p\\) a uniform prior; that is, \\(g(p) = 1\\). If we substitute this prior for \\(g(p)\\), then the predictive density is given by \\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} dp. \\nonumber \\\\\n       =  {n^* \\choose y^*} B(y^*+1, B(n^* - y^*+1)  \\nonumber \\\\\n       =  \\frac{1}{n^*+1}. \\nonumber \\\\\n\\end{eqnarray*}\\] If we use a uniform prior, then each of the \\(n^*+1\\) possible values of \\(y^*\\) are equally likely.\nSuppose our current knowledge about the proportion is contained in a beta(\\(a, b\\)) density. Then the predictive density is given by \\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} \\frac{1}{B(a, b)} p^{a-1}(1-p)^{b-1} dp  \\nonumber \\\\\n       =  {n^* \\choose y^*}  \\frac{B(a + y^*, b + n^* - y^*)}{B(a, b)}, y^* = 0, ..., n^*. \\nonumber \\\\\n\\end{eqnarray*}\\] This is called a beta-binomial density since it is a mixture of binomial densities, where the proportion \\(p\\) follows a beta density.\nIn our example, after observing the sample, the beliefs about the proportion of math anxious students is represented by a beta(14.0, 32.5) distribution. By use of the R function pbetap(), one can compute the predictive density for the number of math anxious students in a future sample of \\(n^* = 30\\). The figure shows that there is a sizable variation in \\(y^*\\); a 90% prediction interval for \\(y^*\\) is given by {4, 5, …, 13, 15}. Why is the prediction interval so wide? There are two sources of variability in prediction. First, there is uncertainty about the proportion of math anxious students \\(p\\) as reflected in the posterior density \\(g\\), and there is uncertainty in the number of anxious students \\(y^*\\) for a fixed value of \\(p\\) as reflected in the sampling density \\(f\\). The prediction distribution incorporates both types of uncertainty and therefore results in a relatively wide prediction interval estimate."
  },
  {
    "objectID": "single_parameter.html",
    "href": "single_parameter.html",
    "title": "5  Single Parameter Inference",
    "section": "",
    "text": "In this chapter, we introduce Bayesian thinking for several one-parameter problems. We first consider normally distributed data and discuss learning about the normal mean given a known value of the variance and learning about the normal variance given a known mean. These situations are artificial, but we will learn particular forms of posterior distributions that will be used in the case where both parameters of the normal population are unknown. We continue by illustrating Bayesian inference for a Poisson mean and an exponential location parameter. In all examples, the parameter is assigned a conjugate prior and the posterior density has a convenient functional form and easy to summarize. One way of generalizing the class of conjugate priors is by use of mixtures and we illustrate the use of a simple mixture in estimating a Poisson mean."
  },
  {
    "objectID": "single_parameter.html#learning-about-a-normal-mean-with-known-variance",
    "href": "single_parameter.html#learning-about-a-normal-mean-with-known-variance",
    "title": "5  Single Parameter Inference",
    "section": "5.2 Learning about a Normal Mean with Known Variance",
    "text": "5.2 Learning about a Normal Mean with Known Variance\n\n5.2.1 A single observation\nA basic problem in statistics is to learn about the mean of a normal population. Suppose we observe a single observation \\(y\\) from a normal population with mean \\(\\theta\\) and known variance \\(\\sigma^2\\). Here the likelihood function is the sampling density of \\(y\\) viewed as a function of the parameter \\(\\theta\\). \\[\nL(\\theta) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(y-\\theta)^2}{2 \\sigma^2}\\right).\n\\] As an example, suppose Joe takes an IQ test and his score is \\(y\\). Joe’s ``true IQ” is \\(\\theta\\) – this would represent Joe’s average IQ test score if he were able to take the test an infinite number of times. We assume that his test score \\(y\\) is normally distributed with mean equal to his true IQ and standard deviation \\(\\sigma\\). Here \\(\\sigma\\) represents the measurement error of the IQ test and we know from published reports that the standard deviation \\(\\sigma = 10\\).\nSuppose one has some prior beliefs about the location of the mean and one represents these beliefs by a normal curve with mean \\(\\mu\\) and standard deviation \\(\\tau\\). That is, \\[\ng(\\mu) = \\frac{1}{\\sqrt{2 \\pi \\tau^2}} \\exp\\left(-\\frac{(\\theta-\\mu)^2}{2 \\tau^2}\\right).\n\\] Here \\(\\mu\\) represents the person’s best guess at the value of the normal mean, and \\(\\tau\\) reflects the sureness of this guess. In our IQ example, suppose one believes that Joe has average intelligence so one sets the prior mean \\(\\mu = 100\\). Moreover, one is pretty confident (with probability 0.90) that \\(\\mu\\) falls in the interval (81, 119). This information can be matched with the standard deviation \\(\\tau = 15\\).\nAfter we observe the observation \\(y\\), we wish to find the posterior density of the mean \\(\\theta\\). By Bayes’ rule, the posterior density is proportional to the product of the prior of the likelihood. \\[\ng(\\theta | y) \\propto g(\\theta) L(\\theta).\n\\] To find the functional form of this posterior, we combine the terms in the exponent. \\[\\begin{eqnarray*}\ng(\\theta | y)  \\propto  \\exp\\left(-\\frac{(\\theta-\\mu)^2}{2 \\tau^2}\\right) \\times \\exp\\left(-\\frac{(y-\\theta)^2}{2 \\sigma^2}\\right) \\\\\n       =  \\exp\\left(-\\frac{(\\theta-\\mu)^2}{2 \\tau^2}-\\frac{(y-\\theta)^2}{2 \\sigma^2}\\right).  \\nonumber \\\\\n\\end{eqnarray*}\\] By completing the square, one can show that the exponent is equal to \\[\n-\\frac{1}{2}\\left(\\frac{1}{\\tau^2}+\\frac{1}{\\sigma^2}\\right)\n\\left[\\theta^2 - 2 \\left(\\frac{\\mu/\\tau^2 + y/\\sigma^2}{1/\\tau^2+1/\\sigma^2}\\right) +\n\\left(\\frac{\\mu/\\tau^2 + y/\\sigma^2}{1/\\tau^2+1/\\sigma^2}\\right)^2 \\right]\n\\] \\[\n= -\\frac{1}{2}\\left(\\frac{1}{\\tau^2}+\\frac{1}{\\sigma^2}\\right)\n\\left(\\theta -  \\frac{\\mu/\\tau^2 + y/\\sigma^2}{1/\\tau^2+1/\\sigma^2} \\right)^2 .\n\\] We see then that, up to a proportionality constant, the posterior density has the normal functional form \\[\ng(\\theta | y) \\propto \\exp\\left(-\\frac{1}{2 \\tau_1^2} (\\theta - \\mu_1)^2 \\right),\n\\] where the posterior mean and posterior variance have the form \\[\n\\mu_1 = \\frac{\\mu/\\tau^2 + y/\\sigma^2}{1/\\tau^2+1/\\sigma^2}, \\,\\, \\tau_1^2 = \\frac{1}{1/\\tau^2+1/\\sigma^2}.\n\\]\nOne can see how the posterior combines the information in the prior and the data by using the notion of {}. The precision is defined to be the reciprocal of the variance. The prior precision, denoted \\(P_0\\), is the reciprocal of the prior variance \\[\nP_0 = 1/\\tau^2.\n\\] In a similar fashion, the data precision, denoted by \\(P_D\\), is the reciprocal of the data variance \\[\nP_D = 1/\\sigma^2.\n\\] The posterior precision, denoted by \\(P_1 = 1/\\tau_1^2\\), is found simply by adding the prior precision and the data precision: \\[\nP_1 = P_0 + P_D.\n\\] The posterior mean \\(\\mu_1\\) is the weighted average of the prior mean \\(\\mu\\) and the observation \\(y\\), where the weights are proportional to the precisions: \\[\n\\mu_1 = \\frac{P_0}{P_0 + P_D} \\mu + \\frac{P_D}{P_0 + P_D} y .\n\\]\nReturning to our example, suppose Joe’s score on the IQ test is \\(y = 120\\). What have we learned about his true IQ \\(\\theta\\)? Table 4.1 illustrates the calculations of the posterior distribution.\n\nWe first compute the precision \\(P_0 = 1/\\tau^2\\) of the prior and the precision \\(P_D = 1/\\sigma^2\\) of the data.\nThe posterior precision \\(P_1\\) is the sum of the prior precision and the data precision. \\[\nP_1 = P_0 + P_D = 0.0044 + 0.0100 = 0.0144 .\n\\]\nThe variance of the posterior \\(\\tau_1^2\\) is the reciprocal of the posterior precision.\nWe compute the posterior mean \\(\\mu_1\\) that is a weighted average of the prior mean and the observation: \\[\n\\mu_1 = \\frac{0.0100}{0.0144} \\times 100 + \\frac{0.0044}{0.0144} \\times 113.8\n\\]\n\n\n\n\nEstimate\nVariance\nPrecision\n\n\n\n\nPrior\n100\n225\n\n\nData\n120\n100\n\n\nPosterior\n113.8\n69.23\n\n\n\nBefore sampling, one believed that Joe was of average intelligence and the prior mean was \\(\\mu = 100\\). After the IQ test \\(y = 120\\) is observed, one’s opinion about Joe’s intelligence has changed and the posterior mean is now at \\(\\mu_1 = 113.8\\). The posterior mean, as expected, falls between the prior mean and the observed test score. The posterior mean is closer to the test score than the prior mean – this is due to the fact that there is more information (measured by the precision) in the data value than the prior mean. Also note that the posterior variance is smaller than either the prior variance and the data variance. Since the posterior precision is the sum of the prior precision and data precision, one gains information by adding the information from the two sources, and this will result in a smaller posterior variance.\nAlthough we have focused on learning about Joe’s true IQ \\(\\theta\\), one may be interested in predicting Joe’s test score on a future test. Denote a future test score by \\(\\tilde y\\). We are interested in obtaining the predictive density of \\(\\tilde y\\) denoted by \\(f(\\tilde y)\\). To obtain this density, we apply some results from normal sampling theory. By adding and subtracting \\(\\theta\\) we write the random variable \\(\\tilde y\\) as \\[\n\\tilde y = W + \\theta,\n\\] where \\(W = \\tilde y - \\theta\\). Suppose the current beliefs about \\(\\theta\\) are represented by a normal density with mean \\(\\mu\\) and variance \\(\\tau^2\\). For a given value of \\(\\theta\\), the future observation \\(\\tilde y\\) is normal with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Equivalently, the distribution of \\(W = \\tilde y - \\theta\\) is normal with mean 0 and variance \\(\\sigma^2\\). Since this distribution of W doesn’t depend on \\(\\theta\\), this also represents the unconditional distribution of W. It can be shown that the random variables \\(W\\) and \\(\\theta\\) are independent. Since \\(\\tilde y\\) is the sum of two independent normal variates, it follows that the distribution for \\(\\tilde y\\) will also be normal with mean \\(\\mu\\) and variance \\(\\sigma^2 + \\tau^2\\).\nWe have already observed Joe’s test score of 120 and the posterior distribution of his true IQ \\(\\theta\\) is \\(N(113.8, \\sqrt{69.23})\\). We wish to construct a 90% prediction interval for the score of a future test \\(\\tilde y\\). Applying the above result, the future test score will be normal with mean \\(\\mu_1 = 113.8\\) and variance \\(\\sigma^2 + \\tau_1^2 = 100 + 69.23 = 169.23\\). So the interval \\[\n(113.8 - 1.645 \\sqrt{169.23}, 113.8 + 1.645 \\sqrt{169.23})\n\\] will cover 90% of the predictive distribution of the future test score.\n\n\n5.2.2 Multiple observations\nIn our discussion, we observed only a single observation. Suppose now that we observe a random sample \\(y_1, ..., y_n\\) from a normal distribution with mean \\(\\theta\\) and variance \\(\\sigma^2\\). In this case, the likelihood function for \\(\\theta\\) is the product of the sampling densities \\[\nL(\\theta) = \\prod_{i=1}^n \\exp\\left(-\\frac{(y_i-\\theta)^2}{2 \\sigma^2}\\right).\n\\] Suppose we subtract and add the sample mean \\(\\bar y = \\frac{1}{n}\\sum_{i=1}^n y_i\\) to the term in parentheses in the exponent: \\[\nL(\\theta) = \\prod_{i=1}^n \\exp\\left(-\\frac{(y_i - \\bar y + \\bar y -\\theta)^2}{2 \\sigma^2}\\right).\n\\] If we expand the quadratic term and simplify, ignoring multiplicative constants not depending on \\(\\theta\\), one can show that \\[\nL(\\theta) = \\exp\\left(-\\frac{n (\\bar y - \\theta)^2}{2 \\sigma^2}\\right).\n\\] What we have shown is that \\(\\bar y\\) is a sufficient statistic for \\(\\theta\\). Also it shows that the multiple observation situation is really equivalent to observing the {} data value \\(\\bar y\\) that is normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2/n\\).\nSuppose a normal(\\(\\mu, \\tau^2\\)) prior is chosen for \\(\\theta\\). Then, by applying the results of the previous section, the posterior distribution will be normal(\\(\\mu_1, \\tau_1^2)\\) where the mean and variance are given by \\[\n\\mu_1 = \\frac{\\mu/\\tau^2 + \\bar y n/\\sigma^2}{1/\\tau^2+n/\\sigma^2}, \\,\\, \\tau_1^2 = \\frac{1}{1/\\tau^2+n/\\sigma^2}.\n\\]\n\n\n5.2.3 Inference with a noninformative prior\nSuppose that one has little prior information about the location of the normal mean. This means one believes that every possible IQ value (within reasonable limits) is equally likely. This lack of knowledge can be represented by a uniform curve \\[\ng(\\theta) = c, \\, \\, \\infty < \\theta < \\infty .\n\\] One might object to this choice of prior since \\(g\\) is not a proper probability density. However this choice results in a posterior density for \\(\\theta\\) that is indeed proper. In the case where a random sample of \\(n\\) is taken, then the posterior density will be given by \\[\\begin{eqnarray*}\ng(\\theta | y)  \\propto  L(\\theta) g(\\theta)  \\nonumber \\\\\n  =  \\exp\\left(-\\frac{n (\\bar y - \\theta)^2}{2 \\sigma^2}\\right)\n\\end{eqnarray*}\\] We recognize this posterior as a normal density with mean \\(\\bar y\\) and variance \\(\\sigma^2/n\\).\nIf we use this uniform prior, then Bayesian inference will mimic the usual frequentist inference about a mean with known variance. For example, suppose we want to construct a 95% Bayesian interval estimate. The ``equal-tails” interval \\[\n(\\bar y - 1.96 \\frac{\\sigma}{\\sqrt{n}}, \\bar y + 1.96 \\frac{\\sigma}{\\sqrt{n}})\n\\] covers the central 95% of the posterior distribution of \\(\\theta\\). This interval also has a frequentist 95% probability of coverage in repeated sampling\n\n\n5.2.4 Inference with large samples\nSuppose one’s prior beliefs about a mean are modeled by a normal distribution and one observes a very large sample. What is the impact of this large sample size on the posterior distribution? As an example, suppose I’m interested in learning about the mean height \\(\\theta\\) of undergraduate female students at my university. Based on my knowledge, my ``best guess” at \\(\\theta\\) is 65.5 inches and I am 90% confident that the mean is within 2 inches of my best guess. I can represent this information by a normal curve with mean \\(\\mu = 65.5\\) and standard deviation \\(\\tau = 1.2\\). A large sample of \\(n = 427\\) female students are asked about their height and we observe a sample mean of \\(\\bar y = 64.71\\) inches. What have we learned about the population mean height \\(\\theta\\)? For this example, we will assume that we know the the standard deviation of the population of female heights is \\(\\sigma = 3\\) inches.\nTable 4.2 shows the posterior calculations for this example. The first row contains the mean, standard deviation, variance and precision for our prior, and the second row contains the same quantities for the data. Here the standard error of the mean is \\(\\sigma/\\sqrt{n} = 3/\\sqrt{427} = 0.145\\), the data variance is \\(\\sigma^2/n = 0.021\\) and the data precision is \\(n/\\sigma^2 = 47.56\\). The posterior mean is given by \\[\nE(\\theta | y) = \\frac{0.69}{0.69 + 47.56} \\times 65.5 + \\frac{47.56}{0.69 + 47.56} \\times 64.71 = 64.72.\n\\]\n\n\n\n\nEstimate\nStandard Deviation\nVariance\nPrecision\n\n\n\n\nPrior\n65.5\n1.2\n1.44\n0.69\n\n\nData\n64.71\n0.145\n0.021\n47.56\n\n\nPosterior\n64.72\n0.144\n0.0207\n48.25\n\n\n\nRecall the precision is a measure of the amount of information and it is clear in this example that there is much more information about \\(\\theta\\) contained in the sample of \\(427\\) students than the prior. As a result, the likelihood function is much more precise than the prior and the posterior is essentially controlled by the data. In other words, since the data is so precise relative to the prior, the prior acts like a constant noninformative prior. The posterior mean and posterior standard deviation are approximately equal to the sample mean and classical standard error, respectively.\nIn this particular example, there was some conflict between the information in the prior and the data. My prior beliefs about the average female height was approximately one inch too high. But since a large sample was collected, my ``wrong” prior information has little impact on the posterior inference. In other words, the posterior inference in this case is robust or insensitive to the choice of prior distribution."
  },
  {
    "objectID": "single_parameter.html#learning-about-a-normal-variance-with-known-mean",
    "href": "single_parameter.html#learning-about-a-normal-variance-with-known-mean",
    "title": "5  Single Parameter Inference",
    "section": "5.3 Learning About a Normal Variance with Known Mean",
    "text": "5.3 Learning About a Normal Variance with Known Mean\n\n5.3.1 Inference using an informative prior\nSuppose we observe \\(y_1, ..., y_n\\) from a normal population with known mean \\(\\theta\\) and unknown variance \\(\\sigma^2\\). The likelihood function for \\(\\sigma^2\\) is given by \\[\\begin{eqnarray*}\nL(\\sigma^2)  =  \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left( -\\frac{1}{2 \\sigma^2}(y_i - \\theta)^2\\right)  \\nonumber \\\\\n       \\propto  \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\theta)^2\\right). \\nonumber \\\\\n\\end{eqnarray*}\\]\nA conjugate prior for a variance is the inverse gamma distribution. Suppose \\(X\\) has a gamma distribution with shape \\(\\alpha\\) and rate \\(\\beta\\) with density \\[\nf(x) = \\frac{ x^{\\alpha-1} \\exp(-\\beta x) \\beta^\\alpha}{\\Gamma(\\alpha)}, \\, \\, x > 0.\n\\] If we let \\(W = 1/X\\), then \\(W\\) has an inverse gamma distribution with parameters \\(\\alpha\\) and \\(\\beta\\) with density \\[\nf(w) = \\frac{\\exp(-\\beta/w) \\beta^\\alpha}{w^{\\alpha+1} \\Gamma(\\alpha)}, \\, \\, w > 0.\n\\]\nNow we assume that one’s prior beliefs about \\(\\sigma^2\\) can be represented by an inverse gamma(\\(\\alpha, \\beta)\\) density \\[\ng(\\sigma^2) = \\frac{\\exp(-\\beta/\\sigma^2) \\beta^\\alpha}{(\\sigma^2)^{\\alpha+1} \\Gamma(\\alpha)}.\n\\] Then by combining prior and likelihood, the posterior of \\(\\sigma^2\\) is equal to \\[\\begin{eqnarray*}\ng(\\sigma^2 | y)  \\propto  L(\\sigma^2) \\times g(\\sigma^2) \\\\\n       \\propto  \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\theta)^2\\right)\n          \\times \\frac{\\exp(-\\beta/\\sigma^2) }{(\\sigma^2)^{\\alpha+1} }  \\nonumber \\\\\n       =  \\frac{1}{(\\sigma^2)^{\\alpha+n/2+1}} \\exp\\left(-\\frac{1}{ \\sigma^2}\\left[\\beta+ \\frac{1}{2}\\sum_{i=1}^n (y_i - \\theta)^2\\right]\\right),\\nonumber \\\\\n\\end{eqnarray*}\\] which we recognize as a inverse gamma density with updated parameters \\(\\alpha_1 = \\alpha + n/2\\) and \\(\\beta_1 = \\beta+ \\frac{1}{2} \\sum_{i=1}^n (y_i - \\theta)^2\\).\nIt is common to represent the inverse gamma prior and posterior densities in terms of the ``scale times inverse chi-square” density. A chi-square random variable with \\(\\nu\\) degrees of freedom has density \\[\nf(w) \\propto w^{\\nu/2-1} \\exp(-w/2), \\, w > 0.\n\\] The random variable \\(V = c / W\\) has the density \\[\nf(v) \\propto \\frac{1}{v^{\\nu/2+1}} \\exp\\left(-\\frac{c}{2 v}\\right), \\, v > 0.\n\\] Since the density of \\(V\\) is derived as a constant divided by a chi-squared variable, we write \\[\nV \\sim c \\chi^{-2}_\\nu .\n\\] Using this notation, our inverse gamma prior can represented as $ 2 ^{-2}_{2 }$ and likewise the posterior is represented as $ 2 1 ^{-2}{2 _1}$.\n\n\n5.3.2 Inference using a noninformative prior\nIn the case where one has little prior information about a variance, the standard noninformative prior is given by the improper density \\[\ng(\\sigma^2) = \\frac{1}{\\sigma^2}, \\, \\, \\sigma^2 > 0.\n\\] This can viewed as a limiting case of the inverse gamma density as the shape parameter \\(\\alpha\\) and the rate parameter \\(\\beta\\) both approach zero. If this prior is combined with the likelihood, one obtains the posterior density \\[\\begin{eqnarray*}\ng(\\sigma^2 | y)\n       =  \\frac{1}{(\\sigma^2)^{n/2+1}} \\exp\\left(-\\frac{1}{ \\sigma^2}\\left[\\frac{1}{2}\\sum_{i=1}^n (y_i - \\theta)^2\\right]\\right),\\nonumber \\\\\n\\end{eqnarray*}\\] which is inverse gamma with parameters \\(\\alpha_1 = n/2\\) and \\(\\beta_1 = \\frac{1}{2} \\sum_{i=1}^n (y_i - \\theta)^2\\). Relating the posterior to the inverse chi-squared distribution, we can say that \\[\n\\sigma^2 \\sim (\\sum_{i=1}^n (y_i - \\theta)^2) \\chi^{-2}_{n}.\n\\]\n\n\n5.3.3 An example\nTo illustrate learning about a variance, consider the following winning percentages for all Major League Baseball teams in the 1964 season. These can be considered a random sample of percentages from a normal distribution with mean \\(\\mu = 50\\) and unknown variance \\(\\sigma^2\\). The value of the variance is a measure of the level of competition in the baseball league where small values of \\(\\sigma^2\\) correspond to teams that are relatively equal in ability.\n57.4 56.8 56.8 55.6 54.3 49.4 49.4 46.9 40.7 32.7 \n61.1 60.5 59.9 52.5 50.6 48.8 48.8 44.4 38.3 35.2\nSuppose one has some prior knowledge about the value of \\(\\sigma^2\\). The value of the sample variance of the team winning percentages during the previous season is equal to 69.2 and you are pretty confident (with probability 0.90) that the variance \\(\\sigma^2\\) is within 20% of 69.2. With some trial and error, one finds that the inverse gamma density with \\(\\alpha = 70\\) and \\(\\beta = 4500\\) approximately matches this prior information.\nFrom the observed data, we compute \\[\nn = 20, \\, \\, \\sum_{i=1}^n (y_i - 50)^2 = 1321.45.\n\\] So the posterior density will be inverse gamma(\\(\\alpha_1, \\beta_1)\\) with \\[\n\\alpha_1 = 70 + 20/2 = 80, \\, \\, \\beta_1 = 4500 + 1321.45/2 = 5160.725\n\\]\nOne can summarize the posterior by computing suitable percentiles. Statistics packages like R typically have functions for computing percentiles of a gamma distribution and these functions can be used to find percentiles of the inverse gamma distribution. For example, suppose one wishes to find the pth percentile \\(x_p\\) of a inverse gamma(\\(\\alpha, \\beta\\)) density – the median satisfies the relationship \\[\nP( X < x_p) = p,\n\\] where \\(X\\) is inverse gamma(\\(\\alpha, \\beta\\)). One can rewrite this statement as \\[\nP(1/X > 1/x_p) = p,\n\\] where \\(Y = 1/X\\) has a gamma(\\(\\alpha, \\beta\\)) density. Using this relationship, it is straightforward to show that the inverse gamma percentile satifies \\[\nx_p = \\frac{1}{y_{1-p}},\n\\] where \\(y_{1-p}\\) is the \\((1-p)\\) percentile of a gamma(\\(\\alpha, \\beta\\)) density.\nThe 5th, 50th, and 95th percentiles of the inverse gamma posterior distribution are displayed in Table 3.3. The median (50th percentile) of 64.78 is a reasonable point estimate at \\(\\sigma^2\\) and the 5th and 95th percentiles, 54.17 and 78.34, form a ``equal-tails” interval estimate. In the case where prior information is not available for the variance, one can place a noninformative prior with \\(\\alpha = 0, \\beta = 0\\) on \\(\\sigma^2\\) and the table also shows the posterior percentiles for this choice of prior. In this situation, the informative prior information has a substantial impact on the posterior inference and the posterior interval estimate with the informative prior is significantly shorter than the interval estimate with the vague prior.\n\n\n\nPrior\n5th Percentile\nMedian\n95th Percentile\n\n\n\n\nInverse Gamma(70, 4500)\n54.17\n64.78\n78.34\n\n\nNoninformative\n42.07\n68.34\n121.78"
  },
  {
    "objectID": "single_parameter.html#learning-about-a-poisson-mean",
    "href": "single_parameter.html#learning-about-a-poisson-mean",
    "title": "5  Single Parameter Inference",
    "section": "5.4 Learning About a Poisson Mean",
    "text": "5.4 Learning About a Poisson Mean\n\n5.4.1 Introduction\nThe author has a website for one of his books and Google Analytics ({}) records the number of visits to this particular website every day.\nThe author records the following counts of weekday visits for a 21-day period during May and June of 2009.\n 20 30 22 20 20 17 21 26 22 30 36\n 15 30 27 22 23 18 24 28 23 12\nA common model for count data such as these is the Poisson. Suppose the counts \\(y_1, ..., y_n\\) represent a random sample from a Poisson distribution with parameter \\(\\lambda\\) with probability mass function \\[\np(y | \\lambda) = \\frac{\\exp(-\\lambda) \\lambda^y}{y!}, \\, \\, y = 0, 1, 2, ...\n\\] One objective is to learn about the mean parameter \\(\\lambda\\). In the example, \\(\\lambda\\) would represent the average number of hits to this website over a long period of days. Also we are interested in predicting the number of website counts in future days.\nSuppose that the author has been observing the counts for daily visits to this website and so he has some beliefs about the location of \\(\\lambda\\) before sampling. In particular, he believes that the quartiles of \\(\\lambda\\) are 21.3 and 26.4. Equivalently, one believes \\[\nP(\\lambda < 21.3) = 0.25, \\, \\, P(\\lambda < 26.4) = 0.75.\n\\] Any prior density \\(g(\\lambda)\\) that matches this prior information would suitable for use in this example. But we’ll shortly see that it is convenient to choose a gamma density. After some trial and error, the author finds that the gamma prior density \\[\ng(\\lambda) = \\frac{\\exp(-\\beta \\lambda) \\lambda^{\\alpha-1} \\beta^\\alpha}{\\Gamma(\\alpha)}, \\lambda > 0,\n\\] where the shape parameter \\(\\alpha = 40\\) and the rate parameter \\(\\beta = 1.67\\) approximately matches these prior quartiles.\n\n\n5.4.2 Learning about the Mean\nAfter counts have been observed, one’s opinion about \\(\\lambda\\) is based on the posterior distribution. First, one finds the likelihood \\(L(\\lambda)\\). By the independence assumption, the joint mass function of the counts \\(y_1, ..., y_n\\) is given by the product \\[\np(y_1, ..., y_n | \\lambda) = \\prod_{i=1}^n \\frac{\\exp(-\\lambda) \\lambda^y_i}{y_i!}.\n\\] Once the counts are observed, then the likelihood function is this joint mass function, viewed as a function of \\(\\lambda\\). \\[\\begin{eqnarray*}\nL(\\lambda)  =  \\prod_{i=1}^n \\frac{\\exp(-\\lambda) \\lambda^y_i}{y_i!} \\nonumber \\\\\n            =  C \\exp(-n \\lambda) \\lambda ^s,  \\nonumber \\\\\n\\end{eqnarray*}\\] where \\(n\\) is the sample size, $s = _{i=1}^n y_i $ is the sum of observations, and \\(C\\) is a constant not depending on the parameter \\(\\lambda\\).\nThe posterior of \\(\\lambda\\) is found by multiplying the prior and the likelihood: \\[\\begin{eqnarray*}\ng(\\lambda| y)  \\propto  g(\\lambda) \\times L(\\lambda) \\nonumber \\\\\n          =  \\exp(-\\beta \\lambda) \\lambda^{\\alpha-1} \\times \\exp(-n \\lambda) \\lambda ^s \\nonumber \\\\\n            =  \\exp(-(\\beta + n) \\lambda) \\lambda^{\\alpha + s -1}.\n\\end{eqnarray*}\\] One sees that the posterior density of \\(\\lambda\\) is also of the gamma functional form with updated parameters \\[\n\\alpha_1 = \\alpha + s, \\, \\, \\beta_1 = \\beta + n .\n\\] For our example, a Gamma(\\(\\alpha, \\beta\\)) prior was assigned with \\(\\alpha = 40\\) and \\(\\beta = 1.67\\). From the observed data, there are \\(n = 21\\) observations and the sum of the counts is \\(s = \\sum_{i=1}^n y_i = 486\\). So the posterior density for \\(\\lambda\\) will be gamma(\\(\\alpha_1, \\beta_1)\\) where \\[\n\\alpha_1 = 40 + 486 = 526, \\, \\, \\beta_1 = \\beta + n = 1.67 + 21 = 22.67.\n\\]\nOne can estimate \\(\\lambda\\) by the posterior median that is 23.19. A 90% interval estimate for \\(\\lambda\\) is formed from the 0.05 and 0.95 quantiles of the gamma(526, 22.67) density given by 21.56 and 24.89. So the mean number of website visits falls in the interval (21.56, 24.89) with probability 0.90.\n\n\n5.4.3 Prediction\nNext, suppose we are interested in predicting the number of websites \\(\\tilde y\\) on a future weekday. If our current beliefs about the mean \\(\\lambda\\) are given by a Gamma(\\(\\alpha, \\beta\\)) distribution, then the predictive density of \\(\\tilde y\\) is given by \\[\\begin{eqnarray*}\nf(\\tilde y)  =  \\int_0^\\infty f(\\tilde y | \\lambda) g(\\lambda) d\\lambda\\nonumber \\\\\n            =  \\int_0^\\infty \\frac{\\lambda^{\\tilde y} \\exp(-\\lambda)}{\\tilde y!} \\times\n                               \\frac{\\lambda^{\\alpha-1} \\exp(-\\beta \\lambda) \\beta^\\alpha}{\\Gamma(\\alpha)}  d\\lambda \\nonumber \\\\\n\\end{eqnarray*}\\] One can analytically integrate out \\(\\lambda\\), obtaining the predictive density \\[\nf(\\tilde y) = \\frac{\\beta^\\alpha \\Gamma(\\alpha + \\tilde y)}{(\\beta + 1)^{\\alpha + \\tilde y} \\Gamma(\\alpha) y!}, \\, y = 0, 1, 2, ...\n\\]\nIn our example, after observing the data, the current beliefs about \\(\\lambda\\) are contained in the Gamma(526, 22.67) posterior density. The corresponding {} density is the distribution of a future number of website visits for a future weekday. Using R, we compute values of \\(f(\\tilde y)\\) for values of \\(\\tilde y\\) from 0 to 200. We find that the most likely value of \\(\\tilde y\\), the value with the largest predictive probability, is equal to 23. But there is much uncertainty about this prediction since (1) we are uncertain about the mean number of hits \\(\\lambda\\) and (2) there is Poisson variability about the number of hits \\(\\tilde y\\) given a value of \\(\\lambda\\).\nUsing the R function {}, we find that \\[\nP( 15 \\le \\tilde y \\le 31) = 0.917,\n\\] so (15, 31) is a 91.7% prediction interval for this future count.\nThe predictive density is useful for making predictions about future data. It is also helpful in judging the suitability of our Poisson/gamma model. The basic idea is that our model is reasonable if the actual observed data is consistent with predictions made from the model. We just saw that approximately 90% of the predictions fall between 15 and 31 visits. Looking at our data, we see that only 2 of the 21 observations (namely 12 and 36) fall outside of the interval (15, 31). Since the observed data appears consistent with the posterior predictive distribution, the model with Poisson sampling and a gamma(40, 1.67) prior seems to be a reasonable description of the observed counts."
  },
  {
    "objectID": "single_parameter.html#learning-about-an-exponential-threshold-parameter",
    "href": "single_parameter.html#learning-about-an-exponential-threshold-parameter",
    "title": "5  Single Parameter Inference",
    "section": "5.5 Learning About an Exponential Threshold Parameter",
    "text": "5.5 Learning About an Exponential Threshold Parameter\nIn a reliability application, suppose that one observes the times to failure for a sample of washing machines. We assume that the failure times \\(y_1, ..., y_n\\) represent a random sample from an exponential distribution with threshold \\(\\theta\\) and known rate \\(\\beta\\). The sampling density is given by \\[\nf(y | \\theta) = \\beta \\exp(-\\beta (y - \\theta)), \\, \\, y \\ge \\theta.\n\\] In this application, the parameter \\(\\theta\\) can represent the length of a warranty period where no failures can occur.\nTo simplify the problem, we are assuming that one does not know the warranty period but knows the parameter \\(\\beta\\) that describes the pattern of failures after the warranty period.\nFirst, suppose that little information exists about the value of the positive parameter \\(\\theta\\), and so we assign this parameter a uniform prior on positive values: \\[\ng(\\theta) = 1, \\, \\, \\theta > 0.\n\\] The likelihood function is given by \\[\\begin{eqnarray*}\nL(\\theta)  =  \\prod_{i=1}^n f(y_i | \\theta) \\nonumber \\\\\n            =  \\prod_{i=1}^n \\left( \\beta \\exp(-\\beta (y_i - \\theta)) I(y_i \\ge \\theta) \\right) \\nonumber \\\\\n            \\propto  \\exp(n \\beta \\theta) I(\\theta \\le \\min y_i)  \\nonumber \\\\\n\\end{eqnarray*}\\] Combining the likelihood and prior, we see that the posterior density is defined, up to a proportional constant, by \\[\\begin{eqnarray*}\ng(\\theta | y)  \\propto  L(\\theta) g(\\theta) \\nonumber \\\\\n            \\propto  \\exp(n \\beta \\theta) I(0 < \\theta \\le \\min y_i). \\nonumber \\\\\n\\end{eqnarray*}\\] We see that the posterior density is an exponential density with rate \\(n \\beta\\) that is truncated to the right by \\(\\min y_i\\).\nAs an example, suppose that one observes the following failure times (in months) for 15 refrigerators:\n 51.8  50.8  20.6  42.4  20.5  18.7  27.9  18.7  \n 42.9 123.7  62.7  22.8  89.6  21.4  49.4\nFrom past experience, one knows that \\(\\beta = 1/24\\) – this indicates the belief that the average failure time for a refrigerator will be 24 months after the warranty time. If one assigns a uniform prior, then the posterior density for the warranty time \\(\\theta\\) is given by \\[\\begin{eqnarray*}\ng(\\theta | y)  \\propto  \\exp(n \\beta \\theta) I(0 < \\theta \\le \\min y_i) \\nonumber \\\\\n            \\propto  \\exp(15/24 \\theta) I(0 < \\theta \\le 18.7). \\nonumber \\\\\n\\end{eqnarray*}\\] When one normalizes the density, one finds the posterior density is equal to \\[\ng(\\theta | y) = \\frac{\\exp(15/24 \\theta)}{1- \\exp(15/24 \\times 18.7)}, \\, \\, 0 < \\theta < 18.7.\n\\]\nIf one graphs this density, one sees that the posterior density for \\(\\theta\\) is strongly left skewed with a mode at 18.7 months.\nA HPD interval for the threshold clearly will have the form \\((\\theta_0, 18.7)\\) where \\(\\theta_0\\) is chosen so that the probability content has the given level of \\(\\gamma\\). If one desires a 90% interval estimate where \\(\\gamma = 0.90\\), then a straightforward calculation shows that the HPD interval for \\(\\theta\\) is given by (16.0, 18.7).\n Exercise: Assume \\(\\theta\\) has the prior \\[\ng(\\theta) \\propto \\exp(a \\theta), \\, \\, \\theta < b .\n\\]\n\nFind the posterior density for \\(\\theta\\).\nShow that the posterior has the same functional form as the prior with updated parameters \\[\na_1 = n \\beta + a, \\, \\, b_1 = \\min(\\min y_i, b)).\n\\]\nSuppose one believes that the threshold \\(\\theta\\) is definitely smaller than 24 months and you are 90% sure the threshold is larger than 15 months. Find values of the parameters \\(a\\) and \\(b\\) that match these prior beliefs.\nUsing the prior constructed in part (c) and the refrigerator failure data, find a 90% interval estimate for the threshold parameter \\(\\theta\\). Compare this interval estimate with the interval estimate using a noninformative prior."
  },
  {
    "objectID": "single_parameter.html#using-mixtures-of-conjugate-priors",
    "href": "single_parameter.html#using-mixtures-of-conjugate-priors",
    "title": "5  Single Parameter Inference",
    "section": "5.6 Using Mixtures of Conjugate Priors",
    "text": "5.6 Using Mixtures of Conjugate Priors\nOne way of extending the class of conjugate priors is by the use of discrete mixtures. We illustrate the use of mixtures for the Poisson scenario, although this approach can be applied to any sampling model where there is a conjugate prior.\nSuppose we assign the Poisson parameter \\(\\lambda\\) the discrete mixture prior \\[\ng(\\lambda) = p g_1(\\lambda) + (1 - p) g_2(\\lambda)\n\\] where \\(g_1\\) is gamma(\\(\\alpha_1, \\beta_1\\)), \\(g_2\\) is gamma(\\(\\alpha_2, \\beta_2)\\), and \\(p\\) is a known mixing probability between 0 and 1.\nSuppose we observe (\\(y, t\\)), where \\(y\\) is the count in the time interval \\(t\\). We assume that \\(y\\) is Poisson(\\(t \\lambda\\)) with density \\[\nf(y | \\lambda) = \\frac{(t \\lambda)^y \\exp(-t \\lambda)}{y!}, \\, \\, y = 0, 1, 2, ...\n\\]\nIn the following computation, we include all of the terms to motivate a special expression for the posterior density. The posterior density for \\(\\lambda\\) is given by \\[\\begin{eqnarray*}\ng(\\lambda| y)  =  \\frac{g(\\lambda) \\times f(y | \\lambda)}{f(y)} \\nonumber \\\\\n          =  \\frac{\\left(p g_1(\\lambda) + (1-p) g_2(\\lambda)\\right)\\times f(y | \\lambda)}{f(y)} \\nonumber \\\\\n          =  \\frac{p g_1(\\lambda)f(y | \\lambda) + (1-p) g_2(\\lambda)f(y | \\lambda)}{f(y)}. \\nonumber \\\\\n\\end{eqnarray*}\\] The predictive density \\(f(y)\\) can be written as \\[\\begin{eqnarray*}\nf(y)  =  \\int_0^\\infty g(\\lambda) f(y|\\lambda) d\\lambda \\nonumber \\\\\n          =  \\int_0^\\infty \\left( p g_1(\\lambda)f(y | \\lambda) + (1-p) g_2(\\lambda)f(y | \\lambda)\\right) d\\lambda \\nonumber \\\\\n          =  p f_1(y) + (1-p) f_2(y) \\nonumber ,\\\\\n\\end{eqnarray*}\\] where \\(f_1\\) and \\(f_2\\) are respectively the predictive densities for \\(y\\) when \\(\\lambda\\) is assigned the priors \\(g_1\\) and \\(g_2\\), respectively. If we substitute this expression into the posterior density expression and rearrange terms, one can see that the posterior density has the representation \\[\ng(\\lambda | y) = p(y) g_1(\\lambda | y) + (1- p(y)) g_2 (\\lambda | y),\n\\] where \\(g_1(\\lambda | y)\\) and \\(g_2(\\lambda | y)\\) are the posterior densities assuming the priors \\(g_1\\) and \\(g_2\\) and \\[\np(y) = \\frac{ p f_1(y)}{p f_1(y) + (1-p) f_2(y)}.\n\\] When \\(g_1\\) and \\(g_2\\) are gamma (conjugate) priors, then the posterior density will also be a mixture of gamma distributions, where the mixing weights \\(p(y)\\) and \\(1 - p(y)\\) depend on the mixing probability \\(p\\) and the predictive densities \\(f_1(y)\\) and \\(f_2(y)\\) using the two priors.\nTo illustrate the use of mixtures, suppose I am interested in learning about the home run rate \\(\\lambda\\) for the baseball player Derek Jeter before the start of the 2004 season. (A home run rate is the proportion of official at-bats that are home runs.) Suppose my prior beliefs are that the median of \\(\\lambda\\) is equal to 0.05 and the 90th percentile is equal to 0.081. Here are two priors that match this information. The first is a conjugate Gamma prior and the second is a mixture of two conjugate Gamma priors with mixing probabilities 0.88 and 0.12.\n\nPrior 1: Gamma(shape = 6, rate = 113.5)\nPrior 2: 0.88 x Gamma(shape = 10, rate = 193.5) + 0.12 x Gamma(shape = 0.2, rate = 0.415)\n\nOne can check that these two priors match the prior beliefs. If one graphs the two priors, they are similar in location and spread but the mixture prior (Prior 2) has flatter tails.\nNow we observe some data – Jeter hit \\(y = 23\\) homeruns in \\(t = 643\\) at-bats. If one assumes Prior 1, then one can show that the posterior density for \\(\\lambda\\) will be Gamma with shape \\(29\\) and rate \\(756.5\\). If one uses the mixture Prior 2, then the posterior density can be shown to be \\[\ng(\\lambda|y) = 0.98 \\times Gamma(33.0, 836.5) + 0.02 \\times Gamma(23.3, 643.4).\n\\] Does the choice of prior make a difference in this situation? If one plots the two posterior densities on the same scale, they look barely distinguishable, indicating that inference about \\(\\lambda\\) is robust or insensitive to the choice of prior.\nBut this robustness of the inference with respect to the prior depends on the observed data. Suppose that Jeter is a ``steriod slugger” during the 2004 season and hits 70 home runs in 500 at-bats. If we again use the same two priors, the posterior density for \\(\\lambda\\) using Prior 1 will be Gamma(76, 693.5). The posterior using Prior 2 is given by the mixture \\[\ng(\\lambda | y) = 0.23 \\times Gamma(80, 693.5) + 0.77 \\times Gamma(70.2, 500.4).\n\\] If one draws the two posteriors on the same scale, one sees that the two posterior densities are significantly different, indicating that the inference depends on the choice of prior."
  },
  {
    "objectID": "prior.html",
    "href": "prior.html",
    "title": "6  Prior Distributions",
    "section": "",
    "text": "In a Bayesian analysis, one needs to specify a density \\(g(\\theta)\\) that reflects one’s prior beliefs about the location of the parameter \\(\\theta\\). The problem is that one typically has only knowledge about a typical value of \\(\\theta\\) and some information about the sureness of this guess. The question is: “How can one construct a prior density that represents this imprecise prior information?”\nIn this section, we will talk about constructing a prior for a proportion, although the discussion will extend to any single parameter.\nAs a concrete example, suppose I’m interested in the proportion of students \\(p\\) at my university who send or receive text messages while driving. I wish to construct a prior for \\(p\\) that reflects my beliefs about the size of this proportion.\nA standard approach for constructing a prior assumes that \\(p\\) has density that is a member of a familiar functional form, and one chooses the parameters of the density that match one’s beliefs. For a proportion, the usual choice for density is a beta curve with parameters \\(a\\) and \\(b\\). This simplifies the prior assessment task considerably. Instead of constructing an entire density function, one needs only to assess two parameter values. The implicit assumption is that the beta family of distributions is sufficiently flexible to represent different beliefs about the proportion value.\nTo choose the parameters \\(a\\) and \\(b\\), one matches these parameter values with statements about the location and spread of the density. We typically measure location by the mean and spread by the standard deviation – these moments have simple expressions for the beta family: \\[\nE(p) = \\frac{a}{a+b}, \\, \\, SD(p) = \\sqrt{\\frac{a b}{(a+b)^2 (a + b + 1)}}.\n\\] One can guess at the mean and standard deviation of \\(p\\), then use the expressions to find values of the matching parameters \\(a\\) and \\(b\\).\nUnfortunately, there are problems using this method. It is generally hard to specify a mean and standard deviation of a parameter. The moments of a prior can be significantly affected by the tails of the distribution, but one typically has little information about the tail portion of the prior. It is typically easier to state beliefs about location and spread in terms of percentiles of the distribution.\nIn our example, it seems easy to first think about the median of my prior. I think of a value \\(p_{0.5}\\), such that the proportion of text-messaging drivers is equally likely to be smaller or larger than that value. After some reflection, I decide that \\(p_{0.5}\\) = 0.10. Next, I express my belief about spread by thinking about a second percentile, say the 90th. I specify a proportion value \\(p_{0.9}\\) such that it is unlikely (with 10% probability) that \\(p\\) will larger than that value. This is a harder value to specify. After some thought, I decide on \\(p_{0.9}\\) = 0.25. I then match these two percentiles with a beta curve. Using the {} function, I find that the beta curve with \\(a = 1.41\\) and \\(b = 10.15\\) match my beliefs.\nIs the beta(1.41, 10.15) density a good representation of my prior beliefs? To check, one can assesses other percentiles of the prior and see if they match up with the beta density. In our example, suppose that I also believe that the 10th percentile of my prior is \\(p_{0.1} = 0.05.\\). Since the 10th percentile of the beta(1.41, 10.15) prior is 0.024, there is some incompatability of my prior information with the fitted beta curve. By several of these checks, I can adjust the values of the beta shape parameters so it seems to be a better representation of my beliefs.\n\n\n\nOne difficulty in specifying a prior is that the parameter \\(p\\) is relatively abstract. In this example, \\(p\\) represents the proportion of {} students at my university who text while driving. It may be easier to think about the proportion of a {} of students who are texting.\nSuppose you have a random sample of \\(n = 20\\) students. Assuming a beta(\\(a, b\\)) prior, the number \\(y\\) of students who text while driving has a beta-binomial predictive distribution of the form \\[\\begin{eqnarray*}\nf(y | a, b) = \\int_0^1 {n \\choose y} p^y (1-p)^{n-y} \\frac{1}{B(a, b)} p^{a-1} (1-p)^{b-1} dp\n\\nonumber \\\\\n   =  {n \\choose y} \\frac{B(a+y, b+n-y)}{B(a, b)}, \\, \\, y = 0, ..., n \\nonumber \\\\\n\\end{eqnarray*}\\]\nSuppose our initial assessment for \\(p\\) resulted in a beta(1.41, 10.15) prior. Using the beta-binomial distribution, we can use this prior to predict the number of text message students in the sample of \\(n = 20\\) students. By using the function {} in the LearnBayes package, we find that that \\(P(y \\le 4)= 0.827\\) and \\(P(y \\le 5)= 0.934\\). If those probabilities don’t reflect your beliefs about the plausibility of the events \\(y \\le 4\\) and \\(y \\le 5\\), then some adjustment needs to be made to the values of the beta shape parameters."
  },
  {
    "objectID": "prior.html#noninformative-prior",
    "href": "prior.html#noninformative-prior",
    "title": "6  Prior Distributions",
    "section": "6.2 Noninformative Prior",
    "text": "6.2 Noninformative Prior\n\n6.2.1 Uniform prior\nIn the event that little or no information exists about a parameter, then one can assign a vague or noninformative prior. When Thomas Bayes wrote his famous Bayesian paper, he placed a uniform prior on an unknown proportion. This certainly seems like a reasonable choice since this reflects the belief that any subset of \\(p\\) of the same length has the same probability.\nSuppose instead of the proportion \\(p\\), we focus on the parameter \\(p^2\\) that in our example represents the probability (conditional on \\(p\\)) that two consecutive sampled students text while driving. Since \\(p^2\\) is an unknown parameter on the unit interval, it certainly is reasonable to assign \\(p^2\\) a uniform prior. But if \\(p\\) has a uniform prior, it is straightforward to show using a transformation argument that \\(\\theta = p^2\\) has the density \\[\ng(\\theta) = \\frac{1}{2 \\sqrt{\\theta}}, \\, \\, 0 < \\theta < 1.\n\\] So if the proportion has a uniform prior, then the proportion squared has a nonuniform prior that favors values of \\(p^2\\) near zero.\nA uniform prior is not transformation invariant. This means that the belief in uniformity of a parameter will change under a nonlinear transformation. Since it is unclear which parameter (in our example, \\(p\\) or \\(p^2\\)) should be uniform, this notion of uniformity will not lead to a unique choice of prior.\n\n\n6.2.2 Improper prior\nSometimes improper priors, that is, prior densities that don’t integrate to one, will be chosen as noninformative priors. These type of priors can seem appropriate for use in particular applications. However, their use should be made with some caution, since the choice of an improper prior may lead to an improper posterior distribution.\nConsider again the family of beta\\((a, b)\\) priors for the proportion \\(p\\). The parameters \\(a\\) and \\(b\\) can be viewed as the respective number of successes and number of failures in a preliminary experiment. The total amount of information in the experiment is measured by the “preliminary sample size” \\(a+ b\\). If we have little information about the proportion, it is reasonable to let both \\(a\\) and \\(b\\) approach zero, resulting in the improper prior \\[\ng(p) \\propto \\frac{1}{p(1-p)}, \\, \\, 0 < p < 1.\n\\] The corresponding posterior density, given \\(y\\) successes in \\(n\\) trials, is equal to \\[\ng(p | y) \\propto p^{y-1} (1-p)^{n-y-1} .\n\\] This will be a proper posterior density only if the number of successes is in the interval from 1 to \\(n-1\\). If one observes no successes (\\(y = 0\\)) or all failures (\\(y = n\\)), the posterior density will be improper.\nIn the binomial situation, it is best to avoid these awkward situations and use a prior where both \\(a\\) and \\(b\\) are positive. In the next section, we will derive one type of “optimal” prior which does not result in an improper posterior.\n\n\n6.2.3 Jeffreys prior\nOne popular way of defining a noninformative prior was suggested by Harold Jeffreys. To define this prior, we review the concept of information. If a single observation \\(y\\) has a sampling density \\(f(y | \\theta)\\), then we define the Fisher information as \\[\nI(\\theta) = - E\\left[ \\frac{\\partial^2}{\\partial \\theta^2} \\log f(y | \\theta) \\right],\n\\] where the expectation is taken over the distribution of \\(y\\). As an example, suppose the binary observation \\(y\\) has the density \\[\nf(y | p) = p^y (1-p)^{1-y}, y = 0, 1.\n\\] An easy calculation shows that the information is given by \\[\nI(p) = \\frac{1}{p(1-p)}.\n\\] If we have independent observations \\(y_1, ..., y_n\\) from \\(f(y|\\theta)\\) and \\(I^*\\) denotes the information, then it can be shown that \\(I^*(\\theta) = n I(\\theta)\\), where \\(I\\) is the information for a single observation. Applying this result, if we have a sample of Bernoulli(\\(p\\)) observations \\(y_1, ..., y_n\\), then the information based on this sample is \\[\nI(p) =  \\frac{n}{p(1-p)}.\n\\]\nJeffreys suggests that a suitable noninformative prior is the square root of the information \\[\ng(\\theta) = \\sqrt{I(\\theta)}.\n\\] The reasoning for this prior is based on the fact that this prior is invariant under transformation. Suppose \\(\\theta\\) is assigned this prior and one transforms \\(\\theta\\) to a new parameter \\(\\eta = h(\\theta)\\). Then one can show that the prior on \\(\\eta\\) is given by the same functional form \\[\ng_1(\\eta) = \\sqrt{I(\\eta)}.\n\\]\nIn the Bernoulli case, we have already shown that the information \\(I(p) = 1/(p(1-p))\\). So the Jeffreys prior is given by \\[\ng(p) = \\sqrt{I(p)} = \\frac{1}{\\sqrt{p(1-p)}} = p^{1/2-1} (1-p)^{1/2-1}.\n\\]\nAt this point, we have talked about three possible priors for a proportion that are all special or limiting cases of a beta density. The choice \\(a = b = 1\\) leads to the uniform prior used by Bayes, \\(a = b = 1/2\\) leads to the Jeffreys prior, and the limiting case where \\(a\\) and \\(b\\) approach zero results in the improper prior proportional to \\((p(1-p))^{-1}\\)."
  },
  {
    "objectID": "many_parameters.html",
    "href": "many_parameters.html",
    "title": "7  Many Parameter Inference",
    "section": "",
    "text": "In this chapter, we illustrate Bayesian learning from several two parameter problems. Building on the one-parameter posteriors of Chapter 4, we first illustrate learning about both parameters of the normal density with noninformative and informative priors. To compare two independent Poisson samples, we illustrate computing the marginal posterior density of the ratio of Poisson means. Last, we illustrate learning about both the sample size and the probability of success for binomial data where only the number of successes is observed. In the last example, we illustrate constructing a dependent prior for the two parameters in a baseball setting where historical data is available."
  },
  {
    "objectID": "many_parameters.html#normal-sampling-with-both-parameters-unknown",
    "href": "many_parameters.html#normal-sampling-with-both-parameters-unknown",
    "title": "7  Many Parameter Inference",
    "section": "7.2 Normal Sampling with Both Parameters Unknown",
    "text": "7.2 Normal Sampling with Both Parameters Unknown\n\n7.2.1 Noninformative Prior\nSuppose we observe \\(y_1, ..., y_n\\) from a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), where both parameters are unknown. We assume that we have little prior knowledge about the location of either the mean or the variance, and so we assign \\((\\mu, \\sigma^2)\\) the usual noninformative prior \\[\ng(\\mu, \\sigma^2) = \\frac{1}{\\sigma^2}.\n\\]\nBefore we consider this situation, let’s review some results from the previous chapter.\n\nSuppose we wish to learn about the normal mean \\(\\mu\\) when the variance \\(\\sigma^2\\) is assumed known. If we assign \\(\\mu\\) the noninformative uniform prior, then the posterior distribution for \\(\\mu\\) is normal with mean \\(\\bar y\\) and variance \\(\\sigma^2/n\\).\nSuppose instead that we are interested in the variance \\(\\sigma^2\\) when the mean \\(\\mu\\) is known and the typical noninformative prior of the form \\(1/\\sigma^2\\) is assigned to the variance. Then \\(\\sigma^2\\) is distributed \\(S \\chi^{-2}_v\\) where \\(v=n\\) and \\(S = \\sum_{i=1}^n (y_i-\\mu)^2\\). \\end{enumerate}\n\nIn the general case where both parameters are unknown, the likelihood function is given by \\[\\begin{eqnarray*}\nL(\\mu, \\sigma^2)  =  \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (y_i - \\mu)^2\\right) \\nonumber \\\\\n                  \\propto  \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2\\right) \\nonumber \\\\\n\\end{eqnarray*}\\] If the likelihood is combined with the noninformative prior, we obtain the joint posterior density \\[\\begin{eqnarray*}\ng(\\mu, \\sigma^2 | y) \\propto  \\frac{1}{(\\sigma^2)^{n/2+1}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2\\right) \\nonumber \\\\\n\\end{eqnarray*}\\] Suppose one subtracts and adds the sample mean \\(\\bar y = \\frac{1}{n} \\sum_{i=1}^n y_i\\) in the expression \\(\\sum_{i=1}^n (y_i - \\mu)^2\\). Then one obtains the identity \\[\n\\sum_{i=1}^n (y_i - \\mu)^2 = \\sum_{i=1}^n (y_i - \\bar y)^2 + n (\\mu - \\bar y)^2 .\n\\] Using this identity and rearranging some terms, one obtains the following representation of the joint posterior density: \\[\\begin{eqnarray*}\ng(\\mu, \\sigma^2 | y) \\propto  \\frac{1}{(\\sigma^2)^{1/2}} \\exp\\left(-\\frac{n}{2 \\sigma^2} (\\mu - \\bar y)^2 \\right)\n                     \\times  \\frac{1}{(\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\bar y)^2\\right). \\nonumber \\\\\n\\end{eqnarray*}\\]\nWhat we have done is represent the joint posterior density as the product of terms \\[\ng(\\mu, \\sigma^2 | y) = g(\\mu | \\sigma^2, y) \\times g(\\sigma^2 | y) .\n\\] The first term in the product represents the posterior density of the mean \\(\\mu\\) conditional on the variance \\(\\sigma^2\\) – we recognize this as a normal density with mean \\(\\bar y\\) and variance \\(\\sigma^2/n\\). The second term in the product is proportional to the marginal posterior density of \\(\\sigma^2\\). From our earlier work, we recognize this marginal density as the ``scale times inverse chi-square” form \\[\n\\sigma^2 \\sim S \\chi^{-2}_v,\n\\] where the degrees of freedom is \\(v=n-1\\) and the sum of squares \\(S = \\sum_{i=1}^n (y_i-\\bar y)^2\\). This posterior density is commonly called the {} distribution.\nIn this setting, typically one is interested in inferences about the normal mean \\(\\mu\\) and we base this inference on its marginal posterior density. This is obtained by integrating out \\(\\sigma^2\\) from the joint density. Using our earlier expressions, we write this integral as \\[\ng(\\mu | y) \\propto \\int_0^\\infty \\frac{1}{(\\sigma^2)^{n/2+1}}\n                      \\exp\\left(-\\frac{1}{2 \\sigma^2}\\left[ S + (\\mu - \\bar y)^2 \\right] \\right) d\\sigma^2.\n\\] At this point, it is helpful to recall the following integral identity for an inverse gamma integral \\[\n\\int_0^\\infty \\frac{1}{y^{a+1}} \\exp(-b y) dy = \\frac{\\Gamma(a)}{b^a} .\n\\] Since the above integral has this form with \\[\na = n/2, \\, \\, b = S + (\\mu - \\bar y)^2,\n\\] we see the marginal posterior density for \\(\\mu\\) is given by \\[\ng(\\mu | y) \\propto \\frac{1}{(S + (\\mu - \\bar y)^2)^{n/2}},\n\\] which has the t functional form. After some manipulation, one can show that the standardized random variable \\[\n\\frac{\\sqrt{n}(\\mu - \\bar y)}{\\sqrt{S/(n-1)}} = \\frac{\\sqrt{n}(\\mu - \\bar y)}{s},\n\\] where \\(s\\) is the sample standard deviation, has a standardized t distribution with \\(n-1\\) degrees of freedom.\nThis is a familiar result from sampling theory. If one samples from a normal population, then it is well-known that the ``t-statistic” \\[\nT = \\frac{\\sqrt{n}(\\bar y - \\mu)}{s}\n\\] has a t distribution with \\(n-1\\) degrees of freedom. Our result switches the role of the data \\(y\\) and the parameter \\(\\mu\\). Assuming the noninformative prior on \\(\\mu, \\sigma^2\\), the standardized marginal posterior of \\(\\mu\\) (with \\(y\\) fixed) has the same t distribution.\nWhat is the implication of this similarity of frequentist and Bayesian distribution results? It means that classical and Bayesian inferential procedures will agree in this setting. For example, suppose one is interested in a 95% interval estimate for the mean \\(\\mu\\). Then standard frequentist interval has the form \\[\n\\left(\\bar y - t_{n-1, .025}\\frac{s}{\\sqrt{n}}, \\bar y + t_{n-1, .025}\\frac{s}{\\sqrt{n}}\\right),\n\\] where \\(t_{n-1, .025}\\) is the upper .025 quantile of a t distribution with \\(n-1\\) degrees of freedom. In repeated sampling from a normal distribution, this interval will have 95% frequentist coverage. This is equivalant to saying that \\[\nP^{Data}\\left(\\bar y - t_{n-1, .025}\\frac{s}{\\sqrt{n}} < \\mu < \\bar y + t_{n-1, .025}\\frac{s}{\\sqrt{n}}\\right) = 0.95,\n\\] where the probability is taken over the {} observations \\(y_1, ..., y_n\\). From a Bayesian viewpoint, one can say that \\[\nP^\\mu\\left(\\bar y - t_{n-1, .025}\\frac{s}{\\sqrt{n}} < \\mu < \\bar y + t_{n-1, .025}\\frac{s}{\\sqrt{n}} | y \\right) = 0.95,\n\\] This means that the posterior probability that \\(\\mu\\) is contained in this fixed interval is 95%. The actual computed intervals of the standard frequentist and Bayesian procedures are identical. But the frequentist and Bayesian interpretations are very different. The frequentist statement refers to the characteristics of this interval in repeated sampling and the Bayesian statement refers to the property of this interval conditional on a particular set of observations \\(y_1, ..., y_n\\).\nA similar correspondence is true for inferences about the normal variance \\(\\sigma^2\\). We earlier noted that the marginal posterior density for the variance has the form \\(\\sigma^2 \\sim S \\chi^{-2}_{n-1}\\). Equivalently, one can say that the posterior of the function \\[\n\\frac{S}{\\sigma^2} = \\frac{\\sum_{i=1}^n (y_i - \\bar y)^2}{\\sigma^2}\n\\] is chi-squared with \\(n-1\\) degrees of freedom. From a frequentist perspective, if \\(\\sigma^2\\) is fixed, then the statistic \\[\nY = \\frac{\\sum_{i=1}^n (y_i - \\bar y)^2}{\\sigma^2}\n\\] has a chi-square (\\(n-1\\)) sampling distribution. Again this correspondence means that Bayesian inferential statements about a variance (assuming a noninformative prior) will be numerically equivalent to the corresponding frequentist inferential statements. But the interpretation of these statements will be different. For an interval estimate, the posterior probability that a particular interval contains \\(\\sigma^2\\) is the given level. In contrast, the ``confidence” of the frequentist interval refers to the probability of containing the parameter in repeated sampling.\n\n\n7.2.2 Using a Informative Prior\nThe form for the posterior distribution for \\((\\mu, \\sigma^2)\\) in the noninformative case suggests the form for an informative conjugate prior. We assume that the prior for the mean \\(\\mu\\) conditional on the variance \\(\\sigma^2\\) has a normal distribution with mean \\(\\mu_0\\) and variance \\(\\sigma^2/n_0\\). Then we assume the marginal prior on \\(\\sigma^2\\) is distributed \\(S_0 \\chi^{-2}_{v_0}\\).\nHow do we interpret these parameters?\n\nThe prior mean \\(\\mu_0\\) is a guess at the normal mean and \\(n_0\\) is a number of ``prior observations” representing the sureness of this guess.\nA prior guess at the variance \\(\\sigma^2\\) is \\(S_0/v_0\\) and \\(v_0\\) represents the precision of this guess expressed again in term of prior observations.\n\nIf we apply this prior density, then it can be shown that the posterior density for \\((\\mu, \\sigma^2)\\) has the same normal-inverse-chisquare form. First, if we condition on \\(\\sigma^2\\), and combine the normal prior on \\(\\mu\\) with the normal likelihood, then the posterior density of \\(\\mu\\) is normal(\\(\\mu_1, \\sigma^2/n_1\\)), where \\[\n\\mu_1 = \\frac{n_0}{n_0 + n} \\mu_0 + \\frac{n}{n_0 + n} \\bar y,\n\\] and \\(n_1 = n_0 + n\\). Second, one can show that \\[\n\\sigma^2 \\sim S_1 \\chi^{-2}_{v_1},\n\\] where \\(v_1 = v_0 + n\\) and \\[\nS_1 = S_0 + S + \\frac{n_0 n}{n_1} (\\bar y - \\mu_0)^2 .\n\\]"
  },
  {
    "objectID": "many_parameters.html#comparing-two-poisson-means",
    "href": "many_parameters.html#comparing-two-poisson-means",
    "title": "7  Many Parameter Inference",
    "section": "7.3 Comparing Two Poisson Means",
    "text": "7.3 Comparing Two Poisson Means\nIn Chapter 4, we considered the problem of learning about the mean number of visits to a particular website during weekdays in Summer 2009. We only included the visit counts during the weekdays, since we suspected that there was a different pattern of visits between weekdays and weekends (Saturday and Sunday). We suspect that there are fewer visits on weekends, but would be interested in estimating the magnitude of the ``weekend effect.”\nSuppose we observe two independent Poisson samples. Counts {\\(y_{Ai}\\)} from the weekend days are assumed Poisson with mean \\(\\lambda_A\\) and counts {\\(y_{Bj}\\)} from the weekday days are assumed Poisson with mean \\(\\lambda_B\\). We are interested in learning about the ratio of means \\[\n\\gamma=\\frac{\\lambda_B}{\\lambda_A}.\n\\]\nThe first step is to find the likelihood of the parameters. Using the assumption of independence, the joint density of the counts {\\(y_{Ai}\\)} and {\\(y_{Bj}\\)} is given by \\[\nf(\\{y_{Ai}\\}, \\{y_{Bj}\\}|\\lambda_A, \\lambda_B) = \\left(\\prod_i\\frac{ \\lambda_A^{y_{Ai}}\\exp(-\\lambda_A)}{y_{Ai}!}\\right)\n                            \\left(\\prod_j\\frac{ \\lambda_B^{y_{Bi}}\\exp(-\\lambda_B)}{y_{Bj}!}\\right).\n\\] Following the work in Chapter 4, the likelihood can be expressed as \\[\nL(\\lambda_A, \\lambda_B) = \\exp(-n_A \\lambda_A) \\lambda_A^{s_A} \\exp(-n_B \\lambda_B) \\lambda_B^{s_B},\n\\] where \\(n_A\\) and \\(s_A\\) are respectively the sample size and the sum of observations from the first sample, and \\(n_B\\) and \\(s_B\\) are the analogous quantities from the second sample.\nSuppose we reparametrize the likelihood in terms of the first Poisson mean \\(\\theta = \\lambda_A\\) and the ratio of means \\(\\gamma=\\frac{\\lambda_B}{\\lambda_A}\\). Since \\(\\lambda_B = \\theta \\gamma\\), the likelihood function in terms of the new parameters is given by \\[\nL(\\theta, \\gamma) = \\exp(-n_A \\theta) \\theta^{s_A} \\exp(-n_B (\\theta\\gamma)) (\\theta\\gamma)^{s_B}.\n\\]\nSuppose prior information about the means is expressed through the parameters \\(\\theta\\) and \\(\\gamma\\). We assume that \\(\\theta\\) and \\(\\gamma\\) are independent with \\[\n\\theta \\sim Gamma(a_0, b_0), \\, \\, \\gamma \\sim Gamma(a_g, b_g).\n\\] Then the posterior density of \\((\\theta, \\gamma)\\) is given, up to a proportionality constant, by \\[\\begin{eqnarray*}\ng(\\theta, \\gamma | {\\rm data})  \\propto  \\exp(-n_A \\theta) \\theta^{s_A} \\exp(-n_B (\\theta\\gamma)) (\\theta\\gamma)^{s_B} \\nonumber \\\\\n                  \\times  \\theta^{a_0-1} \\exp(-b_0 \\theta) \\gamma^{a_g-1} \\exp(-b_g \\gamma) .\\nonumber \\\\\n\\end{eqnarray*}\\] Our interest is in the ratio of means \\(\\gamma\\) and \\(\\theta\\) is a nuisance parameter. We learn about \\(\\gamma\\) by its marginal posterior density obtained from integrating out \\(\\theta\\) from the joint posterior density. \\[\ng(\\gamma | {\\rm data}) = \\int_0^\\infty  g(\\theta, \\gamma | {\\rm data}) d\\theta .\n\\] When one combines terms, one sees that, for a fixed value of \\(\\gamma\\), the integral has a gamma form in \\(\\theta\\). So one is able to analytically integrate out \\(\\theta\\), resulting in the marginal posterior density \\[\ng(\\gamma | {\\rm data}) \\propto \\frac{\\gamma^{s_B+a_g-1} \\exp(-b_g \\gamma)}{(n_A+n_B \\gamma + b_0)^{s_A + s_B + a_0}}.\n\\]\nIn our example, we first construct priors for \\(\\theta\\), the mean number of website visits during weekend days, and \\(\\gamma\\), the ratio of the mean weekday visits and the mean weekday visits. We choose the independent priors \\[\n\\theta \\sim Gamma(2, 1), \\, \\, \\gamma \\sim Gamma(8, 8).\n\\] The prior for \\(\\theta\\) reflects vague information about the mean number of visits during weekends, and the prior for \\(\\gamma\\) reflects the belief that website visits for weekends and weekdays are similar in size.\nNext, we observe the following individual counts of visits for \\(n_A = 10\\) weekend days and \\(n_B = 21\\) weekdays.\nweekend counts\n 7 12 11 12 12 17 17 18 20 17\n\nweekday counts\n20 30 22 20 20 17 21 26 22 30 36 15 30 27 22 23 18 24 28 23 12\nFrom these data, we compute \\(s_A = 143\\) and \\(s_B = 486\\). With the appropriate substitutions, the marginal posterior density of \\(\\gamma\\) is given by \\[\ng(\\gamma | {\\rm data}) \\propto \\frac{\\gamma^{486+8-1} \\exp(-8 \\gamma)}{(10 + 21 \\gamma + 1)^{143 + 486 + 2}}.\n\\]\nIn summarizing this marginal posterior for \\(\\gamma\\), we learn that the posterior mode is 1.66. So the website visits tend to be 66% higher on weekdays than on the weekends. In addition, a 90% interval estimate for \\(\\gamma\\) is given by (1.44, 1.92). Since both values are larger than 1, one is pretty confident that there are more visits on weekdays than weekends."
  },
  {
    "objectID": "many_parameters.html#learning-about-a-sample-size-and-a-probability",
    "href": "many_parameters.html#learning-about-a-sample-size-and-a-probability",
    "title": "7  Many Parameter Inference",
    "section": "7.4 Learning about a Sample Size and a Probability",
    "text": "7.4 Learning about a Sample Size and a Probability\nIn the game of baseball, a batter gets an opportunity at the plate called an {}. He wants to get a base hit and a standard measure of hitting performance is the batting average \\[\nAVG = \\frac{H}{AB},\n\\] where \\(H\\) is the number of hits and \\(AB\\) the number of at-bats during a baseball season. A standard model for hitting assumes the number of hits \\(H\\) follows a binomial distribution with sample size \\(AB\\) and probability of success \\(p\\). The hitting ability of the batter can be measured by the probability of a hit \\(p\\).\nSuppose the player has obtained 200 hits during the season. What have you learned about the number of at-bats and probability of hit for this player? Can you predict the number of hits this player will get for the following season?\nThis problem is a bit unusual since one does not know the number of at-bats AB or the probability \\(p\\) for this player. But we have prior knowledge about the number of at-bats and the hitting probability that we can model by a prior distribution \\(g(AB, p)\\). By combining this prior with the likelihood, we can learn about the at-bats and probability of success by the posterior distribution, and we can use the predictive distribution to learn about the number of hits in the following season.\n\n7.4.1 Construction of a prior\nWe construct a prior for the pair (\\(AB, p\\)) by decomposing the prior as the product \\[\ng(AB, p) = g(AB) g(p | AB),\n\\] and separately construct the marginal prior for the at-bats \\(AB\\) and the prior of the hitting probability \\(p\\) conditional on the at-bats \\(AB\\).\nThe player is known to be a full-time player which means that the player obtains between 400 and 700 at-bats in a season. We can construct a prior for \\(AB\\) by looking at the distribution of at-bats for all players in a particular season. Figure 1 shows a histogram of the at-bats and the smooth curve represents a density estimate. We can use this density estimate as our prior density for \\(AB\\).\nNext, we construct a prior on the hitting probability \\(p\\) conditional on the number of at-bats \\(AB\\). We don’t know the player’s hitting probability, but we can collect the batting averages \\(AVG = H/AB\\) for all full-time players. Figure 2 shows a scatterplot of \\(AVG\\) against the at-bats \\(AB\\). We see from the superimposed least-squares fit that there is a positive relationship between the batting average and at-bats. So our prior mean for \\(p\\) will depend on \\(AB\\). We will use a beta density for \\(p\\) of the form \\[\ng(p | AB) \\propto p^{K \\eta - 1} (1 - p)^{K(1-\\eta)-1},\n\\] where \\(\\eta\\) is the mean and \\(K\\) is the precision parameter. We use the least-squares fit to obtain the prior mean \\[\n\\eta = E(p | AB) = 0.2208886 +   0.0001148 \\times AB .\n\\] It is more difficult to assess \\(K\\) since this reflects the variability in the hitting probability and Figure ?? shows the variability in the batting average \\(AVG = H/AB\\). Using techniques from the hierarchical modeling chapter, we choose the precision value \\(K = 400\\).\nFigure 3 displays a contour plot of the joint prior on \\((AB, p)\\). Note that the beliefs about the number of at-bats are pretty vague and \\(AB\\) and the hitting probability \\(p\\) are positively correlated as expected.\n\n\n7.4.2 Computation of the posterior and inference\nThe construction of the prior distribution was the biggest task in this problem. It is straightforward to compute and summarize the posterior distribution.\nWe observe the number of hits \\(H\\) for our player. The likelihood is simply the probability of obtaining \\(H\\) hits given values of the parameters \\(AB\\) and \\(p\\) which is given by the binomial form \\[\nL(AB, p) = {AB \\choose H} p^H (1- p)^{AB - H}.\n\\] Once \\(H\\) is observed, the posterior density of \\((AB, p)\\) is equal to the product of the prior and the likelihood: \\[\ng(AB, p | H) \\propto g(AB, p) L(AB, p)\n\\] In the following we will pretend that the number of at-bats \\(AB\\) is continuous. This will simplify the computational strategy in summarizing the posterior distribution.\nOur player is observed to get \\(H = 200\\) hits during the season. Figure 4 displays the joint posterior of \\((AB, p)\\). Comparing Figure 3 and Figure 4, it appears that 200 hits indicates that the player had a large number of at-bats and is a good hitter and the posterior is concentrated on large values of \\(AB\\) and \\(p\\). By computing the joint posterior density on a fine grid, and then simulating from the grid, one can obtain simulated draws from the marginal posterior densities of \\(AB\\) and \\(p\\). Figure 5 presents density estimates of these marginal posterior densities. The simulated samples can easily be used to construct interval estimates for each parameter.\n\n\n7.4.3 Prediction\nRecall that we were interested in predicting the number of hits our player would get in the following season. If we denote this future hit value by \\(\\tilde H\\), then we learn about \\(\\tilde H\\) by its posterior predictive density \\(f(\\tilde H | H)\\). One can express this by the integral \\[\nf(\\tilde H | H) \\int f(\\tilde H | AB, p, H) g(AB, p | H) dAB dp,\n\\] where \\(f(\\tilde H | AB, p, H)\\) is the binomial probability \\[\nf(\\tilde H | AB, p, H) = {AB \\choose \\tilde H} p^{\\tilde H} (1-p)^{AB - \\tilde H},\n\\] and \\(g(AB, p | H)\\) is the joint posterior density of at-bats and probability of a hit. It is not possible to compute this integral analytically, but it is straightforward to simulate from this distribution by first simulating a pair (\\(AB, p)\\) from the joint posterior distribution, and th"
  }
]