[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Bayesian Inference",
    "section": "",
    "text": "Statistics, the science of learning from data, is a relatively new discipline. One can divide the history of Statistics into three periods using the years 1900 and 1960.\n\nIn the early days of Statistics (before 1900), much of the statistical work was devoted to data analysis including the construction of graphical displays. There was little work done on inferential statistics. The foundations of Bayesian inference had been developed by Bayes and Laplace in the 18th century.\nThe foundations of statistical inference were developed in the period between 1900 and 1970. Karl Pearson developed the chi-square goodness of fit procedure around the year 1900 and R. A. Fisher developed the notions of sufficiency and maximum likelihood in this period. Statistical procedures are evaluated in terms of their long-run behavior in repeated sampling. For this reason, these procedures are known as frequentist methods. Properties such as unbiasedness and mean square error are used to evaluate procedures. Some prominent Bayesians such as Harold Jeffreys, Jimmie Savage, and I. J. Good made substantial contributions during this period, but the frequentist methods became the standard inferential methods in the statistician’s toolkit.\nIn the last 40 years, there has been a great development in new statistical methods, especially computational demanding methods such as the bootstrap and nonparametric smoothing. Due to the recent availability of high-speed computers together with new simulation-based fitted algorithms, Bayesian methods have become increasingly popular. In contrast to the middle period of statistics where frequentist methods were dominate, we currently live in a frequentist/Bayesian world where statisticians routinely use Bayesian methods in situations where this inferential perspective has particular advantages.\n\n\n\n\nOne fundamental inference problem is learning about the association pattern in a 2 by 2 contingency table. Suppose we sample data values that are categorized with respect to the presence and absence of two variables \\(A\\) and \\(B\\) and one observes the following table of counts.\n\n\n\n\nVar B\n\n\n\n\n\nVar A\nyes\nno\n\n\nyes\n\\(a\\)\n\\(b\\)\n\n\nno\n\\(c\\)\n\\(d\\)\n\n\n\nThere are two common questions that one is interested in answering. First, is there a significant association structure in the table? Second, if variables \\(A\\) and \\(B\\) are indeed dependent, one is interested in estimating the strength of the association.\nAs an example, suppose one observes the following table counts.\n\n\n\n\nVar B\n\n\n\n\n\nVar A\nyes\nno\n\n\nyes\n\\(10\\)\n\\(0\\)\n\n\nno\n\\(2\\)\n\\(5\\)\n\n\n\nOne constructs a statistical test of the hypothesis of independence to see if there is significant association in the table. The standard test of independence is based on the Pearson’s chi-squared test. One implements this testing procedure on R by the function chisq.test() and one observes the following output for these data.\n\ncounts <- matrix(c(10, 2, 0, 5), 2, 2)\nchisq.test(counts)\n\nWarning in chisq.test(counts): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  counts\nX-squared = 6.971, df = 1, p-value = 0.008284\n\n\nWe note that the p-value of the test statistic is 0.008284 which indicates that there is significant evidence that the two variables are dependent. But we see a warning in the output saying that the accuracy of this p-value computation is in doubt.\nWhat is going wrong? The chi-squared test is based on the test statistic \\[\nX = \\sum \\frac{(o - e)^2}{e},\n\\] where \\(o\\) and \\(e\\) represent, respectively, the observed cell count and estimated expected cell count under the independence assumption. Asymptotically, under the assumption of independence, \\(X\\) has a chi-squared distribution with one degree of freedom. The displayed p-value is the tail probability of a chi-square(1) random variable. When the cell counts are large, the distribution of \\(X\\) is approximately chi-square. But, when the counts are small (as in this example), the distribution of \\(X\\) may not be approximately chi-square(1) and so the accuracy of the p-value calculation is in doubt.\nWhat can one do in this situation? A standard alternative test procedure is Fisher’s exact test where the p-value is computed based on the hypergeometric distribution. If one implements this test using the R function fisher.test(), one sees the following output.\n\ncounts <- matrix(c(10, 2, 0, 5), 2, 2)\nfisher.test(counts)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  counts\np-value = 0.003394\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 2.164093      Inf\nsample estimates:\nodds ratio \n       Inf \n\n\nOne obtains a new p-value of 0.003394 which is significantly different from the ``large sample” p-value of 0.008284, indicating that the accuracy of the chi-square approximation was relatively poor. But this analysis raises new questions.\n\nWhat sampling model?\n\nThere are different sampling models that can produce the observed table counts. For example, one may be taking a single random sample of a particular size and classifying each observation with respect to the two variables – this is the multinomial sampling model. Alternatively, one may be taking two independent samples; the “A-sample” is classified with respect to variable B, and a second “not A-sample” is also classified with respect to variable B – this is the product of binomials sampling model. Or perhaps one assumes that the observed margins of the table are fixed and the only random quantity is the one count in the top left of the table – this gives rise to the hypergeometric distribution under independence that is the basis for Fisher’s exact test.\n\nDoes the choice of sampling model matter?\n\nIf one is unsure about the sampling method that produces the table, one might hope that the test of significance is insensitive to the choice of sampling model. But this is not the case. The p-value is dependent on the choice of model. Actually, there is a debate among frequentists on the “proper” choice of sampling model in the test of independence.\n\nWhat about estimating the association?\n\nIn this example, since the test of independence seems to be clearly rejected, the focus should be on the estimation of the association. A standard measure of association in a two by two table is the odds ratio defined by \\[\n\\alpha = \\frac{p_{11} p_{22}}{p_{12} p_{21}},\n\\] where (assuming a multinomial sampling model) \\(p_{ij}\\) is the probability of an observation in the \\(i\\)th row and \\(j\\)th column of the table. The maximum likelihood estimate of \\(\\alpha\\) is given by \\[\n\\hat \\alpha = \\frac{a d}{b c}.\n\\] For these data, we observe \\(a = 10\\), \\(b = 0\\), \\(c = 2\\) and \\(d = 5\\), resulting in an infinite estimate for \\(\\alpha\\). This is indicated by the fisher.exact() output. Also the standard (asymptotic) 95% confidence interval for \\(\\alpha\\) for these data is given by (2.164093, \\(\\infty)\\). We see that the observed zero count has made it difficult to get reasonable point and interval estimates of the odds ratio.\nIn this problem, we see some pitfalls in applying frequentist testing methods for this simple problem. Since there are small counts, standard methods relying on asymptotic approximations seem unsuitable. But the computation of an “exact” p-value is also unclear in this situation, since this computation relies on the sampling distribution which may be unknown.\nFrequentist methods also perform poorly for the estimation problem since the infinite estimate of \\(\\alpha\\) is not reasonable. If one thinks about the cell probabilities, then one would think that all of these probabilities would be positive, resulting in a finite value of the odds-ratio. But there are no ways to include these ``prior beliefs” that the probabilities are positive in the estimation problem. A standard ad-hoc solution to this problem is to add a fake count of 1/2 to each cell count, and estimate alpha by computing the maximum likelihood estimate on these adjusted counts: \\[\n\\hat \\alpha = \\frac{(a+1/2) (d+1/2)}{(b+1/2) (c+1/2)}.\n\\] But it is not obvious that 1/2 is the correct choice of fake count to get a “best” estimate of the odds ratio.\n\n\n\nThe previous example illustrates some of the problems in applying frequentist inferential methods and so it desirable to consider the alternative Bayesian paradigm for inference. Here is a short list of some positive and negative aspects of the frequentist and Bayesian approaches to inference.\nPositive Aspects of Frequentist Inference:\n\nThere are a number of good methods such as maximum likelihood and most powerful tests and good criteria for evaluating procedures such as unbiased and mean square error.\nThese methods are automatic to apply and have wide applicability.\nOne is generally interested in evaluating procedures by their performance in repeated sampling.\n\nNegative Aspects of Frequentist Inference:\n\nThere is no general method for inference. One has to be clever to devise good statistical procedures in situations where standard methods fail.\nFrequentist methods can perform poorly. For example, frequentist methods do not perform well for sparse contingency tables with one or more observed zeros.\nOne is unable to incorporate prior knowledge into the inference.\n\nPositive Aspects of Bayesian Inference:\n\nOne has one recipe (Bayes’ rule) for statistical inference.\nOne can formally incorporate prior information into the analysis.\nNuisance parameters are easily handled in a Bayesian analysis.\n\nNegative Aspects of Bayesian Inference:\n\nBayesian thinking requires more thought with the introduction of a prior distribution.\nFrom a calculation perspective, it can be difficult to implement Bayesian methods, although powerful computational tools exist."
  },
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "2  Probability",
    "section": "",
    "text": "Bayesian thinking is based on the subjective viewpoint of probability. In this chapter, we will talk about the different ways of thinking about probability."
  },
  {
    "objectID": "probability.html#measuring-uncertainty",
    "href": "probability.html#measuring-uncertainty",
    "title": "2  Probability",
    "section": "2.2 Measuring Uncertainty",
    "text": "2.2 Measuring Uncertainty\nWe live in a world of uncertain events and some events are more likely to occur than other events. Words such as “likely”, “probable”, “possible”, “rare”, and “maybe” are used to describe this uncertainty. It is natural to use numbers that we call probabilities to quantify this uncertainty. The probability of an event \\(A\\), denoted \\(P(A)\\), is a number between 0 and 1 assigned to the event \\(A\\) where a larger number indicates that the event is more likely to occur.\nSome uncertain events already have numbers assigned to them. In games of chance where dice are rolled or cards are dealt from a well-shuffled deck, outcomes have particular probabilities. For example, the chance of rolling two dice equal to double-sixes is 1/36 and the chance of dealing a four of diamonds in a regular deck is 1/52. In actuarial tables, there are assigned probabilities that a person’s life span will be a particular length based on one’s gender and age. These actuarial tables are used by insurance companies to write up a life insurance policy and decide on the cost of the policy to the customer.\nThere are two ways of viewing probabilities that allow us to assign probabilities in games of chance and actuarial tables. The classical or “equally-likely” view assumes that one can represent the outcomes of a random experiment in such a way such that the outcomes are equally likely. Then each outcome is assigned a probability equal to one divided by the total number of outcomes. In the dice example, there are 36 equally likely ways of representing the possible rolls of the dice, and the probability of one outcome (two sixes) is equal 1/36. In the card example, there are 52 possible draws in a deck of cards, and if the deck is well-shuffled, each outcome such as “four of diamonds” is assigned the probability of 1/52.\nA second way of thinking about probabilities is based on long-run relative frequencies. Suppose you are able to repeat a random experiment many times under similar conditions. Then the probability of an event is approximated by its relative frequency in the large number of trials. This viewpoint can be applied in games of chance. For example, the probability that the sum of two dice is equal to 7 can be approximated by the relative frequency of 7 in many rolls of the two dice. This definition can also be used for actuarial tables. The chance that a male of age 70 will survive ten years can be approximated by the relative frequency of 70-year old males who survive ten years.\nIs it possible use the relative frequency viewpoint to measure uncertainty for all random events? Lindley makes a distinction between two types of events. Statistical events are the events that can be repeated under similar conditions and non-statistical events are events that are essentially unique and can not be repeated. Games of chance are statistical events, while one-time events such as “Jones committed the murder” or “a Republican will be the next American president” are non-statistical events. One can use the relative frequency perspective to measure the probability of statistical events, but this viewpoint is clearly inappropriate in measuring the chance of non-statistical events. Also there are issues in applying the relative frequency viewpoint. Sometimes it is not clear how to repeat a random experiment under similar circumstances. For example, suppose one observes three flips of a coin with the first head on the third flip. How does one repeat this experiment. Does one consider sets of three flips, or instead consider flips that end with the first head?"
  },
  {
    "objectID": "probability.html#the-subjective-viewpoint",
    "href": "probability.html#the-subjective-viewpoint",
    "title": "2  Probability",
    "section": "2.3 The Subjective Viewpoint",
    "text": "2.3 The Subjective Viewpoint\nThere is a third viewpoint of probability, the subjective viewpoint, that is the basis for Bayesian thinking. We start with a proposition which is any statement that can be true or false. For example, consider the proposition “it will rain tomorrow.” A person’s belief in the truth in this proposition can vary; the person may believe it is certainly false or she may believe it is certainly true. A probability represents a number attached to the proposition “it will rain tomorrow” that reflects this belief. A probability of 1 means that the person believes the proposition is true, and a probability of 0 means that the person believes with certainty that the proposition is false. A probability of 0.5 means that the person believes that the propositions “rain tomorrow” and “no rain tomorrow” are equally likely.\nIn the above definition, it should be noted that we are assigning numerical measures to propositions, which are more general than events. A proposition is any statement that is either true or false. Both statistical events and non-statistical events are examples of propositions. Second, an assigned probability is personal in that it reflects one person’s belief about the truth of the proposition. Different people may assign different probabilities to a given proposition. Certainly if we consider the proposition “Susie is receiving a final grade of A in her statistics class”, Susie and her instructor may have different beliefs about the truth in this proposition. Also a person’s probabilities about a proposition may change over time. As she obtains more information, her belief and therefore her probabilities can change. In our example, as Suzie receives exam grades, she will have different information and therefore possibly different beliefs in the proposition that she will get a final grade of A.\nTo summarize, from the subjective viewpoint, a probability is a numerical measure of the degree of belief by a person in a proposition based on the person’s current information. If \\(E\\) is a proposition and \\(H\\) is the current information or history of the individual, then we represent a probability by the notation \\(P(E | H)\\)."
  },
  {
    "objectID": "probability.html#measuring-subjective-probabilities",
    "href": "probability.html#measuring-subjective-probabilities",
    "title": "2  Probability",
    "section": "2.4 Measuring Subjective Probabilities",
    "text": "2.4 Measuring Subjective Probabilities\nAt this point, all we know about a subjective probability \\(P(E|H)\\) is that it falls between the values of 0 and 1 and larger values correspond to stronger beliefs in the truth in the proposition. Since subjective probabilities are generally difficult to assess, it is appropriate to describe some measurement methods.\nThe direct measurement approach takes a measurement of an object by comparing it with a collection of reference objects. To learn about the length of a piece of string, a direct measurement method uses a ruler, and a direct measurement way of learning about the weight of an object places it on a scale. To directly measure probabilities, we need to consider a set of propositions where the probabilities are known.\nConsider the following “balls in bag” experiment. We have a bag with \\(r\\) red and \\(w\\) white balls and one ball is chosen from the bag. Let \\(R(r, w)\\) denote the proposition that the chosen ball is red. We assume that the balls are all identical in appearance except color, the bag is mixed well, and one makes the draw blindfold. Then we would agree that the probability of \\(R(r, w)\\) is equal to the fraction \\(r/(r+w)\\). Consider the set of reference propositions \\(R(0, 1), R(1, 0), R(1, 1), ...\"\\). The reference probabilities \\(r/(r+w)\\) cover all rational values between 0 and 1.\nTo use these reference propositions to measure your probability \\(P(E | H)\\), you compare the proposition \\(E\\) with the reference propositions {\\(R(r, w)\\)}. Suppose you have a stronger belief in the truth of \\(E\\) than \\(R(r, w)\\). This implies that your probability \\(P(E | H)\\) exceeds the fraction \\(r/(r+w)\\). By making a sequence of comparisons of \\(E\\) with \\(R(r, w)\\) for different choices of \\((r, w)\\), one can in theory get an accurate assessment of your probability \\(P(E | H)\\).\nI am a Phillies fan and I wish to assess my probability of the event \\(A =\\)“the Phillies will be in the World Series” this season. To using this direct approach of assessment, I make the following comparisons.\n\nI first compare “Phillies in the World Series” with the event \\(R(1, 1)\\), choosing a red out of a bowl with one red ball and one white ball. I believe \\(R(1, 1)\\) is more likely, so my probability of \\(A\\), \\(P(A) < 1/2\\).\nNext, I compare the event \\(A\\) with the event \\(R(1, 3)\\), choosing a red out of a bowl with one red and three white balls. I believe that \\(R(1, 3)\\) is more likely, so \\(P(A) < 1/4\\).\nI continue with comparing \\(A\\) with \\(R(1, 7)\\), choosing a red out of a bowl with one red and seven white balls. I believe that the Phillies in the World Series is more likely. So \\(P(A) > 1/8\\) and combining my comparisons, I now know that \\(P(A)\\) is in the interval \\((1/8, 1/4)\\).\nI continue with these assessments until it is difficult to make further comparisons. I will have a small interval that I believes contains my probability of the event.\n\nOther measurements are taken in an indirect manner. For example, one older style of thermometer is constructed by the use of mercury in a glass tube. Heat applied to the glass causes the mercury to expand and one measures the temperature by reading the location of the mercury on a printed numerical scale. For this type of thermometer, one indirectly measures temperature by use of the expansion and contraction of mercury. In a similar fashion, one can measure probabilities by means of bets that are indirectly related to probabilities.\nA bet consists of a proposition that determines the outcome of the bet, odds that are offered by the bookmaker, and the amount of money that you are willing to stake. If you decide to stake $\\(s\\) on the proposition \\(E\\) at odds \\(z\\), this means that\n\nif \\(E\\) is false, you will give the bookmaker $\\(s\\)\nif \\(E\\) is true, the bookmaker gives you $ \\(z s\\)\n\nThe stake is the amount that you can lose if the proposition \\(E\\) is false and the odds is the ratio of the amount you can win if \\(E\\) is true to the amount you lose if \\(E\\) is false.\nUsing this indirect method, one measures your probability \\(P(E | H)\\) by means of bets on \\(E\\) between you and a hypothetical bookmaker. One can fix a value of the stake, say \\(s = \\$5\\) and bet on \\(E\\) using different values of the odds \\(z\\). You decide which bets to accept and reject.\nHow can one obtain one’s probability on the basis of these bets? First, note that you will accept any bet if the odds \\(z\\) is sufficiently large. But as the odds \\(z\\) is decreased, one will be less inclined to accept the bet, and for small values of odds, you will reject the bet. There will be one odds value \\(z_0\\) where you will accept bets for odds \\(z > z_0\\), and reject bets for \\(z , z_0\\). The value \\(z_0\\) is often called the {} of the proposition \\(E\\) based on your current information, denoted by \\(O(E | H)\\). We transform odds to a probability by the expression \\[\nP(E | H) = \\frac{1}{1+O(E|H)}.\n\\]\nLet us illustrate this indirect method of measuring probability for assessing my probability of the event \\(A\\) that the Phillies are in the World Series. I decide on using the stake $5 and consider the following bets:\n\nBET 1: At odds \\(z = 1\\), I will either lose $5 if \\(A\\) is false or win $5 if \\(A\\) is true.\nBET 2: At odds \\(z = 2\\), I will either lose $5 if \\(A\\) is false or win $10 if \\(A\\) is true.\nBET 3: At odds \\(z = 4\\), I will either lose $5 if \\(A\\) is false or win $20 if \\(A\\) is true.\nBET 4: At odds \\(z = 10\\), I will either lose $5 if \\(A\\) is false or win $50 if \\(A\\) is true.\n\nI will definitely not accept Bets 1 or 2 (the winning amounts are too small), and would accept Bet 4 which seems to have a generous odds. After some thought, suppose I am satisfied with a bet between Bet 3 and Bet 4 where the odds are \\(z = 7\\). Then my fair odds would be \\(O(A | H) = 7\\) and my probability of “Phillies in the World Series” would be \\[\nP(A | H) = \\frac{1}{1+7} = 0.125.\n\\]"
  },
  {
    "objectID": "probability.html#true-and-measured-probabilities",
    "href": "probability.html#true-and-measured-probabilities",
    "title": "2  Probability",
    "section": "2.5 True and Measured Probabilities",
    "text": "2.5 True and Measured Probabilities\nWe have discussed two methods, a direct method and an indirect method, for measuring the subjective probability of a proposition. Generally people will have trouble applying these methods since they have little experience in specifying probabilities. So in a typical application, one will not be able to specify his/her probability with high accuracy. Here it is helpful to distinguish a person’s true probability and her measured probability. A person’s true probability is the value she would obtain if she were able to make very fine comparisons in the likelihoods of events and had an infinite amount of time to make the assessment. But in real life, the person is unable to make fine comparisons and will spend only a finite amount of time on this task. So the specified probability \\(P(E | H)\\) is simply a measured estimate at the true probability. Since our measuring methods, such as the balls in bag experiment, are relatively crude, there can be significant measurement error in the specification of this probability."
  },
  {
    "objectID": "bayes_rule.html",
    "href": "bayes_rule.html",
    "title": "3  Bayes Rule",
    "section": "",
    "text": "Here is a basic exposition of Bayes rule. Suppose you have events \\(E_1, ..., E_k\\) that form a partition of the sample space.\n\n\\(P(E_i), i = 1, ..., k\\)\n\\(P(A | E_i), i = 1, ..., k\\)\n\nOne is interested in computing the probabilities \\(P(E_i | A), i = 1, ..., k\\). By a standard manipulation of conditional probabilities, one obtains the result:\n\\[\nP(E_i | A) = \\frac{P(E_i) P(A | E_i)} {\\sum_{j=1}^k P(E_j) P(A | E_j)} .\n\\]"
  },
  {
    "objectID": "bayes_rule.html#illustrations-of-bayes-rule",
    "href": "bayes_rule.html#illustrations-of-bayes-rule",
    "title": "3  Bayes Rule",
    "section": "3.2 Illustrations of Bayes’ Rule",
    "text": "3.2 Illustrations of Bayes’ Rule\n\n3.2.1 Example: Student Takes a Test\nSuppose a student is taking a one-question multiple choice test with four possible choices. Either the student knows the material or she doesn’t; we denote these two possibilities by \\(K\\) and “not \\(K\\)”. Based on previous work, the teacher decides the student likely knows the material and so assigns \\(P(K) = 0.7\\). Therefore, the probability the student doesn’t know the material is \\(P({\\rm not} \\, K) = 1 - 0.7 = 0.3.\\) The student will take the one-question test and either she will get it correct, which we denote by \\(C\\). If the student knows the material, then the chance she will get the question correct is 90%. On the other hand, if the student doesn’t know the material, then we will guess and obtain the correct answer with probability 25%. Suppose the student takes the test and gets the question correct – what is the probability she really knows the material?\nHere the events \\(K\\) and “not \\(K\\)” form a partition of the sample space and we are given the probabilities of these two events. The probability the student gets the question correct depends on whether she knows the material – we are given that\n\\[\nP(C | K) = 0.9, \\, P(C | {\\rm not} , K) = 0.25.\n\\]\nGiven that the student gets the question correct, we’re interested in determining the probability of \\(K\\); that is, we wish to compute \\(P(K | C)\\). By Bayes’ rule, this is given by\n\\[\nP(K | C) = \\frac{P(K) P(C | K)} {P(K) P(C | K) + P({\\rm not} , K) P(C | {\\rm not} , K)}.\n\\]\nSubstituting in the given values, we obtain\n\\[\nP(K | C) = \\frac{0.7 \\times 0.9} {0.7 \\times 0.9 + 0.3 \\times 0.25} = \\frac{0.63}{0.63+0.075} = 0.894 .\n\\]\nDoes this answer make sense? Before the test, the teacher believed that the student knew the material with probability 0.7. The student got the question correct which intuitively should increase the teacher’s probability that the student was a good student. Bayes’ rule allows us to explicitly compute how the probability should increase – the probability has increased from \\(P(K) = 0.7\\) to \\(P(K | C) = 0.894\\).\n\n\n3.2.2 Example: Balls in a Bag\nSuppose a bag contains exactly one white ball. You roll a die and if the outcome of the die roll is \\(i\\), you add \\(i\\) red balls to the bag. You then select a ball from the bag and the color of the ball is red. What is the chance that the die roll is \\(i\\)?\nIn this example, let \\(D_i\\) denote the outcome that the die roll lands \\(i\\) and let \\(R\\) denote the outcome that a red ball is chosen. If we assume a fair die, then the six possible die rolls are equally likely, so \\(P(D_1) = P(D_2) = ... = P(D_6) = 1/6\\).\nThe probability of observing a red depends on the die roll. If the die roll is \\(i\\), one adds \\(i\\) red balls to the bag and the chance of choosing a red will be \\(i/(i+1)\\), so\n\\[\nP(R | D_i) = \\frac{i}{i+1}, , i = 1, ..., 6.\n\\]\nIn this story, a red ball is observed and we are interested in computing \\(P(D_i | R)\\). By applying Bayes rule\n\\[\nP(D_i | R) = \\frac{P(D_i) P(R | D_i)}{\\sum_{j=1}^6 P(D_j) P(R | D_j)}.\n\\]\nBy substituting the known quantities, we have\n\\[\nP(D_i | R) = \\frac{\\frac{1}{6} \\times \\frac{i}{i+1}}{\\sum_{j=1}^6 \\frac{1}{6} \\times \\frac{j}{j+1}}.\n\\]\nA convenient way of computing the die roll probabilities is by use of a table. In Table 2.1, each row corresponds to a specific die roll – we call these alternatives in the table. For each die roll, the table gives the initial probability \\(P(D_i)\\) and the probability of observing red for that die roll \\(P(R | D_i)\\). The updated probability \\(P(D_i | R)\\) is proportional to the product \\(P(D_i) P(R | D_i)\\) and the products are shown in the table.\nOne computes the updated probabilities by dividing each product by the sum of the products. For example the updated probability \\(P(D_1 | R)\\) is given by the product (1/6)(1/(1+1)) divided by the sum of the products \\(1/12 + 2/18 + ... + 6/42 = 0.734\\) which is equal to 0.113.\n\n\n\nAlternative\nProbability\n\\(P(R | {\\rm Die \\, \\, Roll})\\)\nProduct\n\n\n\n\n\\(D_1\\)\n1/6\n1/(1+1)\n1/12\n\n\n\\(D_2\\)\n1/6\n2/(2+1)\n2/18\n\n\n\\(D_3\\)\n1/6\n3/(3+1)\n3/24\n\n\n\\(D_4\\)\n1/6\n4/(4+1)\n4/30\n\n\n\\(D_5\\)\n1/6\n5/(5+1)\n5/36\n\n\n\\(D_6\\)\n1/6\n6/(6+1)\n6/42\n\n\n\nTo make sense of these calculations, we started assuming that all six possible rolls of the die were equally likely.\nWith the observation of a red ball, the updated probabilities are unequal and give support for larger rolls of the die."
  },
  {
    "objectID": "bayes_rule.html#new-terminology",
    "href": "bayes_rule.html#new-terminology",
    "title": "3  Bayes Rule",
    "section": "3.3 New Terminology",
    "text": "3.3 New Terminology\nIn general, we are interested in learning about \\(k\\) different models that we denote by \\(M_1, ..., M_k\\). Initially, we have beliefs about the plausibility of these models that we express through the probabilities \\(P(M_1), ..., P(M_k)\\). We refer to these as prior probabilities since these express our opinions about the models before or prior to observing any data. Next, we observe data denoted by \\(D\\) that will give us information about the models. We are given the probabilities of each data outcome for each model, that is, \\(P(D|M_1), ..., P(D|M_k)\\); these are called the likelihoods.\nNow the a particular data result \\(D\\) is observed. How has this data result changed our beliefs about the \\(k\\) models? Bayes’ rule is the recipe for modifying the model probabilities. It says that the new probability for model \\(M_i\\) is proportional to the product of the prior probability and the likelihood:\n\\[\nP(M_i | D) \\propto P(M_i) P(D | M_i).\n\\]\nThe updated probabilities {\\(P(M_i | D)\\)} are called posterior probabilities since they reflect our opinions about the models _after observing the data. Using words, we can write\nPOSTERIOR \\(\\propto\\) PRIOR \\(\\times\\) LIKELIHOOD.\nA convenient way to performing the Bayes’ rule calculations is by use of a table similar to the example. We illustrate the use of the new terminology and the table calculations for two additional examples."
  },
  {
    "objectID": "bayes_rule.html#sequential-learning",
    "href": "bayes_rule.html#sequential-learning",
    "title": "3  Bayes Rule",
    "section": "3.6 Sequential Learning",
    "text": "3.6 Sequential Learning\nA machine in a small factory is producing a particular automotive component. Most of the time (specifically, 90% from historical records), the machine is working well and produces 95% good parts. Some days, the machine doesn’t work as well (it’s broken) and produces only 70% good parts. A worker inspects the first dozen parts produced by this machine on a particular morning and obtains the following results (\\(g\\) represents a good component and \\(b\\) a bad component):\n\\[\ng, b, g, g, g, g, g, g, g, b, g, b.\n\\]\nThe worker is interested in assessing the probability the machine is working well.\nIn this problem there are two models – either the machine is working well, or “working” for short, or it is “broken”.\nBased on the historical data, the worker assigns prior probabilities of 0.90 and 0.10 to the models “working” and “broken”. The data are the results of the inspection on the 12 parts. To understand the relationship between the data and the models, we compute the sampling probabilities, the probabilities of each data outcome for each model. If the machine is working, the probabilities of a good (g) part and a bad (b) part are 0.95 and 0.05, respectively. So\n\\[\nP(g | {\\rm working}) = 0.95,\\, P(b | {\\rm working}) = 0.05 .\n\\]\nIf instead the machine is broken, the probabilities of good and bad part are 0.70 and 0.30, respectively:\n\\[\nP(g | {\\rm broken}) = 0.70, \\, P(b | {\\rm broken}) = 0.30 .\n\\]\nNow we’re ready to do the Bayes’ rule computation. The outcomes of twelve inspections of parts are the data:\n\\[\nDATA = {g, b, g, g, g, g, g, g, g, b, g, b}.\n\\]\nThe likelihoods are the probabilities of this data result for each of the two models. Assuming independence of individual outcomes, the likelihood of the working model is given by\n\\[\nLIKE({\\rm working}) =  P(\\{g, b, g, g, g, g, g, g, g, b, g, b\\} | {\\rm working})\n\\] \\[\n=  P(g | {\\rm working}) \\times ... \\times P(b | {\\rm working})\n\\] \\[ =  0.95 \\times 0.05 \\times 0.95 \\times ... \\times 0.05\n\\] \\[\n=  0.00007878.\n\\]\nSimilarly, the likelihood of the broken model is\n\\[\nLIKE({\\rm broken}) =  P(\\{g, b, g, g, g, g, g, g, g, b, g, b\\} | {\\rm broken})\n\\] \\[\n=  0.70 \\times 0.30 \\times 0.70 \\times ... \\times 0.30\n\\] \\[\n= 0.00108955\n\\]\nUsing the “prior times likelihood” recipe, we compute the posterior probabilities in the following table.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.90\n0.00007878\n0.000070902\n0.3942\n\n\nBroken\n0.10\n0.00108955\n0.000108955\n0.6058\n\n\n\nWe see that the posterior probability that the machine is broken is over 60% and perhaps the machine should be stopped for inspection and repair.\nThere is another way to implement Bayes’ rule when the data are observed in a sequential manner. Before any data are collected, the inspector’s probabilities of the two states of the machine, working and broken, are given by 0.90 and 0.10. He observes the quality of the first part – “g” – and then he can immediately update his probabilities by Bayes’ rule.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.90\n0.95\n0.855\n0.9243\n\n\nBroken\n0.10\n0.70\n0.070\n0.0757\n\n\n\nAfter this single observation, he is slightly more confident (with probability 0.9243) that the machine is working.\nThe inspector’s current probabilities of the two models are 0.9243 and 0.0757. He observes the quality of the next part – “b” – and again he can update his probabilities by Bayes’ rule. In this table “Prior” refers to his beliefs before observing the data.\n\n\n\nModel\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\nWorking\n0.9243\n0.05\n0.046215\n0.6705\n\n\nBroken\n0.0757\n0.30\n0.022710\n0.3295\n\n\n\nWe see that, after observing two parts, the inspector’s probability that the machine is working is 0.6705.\nOne can continue learning in this sequential manner. As one observes the quality of each single part, the inspector can update his probability of the two models by Bayes’ rule. Table 2.9 summarizes the results of this sequential learning. The first row of the table displays the prior probabilities of the working and broken models and the following rows display the probabilities after each outcome is observed. Note that the final row indicates that the probabilities after observing the 12 parts are equal to 0.3942 and 0.6058. As expected, these posterior probabilities are the same as the ones computed using the group of 12 observations as data.\n\n\n\nObservation\nP(Working)\nP(Broken)\n\n\n\n\nPrior\n0.9000\n0.1000\n\n\ng\n0.9243\n0.0757\n\n\nb\n0.6706\n0.3294\n\n\ng\n0.7342\n0.2658\n\n\ng\n0.7894\n0.2106\n\n\ng\n0.8358\n0.1642\n\n\ng\n0.8735\n0.1265\n\n\ng\n0.9036\n0.0964\n\n\ng\n0.9271\n0.0729\n\n\ng\n0.9452\n0.0548\n\n\nb\n0.7421\n0.2579\n\n\ng\n0.7961\n0.2039\n\n\nb\n0.3942\n0.6058"
  },
  {
    "objectID": "bayes_rule.html#example-testing-for-a-disease",
    "href": "bayes_rule.html#example-testing-for-a-disease",
    "title": "3  Bayes Rule",
    "section": "3.4 Example: Testing for a Disease",
    "text": "3.4 Example: Testing for a Disease\nSuppose you are one of the many people who are tested for a rare disease. From reports, you known the the incidence of this disease is 1 out of 5000. You take the test and there are two results: either you are told “ok” or “see your doctor for further checks.” How should you feel on the basis of these two results?\nThere are two possible models in this example: you are either “diseased” or “not disease”. Assuming that you are a representative person from your community, your prior beliefs are that\n\\[\nP({\\rm diseased}) = \\frac{1}{5000} = 0.0002, , P({\\rm not \\, diseased}) = \\frac{4999}{5000} = 0.9998 .\n\\]\nThe “data” in this example is the screening test result. There are two outcomes: either the test will be “positive” or “+”, which is some indication that you have the disease, or “negative” or “-” which is good news. From past experience, the screening test has 5% false positives and 2% false negatives.\nThis means that if you really don’t have the disease, the chance you get a positive result is 0.05; that is,\n\\[\nP(+ , {\\rm result} | {\\rm not \\, diseased}) = 0.05,  P(- , {\\rm result} | {\\rm not \\, diseased}) = 0.95.\n\\]\nSimilarly, if you really have the disease, the chance of an incorrect negative result is 0.02:\n\\[\nP(- , {\\rm result} | {\\rm diseased}) = 0.02, \\, P(+ , {\\rm result} | {\\rm diseased}) = 0.98.\n\\]\nThese values are the likelihoods – the probabilities of the data outcomes for each model.\nSuppose you have a positive test result (\\(+\\)). We can find the new probabilities of diseased and not diseased by Bayes’ rule that we present in a table format in Table 2.2.\n\n\n\nPrior\nProbability\n\\(P(+ | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\nNot diseased\n0.9998\n0.05\n0.04999\n0.9961\n\n\nDiseased\n0.0002\n0.98\n0.000196\n0.0039\n\n\n\nBefore the test, your probability of having the disease was 0.02 and after getting the positive test result, this probability has increased to 0.039. This new probability is almost twice the initial probability, but you are still very unlikely to have the disease.\nWhat if you received a negative test result? We repeat the Bayes’ rule calculations in Table 2.3 with a change in the likelihood values.\n\n\n\nModel\nPrior\n\\(P(- | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\nNot diseased\n0.9998\n0.95\n0.949810\n0.999996\n\n\nDiseased\n0.0002\n0.02\n0.000004\n0.000004\n\n\n\nThe probability of having the disease has decreased from 0.0002 to 0.000004.\nThese results are usually surprising to doctors and patients. It seems difficult to update probabilities accurately and people typically have a much stronger opinion they have the disease when faced with a positive test result."
  },
  {
    "objectID": "bayes_rule.html#example-the-three-door-problem",
    "href": "bayes_rule.html#example-the-three-door-problem",
    "title": "3  Bayes Rule",
    "section": "3.5 Example: The Three Door Problem",
    "text": "3.5 Example: The Three Door Problem\nThere is a famous probability problem, called The Three Door Problem or The Car and the Goats that can be addressed by Bayes’ rule. There is a TV show where a contestant is showed three numbered doors, Door 1, Door 2, and Door 3, where one door is hiding a car and the other two doors hiding goats. The contestant is allowed to choose a door and win the corresponding prize. The contestant chooses Door 1. The host, who knows which door hides the car, then opens Door 2 to reveal a goat. The contestant is given the opportunity to change her selection. Should she switch her choice to Door 3?\nIn this example the unknown model is the location of the car. We will let \\(C_i\\) denote the event that the car is behind Door \\(i, i = 1, 2, 3.\\) Initially, the constestant believes the car is equally likely to be behind each of the three doors, so\n\\[\nP(C_1) = P(C_2) = P(C_3) = \\frac{1}{3}.\n\\]\nHere the data is the event that the host showed Door 2 – we’ll call this event \\(H\\). We wish to find the new probabilities of \\(C_1, C_2\\) and \\(C_3\\) conditional on the new information \\(H\\). We put the given information in the “Bayes’ table”:\n\n\n\nModel\nPrior\n\\(P(H | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\n\\(C_1\\)\n1/3\n\\(P(H | C_1)\\)\n\n\n\n\n\\(C_2\\)\n1/3\n\\(P(H | C_2)\\)\n\n\n\n\n\\(C_3\\)\n1/3\n\\(P(H | C_3)\\)\n\n\n\n\n\nLet’s consider the likelihood \\(P(H | C_i)\\) that represents the probability the host shows Door 2 if the car is behind Door \\(i\\). Remember that the contestant chose Door 1, so the host cannot choose this door.\n\nIf the car is really behind door 1, the host can either show Door 2 or Door 3. We will assume that the probability he shows Door 2 is a number \\(q\\) between 0 and 1, so \\(P(H | C_1) = q\\).\nIf the car is behind door 2, the host cannot show this door. So \\(P(H | C_2) = 0\\).\nIf the car is behind door 3, the host cannot show this door -- he has to show Door 2. So \\(P(H | C_3) = 1\\).\n\nWe complete the table in Table 2.5 by filling in the likelihoods and computing the posterior probabilities.\n\n\n\nModel\nPrior\n\\(P(H | {\\rm Model})\\)\nProduct\nPosterior\n\n\n\n\n\\(C_1\\)\n1/3\n\\(q\\)\n\\(q/3\\)\n\\(q/(q+1)\\)\n\n\n\\(C_2\\)\n1/3\n0\n0\n0\n\n\n\\(C_3\\)\n1/3\n1\n1/3\n\\(1/(q+1)\\)\n\n\n\nLet’s return to our question. Remember the contestant chose Door 1 and has the opportunity to switch to Door 3. Given the data “host shows Door 2”, we have found that the probability the car is behind Door 1 is \\(q/(q+1)\\) and the probability the car is behind Door 3 is \\(1/(q+1)\\). The contestant should switch if the probability of \\(C_3\\) is greater than the probability of \\(C_1\\), that is,\n\\[\nP(C_3 | H) > P(C_1 | H)\n\\]\nor\n\\[\n\\frac{1}{q+1} > \\frac{q}{q+1}\n\\]\nwhich is true if \\(q > 0\\). So the contestant will increase her probability of winning by switching. Remember \\(q\\) is the probability the host will show Door 2 instead of Door 3 if he has a choice. If we assume \\(q = 1/2\\), that is, the host chooses a door at random, then the probability the car is behind Door 3 is \\(1/(1/2 + 1) = 2/3\\)."
  },
  {
    "objectID": "proportion.html",
    "href": "proportion.html",
    "title": "4  Learning About a Proportion",
    "section": "",
    "text": "Suppose data \\(y\\) is observed from a sampling distribution \\(f(y | \\theta)\\) that depends on an unknown parameter \\(\\theta\\). We assume that one has beliefs about \\(\\theta\\) before sampling that are expressed through a prior density \\(g(\\theta | y)\\). Once a value of \\(y\\) is observed, then one’s updated beliefs about the parameter \\(\\theta\\) are reflected in the posterior density, the conditional density of \\(\\theta\\) given \\(y\\): \\[\ng(\\theta | y) = \\frac{f(y | \\theta)g(\\theta) }{f(y)},\n\\] where \\(f(y)\\) is the marginal density of \\(y\\) \\[\nf(y) = \\int  f(y | \\theta) g(\\theta) d\\theta .\n\\]\nIn the computation of the posterior density, note that the only terms involving the unknown parameter \\(\\theta\\) are the likelihood function \\(L(\\theta) = f(y | \\theta)\\) and the prior density \\(g(\\theta)\\). Bayes’ rule says that the posterior density is proportional to the product of the likelihood and the prior, or \\[\ng(\\theta | y) \\propto L(\\theta) g(\\theta).\n\\]\nIn a Bayesian analysis, both the posterior density and the marginal density play important roles. The posterior density contains all information about the parameter contained in both the prior density and the data. One performs different types of inference by computing relevant summaries of the posterior density. The marginal density \\(f(y)\\) reflects the distribution of the data \\(y\\) before observing any data. This density is called the predictive density since \\(f(y)\\) is used to make predictions about future data values."
  },
  {
    "objectID": "proportion.html#an-example-on-learning-about-a-proportion",
    "href": "proportion.html#an-example-on-learning-about-a-proportion",
    "title": "4  Learning About a Proportion",
    "section": "4.2 An Example on Learning About a Proportion",
    "text": "4.2 An Example on Learning About a Proportion\nIn this chapter, we discuss the basic elements of a Bayesian analysis through the problem of learning about a population proportion \\(p\\). We take a random sample from the population of size \\(n\\) and observe \\(y\\) successes – for a given value of \\(p\\), the probability of \\(y\\) is given by the binomial formula \\[\nf(y | p) = {n \\choose y} p^y (1-p)^{n - y}.\n\\]\nAs an example, suppose that coordinator of developmental math courses at a particular university is concerned about the proportion of students in these courses who have math anxiety, where “math anxiety” is defined by obtaining a particular score on an anxiety rating instrument. A sample of 30 students takes the instrument and 10 have math anxiety. What can be said about the proportion of all developmental math course students who have math anxiety?\nThe standard estimate of \\(p\\) is the proportion of successes in the sample \\(\\hat p = y/n\\) and the traditional Wald “large-sample” confidence interval for \\(p\\) is given by \\[\n\\left(\\hat p - z_{\\alpha/2} \\sqrt{\\frac{\\hat p (1- \\hat p)}{n}}, \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p (1- \\hat p)}{n}}\\right),\n\\] where \\(z_\\alpha\\) is the \\(1-\\alpha\\) quantile of the standard normal distribution.\nFor large samples, this interval will cover the unknown proportion in repeated sampling with probability \\(1 - \\alpha\\). However this interval estimate has questionable value for samples with very few observed successes or failures. Suppose that no students in our sample have math anxiety. Then \\(y = 0\\), \\(\\hat p = 0/30 = 0\\) and the confidence interval will be degenerate at zero. (Similarly, if all the students have math anxiety, then \\(\\hat p = 30/30 = 1\\) and the confidence interval will be degenerate at one.) Since one certainly believes that the proportion is larger than zero, this degenerate interval at zero doesn’t make any sense.\nOne ad-hoc solution to the “zero successes” problem is to initially add two artificial successes and two artificial failures to the data, and then apply the Wald interval to this adjusted data. This is a recommended approach in the literature and the resulting confidence interval has good sampling probabilities. We will see that this ad-hoc procedure has a natural correspondence with a Bayesian interval that incorporates prior information about the proportion."
  },
  {
    "objectID": "proportion.html#using-a-discrete-prior",
    "href": "proportion.html#using-a-discrete-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.3 Using a Discrete Prior",
    "text": "4.3 Using a Discrete Prior\nOne simple way of incorporating prior information about \\(p\\) is by use of a discrete prior. One makes a list of plausible values \\(p_1, ..., p_k\\) for the proportion and then assigns probabilities \\(P(p_1), ..., P(p_k)\\) to these values. It may be difficult to directly assess the individual prior probabilities, but it may be easier to think about the probability of one proportion value relative to the probabilities of other values. One might first assign a large integer value, say 10, to the value of \\(p\\) that is believed most likely, and then assess the probabilities of the remaining values relative to the probability of the most likely value. Once the relative probabilities are determined, then the probabilities are normalized to obtain the prior probabilities.\nIn the example, suppose one lists the possible values for the proportion of mathematics students with math anxiety displayed in the following table.\n\n\n\n\\(p\\)\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n\n\n\n\nPrior\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose one’s best guess at the proportion of students with math anxiety is \\(p = 0.20\\) so this value is assigned a “prior weight” of 10.\nThe values \\(p = 0.15\\) and \\(p = 0.25\\) are believed to half as likely as \\(p = 0.20\\) so each value is assigned a prior weight of 5. The value \\(p = 0.30\\) is thought to be only 30% as likely as \\(p = 0.20\\) so this proportion value is assigned a weight of 3. Continuing in this fashion, one obtains the table of prior weights for \\(p\\) as shown in Table \\(\\ref{table:priortable}\\). One converts these prior weights to probabilities by dividing each weight by its sum. Since the sum of prior weights is 31, the prior probability of \\(p = 0.5\\) is equal to \\(P(.05) = 1/31 = 0.32\\). The third row of the table display the prior probabilities.\n\n\n\n\\(p\\)\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n\n\n\n\nPrior Weight\n1\n2\n5\n10\n5\n3\n2\n1\n1\n1\n\n\nPrior\n.032\n.065\n.161\n.323\n.161\n.097\n.065\n.032\n.032\n.032\n\n\n\nOnce this prior distribution is assigned, one can compute the posterior probabilities by use of Bayes’ rule. One observes \\(y\\) successes in \\(n\\) trials. The likelihood of \\(p = p_i\\) given this result is given by \\[\nL(p_i) = p_i^y (1- p_i)^{n-y},\n\\] and the posterior probability of \\(p_i\\) will be given (up to a proportionality constant) by multiplying the prior probability by the likelihood. \\[\nP(p_i | {\\rm data}) \\propto P(p_i) L(p_i) = P(p_i)  p_i^y (1- p_i)^{n-y}.\n\\] The following table displays the posterior distribution calculations in the familiar table format. The columns of the table include the values of the proportion, the values of the prior, the likelihoods, and the products of the prior and the likelihood. One normalizes the probabilities by first computing the sum of the products (denoted by SUM in the table), and then dividing each product by this sum.\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\n\\(p_1\\)\n\\(P(p_1)\\)\n\\(p_1^y(1-p_1)^{n-y}\\)\n\\(P(p_1)\\) \\(p_1^y(1-p_1)^{n-y}\\)\n\\(P(p_1)\\) \\(p_1^y(1-p_1)^{n-y}/SUM\\)\\\n\n\n\\(p_2\\)\n\\(P(p_2)\\)\n\\(p_2^y(1-p_2)^{n-y}\\)\n\\(P(p_2)\\) \\(p_2^y(1-p_2)^{n-y}\\)\n\\(P(p_2)\\) \\(p_2^y(1-p_2)^{n-y}/SUM\\) \\\n\n\n–\n–\n–\n–\n–\n\n\n–\n–\n–\n–\n–\n\n\n–\n–\n–\n–\n–\n\n\n\\(p_k\\)\n\\(P(p_k)\\)\n\\(p_k^y(1-p_k)^{n-y}\\)\n\\(P(p_k)\\) \\(p_k^y(1-p_k)^{n-y}\\)\n\\(P(p_k)\\) \\(p_k^y(1-p_k)^{n-y}/SUM\\) \\ \n\n\n–\n–\n–\nSUM\n–\n\n\n\nThe Bayes’ rule calculations are illustrated in the following table for our math anxiety example. For the example, we observed \\(y = 10\\) who had math anxiety in a sample of \\(n = 30\\) and the likelihood is \\(p^{10} (1-p)^{20}\\). The computed values of the likelihood are very small so they have been multiplied by \\(10^{12}\\) in the table to obtain integer values.\n\n\n\n\\(p\\)\nPrior\nLikelihood\nProduct\nPosterior\n\n\n\n\n0.05\n0.032\n0\n0\n0.000\n\n\n0.10\n0.065\n12\n1\n0.000\n\n\n0.15\n0.161\n224\n36\n0.019\n\n\n0.20\n0.323\n1181\n381\n0.200\n\n\n0.25\n0.161\n3024\n487\n0.255\n\n\n0.30\n0.097\n4712\n457\n0.239\n\n\n0.35\n0.065\n5000\n325\n0.170\n\n\n0.40\n0.032\n3834\n123\n0.064\n\n\n0.45\n0.032\n2185\n70\n0.037\n\n\n0.50\n0.032\n931\n30\n0.016\n\n\n\nTo interpret the posterior probabilities, remember that initially we believed that the proportion of math anxiety students was about 0.20, although we were unsure about its true value and the prior was relatively diffuse about \\(p = 0.20\\). The most likely value of \\(p\\) from the posterior distribution is \\(p = 0.25\\). The observed proportion of math anxiety values from the sample is \\(y/n = 10/30 = 0.33\\) and the posterior estimate is a compromise between the sample proportion and the prior mode. We can use the posterior distribution to find an interval estimate for the proportion. Note from the table that the most likely values of \\(p\\) are \\[\np = 0.20, 0.25, 0.30, 0.35\n\\] with total probability \\[\n0.200 + 0.255 + 0.239 + 0.170 = 0.864.\n\\] So the interval (0.20, 0.35) is a 86.4% interval estimate for \\(p\\) – the posterior probability \\[\nP(0.20 \\le p \\le 0.35| {\\rm data}) = 0.864.\n\\]"
  },
  {
    "objectID": "proportion.html#using-a-noninformative-prior",
    "href": "proportion.html#using-a-noninformative-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.4 Using a Noninformative Prior",
    "text": "4.4 Using a Noninformative Prior\nThere are some advantages to using a discrete prior for a proportion. It provides a starting point for finding a prior distribution that reflects one’s knowledge, before sampling, about the location of the proportion. Also it is easy to summarize a discrete posterior distribution. But since the proportion \\(p\\) is a continuous parameter, one’s prior should be a continuous distribution on the interval from 0 to 1.\nFirst, suppose one has little knowledge about the location of the proportion. In our example, suppose that one has little information about the proportion of students in the class who have math anxiety. How can one construct a prior distribution that reflects little or imprecise knowledge about the location of the parameter? This type of distribution is called a noninformative prior or ignorance prior. Using this type of prior, the posterior distribution will typically be more influenced by the data than the prior information.\nOne possible choice for a noninformative prior assumes that \\(p\\) has a uniform distribution \\[\ng(p) = 1, 0 < p < 1.\n\\] This distribution implies that every subset of \\(p\\) of a given length has the same probability.\nIf we observe \\(y\\) successes in \\(n\\) trials, we wish to find the posterior density of \\(p\\), the density of the proportion conditional on \\(y\\). By Bayes’ rule, this density is given by \\[\ng(p | y) = \\frac{f(y | p) g(p)}{\\int_0^1 f(y | p) g(p) dp} \\propto f(y|p) g(p),\n\\] which gives the familiar POSTERIOR \\(\\propto\\) LIKELIHOOD \\(\\times\\) PRIOR recipe.\nIf we use a uniform prior for \\(p\\), then the posterior density is given by \\[\ng(p | y) \\propto p^y (1-p)^{n-y}, \\, 0 < p < 1.\n\\] If we view this function as a function of the proportion \\(p\\) where \\(y\\) and \\(n\\) are fixed, then we recognize this density as a beta density of the form \\[\ng(p | y) = \\frac{1}{B(a^*, b^*)} p^{a^* - 1} (1-p)^{b^*-1}, \\, 0 < p < 1,\n\\] where \\(a = y+1\\) and \\(b = n - y + 1\\)"
  },
  {
    "objectID": "proportion.html#using-a-conjugate-prior",
    "href": "proportion.html#using-a-conjugate-prior",
    "title": "4  Learning About a Proportion",
    "section": "4.5 Using a Conjugate Prior",
    "text": "4.5 Using a Conjugate Prior\nIn many situations, the use of noninformative priors is appropriate since the user does not have any knowledge about the parameter from previous experience. But in other situations such as the math anxiety example, the user does have knowledge about the unknown proportion before sampling and one wishes to construct a continuous prior on the unit interval that represents this prior knowledge.\nOne convenient family of prior distributions is the beta family with shape parameters \\(a\\) and \\(b\\): \\[\ng(p) = \\frac{1}{B(a, b)} p^{a - 1} (1-p)^{b-1}, \\, 0 < p < 1.\n\\] As demonstrated by the graphs in Figure ???, the beta family can have many shapes and can reflect a variety of information about the proportion \\(p\\). In practice, one chooses the parameters \\(a\\) and \\(b\\) that matches one’s beliefs about the proportion.\nOne way of assessing values of \\(a\\) and \\(b\\) is to guess at the values of the prior mean and variance of \\(p\\). Suppose these guesses are \\(M\\) and \\(V\\), respectively. The prior mean and standard deviation of a beta(\\(a, b\\)) distribution are \\(a/(a+b)\\) and \\(ab/(a+b)^2/(a+b+1)\\). Then by solving the equations\n\\[\nM  = \\frac{a}{a+b},  \\, \\,     \n   V  =  \\frac{a b}{(a+b)^2 (a+b+1)}\n\\]\nfor \\(a\\) and \\(b\\), one obtains the beta prior distribution. The problem with this method is that it may be difficult for a user to specify the prior moments of the distribution since moments can be affected by the shape or tail behavior of the distribution which may be unknown.\nAn alternative approach is to assess the parameters \\(a\\) and \\(b\\) indirectly through the specification of prior quantiles. In our example, suppose that the user believes that the median of the prior for the proportion of students is \\(q_0.5 = 0.23\\). This means that he/she believes that the proportion is equally likely to be smaller or larger than 0.23. Then the user makes a statement about the sureness of this guess at the median by the statement about a second quantile. Suppose the user says that he/she is 90% confident that the proportion \\(p\\) is less than 0.38. So the prior information is given by \\[\nP(p < 0.23) = 0.50, \\, \\, P(p < 0.38) = 0.90.\n\\] By use of a program such as the function beta.select() in the LearnBayes package, one matches these prior quantiles with the beta parameters \\(a = 4.0, b = 12.5\\).\nOnce one assesses the values of the beta parameters, it is easy to compute the posterior distribution. By multiplying the prior and the likelihood, one obtains that the posterior density of \\(p\\) is proportional to \\[\ng(p | y)  \\propto  L(p) g(p)  \n\\] \\[\n       =  p^y (1-p)^{n-y} \\times p^{a-1} (1-p)^{b-1}\n\\] \\[\n       =  p^{a + y -1} (1-p)^{b + n - y -1},\n\\]\nwhich we recognize as a beta density with updated parameters \\(a^* = a + y\\) and \\(b^* = b + n - y\\). We say that the beta density is a conjugate prior density since the prior and posterior have the same functional form.\nIn our example, if our prior is beta(4.0, 12.5) and we have \\(y = 10\\) math anxious students in a sample of \\(n = 30\\), then the posterior distribution is beta(4.0 + 10, 12.5 + 20) or beta( 14.0, 32.5)."
  },
  {
    "objectID": "proportion.html#inference",
    "href": "proportion.html#inference",
    "title": "4  Learning About a Proportion",
    "section": "4.6 Inference",
    "text": "4.6 Inference\nAfter one observes data, then all knowledge about the parameter is contained in the posterior distribution. It is common to simply display the posterior density and the reader can learn about the location and spread by simply looking at this curve. To obtain different types of statistical inferences, one summarizes the posterior distribution in various ways. We illustrate using the posterior distribution to obtain point and interval estimates of the parameter.\n\n4.6.1 Point Inference\nA suitable point estimate of a parameter is a single-number summary of the posterior density. The posterior mean is the mean of the posterior distribution given by the integral \\[\nE(p | y) = \\int p \\, g(p | y) dp.\n\\] The posterior median is the median of the posterior distribution, the value \\(p_{0.5}\\) such that the proportion is equally likely to be smaller or larger than \\(p\\). \\[\nP(p < p_{0.5}) = 0.5.\n\\] The posterior mode is the value \\(\\hat p\\) where the posterior density is maximized: \\[\ng(\\hat p | y) = \\max_p g(p | y).\n\\]\nIn the case where a beta(\\(a, b\\)) prior is assigned to a proportion \\(p\\), the posterior distribution is also in the beta family with updated parameters \\(a^* = a + y\\) and \\(b^* = b + n - y\\). The posterior mean of \\(p\\) is the mean of the beta density \\[\nE(p | y) = \\frac{a^*}{a^*+b^*} = \\frac{y + a}{n + a + b}.\n\\] The posterior median \\(p_M\\) is the 0.5 fractile of the beta curve. It is not expressible in closed form, but is easily available by use of software. The posterior mode is found by finding the value of \\(p\\) that maximizes the density \\(p^{a^*-1} (1-p)^{b^*-1}\\). A straightforward calculation shows the posterior mode is \\[\n\\hat p = \\frac{a^*-1}{a^*+b^*-2}.\n\\] For our example, our posterior density is beta(14.0, 32.5). The posterior mean is given by \\(E(p | y) = 14.0/(14.0 + 32.5) = 0.301\\). By use of the R command qbeta, the posterior median is found to be \\(p_M = 0.298\\), and the posterior mode is \\(\\hat p = (14.0 -1 )/(14.0 + 32.5 - 2) = 0.292\\).\nIn the case where the posterior density is approximately symmetric, as in this example, the posterior mean, posterior median, and posterior mode will be approximately equal. In other situations where the posterior density is right or left skewed, these summary values can be different. One nice feature of the posterior median is its clear interpretation as the value that divides the posterior probability in half.\n\n\n4.6.2 Interval Estimation\nTypically, a point estimate such as a posterior median is insufficient for understanding the location of a parameter. A Bayesian interval estimate or credible interval is an interval that contains the parameter with a given probability. Specifically, a \\(100 (1-\\gamma)\\) percent credible interval is any interval \\((a, b)\\) such that \\[\nP( a < p < b) = \\gamma.\n\\] There are many intervals that contain \\(100 (1-\\gamma)\\) percent of the posterior probability. A convenient estimate is an equal-tail interval estimate whose endpoints are the \\(\\gamma/2\\) and \\(1-\\gamma/2\\) quantiles of the posterior distribution. \\[\n(p_{\\gamma/2}, p_{1-\\gamma/2}).\n\\] An alternative is the highest posterior density interval or HPD interval which is the shortest interval that contains this probability content.\nIn our example, the posterior for \\(p\\) was beta(14.0, 32.5). If we wish to construct a 90% interval estimate, then one possible interval would be (0, \\(p_{.90}\\)) = (0, 0.389) and another would be \\((p_{.10}, 1) = (0.217, 1)\\). These would be undesirable intervals since they both would have long widths. The equal-tail interval would be formed from the 5th and 95th percentiles that is equal to (0.197, 0.415). Using the function hpd in the TeachingDemos package, one computes the HPD interval (0.191, 0.409). Since the posterior density is approximately symmetric, the equal-tail and HPD intervals are approximately equal.\n\n\n4.6.3 Estimation of Probabilities\nOne attractive feature of the Bayesian approach is that one can see if the parameter falls in different regions by simply computing the posterior probabilities of these regions. In the math anxiety example, suppose we are interested in the plausibility that the proportion falls in the intervals (0, 0.2), (0.2, 0.4), (0.4, 0.6), (0.6, 0.8), (0.8, 1). The posterior distribution for the proportion of math anxious students is beta(14.0, 32.5) and by use of the R pbeta command, we can compute the probabilities of these regions and these probabilities are displayed in Table \\(\\ref{table:postprobs}\\). Is it likely that the proportion of math anxious students is larger than 0.4? The answer would be no, since the posterior probability that \\(p > 0.4\\) is only 0.08. We see from this table that it is very likely that the proportion falls between 0.4 and 0.6.\n\n\n\nInterval\nPosterior Probability\n\n\n\n\n(0, 0.2)\n0.06\n\n\n(0.2, 0.4)\n0.87\n\n\n(0.4, 0.6)\n0.08\n\n\n(0.6, 0.8)\n0.00\n\n\n(0.8, 1.0)\n0.00"
  },
  {
    "objectID": "proportion.html#using-alternative-priors",
    "href": "proportion.html#using-alternative-priors",
    "title": "4  Learning About a Proportion",
    "section": "4.7 Using Alternative Priors",
    "text": "4.7 Using Alternative Priors\nThe choice of a beta prior is made by convenience. By use of a beta prior, the posterior has the same functional (beta) form and it is easy to summarize the posterior distribution. But Bayes’ rule can be applied for any continuous prior density of \\(p\\) on the unit interval. We illustrate this point by using an alternative density for the proportion based on prior beliefs about the logit proportion.\nIn some situations, one may have prior beliefs about the logit of \\(p\\) defined by \\[\n\\theta = \\log \\frac{p}{1-p}.\n\\] Suppose that one believes, before sampling, that \\(\\theta\\) is normally distributed with mean \\(\\mu = -1.21\\) and standard deviation \\(\\tau = 0.55\\). By transforming the logit \\(\\theta\\) to \\(p\\) by \\[\np = \\frac{\\exp(\\theta)}{1+\\exp(\\theta)},\n\\] one can show that the induced prior on \\(p\\) is given by \\[\ng(p) = \\phi(\\log \\frac{p}{1-p}; \\mu, \\tau) \\frac{1}{p(1-p)}, \\, \\, 0 < p < 1,\n\\] where \\(\\phi(x; \\mu, \\tau)\\) is the normal density with mean \\(\\mu\\) and standard deviation \\(\\tau\\).\nAs before, the likelihood function is \\(L(p) = p^y (1-p)^{n-y}\\), where \\(n = 30\\) and \\(y = 10\\). By using the “prior times likelihood” recipe, the posterior density of \\(p\\) is given by \\[\ng(p | y) \\propto L(p) g(p) = \\left(p^y (1-p)^{n-y}\\right) \\times \\left( \\phi(\\log \\frac{p}{1-p}; \\mu, \\tau) \\frac{1}{p(1-p)} \\right).\n\\]\nIn this situation, we no longer have a conjugate analysis, since the prior and posterior densities have different functional forms. Moreover, the posterior has a functional form that we do not recognize as a member of a familiar family such as the beta. However, this just means that we will need alternative tools to summarize the posterior distribution to perform inferences."
  },
  {
    "objectID": "proportion.html#prediction",
    "href": "proportion.html#prediction",
    "title": "4  Learning About a Proportion",
    "section": "4.8 Prediction",
    "text": "4.8 Prediction\nIn this chapter, we have focused on the use of the posterior distribution to make inferences about the proportion \\(p\\). It is also possible to learn about the plausibility of future outcomes by inspection of the predictive distribution. In our math anxiety example, suppose we administer the exam to a new sample of 30 students. How many students in the new sample will be math anxious?\nLet \\(y^*\\) denote the number of math anxious students in a future sample of size \\(n^*\\). Conditional on \\(p\\), the distribution of \\(y^*\\) will be binomial(\\(n^*, p\\)). If our current beliefs about the proportion are represented by the density \\(g(p)\\), then the predictive density of \\(y^*\\) will be given by the integral\n\\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 f(y^*|p) g(p) dp \\nonumber \\\\\n       =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} g(p) dp.  \\nonumber \\\\\n\\end{eqnarray*}\\]\nSuppose we assign \\(p\\) a uniform prior; that is, \\(g(p) = 1\\). If we substitute this prior for \\(g(p)\\), then the predictive density is given by \\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} dp. \\nonumber \\\\\n       =  {n^* \\choose y^*} B(y^*+1, B(n^* - y^*+1)  \\nonumber \\\\\n       =  \\frac{1}{n^*+1}. \\nonumber \\\\\n\\end{eqnarray*}\\] If we use a uniform prior, then each of the \\(n^*+1\\) possible values of \\(y^*\\) are equally likely.\nSuppose our current knowledge about the proportion is contained in a beta(\\(a, b\\)) density. Then the predictive density is given by \\[\\begin{eqnarray*}\nf(y^*)  =  \\int_0^1 {n^* \\choose y^*} p^{y^*} (1-p)^{n^*-y^*} \\frac{1}{B(a, b)} p^{a-1}(1-p)^{b-1} dp  \\nonumber \\\\\n       =  {n^* \\choose y^*}  \\frac{B(a + y^*, b + n^* - y^*)}{B(a, b)}, y^* = 0, ..., n^*. \\nonumber \\\\\n\\end{eqnarray*}\\] This is called a beta-binomial density since it is a mixture of binomial densities, where the proportion \\(p\\) follows a beta density.\nIn our example, after observing the sample, the beliefs about the proportion of math anxious students is represented by a beta(14.0, 32.5) distribution. By use of the R function pbetap(), one can compute the predictive density for the number of math anxious students in a future sample of \\(n^* = 30\\). The figure shows that there is a sizable variation in \\(y^*\\); a 90% prediction interval for \\(y^*\\) is given by {4, 5, …, 13, 15}. Why is the prediction interval so wide? There are two sources of variability in prediction. First, there is uncertainty about the proportion of math anxious students \\(p\\) as reflected in the posterior density \\(g\\), and there is uncertainty in the number of anxious students \\(y^*\\) for a fixed value of \\(p\\) as reflected in the sampling density \\(f\\). The prediction distribution incorporates both types of uncertainty and therefore results in a relatively wide prediction interval estimate."
  }
]